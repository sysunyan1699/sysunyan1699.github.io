
<!DOCTYPE html><html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.28.1" theme-name="Stellar" theme-version="1.28.1">
  
  <meta name="generator" content="Hexo 7.2.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f9fafb">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  
  <title>The Unreasonable Effectiveness of Recurrent Neural Networks - Sun Yan</title>

  
    <meta name="description" content="Andrej Karpathy blog:# The Unreasonable Effectiveness of Recurrent Neural Networks There’s something magical about Recurrent Neural Networks (RNNs). I still remember when I trained my first recurrent">
<meta property="og:type" content="article">
<meta property="og:title" content="The Unreasonable Effectiveness of Recurrent Neural Networks">
<meta property="og:url" content="http://example.com/2472be8a/index.html">
<meta property="og:site_name" content="Sun Yan">
<meta property="og:description" content="Andrej Karpathy blog:# The Unreasonable Effectiveness of Recurrent Neural Networks There’s something magical about Recurrent Neural Networks (RNNs). I still remember when I trained my first recurrent">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2472be8a/1.png">
<meta property="og:image" content="https://karpathy.github.io/assets/rnn/house_read.gif">
<meta property="og:image" content="https://karpathy.github.io/assets/rnn/house_generate.gif">
<meta property="og:image" content="http://example.com/2472be8a/2.png">
<meta property="og:image" content="http://example.com/2472be8a/3.png">
<meta property="og:image" content="http://example.com/2472be8a/4.png">
<meta property="og:image" content="http://example.com/2472be8a/5.png">
<meta property="og:image" content="http://example.com/2472be8a/6.png">
<meta property="og:image" content="http://example.com/2472be8a/7.png">
<meta property="og:image" content="http://example.com/2472be8a/8.png">
<meta property="og:image" content="http://example.com/2472be8a/9.png">
<meta property="og:image" content="http://example.com/2472be8a/10.png">
<meta property="article:published_time" content="2024-06-11T09:59:43.000Z">
<meta property="article:modified_time" content="2024-06-16T14:23:22.626Z">
<meta property="article:author" content="Sun Yan">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="Ilya sutskever‘s 30  papers">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2472be8a/1.png">
  
  
  
  <meta name="keywords" content="AI,神经网络,Ilya sutskever‘s 30  papers">

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="Sun Yan" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/main.css?v=1.28.1">

  

  

  
</head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/images/avatar.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Sun Yan</div><div class="sub cap">Backend Developer</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>


<nav class="menu dis-select"></nav>
</div>
<div class="widgets">


<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/d9903cb/"><span class="title">分摊算法</span></a><a class="item title" href="/6cb5dc64/"><span class="title">InnoDB事务-持久性的实现,binglog & redo log</span></a><a class="item title" href="/5b064db6/"><span class="title">Intro to 事务</span></a><a class="item title" href="/d8e12886/"><span class="title">SafeInventory- 如何高效扣减库存</span></a><a class="item title" href="/ca1e509/"><span class="title">SafeInventory-本地事务下，如何安全操作库存</span></a><a class="item title" href="/b36b0ce9/"><span class="title">InnoDB事务-原子性的实现,undo log</span></a><a class="item title" href="/4bd46d7d/"><span class="title">SpringBoot 自动配置实现原理</span></a><a class="item title" href="/a5120d74/"><span class="title">SafeInventory-分布式事务下，如何安全操作库存</span></a><a class="item title" href="/c3915fbe/"><span class="title">如何处理重复请求保证幂等</span></a><a class="item title" href="/2a483461/"><span class="title">在Spring事务管理下，使用Synchronized   为什么会出现并发问题</span></a></div></widget>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/sysunyan1699" target="_blank" rel="external nofollow noopener noreferrer"><img no-lazy src="/images/github.png" / onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="social" href="https://www.linkedin.com/in/yansun1699/" target="_blank" rel="external nofollow noopener noreferrer"><img no-lazy src="/images/LinkedIn.png" / onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="social" href="/sysunyan1699@gmail.com" rel="noopener noreferrer"><img no-lazy src="/images/gmail.png" / onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a></div></footer>
</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">文章</a></div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2024-06-11T09:59:43.000Z">2024-06-11</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2024-06-16T14:23:22.626Z">2024-06-16</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>The Unreasonable Effectiveness of Recurrent Neural Networks</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><p><a target="_blank" rel="noopener" href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">Andrej Karpathy blog:# The Unreasonable Effectiveness of Recurrent Neural Networks</a></p>
<p>There’s something magical about Recurrent Neural Networks (RNNs). I still remember when I trained my first recurrent network for <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/deepimagesent/">Image Captioning</a>. Within a few dozen minutes of training my first baby model (with rather arbitrarily-chosen hyperparameters) started to generate very nice looking descriptions of images that were on the edge of making sense. Sometimes the ratio of how simple your model is to the quality of the results you get out of it blows past your expectations, and this was one of those times. What made this result so shocking at the time was that the common wisdom was that RNNs were supposed to be difficult to train (with more experience I’ve in fact reached the opposite conclusion). Fast forward about a year: I’m training RNNs all the time and I’ve witnessed their power and robustness many times, and yet their magical outputs still find ways of amusing me. This post is about sharing some of that magic with you.<br>循环神经网络（RNN）有其独特的魅力。我还记得第一次训练用于图像描述生成的循环神经网络时的情景。只用了短短几十分钟，即使是随意选择的超参数，这个初步模型已经开始生成看起来非常不错的图像描述，尽管这些描述有时只是勉强合理。有时，模型的简单程度与其输出结果的质量之间的比例会远远超出预期，这次就是一个典型的例子。这次结果如此令人震惊的原因在于，当时的普遍认知是，RNN很难训练（随着经验的增加，我实际上得出了相反的结论）。时间快进大约一年：我一直在训练RNN，目睹了它们的强大和稳健，尽管如此，它们神奇的输出依然能不断带给我惊喜。这篇文章旨在与大家分享这种魔力。</p>
<p>We’ll train RNNs to generate text character by character and ponder the question “how is that even possible?”<br>我们将训练循环神经网络（RNN）逐字符地生成文本，并思考这个问题：“这到底是怎么做到的？”</p>
<p>By the way, together with this post I am also releasing <a target="_blank" rel="noopener" href="https://github.com/karpathy/char-rnn">code on Github</a> that allows you to train character-level language models based on multi-layer LSTMs. You give it a large chunk of text and it will learn to generate text like it one character at a time. You can also use it to reproduce my experiments below. But we’re getting ahead of ourselves; What are RNNs anyway?<br>顺便提一下，与这篇文章一起，我还在Github上发布了代码，这些代码可以用来训练基于多层LSTM的字符级语言模型。你只需提供一大段文本，它就会逐字符地学习生成类似的文本。你还可以使用它来重现我下面的实验。但在此之前，我们还是先回到正题上来：我们先来了解一下RNN到底是什么？</p>
<h1 id="recurrent-neural-networks-递归神经网络"><a href="#Recurrent-Neural-Networks-递归神经网络" class="headerlink" title="Recurrent Neural Networks  递归神经网络"></a>Recurrent Neural Networks  递归神经网络</h1><h2 id="sequences"><a href="#Sequences" class="headerlink" title="Sequences"></a>Sequences</h2><p><strong>Sequences</strong>. Depending on your background you might be wondering: _What makes Recurrent Networks so special_? A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model). The core reason that recurrent nets are more exciting is that they allow us to operate over _sequences_ of vectors: Sequences in the input, the output, or in the most general case both. A few examples may make this more concrete:<br>序列。根据你的背景，你可能会问：循环神经网络有什么特别之处？一个显而易见的限制是Vanilla 神经网络（以及卷积神经网络）的API过于受限：它们接受固定大小的向量作为输入（例如，一张图片），并产生固定大小的向量作为输出（例如，不同类别的概率）。不仅如此，这些模型使用固定数量的计算步骤来完成这个映射（例如，模型中的层数）。循环神经网络更令人兴奋的核心原因在于它们允许我们对向量序列进行操作：输入中的序列，输出中的序列，或者在最一般的情况下，两者都是序列。几个例子可以让这一点更加具体：</p>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/1.png" class>
<p>Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN’s state (more on this soon). From left to right: <strong>(1)</strong> Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). <strong>(2)</strong> Sequence output (e.g. image captioning takes an image and outputs a sentence of words). <strong>(3)</strong> Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). <strong>(4)</strong> Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). <strong>(5)</strong> Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.<br>每个矩形代表一个向量，箭头代表函数（例如矩阵乘法）。输入向量用红色表示，输出向量用蓝色表示，绿色向量表示RNN的状态（稍后会详细说明）。从左到右依次是：</p>
<p><strong>(1)</strong> 普通模式的处理，没有使用RNN，从固定大小的输入到固定大小的输出（例如图像分类）。</p>
<p><strong>(2)</strong> 序列输出（例如图像描述生成，输入一张图片，输出一个单词句子）。</p>
<p><strong>(3)</strong> 序列输入（例如情感分析，将给定的句子分类为表达正面或负面情感）。</p>
<p><strong>(4)</strong> 序列输入和序列输出（例如机器翻译：RNN读取一段英文句子，然后输出一段法文句子）。</p>
<p><strong>(5)</strong> 同步的序列输入和输出（例如视频分类，我们希望对视频的每一帧进行标签）。</p>
<p>注意，在每种情况下，序列长度都没有预先指定的限制，因为循环变换（绿色）是固定的，可以根据需要应用多次。</p>
<p>As you might expect, the sequence regime of operation is much more powerful compared to fixed networks that are doomed from the get-go by a fixed number of computational steps, and hence also much more appealing for those of us who aspire to build more intelligent systems. Moreover, as we’ll see in a bit, RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, RNNs essentially describe programs. In fact, it is known that <a target="_blank" rel="noopener" href="http://binds.cs.umass.edu/papers/1995_Siegelmann_Science.pdf">RNNs are Turing-Complete</a> in the sense that they can to simulate arbitrary programs (with proper weights). But similar to universal approximation theorems for neural nets you shouldn’t read too much into this. In fact, forget I said anything.<br>正如你所预料的那样，相较于受限于固定计算步骤的固定网络，序列操作模式要强大得多，因此对于那些希望构建更智能系统的人来说也更具吸引力。此外，正如我们稍后会看到的，RNN通过固定（但可学习）的函数将输入向量与其状态向量结合，生成一个新的状态向量。这在编程术语中可以理解为运行一个具有特定输入和一些内部变量的固定程序。从这个角度来看，RNN本质上是在描述程序。事实上，RNN被认为是图灵完备的，这意味着它们可以模拟任意程序（在适当的权重下）。但是，与神经网络的通用近似定理类似，你不应该对此过于解读。实际上，忘掉我刚才说的话吧。</p>
<blockquote>
<p>If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.<br>如果说训练普通神经网络是对函数的优化，那么训练循环网络就是对程序的优化。</p>
</blockquote>
<p><strong>Sequential processing in absence of sequences</strong>. You might be thinking that having sequences as inputs or outputs could be relatively rare, but an important point to realize is that even if your inputs/outputs are fixed vectors, it is still possible to use this powerful formalism to _process_ them in a sequential manner. For instance, the figure below shows results from two very nice papers from <a target="_blank" rel="noopener" href="http://deepmind.com/">DeepMind</a>. On the left, an algorithm learns a recurrent network policy that steers its attention around an image; In particular, it learns to read out house numbers from left to right (<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1412.7755">Ba et al.</a>). On the right, a recurrent network _generates_ images of digits by learning to sequentially add color to a canvas (<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1502.04623">Gregor et al.</a>):<br>在没有序列的情况下进行顺序处理。您可能认为将序列作为输入或输出可能相对罕见，但需要意识到的重要一点是，即使你的输入/输出是固定向量，仍然可以使用这种强大的形式主义以顺序方式处理它们。例如，下图显示了 DeepMind 的两篇非常好的论文的结果。在左边，算法学习一个循环网络策略，将其注意力引导到图像周围;特别是，它学会了从左到右读出门牌号（Ba等人）。在右边，一个循环网络通过学习依次向画布添加颜色来生成数字图像：<br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://karpathy.github.io/assets/rnn/house_read.gif" alt> <img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://karpathy.github.io/assets/rnn/house_generate.gif" alt></p>
<p>The takeaway is that even if your data is not in form of sequences, you can still formulate and train powerful models that learn to process it sequentially. You’re learning stateful programs that process your fixed-sized data.<br>要点是，即使你的数据不是以序列形式存在，你仍然可以设计和训练强大的模型，使其学会以顺序方式处理这些数据。你正在学习的是处理固定大小数据的有状态程序。</p>
<h2 id="rnn-computation"><a href="#RNN-computation" class="headerlink" title="RNN computation"></a>RNN computation</h2><p><strong>RNN computation.</strong> So how do these things work? At the core, RNNs have a deceptively simple API: They accept an input vector <code>x</code> and give you an output vector <code>y</code>. However, crucially this output vector’s contents are influenced not only by the input you just fed in, but also on the entire history of inputs you’ve fed in in the past. Written as a class, the RNN’s API consists of a single <code>step</code> function:<br>RNN 计算。那么这些东西是如何工作的呢？在核心上，RNN 有一个看似简单的 API：它们接受一个输入向量 <code>x</code> 并给你一个输出向量 <code>y</code> 。然而，至关重要的是，这个输出向量的内容不仅受到你刚刚输入的输入的影响，还受到你过去输入的整个输入历史的影响。RNN 的 API 编写为一个类，由一个 <code>step</code> 函数组成：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rnn = RNN()</span><br><span class="line">y = rnn.step(x) # x is an input vector, y is the RNN&#x27;s output vector</span><br></pre></td></tr></table></figure><br>The RNN class has some internal state that it gets to update every time <code>step</code> is called. In the simplest case this state consists of a single _hidden_ vector <code>h</code>. Here is an implementation of the step function in a Vanilla RNN:<br>RNN 类具有一些内部状态，每次调用时 <code>step</code> 都会更新。在最简单的情况下，此状态由单个隐藏向量组成 <code>h</code> 。以下是 Vanilla RNN 中 step 函数的实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">class RNN:</span><br><span class="line">  # ...</span><br><span class="line">  def step(self, x):</span><br><span class="line">    # update the hidden state</span><br><span class="line">    self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))</span><br><span class="line">    # compute the output vector</span><br><span class="line">    y = np.dot(self.W_hy, self.h)</span><br><span class="line">    return y</span><br></pre></td></tr></table></figure>
<p>The above specifies the forward pass of a vanilla RNN. This RNN’s parameters are the three matrices <code>W_hh, W_xh, W_hy</code>. The hidden state <code>self.h</code> is initialized with the zero vector. The <code>np.tanh</code> function implements a non-linearity that squashes the activations to the range <code>[-1, 1]</code>. Notice briefly how this works: There are two terms inside of the tanh: one is based on the previous hidden state and one is based on the current input. In numpy <code>np.dot</code> is matrix multiplication. The two intermediates interact with addition, and then get squashed by the tanh into the new state vector. If you’re more comfortable with math notation, we can also write the hidden state update as $ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$, where tanh is applied elementwise.<br>上述内容描述了一个基础RNN的前向传播过程。这个RNN的参数是三个矩阵W_hh、W_xh和W_hy。隐藏状态self.h初始化为零向量。np.tanh函数实现了一种非线性激活函数，将激活值压缩到[-1, 1]范围内。简要说明其工作原理：tanh内部有两个项，一个基于前一个时间步隐藏状态，另一个基于当前时间步输入。在numpy中，np.dot表示矩阵乘法。这两个中间结果通过加法相互作用，然后通过tanh函数压缩为新的状态向量。如果你对数学表示法更熟悉，我们也可以将隐藏状态的更新写成 $ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$，其中tanh逐元素应用。</p>
<p>⚠️：numpy是Python中一个非常流行的数值计算库。np.tanh函数和np.dot函数都是numpy库中的函数。np.tanh函数用于计算元素级的双曲正切，而np.dot函数用于执行矩阵乘法。</p>
<p>We initialize the matrices of the RNN with random numbers and the bulk of work during training goes into finding the matrices that give rise to desirable behavior, as measured with some loss function that expresses your preference to what kinds of outputs $y$ you’d like to see in response to your input sequences $x$.<br>我们用随机数初始化RNN的矩阵，在训练过程中，大部分工作是找到能够产生理想行为的矩阵，这通过某种损失函数来衡量，该损失函数表达了你对输入序列$x$对应输出$y$的期望。</p>
<h2 id="going-deep"><a href="#Going-deep" class="headerlink" title="Going deep"></a>Going deep</h2><p><strong>Going deep</strong>. RNNs are neural networks and everything works monotonically better (if done right) if you put on your deep learning hat and start stacking models up like pancakes. For instance, we can form a 2-layer recurrent network as follows:<br>深入研究。RNN是神经网络的一种，如果方法得当，采用深度学习的方法并像叠煎饼一样将模型堆叠起来，一切都会单调地变得更好。例如，我们可以如下构建一个两层的循环神经网络：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y1 = rnn1.step(x)</span><br><span class="line">y = rnn2.step(y1)</span><br></pre></td></tr></table></figure></p>
<p>In other words we have two separate RNNs: One RNN is receiving the input vectors and the second RNN is receiving the output of the first RNN as its input. Except neither of these RNNs know or care - it’s all just vectors coming in and going out, and some gradients flowing through each module during backpropagation.<br>换句话说，我们有两个独立的 RNN：一个 RNN 接收输入向量，第二个 RNN 接收第一个 RNN 的输出作为其输入。除了这些 RNN 都不知道或不关心之外——它们都只是进出的向量，以及在反向传播过程中流过每个模块的一些梯度。</p>
<h2 id="getting-fancy"><a href="#Getting-fancy" class="headerlink" title="Getting fancy"></a>Getting fancy</h2><p><strong>Getting fancy</strong>. I’d like to briefly mention that in practice most of us use a slightly different formulation than what I presented above called a _Long Short-Term Memory_ (LSTM) network. The LSTM is a particular type of recurrent network that works slightly better in practice, owing to its more powerful update equation and some appealing backpropagation dynamics. I won’t go into details, but everything I’ve said about RNNs stays exactly the same, except the mathematical form for computing the update (the line <code>self.h = ...</code> ) gets a little more complicated. From here on I will use the terms “RNN/LSTM” interchangeably but all experiments in this post use an LSTM.<br>更复杂的模型。在实践中，我们大多数人使用的公式与我上面提到的稍有不同，被称为长短期记忆网络（LSTM）。LSTM是一种特定类型的循环神经网络，实际上效果更好，因为它具有更强大的更新方程和一些更具吸引力的反向传播动态。我不会深入讨论细节，但我所说的关于RNN的一切都完全相同，除了计算更新的数学形式（即self.h = …这一行）变得稍微复杂了一些。从现在开始，我会交替使用“RNN/LSTM”这两个术语，但本文中的所有实验都使用LSTM。</p>
<h1 id="character-level-language-models"><a href="#Character-Level-Language-Models" class="headerlink" title="Character-Level Language Models"></a>Character-Level Language Models</h1><p>字符级语言模型</p>
<p>Okay, so we have an idea about what RNNs are, why they are super exciting, and how they work. We’ll now ground this in a fun application: We’ll train RNN character-level language models. That is, we’ll give the RNN a huge chunk of text and ask it to model the probability distribution of the next character in the sequence given a sequence of previous characters. This will then allow us to generate new text one character at a time.<br>好的，所以我们已经对RNN是什么、为什么它们非常令人兴奋以及它们如何工作有了一定的了解。现在，我们将把这些知识应用到一个有趣的实际应用中：我们将训练RNN字符级别的语言模型。也就是说，我们会给RNN提供一大段文本，并让它根据前面字符的序列来建模下一个字符的概率分布。这样一来，我们就可以一次生成一个字符的新文本。</p>
<p>As a working example, suppose we only had a vocabulary of four possible letters “helo”, and wanted to train an RNN on the training sequence “hello”. This training sequence is in fact a source of 4 separate training examples: 1. The probability of “e” should be likely given the context of “h”, 2. “l” should be likely in the context of “he”, 3. “l” should also be likely given the context of “hel”, and finally 4. “o” should be likely given the context of “hell”.<br>作为一个实际例子，假设我们只有四个可能的字母“helo”的词汇表，并且想要在训练序列“hello”上训练一个RNN。这个训练序列实际上是四个独立的训练示例的来源：</p>
<ol>
<li>在“h”的上下文中，“e”的概率应该很大。</li>
<li>在“he”的上下文中，“l”的概率应该很大。</li>
<li>在“hel”的上下文中，“l”的概率也应该很大。</li>
<li>最后，在“hell”的上下文中，“o”的概率应该很大。</li>
</ol>
<p>Concretely, we will encode each character into a vector using 1-of-k encoding (i.e. all zero except for a single one at the index of the character in the vocabulary), and feed them into the RNN one at a time with the <code>step</code> function. We will then observe a sequence of 4-dimensional output vectors (one dimension per character), which we interpret as the confidence the RNN currently assigns to each character coming next in the sequence. Here’s a diagram:<br>具体来说，我们将使用1-of-k编码将每个字符编码成一个向量（即，除了在词汇表中字符索引处为1，其余全为0），然后用step函数将它们逐一输入RNN。随后，我们会得到一系列4维输出向量（每个字符一个维度），我们将这些输出向量解释为RNN当前对序列中下一个字符的置信度。以下是一个示意图：</p>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/2.png" class>
<p>An example RNN with 4-dimensional input and output layers, and a hidden layer of 3 units (neurons). This diagram shows the activations in the forward pass when the RNN is fed the characters “hell” as input. The output layer contains confidences the RNN assigns for the next character (vocabulary is “h,e,l,o”); We want the green numbers to be high and red numbers to be low.<br>具有 4 维输入和输出层的示例 RNN，以及 3 个单元（神经元）的隐藏层。此图显示了将字符“hell”作为输入馈送 RNN 时前向传递中的激活。输出层包含 RNN 为下一个字符分配的置信度（词汇为“h，e，l，o”）;我们希望绿色数字高，红色数字低。</p>
<p>⚠️： W_xh 指输入层和隐藏层之间的权重矩阵， W_hh 指隐藏层之间的权重矩阵， W_hy 指隐藏层和输出层之间的权重矩阵</p>
<p>For example, we see that in the first time step when the RNN saw the character “h” it assigned confidence of 1.0 to the next letter being “h”, 2.2 to letter “e”, -3.0 to “l”, and 4.1 to “o”. Since in our training data (the string “hello”) the next correct character is “e”, we would like to increase its confidence (green) and decrease the confidence of all other letters (red). Similarly, we have a desired target character at every one of the 4 time steps that we’d like the network to assign a greater confidence to. Since the RNN consists entirely of differentiable operations we can run the backpropagation algorithm (this is just a recursive application of the chain rule from calculus) to figure out in what direction we should adjust every one of its weights to increase the scores of the correct targets (green bold numbers). We can then perform a _parameter update_, which nudges every weight a tiny amount in this gradient direction. If we were to feed the same inputs to the RNN after the parameter update we would find that the scores of the correct characters (e.g. “e” in the first time step) would be slightly higher (e.g. 2.3 instead of 2.2), and the scores of incorrect characters would be slightly lower. We then repeat this process over and over many times until the network converges and its predictions are eventually consistent with the training data in that correct characters are always predicted next.<br>例如，我们看到在第一个时间步中，当RNN看到字符“h”时，它对下一个字符的置信度分配为：字符“h”是1.0，字符“e”是2.2，字符“l”是-3.0，字符“o”是4.1。由于在我们的训练数据（字符串“hello”）中，下一个正确字符是“e”，我们希望增加“e”的置信度（用绿色表示），并降低所有其他字符的置信度（用红色表示）。类似地，在每一个时间步上，我们都有一个期望的目标字符，希望网络能对其分配更高的置信度。由于RNN完全由可微操作组成，我们可以运行反向传播算法（这只是微积分中链式法则的递归应用）来确定应调整每个权重的方向，以提高正确目标的得分（绿色加粗数字）。然后，我们可以执行参数更新，将每个权重在该梯度方向上微调一个小量。如果在参数更新后再次将相同的输入提供给RNN，我们会发现正确字符的得分（例如，第一个时间步中的“e”）会略有提高（例如，从2.2提高到2.3），而错误字符的得分会略有降低。然后，我们反复进行这个过程多次，直到网络收敛，其预测最终与训练数据一致，即总是预测出正确的下一个字符。</p>
<p>⚠️：图中output 层 数字并不是置信度，而是logits, 这些logits并不直接表示概率/置信度,要将这些logits转化为概率（置信度），我们通常使用Softmax函数。</p>
<p>A more technical explanation is that we use the standard Softmax classifier (also commonly referred to as the cross-entropy loss) on every output vector simultaneously. The RNN is trained with mini-batch Stochastic Gradient Descent and I like to use <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1502.04390">RMSProp</a> or Adam (per-parameter adaptive learning rate methods) to stablilize the updates.<br>更技术性的解释是，我们在每个输出向量上 同时使用标准的Softmax分类器（也常被称为交叉熵损失）。RNN使用小批量随机梯度下降法进行训练，我喜欢使用RMSProp或Adam（每个参数的自适应学习率方法）来稳定更新。</p>
<p>Notice also that the first time the character “l” is input, the target is “l”, but the second time the target is “o”. The RNN therefore cannot rely on the input alone and must use its recurrent connection to keep track of the context to achieve this task.<br>另请注意，第一次输入字符“l”时，目标是“l”，但第二次目标是“o”。因此，RNN 不能单独依赖输入，必须使用其循环连接来跟踪上下文以实现此任务。</p>
<p>At <strong>test time</strong>, we feed a character into the RNN and get a distribution over what characters are likely to come next. We sample from this distribution, and feed it right back in to get the next letter. Repeat this process and you’re sampling text! Lets now train an RNN on different datasets and see what happens.<br>在测试时，我们将一个字符输入RNN，并获得下一个字符可能出现的概率分布。我们从这个分布中采样，并将采样得到的字符再次输入RNN以获取下一个字符。重复这个过程，就可以生成文本了！现在，让我们在不同的数据集上训练一个RNN，看看会发生什么。</p>
<p>To further clarify, for educational purposes I also wrote a <a target="_blank" rel="noopener" href="https://gist.github.com/karpathy/d4dee566867f8291f086">minimal character-level RNN language model in Python/numpy</a>. It is only about 100 lines long and hopefully it gives a concise, concrete and useful summary of the above if you’re better at reading code than text. We’ll now dive into example results, produced with the much more efficient Lua/Torch codebase.<br>为了进一步说明，我还用Python和numpy编写了一个最小的字符级RNN语言模型。它只有大约100行代码，希望能为你提供一个简洁、具体且有用的总结，如果你更擅长阅读代码而不是文字。现在，我们将深入探讨使用更加高效的Lua/Torch代码库生成的示例结果。</p>
<h1 id="fun-with-rnns"><a href="#Fun-with-RNNs" class="headerlink" title="Fun with RNNs"></a>Fun with RNNs</h1><p>All 5 example character models below were trained with the <a target="_blank" rel="noopener" href="https://github.com/karpathy/char-rnn">code</a> I’m releasing on Github. The input in each case is a single file with some text, and we’re training an RNN to predict the next character in the sequence.<br>下面的所有 5 个示例字符模型都是使用我在 Github 上发布的代码训练的。每种情况下的输入都是一个包含一些文本的单个文件，我们正在训练一个 RNN 来预测序列中的下一个字符。</p>
<h3 id="paul-graham-generator-保罗格雷厄姆发电机"><a href="#Paul-Graham-generator-保罗·格雷厄姆发电机" class="headerlink" title="Paul Graham generator 保罗·格雷厄姆发电机"></a>Paul Graham generator 保罗·格雷厄姆发电机</h3><p>Lets first try a small dataset of English as a sanity check. My favorite fun dataset is the concatenation of <a target="_blank" rel="noopener" href="http://www.paulgraham.com/articles.html">Paul Graham’s essays</a>. The basic idea is that there’s a lot of wisdom in these essays, but unfortunately Paul Graham is a relatively slow generator. Wouldn’t it be great if we could sample startup wisdom on demand? That’s where an RNN comes in.<br>让我们首先尝试一个小型的英文数据集来进行基本检查。我最喜欢的有趣数据集是保罗·格雷厄姆（Paul Graham）的文章合集。基本想法是，这些文章中有很多智慧，但遗憾的是，保罗·格雷厄姆的写作速度相对较慢。如果我们能按需采样创业智慧，那不是很棒吗？这正是RNN的用武之地。</p>
<p>Concatenating all pg essays over the last ~5 years we get approximately 1MB text file, or about 1 million characters (this is considered a very small dataset by the way). _Technical:_ Lets train a 2-layer LSTM with 512 hidden nodes (approx. 3.5 million parameters), and with dropout of 0.5 after each layer. We’ll train with batches of 100 examples and truncated backpropagation through time of length 100 characters. With these settings one batch on a TITAN Z GPU takes about 0.46 seconds (this can be cut in half with 50 character BPTT at negligible cost in performance). Without further ado, lets see a sample from the RNN:<br>将过去大约5年间的所有保罗·格雷厄姆的文章合并起来，我们得到了一个大约1MB的文本文件，约100万个字符（顺便说一下，这被认为是一个非常小的数据集）。技术细节：让我们训练一个具有2层、每层512个隐藏节点的LSTM（大约350万个参数），并在每层之后使用0.5的dropout。我们将使用100个样本的批次和长度为100字符的截断时间反向传播进行训练。在这些设置下，在TITAN Z GPU上处理一个批次大约需要0.46秒（使用50字符的截断时间反向传播，几乎不会影响性能，可以将时间减半）。事不宜迟，让我们看看RNN生成的一个样本：</p>
<p>_“The surprised in investors weren’t going to raise money. I’m not the company with the time there are all interesting quickly, don’t have to get off the same programmers. There’s a super-angel round fundraising, why do you can do. If you have a different physical investment are become in people who reduced in a startup with the way to argument the acquirer could see them just that you’re also the founders will part of users’ affords that and an alternation to the idea. [2] Don’t work at first member to see the way kids will seem in advance of a bad successful startup. And if you have to act the big company too.”_<br>_“投资者的惊讶是，他们并不打算筹集资金。我不是那个有时间的公司，有趣的事情很快就会出现，不需要让相同的程序员离开。有一个超级天使轮的融资，你为什么要这样做。如果你有不同的实体投资，会成为那些在初创公司里减少的人中争论的方式，收购者可能会看到他们只是创始人将成为用户努力的一部分，这是对想法的一种替代。[2] 一开始不要在成员身上工作，看孩子们将如何提前在一个失败的成功初创公司中表现出来。而且，如果你必须行动，那么大公司也一样。”_</p>
<p>Okay, clearly the above is unfortunately not going to replace Paul Graham anytime soon, but remember that the RNN had to learn English completely from scratch and with a small dataset (including where you put commas, apostrophes and spaces). I also like that it learns to support its own arguments (e.g. [2], above). Sometimes it says something that offers a glimmer of insight, such as _“a company is a meeting to think to investors”_. <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/char-rnn/pg.txt">Here’s</a> a link to 50K character sample if you’d like to see more.<br>好的，很明显，以上内容暂时还无法替代保罗·格雷厄姆，但请记住，RNN必须从零开始学习英语，而且是用一个小数据集（包括逗号、撇号和空格的位置）。我也喜欢它学会了支持自己的论点（例如，上文中的[2]）。有时，它会说出一些略带启发性的话，比如“a company is a meeting to think to investors”（公司是与投资者思考的会议）。如果你想查看更多，这里有一个50K字符的样本链接。</p>
<p><strong>Temperature.</strong> We can also play with the temperature of the Softmax during sampling. Decreasing the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, etc). In particular, setting temperature very near zero will give the most likely thing that Paul Graham might say:<br>温度。我们也可以在采样过程中调整Softmax的温度。将温度从1降低到某个较低的数值（例如0.5），会使RNN更有信心，但也更保守于其采样结果。相反，较高的温度会带来更多的多样性，但代价是会有更多的错误（例如拼写错误等）。特别是，将温度设置得非常接近零，会产生最有可能是保罗·格雷厄姆会说的话：</p>
<p>_“is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same”<br>“他们都是一样的，创业公司是，他们都是创业公司，他们都是一样的创业公司，他们都是一样的，创业公司是一样的”_</p>
<p>looks like we’ve reached an infinite loop about startups.<br>看起来我们已经达到了一个关于初创公司的无限循环。</p>
<h3 id="shakespeare-莎士比亚"><a href="#Shakespeare-莎士比亚" class="headerlink" title="Shakespeare 莎士比亚"></a>Shakespeare 莎士比亚</h3><p>It looks like we can learn to spell English words. But how about if there is more structure and style in the data? To examine this I downloaded all the works of Shakespeare and concatenated them into a single (4.4MB) file. We can now afford to train a larger network, in this case lets try a 3-layer RNN with 512 hidden nodes on each layer. After we train the network for a few hours we obtain samples such as:<br>看起来我们可以学会拼写英语单词。但如果数据中有更多的结构和风格呢？为此，我下载了莎士比亚的所有作品，并将它们合并成一个单一的（4.4MB）文件。我们现在有能力训练一个更大的网络，在这种情况下，让我们尝试一个3层的RNN，每层有512个隐藏节点。经过几个小时的训练，我们得到如下样本：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">PANDARUS:</span><br><span class="line">Alas, I think he shall be come approached and the day</span><br><span class="line">When little srain would be attain&#x27;d into being never fed,</span><br><span class="line">And who is but a chain and subjects of his death,</span><br><span class="line">I should not sleep.</span><br><span class="line"></span><br><span class="line">Second Senator:</span><br><span class="line">They are away this miseries, produced upon my soul,</span><br><span class="line">Breaking and strongly should be buried, when I perish</span><br><span class="line">The earth and thoughts of many states.</span><br><span class="line"></span><br><span class="line">DUKE VINCENTIO:</span><br><span class="line">Well, your wit is in the care of side and that.</span><br><span class="line"></span><br><span class="line">Second Lord:</span><br><span class="line">They would be ruled after this chamber, and</span><br><span class="line">my fair nues begun out of the fact, to be conveyed,</span><br><span class="line">Whose noble souls I&#x27;ll have the heart of the wars.</span><br><span class="line"></span><br><span class="line">Clown:</span><br><span class="line">Come, sir, I will make did behold your worship.</span><br><span class="line"></span><br><span class="line">VIOLA:</span><br><span class="line">I&#x27;ll drink it.</span><br></pre></td></tr></table></figure></p>
<p>Remember, all the RNN knows are characters, so in particular it samples both speaker’s names and the contents. Sometimes we also get relatively extented monologue passages, such as:<br>请记住，RNN所知道的只有字符，因此它既采样说话者的名字，也采样内容。有时我们还会得到相对较长的独白段落，例如：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">VIOLA:</span><br><span class="line">Why, Salisbury must find his flesh and thought</span><br><span class="line">That which I am not aps, not a man and in fire,</span><br><span class="line">To show the reining of the raven and the wars</span><br><span class="line">To grace my hand reproach within, and not a fair are hand,</span><br><span class="line">That Caesar and my goodly father&#x27;s world;</span><br><span class="line">When I was heaven of presence and our fleets,</span><br><span class="line">We spare with hours, but cut thy council I am great,</span><br><span class="line">Murdered and by thy master&#x27;s ready there</span><br><span class="line">My power to give thee but so much as hell:</span><br><span class="line">Some service in the noble bondman here,</span><br><span class="line">Would show him to her wine.</span><br><span class="line"></span><br><span class="line">KING LEAR:</span><br><span class="line">O, if you were a feeble sight, the courtesy of your law,</span><br><span class="line">Your sight and several breath, will wear the gods</span><br><span class="line">With his heads, and my hands are wonder&#x27;d at the deeds,</span><br><span class="line">So drop upon your lordship&#x27;s head, and your opinion</span><br><span class="line">Shall be against your honour.</span><br></pre></td></tr></table></figure></p>
<p>I can barely recognize these samples from actual Shakespeare :) If you like Shakespeare, you might appreciate this 100,000 character sample. Of course, you can also generate an infinite amount of your own samples at different temperatures with the provided code.<br>我几乎无法辨认这些样本是否真的是莎士比亚的作品 :) 如果你喜欢莎士比亚，你可能会喜欢这个10万字符的样本。当然，你也可以使用提供的代码在不同温度下生成无限量的样本。</p>
<h3 id="wikipedia-维基百科"><a href="#Wikipedia-维基百科" class="headerlink" title="Wikipedia 维基百科"></a>Wikipedia 维基百科</h3><p>We saw that the LSTM can learn to spell words and copy general syntactic structures. Lets further increase the difficulty and train on structured markdown. In particular, lets take the <a target="_blank" rel="noopener" href="http://prize.hutter1.net/">Hutter Prize</a> 100MB dataset of raw Wikipedia and train an LSTM. Following <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1308.0850">Graves et al.</a>, I used the first 96MB for training, the rest for validation and ran a few models overnight. We can now sample Wikipedia articles! Below are a few fun excerpts. First, some basic markdown output:<br>我们已经看到LSTM可以学会拼写单词和复制一般的句法结构。让我们进一步增加难度，训练在结构化的Markdown上。特别是，让我们使用Hutter Prize的100MB原始维基百科数据集来训练一个LSTM。按照Graves等人的方法，我使用前96MB进行训练，剩余的用于验证，并在一夜之间运行了几个模型。现在我们可以采样生成维基百科文章了！以下是一些有趣的摘录。首先，是一些基本的Markdown输出：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Naturalism and decision for the majority of Arab countries&#x27; capitalide was grounded</span><br><span class="line">by the Irish language by [[John Clair]], [[An Imperial Japanese Revolt]], associated </span><br><span class="line">with Guangzham&#x27;s sovereignty. His generals were the powerful ruler of the Portugal </span><br><span class="line">in the [[Protestant Immineners]], which could be said to be directly in Cantonese </span><br><span class="line">Communication, which followed a ceremony and set inspired prison, training. The </span><br><span class="line">emperor travelled back to [[Antioch, Perth, October 25|21]] to note, the Kingdom </span><br><span class="line">of Costa Rica, unsuccessful fashioned the [[Thrales]], [[Cynth&#x27;s Dajoard]], known </span><br><span class="line">in western [[Scotland]], near Italy to the conquest of India with the conflict. </span><br><span class="line">Copyright was the succession of independence in the slop of Syrian influence that </span><br><span class="line">was a famous German movement based on a more popular servicious, non-doctrinal </span><br><span class="line">and sexual power post. Many governments recognize the military housing of the </span><br><span class="line">[[Civil Liberalization and Infantry Resolution 265 National Party in Hungary]], </span><br><span class="line">that is sympathetic to be to the [[Punjab Resolution]]</span><br><span class="line">(PJS)[http://www.humah.yahoo.com/guardian.</span><br><span class="line">cfm/7754800786d17551963s89.htm Official economics Adjoint for the Nazism, Montgomery </span><br><span class="line">was swear to advance to the resources for those Socialism&#x27;s rule, </span><br><span class="line">was starting to signing a major tripad of aid exile.]]</span><br></pre></td></tr></table></figure></p>
<p>In case you were wondering, the yahoo url above doesn’t actually exist, the model just hallucinated it. Also, note that the model learns to open and close the parenthesis correctly. There’s also quite a lot of structured markdown that the model learns, for example sometimes it creates headings, lists, etc.:<br>如果你在好奇，上述的Yahoo网址实际上并不存在，这是模型臆想出来的。此外，请注意，模型学会了正确地打开和关闭括号。模型还学习了大量的结构化Markdown，例如，有时它会创建标题、列表等内容：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123; &#123; cite journal | id=Cerling Nonforest Department|format=Newlymeslated|none &#125; &#125;</span><br><span class="line">&#x27;&#x27;www.e-complete&#x27;&#x27;.</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;See also&#x27;&#x27;&#x27;: [[List of ethical consent processing]]</span><br><span class="line"></span><br><span class="line">== See also ==</span><br><span class="line">*[[Iender dome of the ED]]</span><br><span class="line">*[[Anti-autism]]</span><br><span class="line"></span><br><span class="line">===[[Religion|Religion]]===</span><br><span class="line">*[[French Writings]]</span><br><span class="line">*[[Maria]]</span><br><span class="line">*[[Revelation]]</span><br><span class="line">*[[Mount Agamul]]</span><br><span class="line"></span><br><span class="line">== External links==</span><br><span class="line">* [http://www.biblegateway.nih.gov/entrepre/ Website of the World Festival. The labour of India-county defeats at the Ripper of California Road.]</span><br><span class="line"></span><br><span class="line">==External links==</span><br><span class="line">* [http://www.romanology.com/ Constitution of the Netherlands and Hispanic Competition for Bilabial and Commonwealth Industry (Republican Constitution of the Extent of the Netherlands)]</span><br></pre></td></tr></table></figure><br>Sometimes the model snaps into a mode of generating random but valid XML:<br>有时，模型会进入生成随机但有效的 XML 的模式：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;page&gt;</span><br><span class="line">  &lt;title&gt;Antichrist&lt;/title&gt;</span><br><span class="line">  &lt;id&gt;865&lt;/id&gt;</span><br><span class="line">  &lt;revision&gt;</span><br><span class="line">    &lt;id&gt;15900676&lt;/id&gt;</span><br><span class="line">    &lt;timestamp&gt;2002-08-03T18:14:12Z&lt;/timestamp&gt;</span><br><span class="line">    &lt;contributor&gt;</span><br><span class="line">      &lt;username&gt;Paris&lt;/username&gt;</span><br><span class="line">      &lt;id&gt;23&lt;/id&gt;</span><br><span class="line">    &lt;/contributor&gt;</span><br><span class="line">    &lt;minor /&gt;</span><br><span class="line">    &lt;comment&gt;Automated conversion&lt;/comment&gt;</span><br><span class="line">    &lt;text xml:space=&quot;preserve&quot;&gt;#REDIRECT [[Christianity]]&lt;/text&gt;</span><br><span class="line">  &lt;/revision&gt;</span><br><span class="line">&lt;/page&gt;</span><br></pre></td></tr></table></figure></p>
<p>The model completely makes up the timestamp, id, and so on. Also, note that it closes the correct tags appropriately and in the correct nested order. Here are <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/char-rnn/wiki.txt">100,000 characters of sampled wikipedia</a> if you’re interested to see more.<br>该模型完全由时间戳、id 等组成。另外，请注意，它正确地关闭了标签，并且按照正确的嵌套顺序。这里有 100,000 个字符的样本维基百科，如果您有兴趣查看更多。</p>
<h3 id="algebraic-geometry-latex-代数几何latex"><a href="#Algebraic-Geometry-Latex-代数几何（Latex）" class="headerlink" title="Algebraic Geometry (Latex)  代数几何（Latex）"></a>Algebraic Geometry (Latex)  代数几何（Latex）</h3><p>The results above suggest that the model is actually quite good at learning complex syntactic structures. Impressed by these results, my labmate (<a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/jcjohns/">Justin Johnson</a>) and I decided to push even further into structured territories and got a hold of <a target="_blank" rel="noopener" href="http://stacks.math.columbia.edu/">this book</a> on algebraic stacks/geometry. We downloaded the raw Latex source file (a 16MB file) and trained a multilayer LSTM. Amazingly, the resulting sampled Latex _almost_ compiles. We had to step in and fix a few issues manually but then you get plausible looking math, it’s quite astonishing:<br>上述结果表明，模型在学习复杂句法结构方面实际上相当不错。这些结果给我留下了深刻的印象，我的实验室同事Justin Johnson和我决定进一步探索结构化领域，并找到了一本关于代数叠/几何的书。我们下载了原始的Latex源文件（一个16MB的文件）并训练了一个多层LSTM。令人惊讶的是，生成的Latex几乎可以编译。我们不得不手动修复一些问题，但最终得到了看起来很合理的数学表达，这真是令人惊叹：<br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/3.png" class><br>Sampled (fake) algebraic geometry. <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/jcjohns/fake-math/4.pdf">Here’s the actual pdf.</a><br>采样（假）代数几何。这是实际的pdf。</p>
<p>Here’s another sample: 下面是另一个示例：<br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/4.png" class><br>More hallucinated algebraic geometry. Nice try on the diagram (right).<br>更多幻觉的代数几何。不错的尝试图（右）。</p>
<p>As you can see above, sometimes the model tries to generate latex diagrams, but clearly it hasn’t really figured them out. I also like the part where it chooses to skip a proof (_“Proof omitted.”_, top left). Of course, keep in mind that latex has a relatively difficult structured syntactic format that I haven’t even fully mastered myself. For instance, here is a raw sample from the model (unedited):<br>正如你在上面看到的，有时模型尝试生成Latex图表，但显然它还没有真正掌握这种技能。我也喜欢它选择跳过证明的部分（“Proof omitted.”，左上角）。当然，请记住，Latex有一个相对复杂的结构化句法格式，我自己都还没有完全掌握。例如，下面是模型生成的一个原始样本（未编辑）：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">\begin&#123;proof&#125;</span><br><span class="line">We may assume that $\mathcal&#123;I&#125;$ is an abelian sheaf on $\mathcal&#123;C&#125;$.</span><br><span class="line">\item Given a morphism $\Delta : \mathcal&#123;F&#125; \to \mathcal&#123;I&#125;$</span><br><span class="line">is an injective and let $\mathfrak q$ be an abelian sheaf on $X$.</span><br><span class="line">Let $\mathcal&#123;F&#125;$ be a fibered complex. Let $\mathcal&#123;F&#125;$ be a category.</span><br><span class="line">\begin&#123;enumerate&#125;</span><br><span class="line">\item \hyperref[setain-construction-phantom]&#123;Lemma&#125;</span><br><span class="line">\label&#123;lemma-characterize-quasi-finite&#125;</span><br><span class="line">Let $\mathcal&#123;F&#125;$ be an abelian quasi-coherent sheaf on $\mathcal&#123;C&#125;$.</span><br><span class="line">Let $\mathcal&#123;F&#125;$ be a coherent $\mathcal&#123;O&#125;_X$-module. Then</span><br><span class="line">$\mathcal&#123;F&#125;$ is an abelian catenary over $\mathcal&#123;C&#125;$.</span><br><span class="line">\item The following are equivalent</span><br><span class="line">\begin&#123;enumerate&#125;</span><br><span class="line">\item $\mathcal&#123;F&#125;$ is an $\mathcal&#123;O&#125;_X$-module.</span><br><span class="line">\end&#123;lemma&#125;</span><br></pre></td></tr></table></figure></p>
<p>This sample from a relatively decent model illustrates a few common mistakes. For example, the model opens a <code>\begin&#123;proof&#125;</code> environment but then ends it with a <code>\end&#123;lemma&#125;</code>. This is an example of a problem we’d have to fix manually, and is likely due to the fact that the dependency is too long-term: By the time the model is done with the proof it has forgotten whether it was doing a proof or a lemma. Similarly, it opens an <code>\begin&#123;enumerate&#125;</code> but then forgets to close it. We observed that these became less common with larger/better models, but nonetheless, these are the kinds of mistakes that come up.<br>这个来自相对不错模型的样本展示了一些常见的错误。例如，模型打开了一个 \begin{proof} 环境，但随后却以 \end{lemma} 结束。这是一个我们必须手动修复的问题的例子，可能是由于依赖关系过于长期：到模型完成证明时，它已经忘记了自己是在进行证明还是引理。类似地，它打开了一个 \begin{enumerate}，但随后忘记了关闭它。我们注意到，这些错误在较大/更好的模型中变得不那么常见，但这些都是可能出现的错误类型。</p>
<h3 id="linux-source-code-linux-源代码"><a href="#Linux-Source-Code-Linux-源代码" class="headerlink" title="Linux Source Code Linux 源代码"></a>Linux Source Code Linux 源代码</h3><p>I wanted to push structured data to its limit, so for the final challenge I decided to use code. In particular, I took all the source and header files found in the <a target="_blank" rel="noopener" href="https://github.com/torvalds/linux">Linux repo on Github</a>, concatenated all of them in a single giant file (474MB of C code) (I was originally going to train only on the kernel but that by itself is only ~16MB). Then I trained several as-large-as-fits-on-my-GPU 3-layer LSTMs over a period of a few days. These models have about 10 million parameters, which is still on the lower end for RNN models. The results are superfun:<br>我想将结构化数据推向极限，因此在最后的挑战中我决定使用代码。具体来说，我收集了Github上Linux仓库中的所有源文件和头文件，将它们合并成一个巨大的文件（474MB的C代码）（我本来打算只训练内核代码，但它本身只有大约16MB）。然后，我在几天内训练了多个尽可能适应GPU容量的三层LSTM模型。这些模型大约有1000万个参数，这在RNN模型中仍然算是较少的。结果非常有趣：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Increment the size file of the new incorrect UI_FILTER group information</span><br><span class="line"> * of the size generatively.</span><br><span class="line"> */</span><br><span class="line">static int indicate_policy(void)</span><br><span class="line">&#123;</span><br><span class="line">  int error;</span><br><span class="line">  if (fd == MARN_EPT) &#123;</span><br><span class="line">    /*</span><br><span class="line">     * The kernel blank will coeld it to userspace.</span><br><span class="line">     */</span><br><span class="line">    if (ss-&gt;segment &lt; mem_total)</span><br><span class="line">      unblock_graph_and_set_blocked();</span><br><span class="line">    else</span><br><span class="line">      ret = 1;</span><br><span class="line">    goto bail;</span><br><span class="line">  &#125;</span><br><span class="line">  segaddr = in_SB(in.addr);</span><br><span class="line">  selector = seg / 16;</span><br><span class="line">  setup_works = true;</span><br><span class="line">  for (i = 0; i &lt; blocks; i++) &#123;</span><br><span class="line">    seq = buf[i++];</span><br><span class="line">    bpf = bd-&gt;bd.next + i * search;</span><br><span class="line">    if (fd) &#123;</span><br><span class="line">      current = blocked;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  rw-&gt;name = &quot;Getjbbregs&quot;;</span><br><span class="line">  bprm_self_clearl(&amp;iv-&gt;version);</span><br><span class="line">  regs-&gt;new = blocks[(BPF_STATS &lt;&lt; info-&gt;historidac)] | PFMR_CLOBATHINC_SECONDS &lt;&lt; 12;</span><br><span class="line">  return segtable;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>The code looks really quite great overall. Of course, I don’t think it compiles but when you scroll through the generate code it feels very much like a giant C code base. Notice that the RNN peppers its code with comments here and there at random. It is also very good at making very few syntactic errors. For example, it uses strings properly, pointer notation, etc. It also opens and closes brackets {   correctly and learns to indent its code very well. A common error is that it can’t keep track of variable names: It often uses undefined variables (e.g. rw above), declares variables it never uses (e.g. int error), or returns non-existing variables. Lets see a few more examples. Here’s another snippet that shows a wider array of operations that the RNN learns:</p>
<p>总体来说，这些代码看起来非常不错。当然，我不认为它能编译，但当你滚动查看生成的代码时，它确实给人一种巨大的C代码库的感觉。注意，RNN会随机在代码中插入注释，并且在语法错误方面表现得非常出色。例如，它能正确使用字符串、指针符号等，还能正确地打开和关闭大括号{}，并很好地学习代码缩进。<br>一个常见的错误是它无法跟踪变量名：它经常使用未定义的变量（例如上面的rw），声明从未使用的变量（例如int error），或者返回不存在的变量。让我们再看一些例子。下面是另一个代码片段，展示了RNN学到的更广泛的操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * If this error is set, we will need anything right after that BSD.</span><br><span class="line"> */</span><br><span class="line">static void action_new_function(struct s_stat_info *wb)</span><br><span class="line">&#123;</span><br><span class="line">  unsigned long flags;</span><br><span class="line">  int lel_idx_bit = e-&gt;edd, *sys &amp; ~((unsigned long) *FIRST_COMPAT);</span><br><span class="line">  buf[0] = 0xFFFFFFFF &amp; (bit &lt;&lt; 4);</span><br><span class="line">  min(inc, slist-&gt;bytes);</span><br><span class="line">  printk(KERN_WARNING &quot;Memory allocated %02x/%02x, &quot;</span><br><span class="line">    &quot;original MLL instead\n&quot;),</span><br><span class="line">    min(min(multi_run - s-&gt;len, max) * num_data_in),</span><br><span class="line">    frame_pos, sz + first_seg);</span><br><span class="line">  div_u64_w(val, inb_p);</span><br><span class="line">  spin_unlock(&amp;disk-&gt;queue_lock);</span><br><span class="line">  mutex_unlock(&amp;s-&gt;sock-&gt;mutex);</span><br><span class="line">  mutex_unlock(&amp;func-&gt;mutex);</span><br><span class="line">  return disassemble(info-&gt;pending_bh);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static void num_serial_settings(struct tty_struct *tty)</span><br><span class="line">&#123;</span><br><span class="line">  if (tty == tty)</span><br><span class="line">    disable_single_st_p(dev);</span><br><span class="line">  pci_disable_spool(port);</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static void do_command(struct seq_file *m, void *v)</span><br><span class="line">&#123;</span><br><span class="line">  int column = 32 &lt;&lt; (cmd[2] &amp; 0x80);</span><br><span class="line">  if (state)</span><br><span class="line">    cmd = (int)(int_state ^ (in_8(&amp;ch-&gt;ch_flags) &amp; Cmd) ? 2 : 1);</span><br><span class="line">  else</span><br><span class="line">    seq = 1;</span><br><span class="line">  for (i = 0; i &lt; 16; i++) &#123;</span><br><span class="line">    if (k &amp; (1 &lt;&lt; 1))</span><br><span class="line">      pipe = (in_use &amp; UMXTHREAD_UNCCA) +</span><br><span class="line">        ((count &amp; 0x00000000fffffff8) &amp; 0x000000f) &lt;&lt; 8;</span><br><span class="line">    if (count == 0)</span><br><span class="line">      sub(pid, ppc_md.kexec_handle, 0x20000000);</span><br><span class="line">    pipe_set_bytes(i, 0);</span><br><span class="line">  &#125;</span><br><span class="line">  /* Free our user pages pointer to place camera if all dash */</span><br><span class="line">  subsystem_info = &amp;of_changes[PAGE_SIZE];</span><br><span class="line">  rek_controls(offset, idx, &amp;soffset);</span><br><span class="line">  /* Now we want to deliberately put it to device */</span><br><span class="line">  control_check_polarity(&amp;context, val, 0);</span><br><span class="line">  for (i = 0; i &lt; COUNTER; i++)</span><br><span class="line">    seq_puts(s, &quot;policy &quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Notice that in the second function the model compares tty == tty, which is vacuously true. On the other hand, at least the variable tty exists in the scope this time! In the last function, notice that the code does not return anything, which happens to be correct since the function signature is void. However, the first two functions were also declared void and did return values. This is again a form of a common mistake due to long-term interactions.<br>注意在第二个函数中，模型比较了tty == tty，这是显然为真的。另一方面，至少这次变量tty存在于作用域中！在最后一个函数中，注意代码没有返回任何东西，这正好是正确的，因为函数签名是void。然而，前两个函数也声明为void，但却返回了值。这再次是一种由于长时间交互而导致的常见错误形式。</p>
<p>Sometimes the model decides that it’s time to sample a new file. This is usually a very amusing part: The model first recites the GNU license character by character, samples a few includes, generates some macros and then dives into the code:<br>有时，模型会决定是时候采样一个新文件了。这通常是非常有趣的部分：模型首先逐字符地背诵GNU许可证，采样几个include语句，生成一些宏，然后深入到代码中：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> *  Copyright (c) 2006-2010, Intel Mobile Communications.  All rights reserved.</span><br><span class="line"> *</span><br><span class="line"> *   This program is free software; you can redistribute it and/or modify it</span><br><span class="line"> * under the terms of the GNU General Public License version 2 as published by</span><br><span class="line"> * the Free Software Foundation.</span><br><span class="line"> *</span><br><span class="line"> *        This program is distributed in the hope that it will be useful,</span><br><span class="line"> * but WITHOUT ANY WARRANTY; without even the implied warranty of</span><br><span class="line"> *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span><br><span class="line"> *</span><br><span class="line"> *  GNU General Public License for more details.</span><br><span class="line"> *</span><br><span class="line"> *   You should have received a copy of the GNU General Public License</span><br><span class="line"> *    along with this program; if not, write to the Free Software Foundation,</span><br><span class="line"> *  Inc., 675 Mass Ave, Cambridge, MA 02139, USA.</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">#include &lt;linux/kexec.h&gt;</span><br><span class="line">#include &lt;linux/errno.h&gt;</span><br><span class="line">#include &lt;linux/io.h&gt;</span><br><span class="line">#include &lt;linux/platform_device.h&gt;</span><br><span class="line">#include &lt;linux/multi.h&gt;</span><br><span class="line">#include &lt;linux/ckevent.h&gt;</span><br><span class="line"></span><br><span class="line">#include &lt;asm/io.h&gt;</span><br><span class="line">#include &lt;asm/prom.h&gt;</span><br><span class="line">#include &lt;asm/e820.h&gt;</span><br><span class="line">#include &lt;asm/system_info.h&gt;</span><br><span class="line">#include &lt;asm/setew.h&gt;</span><br><span class="line">#include &lt;asm/pgproto.h&gt;</span><br><span class="line"></span><br><span class="line">#define REG_PG    vesa_slot_addr_pack</span><br><span class="line">#define PFM_NOCOMP  AFSR(0, load)</span><br><span class="line">#define STACK_DDR(type)     (func)</span><br><span class="line"></span><br><span class="line">#define SWAP_ALLOCATE(nr)     (e)</span><br><span class="line">#define emulate_sigs()  arch_get_unaligned_child()</span><br><span class="line">#define access_rw(TST)  asm volatile(&quot;movd %%esp, %0, %3&quot; : : &quot;r&quot; (0));   \</span><br><span class="line">  if (__type &amp; DO_READ)</span><br><span class="line"></span><br><span class="line">static void stat_PC_SEC __read_mostly offsetof(struct seq_argsqueue, \</span><br><span class="line">          pC&gt;[1]);</span><br><span class="line"></span><br><span class="line">static void</span><br><span class="line">os_prefix(unsigned long sys)</span><br><span class="line">&#123;</span><br><span class="line">#ifdef CONFIG_PREEMPT</span><br><span class="line">  PUT_PARAM_RAID(2, sel) = get_state_state();</span><br><span class="line">  set_pid_sum((unsigned long)state, current_state_str(),</span><br><span class="line">           (unsigned long)-1-&gt;lr_full; low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>There are too many fun parts to cover- I could probably write an entire blog post on just this part. I’ll cut it short for now, but here is <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/char-rnn/linux.txt">1MB of sampled Linux code</a> for your viewing pleasure.<br>有太多有趣的部分要涵盖 - 我可能会写一整篇关于这部分的博客文章。我现在会缩短它，但这里有 1MB 的 Linux 代码样本供您查看。</p>
<h3 id="generating-baby-names-生成婴儿名字"><a href="#Generating-Baby-Names-生成婴儿名字" class="headerlink" title="Generating Baby Names 生成婴儿名字"></a>Generating Baby Names 生成婴儿名字</h3><p>Lets try one more for fun. Lets feed the RNN a large text file that contains 8000 baby names listed out, one per line (names obtained from <a target="_blank" rel="noopener" href="http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/">here</a>). We can feed this to the RNN and then generate new names! Here are some example names, only showing the ones that do not occur in the training data (90% don’t):<br>再来试一个有趣的实验。我们向RNN输入一个包含8000个婴儿名字的大文本文件，每行一个名字（名字从这里获得）。我们可以将其输入RNN，然后生成新的名字！以下是一些示例名字，只展示那些没有出现在训练数据中的名字（90%都不在训练数据中）：<br>_Rudi Levette Berice Lussa Hany Mareanne Chrestina Carissy Marylen Hammine Janye Marlise Jacacrie Hendred Romand Charienna Nenotto Ette Dorane Wallen Marly Darine Salina Elvyn Ersia Maralena Minoria Ellia Charmin Antley Nerille Chelon Walmor Evena Jeryly Stachon Charisa Allisa Anatha Cathanie Geetra Alexie Jerin Cassen Herbett Cossie Velen Daurenge Robester Shermond Terisa Licia Roselen Ferine Jayn Lusine Charyanne Sales Sanny Resa Wallon Martine Merus Jelen Candica Wallin Tel Rachene Tarine Ozila Ketia Shanne Arnande Karella Roselina Alessia Chasty Deland Berther Geamar Jackein Mellisand Sagdy Nenc Lessie Rasemy Guen Gavi Milea Anneda Margoris Janin Rodelin Zeanna Elyne Janah Ferzina Susta Pey Castina_</p>
<p>You can see many more <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/namesGenUnique.txt">here</a>. Some of my favorites include “Baby” (haha), “Killie”, “Char”, “R”, “More”, “Mars”, “Hi”, “Saddie”, “With” and “Ahbort”. Well that was fun.﻿ Of course, you can imagine this being quite useful inspiration when writing a novel, or naming a new startup :)<br>你可以在这里看到更多。我最喜欢的一些包括“宝贝”（haha）、“Killie”、“Char”、“R”、“More”、“Mars”、“Hi”、“Saddie”、“With”和“Ahbort”。嗯，这很有趣。当然，你可以想象这在写小说或命名新的创业公司时是非常有用的灵感:)</p>
<h1 id="understanding-whats-going-on"><a href="#Understanding-what’s-going-on" class="headerlink" title="Understanding what’s going on"></a>Understanding what’s going on</h1><p>We saw that the results at the end of training can be impressive, but how does any of this work? Lets run two quick experiments to briefly peek under the hood.<br>我们看到训练结束时的结果令人印象深刻，但这些是如何实现的呢？让我们进行两个快速实验，简要探究一下其内部工作原理。</p>
<h2 id="the-evolution-of-samples-while-training"><a href="#The-evolution-of-samples-while-training" class="headerlink" title="The evolution of samples while training"></a>The evolution of samples while training</h2><p>训练时样本的演变<br>First, it’s fun to look at how the sampled text evolves while the model trains. For example, I trained an LSTM of Leo Tolstoy’s War and Peace and then generated samples every 100 iterations of training. At iteration 100 the model samples random jumbles:<br>首先，观察模型训练过程中生成文本的演变是很有趣的。例如，我训练了一个基于列夫·托尔斯泰的《战争与和平》的LSTM，并在每100次迭代训练后生成样本。在第100次迭代时，模型生成的样本是随机混杂的字符：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tyntd-iafhatawiaoihrdemot  lytdws  e ,tfti, astai f ogoh eoase rrranbyne &#x27;nhthnee e </span><br><span class="line">plia tklrgd t o idoe ns,smtt   h ne etie h,hregtrs nigtike,aoaenns lng</span><br></pre></td></tr></table></figure>
<p>However, notice that at least it is starting to get an idea about words separated by spaces. Except sometimes it inserts two spaces. It also doesn’t know that comma is amost always followed by a space. At 300 iterations we see that the model starts to get an idea about quotes and periods:<br>然而，请注意至少模型开始有了关于单词由空格分隔的概念。尽管有时它会插入两个空格。它还不知道逗号后几乎总是跟着一个空格。在训练300次迭代时，我们看到模型开始了解引号和句号的用法：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;Tmont thithey&quot; fomesscerliund</span><br><span class="line">Keushey. Thom here</span><br><span class="line">sheulke, anmerenith ol sivh I lalterthend Bleipile shuwy fil on aseterlome</span><br><span class="line">coaniogennc Phe lism thond hon at. MeiDimorotion in ther thize.&quot;</span><br></pre></td></tr></table></figure><br>The words are now also separated with spaces and the model starts to get the idea about periods at the end of a sentence. At iteration 500:<br>现在，单词之间也用空格分隔，模型开始理解句末的句号。在第500次迭代时：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">we counter. He stutn co des. His stanted out one ofler that concossions and was </span><br><span class="line">to gearang reay Jotrets and with fre colt otf paitt thin wall. Which das stimn </span><br></pre></td></tr></table></figure><br>the model has now learned to spell the shortest and most common words such as “we”, “He”, “His”, “Which”, “and”, etc. At iteration 700 we’re starting to see more and more English-like text emerge:<br>模型现在已经学会了拼写最短和最常见的单词，比如“we”、“He”、“His”、“Which”、“and”等。在第700次迭代时，我们开始看到越来越多类似英语的文本出现：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Aftair fall unsuch that the hall for Prince Velzonski&#x27;s that me of</span><br><span class="line">her hearly, and behs to so arwage fiving were to it beloge, pavu say falling misfort </span><br><span class="line">how, and Gogition is so overelical and ofter.</span><br></pre></td></tr></table></figure></p>
<p>At iteration 1200 we’re now seeing use of quotations and question/exclamation marks. Longer words have now been learned as well:<br>在第1200次迭代时，我们现在看到了引号和问号/感叹号的使用。更长的单词也已经被学会了：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;Kite vouch!&quot; he repeated by her</span><br><span class="line">door. &quot;But I would be done and quarts, feeling, then, son is people....&quot;</span><br></pre></td></tr></table></figure><br>Until at last we start to get properly spelled words, quotations, names, and so on by about iteration 2000:<br>直到最后，在大约第2000次迭代时，我们开始得到正确拼写的单词、引号、名字等：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;Why do what that day,&quot; replied Natasha, and wishing to himself the fact the</span><br><span class="line">princess, Princess Mary was easier, fed in had oftened him.</span><br><span class="line">Pierre aking his soul came to the packs and drove up his father-in-law women.</span><br></pre></td></tr></table></figure></p>
<p>The picture that emerges is that the model first discovers the general word-space structure and then rapidly starts to learn the words; First starting with the short words and then eventually the longer ones. Topics and themes that span multiple words (and in general longer-term dependencies) start to emerge only much later.<br>出现的情况是，模型首先发现了整体的单词-空格结构，然后迅速开始学习单词；先是短单词，然后逐渐学习长单词。跨越多个单词的主题和主题（以及一般的长期依赖关系）要到很久以后才会开始出现。</p>
<h2 id="visualizing-the-predictions-and-the-neuron-firings-in-the-rnn"><a href="#Visualizing-the-predictions-and-the-“neuron”-firings-in-the-RNN" class="headerlink" title="Visualizing the predictions and the “neuron” firings in the RNN"></a>Visualizing the predictions and the “neuron” firings in the RNN</h2><p>可视化 RNN 中的预测和“神经元”放电</p>
<p>Another fun visualization is to look at the predicted distributions over characters. In the visualizations below we feed a Wikipedia RNN model character data from the validation set (shown along the blue/green rows) and under every character we visualize (in red) the top 5 guesses that the model assigns for the next character. The guesses are colored by their probability (so dark red = judged as very likely, white = not very likely). For example, notice that there are stretches of characters where the model is extremely confident about the next letter (e.g., the model is very confident about characters during the _<a target="_blank" rel="noopener" href="http://www._">http://www._</a> sequence).<br>另一个有趣的可视化是查看模型对字符的预测分布。在下面的可视化中，我们向一个训练好的Wikipedia RNN模型，提供验证集的字符数据（显示在蓝色/绿色行上），并在每个字符下方可视化（用红色表示）模型对下一个字符的前5个猜测。猜测根据其概率进行着色（深红色=被认为非常可能，白色=不太可能）。例如，请注意在某些字符序列中，模型对下一个字符极为自信(例如，模型对 <a target="_blank" rel="noopener" href="http://www">http://www</a> 序列中的字符非常有信心）</p>
<p>The input character sequence (blue/green) is colored based on the _firing_ of a randomly chosen neuron in the hidden representation of the RNN. Think about it as green = very excited and blue = not very excited (for those familiar with details of LSTMs, these are values between [-1,1] in the hidden state vector, which is just the gated and tanh’d LSTM cell state). Intuitively, this is visualizing the firing rate of some neuron in the “brain” of the RNN while it reads the input sequence. Different neurons might be looking for different patterns; Below we’ll look at 4 different ones that I found and thought were interesting or interpretable (many also aren’t):<br>输入字符序列（蓝色/绿色）是根据RNN隐藏表示中随机选择的一个神经元的激活情况进行着色的。可以理解为绿色=非常激动，蓝色=不太激动（对于熟悉LSTM细节的人来说，这些值在隐藏状态向量中介于[-1,1]之间，这是经过门控和tanh函数处理的LSTM单元状态）。直观地说，这是在可视化RNN“脑中”某个神经元在读取输入序列时的激活率。不同的神经元可能在寻找不同的模式；下面我们将查看4个我发现有趣或可解释的神经元（也有很多是无法解释的）：</p>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/5.png" class>
<p>The neuron highlighted in this image seems to get very excited about URLs and turns off outside of the URLs. The LSTM is likely using this neuron to remember if it is inside a URL or not.<br>此图像中突出显示的神经元似乎对 URL 非常兴奋，并在 URL 之外关闭。LSTM 可能使用这个神经元来记住它是否在 URL 内。</p>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/6.png" class>
<p>The highlighted neuron here gets very excited when the RNN is inside the [[ ]] markdown environment and turns off outside of it. Interestingly, the neuron can’t turn on right after it sees the character “[“, it must wait for the second “[“ and then activate. This task of counting whether the model has seen one or two “[“ is likely done with a different neuron.<br>当 RNN 位于 [[ ]] markdown 环境内部并在其外部关闭时，此处突出显示的神经元会非常兴奋。有趣的是，神经元在看到字符“[”后无法立即打开，它必须等待第二个“[”然后激活。计算模型是否看到一个或两个“[”的任务可能是用不同的神经元完成的。</p>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/7.png" class>
<p>Here we see a neuron that varies seemingly linearly across the [[ ]] environment. In other words its activation is giving the RNN a time-aligned coordinate system across the [[ ]] scope. The RNN can use this information to make different characters more or less likely depending on how early/late it is in the [[ ]] scope (perhaps?).<br>在这里，我们看到一个神经元，它在[[ ]]环境中似乎呈线性变化。换句话说，它的激活为 RNN 提供了一个跨 [[ ]] 范围的时间对齐坐标系。RNN 可以使用此信息或多或少地使不同的字符更有可能，具体取决于它在 [[ ]] 范围内的早/晚（也许？</p>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/8.png" class>
<p>Here is another neuron that has very local behavior: it is relatively silent but sharply turns off right after the first “w” in the “www” sequence. The RNN might be using this neuron to count up how far in the “www” sequence it is, so that it can know whether it should emit another “w”, or if it should start the URL.<br>这是另一个具有非常局部行为的神经元：它相对安静，但在“www”序列中的第一个“w”之后急剧关闭。RNN 可能正在使用这个神经元来计算它在“www”序列中的距离，以便它可以知道它是否应该发出另一个“w”，或者它是否应该启动 URL。</p>
<p>Of course, a lot of these conclusions are slightly hand-wavy as the hidden state of the RNN is a huge, high-dimensional and largely distributed representation. These visualizations were produced with custom HTML/CSS/Javascript, you can see a sketch of what’s involved <a target="_blank" rel="noopener" href="http://cs.stanford.edu/people/karpathy/viscode.zip">here</a> if you’d like to create something similar.<br>当然，很多这些结论都有些笼统，因为RNN的隐藏状态是一个巨大的、高维的、广泛分布的表示。这些可视化是使用自定义的HTML/CSS/Javascript生成的，如果你想创建类似的东西，可以在这里看到涉及的内容示例。</p>
<p>We can also condense this visualization by excluding the most likely predictions and only visualize the text, colored by activations of a cell. We can see that in addition to a large portion of cells that do not do anything interpretible, about 5% of them turn out to have learned quite interesting and interpretible algorithms:<br>我们还可以通过排除最可能的预测并仅根据单元激活情况对文本进行着色来简化这种可视化。我们可以看到，除了大部分不可解释的单元外，大约有5%的单元学会了相当有趣且可解释的算法：<br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/9.png" class><br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2472be8a/10.png" class><br>Again, what is beautiful about this is that we didn’t have to hardcode at any point that if you’re trying to predict the next character it might, for example, be useful to keep track of whether or not you are currently inside or outside of quote. We just trained the LSTM on raw data and it decided that this is a useful quantitity to keep track of. In other words one of its cells gradually tuned itself during training to become a quote detection cell, since this helps it better perform the final task. This is one of the cleanest and most compelling examples of where the power in Deep Learning models (and more generally end-to-end training) is coming from.<br>再次强调，这其中的美妙之处在于，我们不需要在任何时候硬编码，例如在预测下一个字符时需要跟踪当前是否在引号内或引号外。我们只是对LSTM进行原始数据的训练，它自己决定跟踪这个信息是有用的。换句话说，其中一个单元在训练过程中逐渐调整自己，变成了一个引号检测单元，因为这有助于它更好地完成最终任务。这是深度学习模型（更广泛地说，端到端训练）力量的最清晰和最有说服力的例子之一。</p>
<h1 id="source-code-源代码"><a href="#Source-Code-源代码" class="headerlink" title="Source Code 源代码"></a>Source Code 源代码</h1><p>I hope I’ve convinced you that training character-level language models is a very fun exercise. You can train your own models using the <a target="_blank" rel="noopener" href="https://github.com/karpathy/char-rnn">char-rnn code</a> I released on Github (under MIT license). It takes one large text file and trains a character-level model that you can then sample from. Also, it helps if you have a GPU or otherwise training on CPU will be about a factor of 10x slower. In any case, if you end up training on some data and getting fun results let me know! And if you get lost in the Torch/Lua codebase remember that all it is is just a more fancy version of this <a target="_blank" rel="noopener" href="https://gist.github.com/karpathy/d4dee566867f8291f086">100-line gist</a>.<br>我希望我已经让你相信，训练字符级语言模型是一个非常有趣的练习。你可以使用我在Github上发布的char-rnn代码（基于MIT许可证）来训练你自己的模型。它需要一个大型文本文件，并训练一个字符级模型，你可以从中进行采样。此外，如果你有GPU，这会更有帮助，否则在CPU上训练的速度大约会慢10倍。不管怎样，如果你在一些数据上训练并得到了有趣的结果，请告诉我！如果你在Torch/Lua代码库中迷失了方向，请记住，这只是这个100行代码示例的更复杂版本。</p>
<p>_Brief digression._ The code is written in <a target="_blank" rel="noopener" href="http://torch.ch/">Torch 7</a>, which has recently become my favorite deep learning framework. I’ve only started working with Torch/LUA over the last few months and it hasn’t been easy (I spent a good amount of time digging through the raw Torch code on Github and asking questions on their _gitter_ to get things done), but once you get a hang of things it offers a lot of flexibility and speed. I’ve also worked with Caffe and Theano in the past and I believe Torch, while not perfect, gets its levels of abstraction and philosophy right better than others. In my view the desirable features of an effective framework are:<br>简单插曲一下。这段代码是用Torch 7编写的，它最近成为了我最喜欢的深度学习框架。我只是过去几个月才开始使用Torch/LUA，过程并不容易（我花了大量时间在Github上挖掘Torch的源代码，并在他们的gitter上提问以解决问题），但一旦你掌握了它，它就能提供很大的灵活性和速度。我过去也使用过Caffe和Theano，我认为Torch虽然不完美，但它在抽象层次和理念上做得比其他框架更好。在我看来，一个有效框架的理想特性是：</p>
<ol>
<li>CPU/GPU transparent Tensor library with a lot of functionality (slicing, array/matrix operations, etc. )<br><strong>CPU/GPU透明的张量库</strong>：具有丰富的功能（切片、数组/矩阵操作等）。）</li>
<li>An entirely separate code base in a scripting language (ideally Python) that operates over Tensors and implements all Deep Learning stuff (forward/backward, computation graphs, etc)<br><strong>完全独立的脚本语言代码库</strong>：理想情况下是Python，操作张量并实现所有深度学习相关功能（前向/后向传播、计算图等）。</li>
<li>It should be possible to easily share pretrained models (Caffe does this well, others don’t), and crucially<br><strong>能够轻松共享预训练模型</strong>：Caffe在这方面做得很好，其他框架则不尽如人意。</li>
<li>NO compilation step (or at least not as currently done in Theano). The trend in Deep Learning is towards larger, more complex networks that are are time-unrolled in complex graphs. It is critical that these do not compile for a long time or development time greatly suffers. Second, by compiling one gives up interpretability and the ability to log/debug effectively. If there is an _option_ to compile the graph once it has been developed for efficiency in prod that’s fine.<br><strong>没有编译步骤</strong>：或至少不像Theano目前那样。深度学习的发展趋势是使用更大、更复杂的网络，这些网络在复杂的计算图中进行时间展开。关键是这些图不应长时间编译，否则会严重影响开发时间。其次，通过编译，会失去可解释性和有效记录/调试的能力。如果有选项可以在开发完成后编译图以提高生产效率，那也很好。</li>
</ol>
<h1 id="further-reading-延伸阅读"><a href="#Further-Reading-延伸阅读" class="headerlink" title="Further Reading 延伸阅读"></a>Further Reading 延伸阅读</h1><p>Before the end of the post I also wanted to position RNNs in a wider context and provide a sketch of the current research directions. RNNs have recently generated a significant amount of buzz and excitement in the field of Deep Learning. Similar to Convolutional Networks they have been around for decades but their full potential has only recently started to get widely recognized, in large part due to our growing computational resources. Here’s a brief sketch of a few recent developments (definitely not complete list, and a lot of this work draws from research back to 1990s, see related work sections):<br>在文章的结尾，我还想把RNN放在更广泛的背景中，并提供当前研究方向的概述。最近，RNN在深度学习领域引起了大量关注和兴奋。类似于卷积网络，RNN已经存在了几十年，但它们的全部潜力直到最近才开始被广泛认可，这在很大程度上要归功于我们不断增长的计算资源。以下是一些最近发展的简要概述（绝不是完整的列表，其中很多工作可以追溯到1990年代，详见相关研究部分）：</p>
<p>In the domain of <strong>NLP/Speech</strong>, RNNs <a target="_blank" rel="noopener" href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf">transcribe speech to text</a>, perform <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1409.3215">machine translation</a>, <a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~graves/handwriting.html">generate handwritten text</a>, and of course, they have been used as powerful language models <a target="_blank" rel="noopener" href="http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf">(Sutskever et al.)</a> <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1308.0850">(Graves)</a> <a target="_blank" rel="noopener" href="http://www.rnnlm.org/">(Mikolov et al.)</a> (both on the level of characters and words). Currently it seems that word-level models work better than character-level models, but this is surely a temporary thing.<br>在NLP/Speech领域，RNN用于将语音转录为文本、执行机器翻译、生成手写文本，当然，它们也被用作强大的语言模型（Sutskever等人）（Graves）（Mikolov等人）（包括字符级和单词级）。目前看来，单词级模型比字符级模型效果更好，但这肯定只是暂时的。</p>
<p><strong>Computer Vision.</strong> RNNs are also quickly becoming pervasive in Computer Vision. For example, we’re seeing RNNs in frame-level <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1411.4389">video classification</a>, <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1411.4555">image captioning</a> (also including my own work and many others), <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1505.00487">video captioning</a> and very recently <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1505.02074">visual question answering</a>. My personal favorite RNNs in Computer Vision paper is <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1406.6247">Recurrent Models of Visual Attention</a>, both due to its high-level direction (sequential processing of images with glances) and the low-level modeling (REINFORCE learning rule that is a special case of policy gradient methods in Reinforcement Learning, which allows one to train models that perform non-differentiable computation (taking glances around the image in this case)). I’m confident that this type of hybrid model that consists of a blend of CNN for raw perception coupled with an RNN glance policy on top will become pervasive in perception, especially for more complex tasks that go beyond classifying some objects in plain view.<br>计算机视觉。RNN也迅速在计算机视觉领域普及。例如，我们看到RNN用于帧级视频分类、图像描述生成（包括我自己的工作和许多其他人的工作）、视频描述生成以及最近的视觉问答。我个人最喜欢的计算机视觉领域的RNN论文是《视觉注意力的递归模型》，因为它在高层次方向（通过扫视对图像进行顺序处理）和低层次建模（REINFORCE学习规则，这是强化学习中策略梯度方法的特例，允许训练执行不可微计算的模型（在本例中是环顾图像））上都很出色。我相信这种混合模型，即结合了用于原始感知的CNN和用于扫视策略的RNN的模型，将在感知领域普及，特别是在超越简单对象分类的复杂任务中。</p>
<p><strong>Inductive Reasoning, Memories and Attention.</strong> Another extremely exciting direction of research is oriented towards addressing the limitations of vanilla recurrent networks. One problem is that RNNs are not inductive: They memorize sequences extremely well, but they don’t necessarily always show convincing signs of generalizing in the _correct_ way (I’ll provide pointers in a bit that make this more concrete). A second issue is they unnecessarily couple their representation size to the amount of computation per step. For instance, if you double the size of the hidden state vector you’d quadruple the amount of FLOPS at each step due to the matrix multiplication. Ideally, we’d like to maintain a huge representation/memory (e.g. containing all of Wikipedia or many intermediate state variables), while maintaining the ability to keep computation per time step fixed.<br>归纳推理、记忆和注意力。另一个极其令人兴奋的研究方向是解决普通循环网络的局限性。一个问题是RNN不具备归纳能力：它们非常擅长记忆序列，但不一定总是能以正确的方式表现出令人信服的泛化能力（稍后我会提供一些具体的例子）。第二个问题是它们不必要地将表示大小与每步计算量耦合在一起。例如，如果你将隐藏状态向量的大小加倍，那么由于矩阵乘法，每步的浮点运算量（FLOPS）将增加四倍。理想情况下，我们希望保持一个巨大的表示/记忆（例如包含整个维基百科或许多中间状态变量），同时保持每个时间步的计算量固定。</p>
<p>The first convincing example of moving towards these directions was developed in DeepMind’s <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1410.5401">Neural Turing Machines</a> paper. This paper sketched a path towards models that can perform read/write operations between large, external memory arrays and a smaller set of memory registers (think of these as our working memory) where the computation happens. Crucially, the NTM paper also featured very interesting memory addressing mechanisms that were implemented with a (soft, and fully-differentiable) attention model. The concept of <strong>soft attention</strong> has turned out to be a powerful modeling feature and was also featured in <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> for Machine Translation and <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1503.08895">Memory Networks</a> for (toy) Question Answering. In fact, I’d go as far as to say that<br>第一个朝着这些方向前进的令人信服的例子是DeepMind的《神经图灵机》（Neural Turing Machines）论文。这篇论文勾画了一个模型的路径，这些模型可以在大型外部存储阵列和一小组计算发生的存储寄存器（可以将这些视为我们的工作记忆）之间执行读/写操作。至关重要的是，NTM论文还展示了非常有趣的记忆寻址机制，这些机制通过一个（软且完全可微分的）注意力模型实现。软注意力的概念被证明是一个强大的建模特性，它也出现在《通过联合学习对齐和翻译的神经机器翻译》和《记忆网络用于（玩具）问答》中。实际上，我甚至可以说</p>
<p>The concept of <strong>attention</strong> is the most interesting recent architectural innovation in neural networks.<br>注意力的概念是神经网络中最近最有趣的架构创新。</p>
<p>Now, I don’t want to dive into too many details but a soft attention scheme for memory addressing is convenient because it keeps the model fully-differentiable, but unfortunately one sacrifices efficiency because everything that can be attended to is attended to (but softly). Think of this as declaring a pointer in C that doesn’t point to a specific address but instead defines an entire distribution over all addresses in the entire memory, and dereferencing the pointer returns a weighted sum of the pointed content (that would be an expensive operation!). This has motivated multiple authors to swap soft attention models for <strong>hard attention</strong> where one samples a particular chunk of memory to attend to (e.g. a read/write action for some memory cell instead of reading/writing from all cells to some degree). This model is significantly more philosophically appealing, scalable and efficient, but unfortunately it is also non-differentiable. This then calls for use of techniques from the Reinforcement Learning literature (e.g. REINFORCE) where people are perfectly used to the concept of non-differentiable interactions. This is very much ongoing work but these hard attention models have been explored, for example, in <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1503.01007">Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets</a>, <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1505.00521">Reinforcement Learning Neural Turing Machines</a>, and <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1502.03044">Show Attend and Tell</a>.<br>现在，我不想深入研究太多细节，但用于内存寻址的软注意力方案很方便，因为它使模型保持完全可微分，但不幸的是，人们牺牲了效率，因为所有可以处理的东西都被处理了（但很软）。可以把它想象成在 C 语言中声明一个指针，该指针不指向特定地址，而是在整个内存中的所有地址上定义整个分布，并且取消引用指针会返回指向内容的加权总和（这将是一个昂贵的操作！这促使多位作者将软注意力模型换成硬注意力模型，其中一个人对要关注的特定内存块进行采样（例如，对某些记忆单元进行读/写操作，而不是在某种程度上从所有单元读取/写入）。这个模型在哲学上更具吸引力、可扩展性和效率，但不幸的是，它也是不可微分的。然后，这需要使用强化学习文献中的技术（例如REINFORCE），在这些技术中，人们完全习惯了不可微分交互的概念。这是一项正在进行的工作，但这些硬注意力模型已经被探索过，例如，在使用堆栈增强的循环网络推断算法模式、强化学习神经图灵机和显示、出席和讲述中。</p>
<p><strong>People</strong>. If you’d like to read up on RNNs I recommend theses from <a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~graves/">Alex Graves</a>, <a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~ilya/">Ilya Sutskever</a> and <a target="_blank" rel="noopener" href="http://www.rnnlm.org/">Tomas Mikolov</a>. For more about REINFORCE and more generally Reinforcement Learning and policy gradient methods (which REINFORCE is a special case of) <a target="_blank" rel="noopener" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Home.html">David Silver</a>’s class, or one of <a target="_blank" rel="noopener" href="http://www.cs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>’s classes.<br>人。如果你想深入了解RNN，我推荐阅读Alex Graves、Ilya Sutskever和Tomas Mikolov的论文。关于REINFORCE和更广泛的强化学习及策略梯度方法（REINFORCE是其特例），可以参考David Silver的课程，或Pieter Abbeel的课程之一。</p>
<p><strong>Code</strong>. If you’d like to play with training RNNs I hear good things about <a target="_blank" rel="noopener" href="https://github.com/fchollet/keras">keras</a> or <a target="_blank" rel="noopener" href="https://github.com/IndicoDataSolutions/Passage">passage</a> for Theano, the <a target="_blank" rel="noopener" href="https://github.com/karpathy/char-rnn">code</a> released with this post for Torch, or <a target="_blank" rel="noopener" href="https://gist.github.com/karpathy/587454dc0146a6ae21fc">this gist</a> for raw numpy code I wrote a while ago that implements an efficient, batched LSTM forward and backward pass. You can also have a look at my numpy-based <a target="_blank" rel="noopener" href="https://github.com/karpathy/neuraltalk">NeuralTalk</a> which uses an RNN/LSTM to caption images, or maybe this <a target="_blank" rel="noopener" href="http://jeffdonahue.com/lrcn/">Caffe</a> implementation by Jeff Donahue.<br>代码。如果你想尝试训练RNN，我听说keras或passage for Theano的评价很好，可以参考本文发布的用于Torch的代码，或者我之前编写的这个实现了高效批量LSTM前向和后向传递的纯numpy代码。你也可以看看我基于numpy的NeuralTalk，它使用RNN/LSTM生成图像描述，或者看看Jeff Donahue的这个Caffe实现。</p>
<h1 id="conclusion-结论"><a href="#Conclusion-结论" class="headerlink" title="Conclusion 结论"></a>Conclusion 结论</h1><p>We’ve learned about RNNs, how they work, why they have become a big deal, we’ve trained an RNN character-level language model on several fun datasets, and we’ve seen where RNNs are going. You can confidently expect a large amount of innovation in the space of RNNs, and I believe they will become a pervasive and critical component to intelligent systems.<br>我们已经了解了RNN，它们是如何工作的，为什么它们变得如此重要。我们在几个有趣的数据集上训练了一个RNN字符级语言模型，并且看到了RNN的发展方向。你可以自信地期待在RNN领域出现大量的创新，我相信它们将成为智能系统中普遍且关键的组成部分。</p>
<p>Lastly, to add some <strong>meta</strong> to this post, I trained an RNN on the source file of this blog post. Unfortunately, at about 46K characters I haven’t written enough data to properly feed the RNN, but the returned sample (generated with low temperature to get a more typical sample) is:<br>最后，为了给这篇文章增加一些元内容，我用这篇博客文章的源文件训练了一个RNN。不幸的是，大约46K字符的数据量还不足以充分训练RNN，但生成的样本（在低温下生成，以获得更典型的样本）如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I&#x27;ve the RNN with and works, but the computed with program of the </span><br><span class="line">RNN with and the computed of the RNN with with and the code</span><br></pre></td></tr></table></figure>
<p>Yes, the post was about RNN and how well it works, so clearly this works :). See you next time!<br>是的，这篇文章是关于 RNN 及其工作情况的，所以很明显这:)工作。下次再见！</p>
<h1 id="edit-extra-links-编辑额外链接"><a href="#EDIT-extra-links-编辑（额外链接）" class="headerlink" title="EDIT (extra links): 编辑（额外链接）"></a>EDIT (extra links): 编辑（额外链接）</h1><p>Videos: 视频：</p>
<ul>
<li>I gave a talk on this work at the <a target="_blank" rel="noopener" href="https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks">London Deep Learning meetup (video)</a>.<br>我在伦敦深度学习聚会上就这项工作发表了演讲（视频）。</li>
</ul>
<p>Discussions: 讨论：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=9584325">HN discussion HN 讨论</a></li>
<li>Reddit discussion on <a target="_blank" rel="noopener" href="http://www.reddit.com/r/MachineLearning/comments/36s673/the_unreasonable_effectiveness_of_recurrent/">r/machinelearning</a><br>Reddit 关于 r/machinelearning 的讨论</li>
<li>Reddit discussion on <a target="_blank" rel="noopener" href="http://www.reddit.com/r/programming/comments/36su8d/the_unreasonable_effectiveness_of_recurrent/">r/programming</a><br>Reddit 上关于 r/programming 的讨论</li>
</ul>
<p>Replies: 答复：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://twitter.com/yoavgo">Yoav Goldberg</a> compared these RNN results to <a target="_blank" rel="noopener" href="http://nbviewer.ipython.org/gist/yoavg/d76121dfde2618422139">n-gram maximum likelihood (counting) baseline</a><br>Yoav Goldberg 将这些 RNN 结果与 n-gram 最大似然（计数）基线进行了比较</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/nylk">@nylk</a> trained char-rnn on <a target="_blank" rel="noopener" href="https://gist.github.com/nylki/1efbaa36635956d35bcc">cooking recipes</a>. They look great!<br>@nylk培训了char-rnn的烹饪食谱。它们看起来很棒！</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/MrChrisJohnson">@MrChrisJohnson</a> trained char-rnn on Eminem lyrics and then synthesized a rap song with robotic voice reading it out. Hilarious :)<br>@MrChrisJohnson用 Eminem 的歌词训练了 char-rnn，然后合成了一首带有机器人声音的说唱歌曲。搞笑:)</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/samim">@samim</a> trained char-rnn on <a target="_blank" rel="noopener" href="https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0">Obama Speeches</a>. They look fun!<br>@samim培训了奥巴马演讲的char-rnn。他们看起来很有趣！</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/seaandsailor">João Felipe</a> trained char-rnn irish folk music and <a target="_blank" rel="noopener" href="https://soundcloud.com/seaandsailor/sets/char-rnn-composes-irish-folk-music">sampled music</a><br>若昂·费利佩（João Felipe）训练了char-rnn爱尔兰民间音乐并采样了音乐</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/boblsturm">Bob Sturm</a> also trained char-rnn on <a target="_blank" rel="noopener" href="https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/">music in ABC notation</a><br>鲍勃·斯特姆（Bob Sturm）还对char-rnn进行了ABC记谱法的音乐培训</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/RNN_Bible">RNN Bible bot</a> by <a target="_blank" rel="noopener" href="https://twitter.com/the__glu/with_replies">Maximilien</a><br>RNN Bible bot 的 Maximilien</li>
<li><a target="_blank" rel="noopener" href="http://cpury.github.io/learning-holiness/">Learning Holiness</a> learning the Bible<br>学习圣洁 学习圣经</li>
<li><a target="_blank" rel="noopener" href="https://www.terminal.com/tiny/ZMcqdkWGOM">Terminal.com snapshot</a> that has char-rnn set up and ready to go in a browser-based virtual machine (thanks <a target="_blank" rel="noopener" href="https://www.twitter.com/samim">@samim</a>)<br>Terminal.com 已设置 char-rnn 并准备在基于浏览器的虚拟机中使用的快照（感谢 @samim）</li>
</ul>
<h1 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h1><h2 id="1vanilla-神经网络"><a href="#1-Vanilla-神经网络" class="headerlink" title="1.Vanilla 神经网络"></a>1.Vanilla 神经网络</h2><p>“Vanilla 神经网络”通常指的是最基本、最简单的神经网络模型，没有使用任何特殊的层或复杂的架构。具体来说，它一般指的是简单的前馈神经网络（Feedforward Neural Network, FNN）</p>
<h2 id="2-向量vectorvs-序列sequence"><a href="#2-向量（Vector）vs-序列（Sequence）" class="headerlink" title="2. 向量（Vector）vs 序列（Sequence）"></a>2. 向量（Vector）vs 序列（Sequence）</h2><p><strong>向量（Vector）</strong>：</p>
<ul>
<li><strong>定义</strong>：在数学和计算机科学中，向量是一组有序的数值。这些数值可以表示多维空间中的一个点或某个特定的数据结构。</li>
<li><strong>特性</strong>：<ul>
<li>固定长度：向量的长度是固定的，例如一个包含三个数值的向量$x_1, x_2, x_3$。 这种处理方式对于图像分类、固定长度的文本分类等任务非常有效。</li>
<li>无时间依赖：向量中的元素没有时间或顺序上的依赖关系。例如，一张图片的像素数据可以作为输入向量，但这些像素之间没有时间顺序上的关系。</li>
</ul>
</li>
<li><strong>示例</strong>：<ul>
<li>图像处理中的像素值向量。</li>
<li>静态文本分类中的单词向量。</li>
</ul>
</li>
<li><strong>向量输入输出</strong>：向量输入输出通常指的是神经网络处理固定长度的向量，即一组固定大小的数值输入和输出。</li>
<li><strong>应用场景</strong>：<ul>
<li>图像分类：输入是一个固定大小的图像向量，输出是一个类别标签向量。</li>
<li>静态文本分类：输入是一个表示单个文档的向量，输出是分类标签。</li>
</ul>
</li>
</ul>
<p><strong>序列（Sequence）</strong>：</p>
<ul>
<li><strong>定义</strong>：序列是一组按特定顺序排列的数据，通常是时间或顺序相关的。</li>
<li><strong>特性</strong>：<ul>
<li>变长：序列的长度可以变化，例如一段文本可以是一个字符序列$c_1, c_2, …, c_t$</li>
<li>有时间依赖：序列中的元素有时间或顺序上的依赖关系。后续元素依赖于前面出现的元素。例如，在自然语言处理中，一个句子的单词顺序决定了句子的意义。</li>
</ul>
</li>
<li><strong>示例</strong>：<ul>
<li>时间序列数据，如股票价格的每日记录。</li>
<li>文本数据，如一段句子中的单词序列。</li>
</ul>
</li>
<li><strong>序列输入输出</strong>：序列输入输出指的是神经网络处理一系列的输入数据，这些数据有时间或顺序上的依赖关系。RNN（循环神经网络）就是处理序列数据的典型模型。</li>
<li><strong>应用场景</strong>：<ul>
<li>语言模型和文本生成：输入是一个文本序列，输出是下一个字符或单词的预测序列。</li>
<li>机器翻译：输入是源语言的句子序列，输出是目标语言的句子序列。</li>
<li>语音识别：输入是语音信号的时间序列，输出是对应的文本序列。</li>
</ul>
</li>
</ul>
<h2 id="3-rnn-computation"><a href="#3-RNN-computation" class="headerlink" title="3. RNN computation"></a>3. RNN computation</h2><p>论文正文中对该过程的描述文字较多，我反倒觉得结合数学公式后更好理解。<br>这里描述就是 RNN 的前向传播过程， 如果你了解了基础神经网络的前向传播过程，那么RNN也非常好理解。</p>
<p>简单理解就是 相比在神经网络一文中讲述的基础 前向传播过程中，递归神经网络在此基础上增加了一个隐藏层到隐藏层的权重矩阵参与计算。</p>
<p>这3个权重矩阵分别对应文中W_hh（隐藏层到隐藏层）、W_xh（输入层到隐藏层）和W_hy（隐藏层到输出层）,下面以$ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$ 来拆解整个过程</p>
<p>假设网络结构和参数如下</p>
<ol>
<li><strong>输入层</strong>：2个节点，表示输入特征 $x_1$ 和 $x_2$。</li>
<li><strong>隐藏层</strong>：2个节点，表示隐藏状态 $h_1$ 和 $h_2$​，,使用tanh激活函数。</li>
<li><strong>输出层</strong>：1个节点，表示输出 $y$，使用线性激活函数。</li>
</ol>
<h4 id="权重矩阵"><a href="#权重矩阵" class="headerlink" title="权重矩阵"></a>权重矩阵</h4><ol>
<li><p><strong>输入层到隐藏层的权重</strong>： $W_{xh} = \begin{bmatrix} W_{11} &amp; W_{12} \ W_{21} &amp; W_{22} \end{bmatrix}$</p>
<p>$W_{11}$、$W_{12}$​ 连接 $x_1$​ 到 $h_1$​ 和 $h_2$​，$W_{21}$、$W_{22}$​ 连接 $x_2$​ 到 $h_1$​ 和 $h_2$。</p>
</li>
<li><p><strong>隐藏层到隐藏层的权重</strong>：$W_{hh} = \begin{bmatrix} U_{11} &amp; U_{12} \ U_{21} &amp; U_{22} \end{bmatrix}$</p>
<ul>
<li>$U_{11}$和 $U_{12}$ 连接 $h_1(t-1)$到 $h_1(t)$ 和 $h_2(t)$。</li>
<li>$U_{21}$ 和 $U_{22}$ 连接 $h_2(t-1)$ 到 $h_1(t)$ 和 $h_2(t)$。<br>[[#5. 序列数据的处理]]</li>
</ul>
</li>
<li><p><strong>隐藏层到输出层的权重</strong>： $W_{hy} = \begin{bmatrix} W_{31} &amp; W_{32} \end{bmatrix}$</p>
<ul>
<li>$W_{31}$​ 和 $W_{32}$分别连接$h_1$ 和$h_2$到 $y$。</li>
</ul>
</li>
</ol>
<h3 id="前向传播过程"><a href="#前向传播过程" class="headerlink" title="前向传播过程"></a>前向传播过程</h3><p>对于每个时间步 $t$，前向传播的计算步骤如下：</p>
<h4 id="1-输入层到隐藏层"><a href="#1-输入层到隐藏层" class="headerlink" title="1. 输入层到隐藏层"></a>1. <strong>输入层到隐藏层</strong></h4><p>计算当前时间步的隐藏状态, 即正文中的“隐藏状态的更新”<br>$ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$<br>其中，$\mathbf{x}_t$​ 是当前时间步的输入向量，$\mathbf{h}_{t-1}$是前一时间步的隐藏状态。<br>具体展开如下：</p>
<p>$\begin{bmatrix} h_{1t} \ h_{2t} \end{bmatrix} = \text{tanh} \left( \begin{bmatrix} W_{11} &amp; W_{12} \ W_{21} &amp; W_{22} \end{bmatrix} \begin{bmatrix} x_{1t} \ x_{2t} \end{bmatrix} + \begin{bmatrix} U_{11} &amp; U_{12} \ U_{21} &amp; U_{22} \end{bmatrix} \begin{bmatrix} h_{1(t-1)} \ h_{2(t-1)} \end{bmatrix} + \begin{bmatrix} b_1 \ b_2 \end{bmatrix} \right)$</p>
<p>分开计算：<br>$h_{1t} = \text{tanh}(W_{11} x_{1t} + W_{12} x_{2t} + U_{11} h_{1(t-1)} + U_{12} h_{2(t-1)} )$</p>
<p>$h_{2t} = \text{tanh}(W_{21} x_{1t} + W_{22} x_{2t} + U_{21} h_{1(t-1)} + U_{22} h_{2(t-1)})$</p>
<h4 id="2-隐藏层到输出层"><a href="#2-隐藏层到输出层" class="headerlink" title="2.  隐藏层到输出层"></a>2.  <strong>隐藏层到输出层</strong></h4><p>计算当前时间步的输出。 $y_t = W_{hy} \mathbf{h}_t$<br>具体展开如下：<br>$y_t = \begin{bmatrix} W_{31} &amp; W_{32} \end{bmatrix} \begin{bmatrix} h_{1t} \ h_{2t} \end{bmatrix}$</p>
<p>分开计算：</p>
<p>$y_t = W_{31} h_{1t} + W_{32} h_{2t}$</p>
<p>⚠️： tanh 是非线性激活函数</p>
<h2 id="4-1-of-k编码"><a href="#4-1-of-k编码" class="headerlink" title="4. 1-of-k编码"></a>4. 1-of-k编码</h2><p>1-of-k编码，也称为独热编码（One-Hot Encoding），是一种将分类数据转换为二进制向量的方法。它的目的是将非数值型的类别变量转化为适合于机器学习算法处理的数值型数据。</p>
<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><p>假设有一个类别变量，它有 $k$ 个不同的类别。1-of-k编码将每个类别表示为一个长度为 $k$ 的二进制向量，其中只有一个位置为1，其他位置为0。</p>
<p>例如，考虑一个有四个类别的变量：”A”, “B”, “C”, “D”。其1-of-k编码如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>类别</th>
<th>1-of-k编码</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>[1, 0, 0, 0]</td>
</tr>
<tr>
<td>B</td>
<td>[0, 1, 0, 0]</td>
</tr>
<tr>
<td>C</td>
<td>[0, 0, 1, 0]</td>
</tr>
<tr>
<td>D</td>
<td>[0, 0, 0, 1]</td>
</tr>
</tbody>
</table>
</div>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li><strong>消除排序关系</strong>：独热编码将分类变量转化为二进制向量，避免了对分类变量的误解，即认为它们之间存在排序关系。</li>
<li><strong>适合模型处理</strong>：许多机器学习算法（如线性回归、逻辑回归等）无法直接处理非数值型数据，1-of-k编码使这些数据适合于这些算法。</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li><strong>高维度问题</strong>：当类别数量较多时，编码后的向量长度会变得很长，导致高维度问题，增加计算和存储成本。</li>
</ul>
<h4 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h4><ul>
<li><strong>文本处理</strong>：在自然语言处理（NLP）任务中，1-of-k编码常用于将单词转化为二进制向量。</li>
<li><strong>分类任务</strong>：在分类任务中，用于将类别标签转化为模型可以处理的数值型数据。</li>
</ul>
<p>1-of-k编码是数据预处理中的一种重要技术，广泛应用于各种机器学习和深度学习任务中。它帮助将分类数据转化为数值数据，使得各种模型能够更好地处理这些数据。</p>
<h2 id="5-置信度"><a href="#5-置信度" class="headerlink" title="5. 置信度"></a>5. 置信度</h2><p>在机器学习中，置信度（confidence）是衡量模型预测结果确定性的一个指标。置信度可以理解为模型对其预测的某个结果是正确的信心程度。</p>
<p>在机器学习中，置信度通常以概率值的形式表示，反映了模型对某个预测的确定性。例如，在分类任务中，模型对某个样本属于某一类的置信度可能是80%，表示模型认为该样本属于该类的概率为80%。<br>具体应用：</p>
<ul>
<li><strong>分类任务</strong>：如图像分类，模型输出每个类别的概率分布。例如，对于一张图片，模型可能输出：[猫: 0.7, 狗: 0.2, 兔子: 0.1]，其中猫的置信度最高。</li>
<li><p><strong>置信度阈值</strong>：在某些应用中，可能会设置一个置信度阈值，只有当预测的置信度超过某个值时，才认为预测有效。</p>
<h4 id="置信度的计算"><a href="#置信度的计算" class="headerlink" title="置信度的计算"></a>置信度的计算</h4></li>
<li><p><strong>概率分布</strong>：使用Softmax函数将模型输出的logits转化为概率分布，这些概率值即为置信度。</p>
</li>
<li><strong>Softmax公式</strong>：对于第 $i$ 个输出节点，置信度 $P(y_i)$ 为： $P(y_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}$ 其中， $z_i$ 是第 $i$ 个节点的logit。<h3 id="logits"><a href="#Logits" class="headerlink" title="Logits"></a>Logits</h3></li>
</ul>
<p>Logits 是神经网络在分类任务中的输出层的原始得分。它们是未经过归一化的数值，用于表示每个类别的相对置信度。Logits 是通过前向传播计算得到的，表示模型对每个可能的类别的初始估计。</p>
<h4 id="具体理解"><a href="#具体理解" class="headerlink" title="具体理解"></a>具体理解</h4><ol>
<li><strong>原始得分</strong>：Logits 是神经网络最后一层输出的原始分数，这些分数还没有被转换为概率。</li>
<li><strong>用途</strong>：在分类任务中，Logits 被用来计算每个类别的概率，这通常通过 Softmax 函数完成。</li>
<li><strong>Softmax 转换</strong>：Softmax 函数将 Logits 转换为概率分布，使得这些概率的和为1。公式如上</li>
</ol>
<h2 id="6-softmax"><a href="#6-Softmax" class="headerlink" title="6. Softmax"></a>6. Softmax</h2><p>[[0-神经网络（Neural Networks）#^cfe178]]</p>
<h1 id="7-超参数-temperature-温度"><a href="#7-超参数-Temperature-温度" class="headerlink" title="7. 超参数 Temperature 温度"></a>7. 超参数 Temperature 温度</h1><p>Temperature是在模型使用或调优过程中设定的参数，并不通过模型训练过程中的优化算法来更新，因此它属于超参数。<br>Temperature作为超参数，在神经网络中用来控制Softmax输出的概率分布平滑程度，它的作用是调节模型生成样本的多样性和确定性。</p>
<h4 id="temperature的公式"><a href="#Temperature的公式" class="headerlink" title="Temperature的公式"></a>Temperature的公式</h4><p>Softmax函数带有Temperature的公式如下：</p>
<p>$P(y_i) = \frac{e^{z_i / T}}{\sum_{j} e^{z_j / T}}$</p>
<p>其中，$z_i$ 是logits值，$T$ 是Temperature参数。</p>
<h4 id="temperature的影响"><a href="#Temperature的影响" class="headerlink" title="Temperature的影响"></a>Temperature的影响</h4><ol>
<li><p><strong>高Temperature（T &gt; 1）</strong>：</p>
<ul>
<li><strong>平滑分布</strong>：使概率分布更加平滑，增加生成样本的多样性。</li>
<li><strong>增加随机性</strong>：输出类别之间的概率差距缩小，使得选择更随机。</li>
</ul>
<p>示例：假设 logits 为 $[2.0,1.0,0.1]$，使用 $T = 2$ 时，概率可能变得更接近，如 $[0.4,0.35,0.25]$。</p>
</li>
<li><p><strong>低Temperature（0 &lt; T &lt; 1）</strong>：</p>
<ul>
<li><strong>尖锐分布</strong>：使概率分布更加尖锐，增加生成样本的确定性。</li>
<li><strong>减少随机性</strong>：输出类别之间的概率差距加大，使得选择更确定。</li>
</ul>
<p>示例：假设 logits 为 $[2.0,1.0,0.1]$，使用 $T = 0.5$ 时，概率可能变得更尖锐，如 $[0.7,0.25,0.05]$。</p>
</li>
<li><p><strong>Temperature等于1</strong>：</p>
<ul>
<li><strong>标准Softmax</strong>：概率分布保持原样，不做任何调整。</li>
</ul>
</li>
</ol>
<h4 id="作用及应用场景"><a href="#作用及应用场景" class="headerlink" title="作用及应用场景"></a>作用及应用场景</h4><ol>
<li><strong>文本生成</strong>：<ul>
<li>控制生成文本的多样性和创造性。在文本生成任务中，高Temperature可能生成更有创意但不一定合理的句子，而低Temperature可能生成更合理但缺乏多样性的句子。</li>
</ul>
</li>
<li><strong>探索与利用</strong>：<ul>
<li>在强化学习中，高Temperature用于探索多样性策略，低Temperature用于利用已知的最佳策略。</li>
</ul>
</li>
</ol>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/7057a5e3/">RECURRENT NEURAL NETWORK REGULARIZATION</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/6ac941eb/">递归神经网络（Recurrent Neural Networks, RNNs）</a></div></section></div>






<footer class="page-footer footnote"><hr><div class="text"><p>本站由 <a href="/">Sun Yan</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.28.1">Stellar 1.28.1</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#recurrent-neural-networks-%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">Recurrent Neural Networks  递归神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sequences"><span class="toc-text">Sequences</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rnn-computation"><span class="toc-text">RNN computation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#going-deep"><span class="toc-text">Going deep</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#getting-fancy"><span class="toc-text">Getting fancy</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#character-level-language-models"><span class="toc-text">Character-Level Language Models</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#fun-with-rnns"><span class="toc-text">Fun with RNNs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#paul-graham-generator-%E4%BF%9D%E7%BD%97%E6%A0%BC%E9%9B%B7%E5%8E%84%E5%A7%86%E5%8F%91%E7%94%B5%E6%9C%BA"><span class="toc-text">Paul Graham generator 保罗·格雷厄姆发电机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#shakespeare-%E8%8E%8E%E5%A3%AB%E6%AF%94%E4%BA%9A"><span class="toc-text">Shakespeare 莎士比亚</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#wikipedia-%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91"><span class="toc-text">Wikipedia 维基百科</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#algebraic-geometry-latex-%E4%BB%A3%E6%95%B0%E5%87%A0%E4%BD%95latex"><span class="toc-text">Algebraic Geometry (Latex)  代数几何（Latex）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#linux-source-code-linux-%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="toc-text">Linux Source Code Linux 源代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#generating-baby-names-%E7%94%9F%E6%88%90%E5%A9%B4%E5%84%BF%E5%90%8D%E5%AD%97"><span class="toc-text">Generating Baby Names 生成婴儿名字</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#understanding-whats-going-on"><span class="toc-text">Understanding what’s going on</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#the-evolution-of-samples-while-training"><span class="toc-text">The evolution of samples while training</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#visualizing-the-predictions-and-the-neuron-firings-in-the-rnn"><span class="toc-text">Visualizing the predictions and the “neuron” firings in the RNN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#source-code-%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="toc-text">Source Code 源代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#further-reading-%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB"><span class="toc-text">Further Reading 延伸阅读</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#conclusion-%E7%BB%93%E8%AE%BA"><span class="toc-text">Conclusion 结论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#edit-extra-links-%E7%BC%96%E8%BE%91%E9%A2%9D%E5%A4%96%E9%93%BE%E6%8E%A5"><span class="toc-text">EDIT (extra links): 编辑（额外链接）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B3%A8%E9%87%8A"><span class="toc-text">注释</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1vanilla-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">1.Vanilla 神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%90%91%E9%87%8Fvectorvs-%E5%BA%8F%E5%88%97sequence"><span class="toc-text">2. 向量（Vector）vs 序列（Sequence）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-rnn-computation"><span class="toc-text">3. RNN computation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E7%9F%A9%E9%98%B5"><span class="toc-text">权重矩阵</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B"><span class="toc-text">前向传播过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%BE%93%E5%85%A5%E5%B1%82%E5%88%B0%E9%9A%90%E8%97%8F%E5%B1%82"><span class="toc-text">1. 输入层到隐藏层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%9A%90%E8%97%8F%E5%B1%82%E5%88%B0%E8%BE%93%E5%87%BA%E5%B1%82"><span class="toc-text">2.  隐藏层到输出层</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-of-k%E7%BC%96%E7%A0%81"><span class="toc-text">4. 1-of-k编码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-text">缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8"><span class="toc-text">实际应用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%BD%AE%E4%BF%A1%E5%BA%A6"><span class="toc-text">5. 置信度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%AE%E4%BF%A1%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">置信度的计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#logits"><span class="toc-text">Logits</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E7%90%86%E8%A7%A3"><span class="toc-text">具体理解</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-softmax"><span class="toc-text">6. Softmax</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-%E8%B6%85%E5%8F%82%E6%95%B0-temperature-%E6%B8%A9%E5%BA%A6"><span class="toc-text">7. 超参数 Temperature 温度</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#temperature%E7%9A%84%E5%85%AC%E5%BC%8F"><span class="toc-text">Temperature的公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#temperature%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">Temperature的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-text">作用及应用场景</span></a></li></ol></li></ol></li></ol></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>回到顶部</span></a><a class="buttom" onclick="util.scrollComment()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M10.46 1.25h3.08c1.603 0 2.86 0 3.864.095c1.023.098 1.861.3 2.6.752a5.75 5.75 0 0 1 1.899 1.899c.452.738.654 1.577.752 2.6c.095 1.004.095 2.261.095 3.865v1.067c0 1.141 0 2.036-.05 2.759c-.05.735-.153 1.347-.388 1.913a5.75 5.75 0 0 1-3.112 3.112c-.805.334-1.721.408-2.977.43a10.81 10.81 0 0 0-.929.036c-.198.022-.275.054-.32.08c-.047.028-.112.078-.224.232c-.121.166-.258.396-.476.764l-.542.916c-.773 1.307-2.69 1.307-3.464 0l-.542-.916a10.605 10.605 0 0 0-.476-.764c-.112-.154-.177-.204-.224-.232c-.045-.026-.122-.058-.32-.08c-.212-.023-.49-.03-.93-.037c-1.255-.021-2.171-.095-2.976-.429A5.75 5.75 0 0 1 1.688 16.2c-.235-.566-.338-1.178-.389-1.913c-.049-.723-.049-1.618-.049-2.76v-1.066c0-1.604 0-2.86.095-3.865c.098-1.023.3-1.862.752-2.6a5.75 5.75 0 0 1 1.899-1.899c.738-.452 1.577-.654 2.6-.752C7.6 1.25 8.857 1.25 10.461 1.25M6.739 2.839c-.914.087-1.495.253-1.959.537A4.25 4.25 0 0 0 3.376 4.78c-.284.464-.45 1.045-.537 1.96c-.088.924-.089 2.11-.089 3.761v1c0 1.175 0 2.019.046 2.685c.045.659.131 1.089.278 1.441a4.25 4.25 0 0 0 2.3 2.3c.515.214 1.173.294 2.429.316h.031c.398.007.747.013 1.037.045c.311.035.616.104.909.274c.29.17.5.395.682.645c.169.232.342.525.538.856l.559.944a.52.52 0 0 0 .882 0l.559-.944c.196-.331.37-.624.538-.856c.182-.25.392-.476.682-.645c.293-.17.598-.24.909-.274c.29-.032.639-.038 1.037-.045h.032c1.255-.022 1.913-.102 2.428-.316a4.25 4.25 0 0 0 2.3-2.3c.147-.352.233-.782.278-1.441c.046-.666.046-1.51.046-2.685v-1c0-1.651 0-2.837-.089-3.762c-.087-.914-.253-1.495-.537-1.959a4.25 4.25 0 0 0-1.403-1.403c-.464-.284-1.045-.45-1.96-.537c-.924-.088-2.11-.089-3.761-.089h-3c-1.651 0-2.837 0-3.762.089" clip-rule="evenodd"/><path fill="currentColor" d="M9 11a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0"/></svg><span>参与讨论</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.28.1" async></script>

<!-- optional -->



<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://cdn.bootcdn.net/ajax/libs/flying-pages/2.1.2/flying-pages.min.js"></script><script defer src="https://cdn.bootcdn.net/ajax/libs/vanilla-lazyload/17.8.4/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });
</script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.min.css`,
    js: `https://cdn.bootcdn.net/ajax/libs/fancyapps-ui/5.0.22/fancybox/fancybox.umd.min.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || slide.triggerEl.dataset.caption || null
        }
      });
    })
  }
</script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3.1/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\(","\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="//cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body></html>
