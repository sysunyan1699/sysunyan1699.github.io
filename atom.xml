<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sun Yan</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-04-30T01:38:27.626Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Sun Yan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用github page+hexo 创建个人网站</title>
    <link href="http://example.com/2024/04/29/%E4%BD%BF%E7%94%A8githubpage-hexo%E5%88%9B%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
    <id>http://example.com/2024/04/29/%E4%BD%BF%E7%94%A8githubpage-hexo%E5%88%9B%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</id>
    <published>2024-04-29T01:29:29.000Z</published>
    <updated>2024-04-30T01:38:27.626Z</updated>
    
    <content type="html"><![CDATA[<p>关于使用 github page + hexo 创建个人网站， <a href="https://hexo.io/zh-cn/">hexo官网</a>上的步骤已经非常详细，网上也有非常多相关的文章， 所以基础步骤就不写了。</p><p>这里记录一些个性化过程中遇到的问题。</p><h1 id="toc-锚点失效"><a href="#TOC-锚点失效" class="headerlink" title="TOC 锚点失效"></a>TOC 锚点失效</h1><p>文章目录正常生成了，但是点击目录无法跳转到文章对应位置。<br><a href="https://convivae.top/posts/hexo-bo-ke-cai-keng/#%E6%96%B9%E6%B3%95-2">解决办法点这里查看</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;关于使用 github page + hexo 创建个人网站， &lt;a href=&quot;https://hexo.io/zh-cn/&quot;&gt;hexo官网&lt;/a&gt;上的步骤已经非常详细，网上也有非常多相关的文章， 所以基础步骤就不写了。&lt;/p&gt;
&lt;p&gt;这里记录一些个性化过程中遇到的问题。</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>基于2PC+MySQL+泛化调用实现的可靠消息中心</title>
    <link href="http://example.com/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/"/>
    <id>http://example.com/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/</id>
    <published>2024-04-09T08:41:51.000Z</published>
    <updated>2024-04-30T00:47:55.763Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-项目结构介绍"><a href="#0-项目结构介绍" class="headerlink" title="0. 项目结构介绍"></a>0. 项目结构介绍</h1><table><thead><tr><th>Module</th><th>Description</th></tr></thead><tbody><tr><td>trustmessage-mysql</td><td>基于2PC+MySQL表实现的可靠消息中心，业务操作+消息表操作均存在于同一个项目中</td></tr><tr><td>turstmessage-middleware</td><td>可靠消息中心中间件，基于RPC接口提交消息+2PC+MySQL 表实现</td></tr><tr><td>turstmessage-middlewareapi</td><td>可靠消息中心中间件， 回查接口定义</td></tr><tr><td>Turstmessage-middlewareclient</td><td>可靠消息中心中间件， 消息生产者，提供了HTTP回查接口、Dubbo泛化回查接口的示例</td></tr></tbody></table><p>以下是项目正式介绍。</p><p>在业务处理中，经常会有重要但没那么紧急的数据需要同步给下游，比如</p><ol><li>订单侧完成消息后给优惠侧发一个消息，优惠侧做一个单向对账的功能，确保券被正确核销</li></ol><p>在这种场景中，需要把本地业务操作 + 消息发送当成一个事务处理，即满足原子性， 一般常见的解决方案会有两种</p><ol><li>本地事务+本地消息表</li><li>RocketMQ</li></ol><p>本项目将从本地事务+本地消息表 出发， 一步步探讨如何用 MySQL  实现一个支持分布式事务的可靠消息中心，即TrustMessage。</p><h1 id="1-本地事务-本地消息表"><a href="#1-本地事务-本地消息表" class="headerlink" title="1. 本地事务+ 本地消息表"></a>1. 本地事务+ 本地消息表</h1><p>由于Spring 的事务机制只保证数据库操作的原子性，所以当涉及到 数据库的业务操作 和 其他中间件如kafka操作 具有原子性的时候，就要用其他的方案来保证。</p><p>本地事务+ 本地消息表 这种方案是把 需要发送的消息作为数据库操作的一部分，保存到数据库中的一个表里，然后通过另外的逻辑，将消息的真正发送 稍后异步进行，比如用一个定时任务将消息异步发送到Kafka。</p><p>这种方法确保了数据库操作和消息发送在<code>逻辑语义上的原子性</code>，因为它们都在同一个数据库事务中处理。</p><p>这里需要注意，这种方案的实时性是比较差的，所以你需要判断的业务场景场景是否能够容忍这样的异步操作。</p><h2 id="11-业务流程"><a href="#1-1-业务流程" class="headerlink" title="1.1 业务流程"></a>1.1 业务流程</h2><img src="/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/1.png" class><p>以上流程中，在本地事务提交后，有一个定时任务轮询消息表将需要发送的消息消息发送出去。有4个点需要注意一下</p><ol><li>事务提交后了，消息发送失败， 定时任务的重试机制，会找出这条消息进行异步补发 </li><li>事务提交后了，消息发送成功，但是消息状态修改状态， 定时任务会找出这条再次发送</li><li>重试异步补发过程中，如果消息依然发送失败，那么会继续重试补发</li><li>重试异步补发过程中，消息发送成功，但是数据库消息已发送状态修改失败，那么定时任务又会再次找到这条消息再发一遍</li></ol><p>以上 2和4 均会面临消息重复的情况， 个人认为在业务常见中消息重复是一种可接受的情况，有时候业务自己甚至会消息重放， 所以消息消费者做好幂等逻辑就可以了。</p><h2 id="12-消息发送重试次数"><a href="#1-2-消息发送重试次数" class="headerlink" title="1.2 消息发送重试次数"></a>1.2 消息发送重试次数</h2><p>消息发送不能无限次重试</p><ol><li><p>浪费资源，重试了那么多次都未成功，可能是逻辑出现问题了或者宕机了，赶紧去查问题吧</p></li><li><p>上下游业务数据迟迟无法达到最终一致性 ， 本身我们使用消息其终极目的就是为了让系统数据达到最终一致性， 如果一直无限制发送，这个目的是无法达到的, 所以赶紧停下去查问题吧</p></li></ol><p>基于以上两个考虑，系统对于重试都应该有个次数限制，达到次数限制后就应该告警让人工介入处理。</p><h2 id="13-消息表设计"><a href="#1-3-消息表设计" class="headerlink" title="1.3 消息表设计"></a>1.3 消息表设计</h2><p>在本地事务+ 本地消息表 方案中，其消息表的设计一般如下，</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> message (</span><br><span class="line">id <span class="type">bigint</span> unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">message text COMMENT <span class="string">&#x27;消息内容&#x27;</span>,</span><br><span class="line">send_status <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;0-投递中 1-投递成功 2-投递失败&#x27;</span>,</span><br><span class="line">send_try_count <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;commit 消息发送 当前重试次数&#x27;</span>,</span><br><span class="line">send_next_retry_time DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;消息发送 下次重试时间&#x27;</span>,</span><br><span class="line">create_time DATETIME <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line">update_time DATETIME <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (id),</span><br><span class="line"><span class="keyword">UNIQUE</span> INDEX idx_messageKey(message_key)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure><h1 id="2-如果消息表和业务表操作是分布式事务"><a href="#2-如果消息表和业务表操作是分布式事务" class="headerlink" title="2. 如果消息表和业务表操作是分布式事务"></a>2. 如果消息表和业务表操作是分布式事务</h1><p>但是如果保证不了这两个表不在同一个库 &#x2F;数据库实例中，那就会在业务操作和消息表写入两个操作中遇到分布式事务。这在分库分表的业务中是很容易出现的情况。</p><p>针对对分布式事务，常见的解决方案就是 2PC、3PC、TCC、SAGA。</p><p>接下来将讲解以 2PC+MySQL消息表 实现的可靠消息中心</p><h2 id="21-业务流程"><a href="#2-1-业务流程" class="headerlink" title="2.1 业务流程"></a>2.1 业务流程</h2><p>以MySQL消息表+ 2PC 来实现可靠消息中心， 其整体实现流程如下</p><img src="/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/2.png" class><h2 id="22-消息可见性"><a href="#2-2-消息可见性" class="headerlink" title="2.2 消息可见性"></a>2.2 消息可见性</h2><p>消息可见性， 在涉及分布式事务的场景中，消息增加了一个<code>可见性</code>概念， 这是因为在引入2PC 后，写入消息表的消息不再像本地事务+本地消息表一样<code>写入即可见</code>，必须是commit后才对消费者可见， 所以在数据表的设计中需要增加一个状态字段来维护消息可见性。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">message_status INT COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;,</span><br></pre></td></tr></table></figure><p>其状态流转如图所示</p><img src="/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/3.png" class><h2 id="23-如果业务执行消息commit-or-rollback-失败怎么办-消息回查"><a href="#2-3-如果业务执行消息commit-or-rollback-失败怎么办-消息回查" class="headerlink" title="2.3 如果业务执行消息commit or rollback 失败怎么办-消息回查"></a>2.3 如果业务执行消息commit or rollback 失败怎么办-消息回查</h2><p>如流程图中所示，在2PC 阶段，拿到业务执行结果修改消息状态失败有可能是失败。</p><p>一个操作执行失败后，一种常见的解决方案方案就是重试，尽最大努力交付。</p><p>但是对于业务处理来讲，一般有超时时间的限制，因为这种同步重试可能并不适用，即使可以，一般重试次数都会限定在3次。</p><p>除了同步重试，还有一种方案就是 消息回查，我个人理解这相当于一种异步重试。</p><p>在本项目中，消息回查指的就是开启一个定时任务去全表扫描，找出insert一定时间后，其状态仍然是 prepare的消息 ，通过业务逻辑判断该条消息是否已经执行完成 or 失败，对应地把消息状态更改为 commit or rollback。</p><p>为了进行消息回查，肯定要有一个业务唯一标识来识别该条消息需要对应业务数据，从而判断对应业务是否执行完成。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;,</span><br></pre></td></tr></table></figure><h2 id="24-消息回查不能无限次"><a href="#2-4-消息回查不能无限次" class="headerlink" title="2.4 消息回查不能无限次"></a>2.4 消息回查不能无限次</h2><ol><li>浪费资源，回查了这么多次的都没拿到结果，一种可能就是业务逻辑出现问题了，适可而止赶紧去查问题吧</li><li>系统数据迟迟无法达到最终一致性 ， 本身我们使用消息其终极目的就是为了让系统数据达到最终一致性， 如果一直无限制查询，这个目的是无法达到的, 所以赶紧停下去查问题吧</li></ol><p>所有消息回查应该有个次数限制， 这就是表中以下两个字段的作用</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">verify_try_count <span class="type">INT</span> COMMENT <span class="string">&#x27;消息状态回查 下次重试次数&#x27;</span>,  </span><br><span class="line">verify_next_retry_time <span class="type">TIMESTAMP</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;消息状态回查 下次重试时间 1-未发送 2-已发送&#x27;</span>,</span><br></pre></td></tr></table></figure><h2 id="25-消息回查次数达到上限怎么办"><a href="#2-5-消息回查次数达到上限怎么办" class="headerlink" title="2.5 消息回查次数达到上限怎么办"></a>2.5 消息回查次数达到上限怎么办</h2><p>有两种参考方案</p><ol><li>默认修改消息状态为commit  或者 rollback，</li><li>将消息状态置为回查失败状态 ， 告警人工介入处理</li></ol><p>默认修改消息状态为commit  或者 rollback 这个方案，一个最大的问题就是针对状态不确定的消息，不论将其默认修改为那种状态， 都是有可能引起业务上下游数据不一致问题。</p><p>一旦上下游数据产生了数据不一致性，必然导致很长的排查链路和大量的数据修复工作。</p><p>所以本项目中我选择第二种方案，消息回查达到上限后直接告警，让消息生产者这一方人工介入处理。</p><p>此处说明一下，这种方案当然也会有数据不一致的问题，因为下游业务始终还未拿到消息修改自己的状态，但是相比拿到了随机确定的的状态 导致的数据不一致性，此时问题还被控制在消息生产者这一环，问题排查会相对简单。</p><h2 id="26-消息发送重试"><a href="#2-6-消息发送重试" class="headerlink" title="2.6 消息发送重试"></a>2.6 消息发送重试</h2><p>与本地事务+本地消息表方案一致</p><h2 id="27-消息表设计"><a href="#2-7-消息表设计" class="headerlink" title="2.7 消息表设计"></a>2.7 消息表设计</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> message (</span><br><span class="line">id <span class="type">bigint</span> unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">message_key <span class="type">VARCHAR</span>(<span class="number">255</span>) COMMENT <span class="string">&#x27;消息唯一键，用于做回查的标识&#x27;</span>,</span><br><span class="line">message text COMMENT <span class="string">&#x27;消息内容&#x27;</span>,</span><br><span class="line">message_status <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">1</span> COMMENT <span class="string">&#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;</span>,</span><br><span class="line">verify_try_count <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;消息状态回查 当前重试次数&#x27;</span>,</span><br><span class="line">verify_next_retry_time DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;消息状态回查 下次重试时间&#x27;</span>,</span><br><span class="line">send_status <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;0-投递中 1-投递成功 2-投递失败&#x27;</span>,</span><br><span class="line">send_try_count <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;commit 消息发送 当前重试次数&#x27;</span>,</span><br><span class="line">send_next_retry_time DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;消息发送 下次重试时间&#x27;</span>,</span><br><span class="line">create_time DATETIME <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line">update_time DATETIME <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (id),</span><br><span class="line"><span class="keyword">UNIQUE</span> INDEX idx_messageKey(message_key)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure><h2 id="28-消费者消费消息"><a href="#2-8-消费者消费消息" class="headerlink" title="2.8 消费者消费消息"></a>2.8 消费者消费消息</h2><p>针对可见， 即已经commit 的消息，消费者该如何获取到消息消费呢，有两种方案</p><ol><li>消息者直接查询消息表</li><li>消费者从消息队列队列消费</li></ol><h3 id="281-消息者轮训消息表"><a href="#2-8-1-消息者轮训消息表" class="headerlink" title="2.8.1 消息者轮训消息表"></a>2.8.1 消息者轮训消息表</h3><p>这种方案最大的问题就是，在微服务架构下，上下游两个不同的服务 操作 同一个数据表 是一个不合理且不推荐的做法。</p><h3 id="282-消息队列消费"><a href="#2-8-2-消息队列消费" class="headerlink" title="2.8.2 消息队列消费"></a>2.8.2 消息队列消费</h3><p>和本地事务+本地消息表一样，已经commit 的消息可以由一个定时任务轮训发送到业务创建的消息队列中供订阅的消费者消费<br>发送过程也可以有一个重试的过程。</p><h1 id="3-如果这是一个公共中间件-基于rpc-接口实现的可靠消息中心"><a href="#3-如果这是一个公共中间件-基于RPC-接口实现的可靠消息中心" class="headerlink" title="3. 如果这是一个公共中间件-基于RPC 接口实现的可靠消息中心"></a>3. 如果这是一个公共中间件-基于RPC 接口实现的可靠消息中心</h1><p>以上讨论的方案， 都是基于消息表逻辑和业务逻辑同一个服务中， 如果把该功能做成一个公共中间件，那么在技术方案上会略有变化。</p><p>中间件需要提供的功能</p><ol><li>两阶段提交功能</li><li>回查功能</li><li>消息转发</li></ol><p>以上3个功能和上一种方案没有本质上的区别， 只是基于一个中间件的定位，支持这3种功能需要更多的封装与数据信息。</p><h2 id="31-业务流程"><a href="#3-1-业务流程" class="headerlink" title="3.1 业务流程"></a>3.1 业务流程</h2><img src="/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/4.png" class><h2 id="32-两阶段提交功能"><a href="#3-2-两阶段提交功能" class="headerlink" title="3.2 两阶段提交功能"></a>3.2 两阶段提交功能</h2><p>提供3个RPC 接口， prepare， commit, rollback, 接口底层封装对数据表的操作</p><h2 id="33-消息唯一性"><a href="#3-3-消息唯一性" class="headerlink" title="3.3 消息唯一性"></a>3.3 消息唯一性</h2><p>当作为一个公共中间件，接受多个业务数据的时候，消息的唯一性应该有业务标识 + 消息标识共同确定，即bizId + messageKey</p><h2 id="34-回查功能"><a href="#3-4-回查功能" class="headerlink" title="3.4 回查功能"></a>3.4 回查功能</h2><p>相比于直接在业务服务里集成可靠消息的功能时，可以简单直接的在服务内部查询，当作为公共中间件时，  只能通过服务间调用完成，服务间调用有两种形式</p><ol><li>HTTP</li><li>RPC</li></ol><p>为了增加可维护性和拓展型， 无论是哪种形式，中间件都应该定义好调用的格式，让消息生产者按照统一格式提供回查接口。</p><p>这个格式包括</p><ol><li>接口定义</li><li>接口入参</li><li>接口返回值</li></ol><p>其中接口定义信息需要生产消息时提供</p><p>在实现消息生产者按照统一格式提供回查接口 这一点是，HTTP接口的回查相对简单， 如果RPC 接口， 要注意使用泛化调用。</p><p>本项目实现了HTTP 接口的回查和 Dubbo 协议的泛化调用回查</p><p>HTTP接口格式为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://127.0.0.1:8082/verifyMessage?bizID=1&amp;messageKey=key1</span><br></pre></td></tr></table></figure><p>Dubbo RPC 接口定义为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public interface VerifyMessageService &#123;  </span><br><span class="line">  </span><br><span class="line">// 消息回查接口  </span><br><span class="line">int verifyMessage(Integer bizID,String messageKey);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="35-消息转发"><a href="#3-5-消息转发" class="headerlink" title="3.5 消息转发"></a>3.5 消息转发</h2><p>在一个公共中间件里实现消息转发，必然也需要生产消息时提供这部分信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">forward_topic VARCHAR(255) COMMENT &#x27;业务转发topic&#x27;,  </span><br><span class="line">forward_key VARCHAR(255) COMMENT &#x27;业务转发指定key&#x27;,  </span><br></pre></td></tr></table></figure><h2 id="36-消息表设计"><a href="#3-6-消息表设计" class="headerlink" title="3.6 消息表设计"></a>3.6 消息表设计</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> message (</span><br><span class="line">id <span class="type">bigint</span> unsigned <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">    biz_id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;业务ID&#x27;</span>,</span><br><span class="line">    message_key <span class="type">VARCHAR</span>(<span class="number">255</span>) COMMENT <span class="string">&#x27;消息唯一键，用于做回查的标识&#x27;</span>,</span><br><span class="line">message text COMMENT <span class="string">&#x27;消息内容&#x27;</span>,</span><br><span class="line">message_status <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">1</span> COMMENT <span class="string">&#x27;消息状态 1-prepare 2-commit 3-rollback 4-verify fail&#x27;</span>,</span><br><span class="line">    forward_topic <span class="type">VARCHAR</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;业务转发topic&#x27;</span>,</span><br><span class="line">forward_key <span class="type">VARCHAR</span>(<span class="number">255</span>) COMMENT <span class="string">&#x27;业务转发指定key&#x27;</span>,</span><br><span class="line">    verify_info <span class="type">VARCHAR</span>(<span class="number">2000</span>) COMMENT <span class="string">&#x27;回查信息&#x27;</span>,</span><br><span class="line">verify_try_count <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;消息状态回查 当前重试次数&#x27;</span>,</span><br><span class="line">verify_next_retry_time DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;消息状态回查 下次重试时间&#x27;</span>,</span><br><span class="line">send_status <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;0-投递中 1-投递成功 2-投递失败&#x27;</span>,</span><br><span class="line">send_try_count <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span> COMMENT <span class="string">&#x27;commit消息发送 当前重试次数&#x27;</span>,</span><br><span class="line">send_next_retry_time DATETIME  <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> COMMENT <span class="string">&#x27;消息发送 下次重试时间&#x27;</span>,</span><br><span class="line">create_time DATETIME <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line">update_time DATETIME <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="built_in">CURRENT_TIMESTAMP</span>,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (id),</span><br><span class="line"><span class="keyword">UNIQUE</span> INDEX idx_message_key_biz_id (message_key, biz_id)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure><h1 id="4-基于kafka-提交消息实现的可靠事件中心"><a href="#4-基于kafka-提交消息实现的可靠事件中心" class="headerlink" title="4. 基于kafka 提交消息实现的可靠事件中心"></a>4. 基于kafka 提交消息实现的可靠事件中心</h1><p>在实现消息回查的可靠消息中心方案中，另外一种常见的方案是 业务代码直接把消息提交给kafka, 然后中间件消费消息并持久化道数据库中，等待消息提交commit 或者rollback , 没有的话就进行回查。如下图，图片源自极客时间专栏</p><img src="/2024/04/09/%E5%9F%BA%E4%BA%8E2PC-MySQL-%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E4%B8%AD%E5%BF%83/5.png" class><p>我认为两种技术方案没有本质的区别， 其差异只是消息的prepare 、commit、rollback 的提交是由RPC 接口完成还是由消息生产消费完成， 其他回查的逻辑、发送逻辑、以及需要的信息基本无差异。</p><p>不过在使用Kafka 提交时，有以下两种需要考虑</p><h2 id="41-中间件如何识别一条消息是事务消息"><a href="#4-1-中间件如何识别一条消息是事务消息" class="headerlink" title="4.1 中间件如何识别一条消息是事务消息"></a>4.1 中间件如何识别一条消息是事务消息</h2><ol><li>Topic命名约定</li></ol><p>一种简单的方法是通过Topic命名来区分。例如，所有需要支持回查的Topic可以遵循一个特定的命名模式，如添加前缀或后缀（例如，<code>replayable-myTopic</code>）。这种方法的优点是简单易实施，但缺点是灵活性较低，且对现有系统可能需要更多的改动。</p><ol start="2"><li>特定主题或分区</li></ol><p>将需要回查的消息发送到Kafka的特定主题或分区中。这样，中间件只需监听这个特定的主题或分区来处理需要回查的消息。这种方法要求生产者在发送消息时知道哪些消息需要回查，并据此发送到正确的主题或分区。</p><ol start="3"><li>Topic配置属性</li></ol><p>Kafka允许为每个Topic设置自定义配置属性。可以引入一个自定义属性（如<code>replayable=true</code>）来标识一个Topic需要支持消息回查。这种方式比命名约定更为灵活和隐蔽，但要求应用层和消息生产者遵循这一约定，并且需要在应用层实现逻辑来处理这些属性。</p><ol start="4"><li>消息元数据标记</li></ol><p>在消息发送时，可以在消息的元数据（Metadata）中添加特定的标记或字段来指示这条消息需要进行回查。</p><p>设计考虑：</p><ul><li><strong>性能</strong>：确定这些方法中哪一种对生产和消费的性能影响最小。</li><li><strong>易用性</strong>：选择易于实施和维护的方法。</li><li><strong>灵活性</strong>：评估是否需要对单个消息进行标记，还是以Topic为单位进行区分。</li></ul><h2 id="42-如何识别消息类型-转发信息-回查信息"><a href="#4-2-如何识别消息类型、转发信息、回查信息" class="headerlink" title="4.2 如何识别消息类型、转发信息、回查信息"></a>4.2 如何识别消息类型、转发信息、回查信息</h2><p>消息类型包括 prepare、commit、rollback<br>转发信息,需要转发至的真正业务tpoic、 如果需要指定分区的话还包括key信息<br>回查信息，包括回查方式如HTTP、RPC, 回查地址，回查接口等</p><ol><li>使用Kafka消息头</li></ol><p><strong>优点</strong>：</p><ul><li>保持了消息体的纯净和独立性。</li><li>灵活性高，易于添加或修改额外的控制信息和元数据。</li><li>性能考虑，对于小到中等大小的消息，使用消息头的性能开销相对较小<br><strong>缺点</strong>：</li><li>新版本依赖：较旧版本的Kafka客户端可能不支持消息头功能，这要求生产者和消费者使用支持消息头的Kafka版本。</li><li><strong>额外处理</strong>：消费者需要额外的步骤来读取和解析消息头。</li></ul><ol start="2"><li>预先定义消息格式</li></ol><p><strong>优点</strong>：</p><ul><li>直接且简单，易于实现。</li><li>不依赖Kafka特定的功能，具有较好的兼容性。<br><strong>缺点</strong>：</li><li>增加了消息体的大小。</li><li>需要在消费端进行消息解析，略微增加了处理的复杂性。</li></ul><p>本项目以指定topic+预定义消息格式的方式简单实现了消息的提交，消息格式如下， 大家可以参考。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package com.example.trustmessage.middlewareapi.common;</span><br><span class="line">public class MiddlewareMessage &#123;  </span><br><span class="line">  </span><br><span class="line">// 要给到业务方的真正消息  </span><br><span class="line">private String message;  </span><br><span class="line"></span><br><span class="line">private int bizID; </span><br><span class="line">  </span><br><span class="line">// 用于消息回查的业务唯一标识  </span><br><span class="line">private String messageKey;  </span><br><span class="line"> </span><br><span class="line">private int messageStatus;  </span><br><span class="line">  </span><br><span class="line">private String forwardTopic;  </span><br><span class="line">  </span><br><span class="line">// 向业务方转发时需要指定的key，没有则说明按照kafka 默认分区策略进行分区  </span><br><span class="line">private String forwardKey;  </span><br><span class="line">  </span><br><span class="line">private VerifyInfo verifyInfo;  </span><br><span class="line">   </span><br><span class="line">public static class VerifyInfo &#123;  </span><br><span class="line">private int protocolType; // 1-http, 2-rpc-dubbo  </span><br><span class="line">private String registryProtocol;  </span><br><span class="line">private String registryAddress;  </span><br><span class="line">private String url;  </span><br><span class="line">private String version;   </span><br><span class="line">&#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="5-基于rpc接口-vs-基于kafka提交"><a href="#5-基于RPC接口-vs-基于Kafka提交" class="headerlink" title="5. 基于RPC接口 vs 基于Kafka提交"></a>5. 基于RPC接口 vs 基于Kafka提交</h1><p>基于两种不同消息提交方式实现的中间件， 将从以下两方面进行比较</p><ol><li>消息的顺序性</li><li>流量增加后扩容</li></ol><h2 id="51-消息的顺序性"><a href="#5-1-消息的顺序性" class="headerlink" title="5.1 消息的顺序性"></a>5.1 消息的顺序性</h2><p>使用中间件回查机制，由于网络原因，有可能出现 某条业务的commit or rollback 消息比prepare 先到达中间件，面对这种情况,commit or rollback的处理逻辑是需要报错的，client 只能重试或者等待回查机制更新消息状态</p><p>但是由于kafka 可以在一个分区内的保证消息的有序性，所以基于Kafka提交的方案可以有一种优雅的方式保证prepare消息和commit&#x2F;rollback 消息的有序性。</p><p>解决方案很简单，生产者在发送消息按照业务 唯一标识指定key ,即指定目标分区即可。</p><h2 id="52-流量增加后扩容"><a href="#5-2-流量增加后扩容" class="headerlink" title="5.2 流量增加后扩容"></a>5.2 流量增加后扩容</h2><p>以下比较基于在代码层面已经做好分库分表、异步处理、批量处理、cache 等性能优化的基础上</p><p>假设已经分库分表，数据库处理不是瓶颈<br>万一流量激增，基于Kafka提交的方案 可能会产生产生必须要处理的消息积压，针对消息积压常见的解决方案中</p><ol><li>增加消费者数量，不过一般来讲，线上生产环境都会已经把消费者数量和分区数量设置成一样的，所以这个方案无法发挥功能</li><li>增加分区数量，假设公司的工作流程里允许增加，如果使用场景对消息顺序性有要求，你又要考虑新增分区后对消息顺序性的影响</li><li>新建一个更多分区的topic, 涉及到生产者、消费者的代码变更</li><li>消费者性能优化， 比如异步处理、批量处理， 但是如果项目已经做好这些措施，面对消息积压，只能回到下面3种方式</li></ol><p>综合以上，我个人认为基于RPC接口的方案可以用<code>自动扩容策略</code>直接应对， 简单直接优雅。</p><h1 id="6-作为中间件的技术设计"><a href="#6-作为中间件的技术设计" class="headerlink" title="6. 作为中间件的技术设计"></a>6. 作为中间件的技术设计</h1><h2 id="61-性能提升"><a href="#6-1-性能提升" class="headerlink" title="6.1 性能提升"></a>6.1 性能提升</h2><ol><li>线程池异步处理</li><li>cache 存储回查接口</li><li>基于bizID + messageKey 的分库分表</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0-项目结构介绍&quot;&gt;&lt;a href=&quot;#0-项目结构介绍&quot; class=&quot;headerlink&quot; title=&quot;0. 项目结构介绍&quot;&gt;&lt;/a&gt;0. 项目结构介绍&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Module&lt;/th&gt;
&lt;th&gt;Descri</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>深入解析bloom filter的原理与实现</title>
    <link href="http://example.com/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>http://example.com/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/</id>
    <published>2024-03-31T08:16:17.000Z</published>
    <updated>2024-04-30T00:47:55.768Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0什么场景下会用到bloom-filter"><a href="#0-什么场景下会用到bloom-filter" class="headerlink" title="0.什么场景下会用到bloom filter"></a>0.什么场景下会用到bloom filter</h1><ol><li>缓存穿透</li><li>爬虫重复 URL 检测， 避免爬虫过程形成环</li><li>假设有 10 亿条手机号，然后判断某条手机号是否在列表内</li><li><a href="https://redis.com/blog/redis-redisbloom-bloom-filters/?_ga=2.218233113.1633975579.1711521515-926213951.1711521515&_gl=1*538r6b*_ga*OTI2MjEzOTUxLjE3MTE1MjE1MTU.*_ga_8BKGRQKRPV*MTcxMTU4OTkzMi4zLjEuMTcxMTU5MzQyMy41NS4wLjA.*_gcl_au*OTkyMjAyNDAyLjE3MTE1MjE1MTQ">唯一昵称判断 </a></li></ol><p>这些场景可以用什么方式解决</p><ol><li>hashmap, hashset</li><li>MySQL：正常情况下，如果数据量不大，我们可以考虑使用 mysql 存储。将所有数据存储到数据库，然后每次去库里查询判断是否存在。但是如果数据量太大，超过千万，mysql 查询效率是很低的，特别消耗性能。</li><li>bitmap</li><li>bloom filter</li></ol><h1 id="1bloom-filter-是什么"><a href="#1-bloom-filter-是什么？" class="headerlink" title="1.bloom filter 是什么？"></a>1.bloom filter 是什么？</h1><p>布隆过滤器是一种概率性数据结构，它提供了一种空间效率极高的方法来测试一个元素是否属于一个集合。</p><p>其基本原理是使用多个不同的哈希函数对元素进行哈希，然后将得到的哈希值对应到位数组上。一个元素被加入到集合中，那么所有哈希函数计算出的位置都会被置为1。检查元素是否存在于集合中时，使用这些哈希函数计算哈希值，并检查对应的位是否都是1。如果都是1，那么元素可能存在于集合中；如果任何一个位不是1，那么元素肯定不在集合中。</p><p>其主要特点是：</p><ul><li><strong>高空间效率</strong>：相比于传统的集合数据结构，布隆过滤器使用极少的空间来处理大量数据。</li><li><strong>误报率&#x2F;假阳</strong>：布隆过滤器有一定的误报概率，这意味着它可能会错误地认为某个不在集合中的元素存在于集合中。</li><li><strong>零漏报率</strong>：不会遗漏集合中真正存在的元素</li><li><strong>不可删除</strong>：标准的布隆过滤器不支持从集合中删除元素，尽管存在变种（如计数布隆过滤器）支持这一操作。</li><li><strong>多哈希函数</strong>：布隆过滤器通过多个哈希函数来减少误报率，每个元素被多个哈希函数映射到位数组的多个位置。</li></ul><h2 id="11-为什么空间效率高"><a href="#1-1-为什么空间效率高" class="headerlink" title="1.1 为什么空间效率高"></a>1.1 为什么空间效率高</h2><p>bloom filter 采用 位数组（bit array）作为核心的数据结构。</p><p>位数组是一个非常紧凑的数据结构，它可以有效地表示大量的布尔值（true或false），每个值只占用一个位（bit），而不是使用更传统的数据类型会占用更多的空间。</p><p>比如在爬虫场景中，假设有1亿个URL，每个URL算4字节, 如果用hashmap 实现，一个URL所占空间至少4bytes;如果用位数组实现，每个URL 所占的空间仅1bit，空间效率提升了32倍（存储空间不考虑误判率的前提下）。不可谓不高效。</p><h2 id="12-为什么会有误报率x2f假阳"><a href="#1-2-为什么会有误报率-假阳" class="headerlink" title="1.2 为什么会有误报率&#x2F;假阳"></a>1.2 为什么会有误报率&#x2F;假阳</h2><p>既然用到了哈希函数，肯定会遇到哈希冲突。所以一个元素对应 的n  个位置， 可能因为其他元素的哈希冲突 而导致判断时发现等于1， 从而产生假阳现象。</p><h2 id="13-误报如何解决"><a href="#1-3-误报如何解决" class="headerlink" title="1.3 误报如何解决"></a>1.3 误报如何解决</h2><p>假阳问题无法被避免，只能尽可能减少。 减少的途径是选择合适的哈希函数以及指定合适的空间大小</p><h2 id="14-为什么需要多个哈希函数"><a href="#1-4-为什么需要多个哈希函数" class="headerlink" title="1.4 为什么需要多个哈希函数"></a>1.4 为什么需要多个哈希函数</h2><p>布隆过滤器的设计使用多个哈希函数来解决单个哈希函数可能带来的局限性，提高其效率和准确性。具体来说，使用多个哈希函数的原因包括：</p><ul><li><p>降低误报率</p><p>通过使用多个哈希函数独立地映射每个元素到位数组中的多个位置，并在所有这些位置上标记为1，可以显著降低不同元素映射到相同位置（即产生冲突）的概率，从而降低误报率</p></li><li><p>均匀分布</p><p>多个哈希函数可以将元素更均匀地分布在位数组上，减少了集中冲突的可能性。如果只使用一个哈希函数，即使其分布性质良好，也难以保证对于所有可能的输入集合都能保持良好的均匀性。多个哈希函数的组合，如果设计得当，可以相互补偿，实现更为均匀的分布。</p></li></ul><h2 id="15-为什么数据不可删除"><a href="#1-5-为什么数据不可删除" class="headerlink" title="1.5 为什么数据不可删除"></a>1.5 为什么数据不可删除</h2><p>在布隆过滤器中，元素的存在是通过多个位的“1”状态来表示的，而将这些位重置为“0”可能会错误地影响其他元素的存在检测。</p><p>如果需要支持删除，可以考虑使用 变体Bloom Filter， 如cuckoo filter</p><h1 id="2-bitmap-和-bloom-filter-的区别"><a href="#2-bitmap-和-bloom-filter-的区别" class="headerlink" title="2. bitmap 和 bloom filter 的区别"></a>2. bitmap 和 bloom filter 的区别</h1><p>Bitmap（位图）和布隆过滤器都是使用空间效率高的数据结构，它们通过利用位操作来实现存储和查询，但它们的设计目的和应用场景有所不同。</p><h2 id="21-bitmap位图"><a href="#2-1-Bitmap（位图）" class="headerlink" title="2.1 Bitmap（位图）"></a>2.1 Bitmap（位图）</h2><p>位图是一种数据结构，用于高效地存储和查询状态信息。在位图中，每个元素的存在或状态是由单独的位来表示的，即使用1位二进制数（0或1）来表示每个元素是否存在或某种特定状态。</p><p><strong>主要特点和用途</strong>：</p><ul><li><p><strong>简单直接</strong>：适用于需要追踪大量元素（如整数）存在与否的场景。</p></li><li><p><strong>空间效率</strong>：对于大规模数据集，位图使用的空间远小于传统的数据结构（如数组或列表）。</p></li><li><p><strong>随机访问</strong>：可以非常快速地检查任何一个元素的存在与否或状态。</p></li><li><p><strong>固定大小</strong>：位图的大小在创建时由最大元素值决定，因此其空间效率依赖于数据的分布。</p></li><li><p><strong>BitMap 的实现</strong><br>java BitSet<br>redis setbit、getbit</p></li></ul><h2 id="22-区别"><a href="#2-2-区别" class="headerlink" title="2.2 区别"></a>2.2 区别</h2><ul><li><strong>用途</strong>：位图主要用于精确表示一个大型数据集中元素的存在与否或状态信息，而布隆过滤器用于以极小的空间成本判断元素是否可能存在于集合中。</li><li><strong>错误率</strong>：位图提供了100%准确的结果（假设足够的空间来表示所有元素），而布隆过滤器允许一定的误报率。</li><li><strong>操作</strong>：位图支持添加、查询和删除（通过位反转）操作，而标准布隆过滤器不支持删除操作。</li><li><strong>空间效率与数据规模</strong>：布隆过滤器在表示大型集合成员资格时通常比位图更加空间效率，尤其是当元素范围非常大但实际元素数量相对较少时。</li></ul><p>总之，位图和布隆过滤器各有优势和应用场景，选择哪种数据结构取决于具体需求，包括对空间效率、准确率和操作类型的要求。</p><h1 id="3-单机版本guava-cache-源码解析"><a href="#3-单机版本Guava-Cache-源码解析" class="headerlink" title="3. 单机版本Guava Cache 源码解析"></a>3. 单机版本Guava Cache 源码解析</h1><h2 id="31-create"><a href="#3-1-create" class="headerlink" title="3.1 create"></a>3.1 create</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; BloomFilter&lt;T&gt; <span class="title function_">create</span><span class="params">(Funnel&lt;T&gt; funnel, <span class="type">int</span> expectedInsertions <span class="comment">/* n */</span>,  </span></span><br><span class="line"><span class="params">    <span class="type">double</span> falsePositiveProbability)</span> &#123;  </span><br><span class="line">    <span class="type">int</span> <span class="variable">numBits</span> <span class="operator">=</span> optimalNumOfBits(expectedInsertions, falsePositiveProbability);  </span><br><span class="line">    <span class="type">int</span> <span class="variable">numHashFunctions</span> <span class="operator">=</span> optimalNumOfHashFunctions(expectedInsertions, numBits);  </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">BloomFilter</span>&lt;T&gt;(<span class="keyword">new</span> <span class="title class_">BitArray</span>(numBits), numHashFunctions, funnel,  </span><br><span class="line">BloomFilterStrategies.MURMUR128_MITZ_32);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="311-参数解释"><a href="#3-1-1-参数解释" class="headerlink" title="3.1.1 参数解释"></a>3.1.1 参数解释</h3><ul><li><p>**<code>funnel</code>**：<code>Funnel</code>类型的参数，用于将任意类型的数据转化成布隆过滤器内部使用的一种形式。<code>Funnel</code>定义了如何把对象转换成二进制流，然后布隆过滤器使用这个二进制流来计算元素的哈希值。</p></li><li><p>**<code>expectedInsertions</code>**：这个参数指定了预期要插入布隆过滤器的元素数量。这个数值是为了优化布隆过滤器内部数据结构的大小。</p></li><li><p>**<code>falsePositiveProbability</code>**（false positive probability）：误判率。这是指一个不存在集合中的元素被判断为存在的概率。值得注意的是，随着实际插入数量的增加，实际的误判率可能会上升。</p></li></ul><h3 id="312-optimalnumofbits"><a href="#3-1-2-optimalNumOfBits" class="headerlink" title="3.1.2 optimalNumOfBits"></a>3.1.2 optimalNumOfBits</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="type">int</span> <span class="title function_">optimalNumOfBits</span><span class="params">(<span class="type">int</span> expectedInsertions, <span class="type">double</span> falsePositiveProbability)</span> &#123;  </span><br><span class="line"><span class="keyword">return</span> (<span class="type">int</span>) (-n * Math.log(p) / LN2_SQUARED);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>optimalNumOfBits</code>通过计算,可以得到一个在满足特定假阳性率（<code>falsePositiveProbability</code>）要求下，对于给定数量的元素预期插入量（<code>expectedInsertions</code>），所需的最少位数。这使得布隆过滤器能够在保证误判率的前提下，使用最少的空间。这种计算对于设计高效且空间节约的布隆过滤器至关重要</p><h3 id="313-计算逻辑"><a href="#3-1-3-计算逻辑" class="headerlink" title="3.1.3 计算逻辑"></a>3.1.3 计算逻辑</h3><p><code>optimalNumOfBits</code>函数的计算基于以下公式，这个公式可以从布隆过滤器的理论误判率公式推导而来：</p><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/bitnums.png" class><ul><li>m 是位数组的长度（即函数的返回值）。</li><li>n 是<code>expectedInsertions</code>，即预期的插入数量。</li><li>p 是<code>falsePositiveProbability</code>，即期望的假阳性概率。</li><li>ln⁡2 表示自然对数。<br>这个公式利用了布隆过滤器的误判率特性，通过指定的假阳性率和预期插入数量来计算出一个最优的位数组长度。这个长度能够在满足误判率要求的同时，尽可能地减小布隆过滤器所需的空间。</li></ul><h3 id="314-实现注意"><a href="#3-1-4-实现注意" class="headerlink" title="3.1.4 实现注意"></a>3.1.4 实现注意</h3><p>实际实现时，可能还需要对计算结果进行取整处理，并确保结果是一个正整数。此外，实现可能还会考虑到性能和存储效率的平衡，比如通过限制位数组的长度为2的幂等。</p><h3 id="315-optimalnumofhashfunctions"><a href="#3-1-5-optimalNumOfHashFunctions" class="headerlink" title="3.1.5 optimalNumOfHashFunctions"></a>3.1.5 optimalNumOfHashFunctions</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="type">int</span> <span class="title function_">optimalNumOfHashFunctions</span><span class="params">(<span class="type">int</span> n, <span class="type">int</span> m)</span> &#123;  </span><br><span class="line"><span class="keyword">return</span> Math.max(<span class="number">1</span>, (<span class="type">int</span>) Math.round(m / n * LN2));  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>optimalNumOfHashFunctions(expectedInsertions, numBits)</code>这个函数用于计算给定条件下布隆过滤器的最优哈希函数数量。这个计算基于预期要插入的元素数量（<code>expectedInsertions</code>）和布隆过滤器内部位数组的大小（<code>numBits</code>）。目的是为了平衡空间使用和误判率，确保布隆过滤器在给定条件下工作得最有效率。</p><p><strong>计算逻辑</strong></p><p>布隆过滤器的效率和误判率与使用的哈希函数数量有很大关系。太少的哈希函数会增加碰撞的概率，导致误判率升高；而太多的哈希函数又会导致位数组快速填满，同样增加误判率，同时还会增加计算的开销。</p><p>最优哈希函数数量的计算公式是：</p><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/hashnums.png" class><p>这个公式基于以下原理：给定一个固定大小的位数组，存在一个最优的哈希函数数量，可以最小化给定元素数量条件下的误判率。这个最优数量直接关联于位数组的大小和要处理的元素数量。</p><p>其中：</p><ul><li>k 是最优的哈希函数数量，</li><li>m 是位数组的大小（<code>numBits</code>），</li><li>n 是预期插入的元素数量（<code>expectedInsertions</code>），</li><li>ln⁡(2) 是自然对数2的值，大约等于0.693。</li></ul><h3 id="316-new-bitarraynumbits"><a href="#3-1-6-new-BitArray-numBits" class="headerlink" title="3.1.6 new BitArray(numBits)"></a>3.1.6 new BitArray(numBits)</h3><p>Guava cache  bloom filter 在实现位数组是采用创建long[]  + 位移操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">BitArray</span> &#123;  </span><br><span class="line"><span class="keyword">final</span> <span class="type">long</span>[] data;  </span><br><span class="line">  </span><br><span class="line">BitArray(<span class="type">int</span> bits) &#123;  </span><br><span class="line">    <span class="built_in">this</span>(<span class="keyword">new</span> <span class="title class_">long</span>[IntMath.divide(bits, <span class="number">64</span>, RoundingMode.CEILING)]);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// Used by serialization  </span></span><br><span class="line">BitArray(<span class="type">long</span>[] data) &#123;  </span><br><span class="line">    checkArgument(data.length &gt; <span class="number">0</span>, <span class="string">&quot;data length is zero!&quot;</span>);  </span><br><span class="line">    <span class="built_in">this</span>.data = data;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> index)</span> &#123;  </span><br><span class="line">    data[index &gt;&gt; <span class="number">6</span>] |= (<span class="number">1L</span> &lt;&lt; index);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="type">boolean</span> <span class="title function_">get</span><span class="params">(<span class="type">int</span> index)</span> &#123;  </span><br><span class="line">    <span class="keyword">return</span> (data[index &gt;&gt; <span class="number">6</span>] &amp; (<span class="number">1L</span> &lt;&lt; index)) != <span class="number">0</span>;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">/** Number of bits */</span>  </span><br><span class="line"><span class="type">int</span> <span class="title function_">size</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="keyword">return</span> data.length * Long.SIZE;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="32-put"><a href="#3-2-put" class="headerlink" title="3.2 put"></a>3.2 put</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MURMUR128_MITZ_32() &#123;  </span><br><span class="line"><span class="meta">@Override</span> <span class="keyword">public</span> &lt;T&gt; <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(T object, Funnel&lt;? <span class="built_in">super</span> T&gt; funnel,  </span></span><br><span class="line"><span class="params"><span class="type">int</span> numHashFunctions, BitArray bits)</span> &#123;  </span><br><span class="line"><span class="comment">// TODO(user): when the murmur&#x27;s shortcuts are implemented, update this code  </span></span><br><span class="line"><span class="type">long</span> <span class="variable">hash64</span> <span class="operator">=</span> Hashing.murmur3_128().newHasher().putObject(object, funnel).hash().asLong();  </span><br><span class="line"><span class="type">int</span> <span class="variable">hash1</span> <span class="operator">=</span> (<span class="type">int</span>) hash64;  </span><br><span class="line"><span class="type">int</span> <span class="variable">hash2</span> <span class="operator">=</span> (<span class="type">int</span>) (hash64 &gt;&gt;&gt; <span class="number">32</span>);  </span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= numHashFunctions; i++) &#123;  </span><br><span class="line"><span class="type">int</span> <span class="variable">nextHash</span> <span class="operator">=</span> hash1 + i * hash2;  </span><br><span class="line"><span class="keyword">if</span> (nextHash &lt; <span class="number">0</span>) &#123;  </span><br><span class="line">nextHash = ~nextHash;  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="comment">// up to here, the code is identical with the next method  </span></span><br><span class="line">bits.set(nextHash % bits.size());  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先，这行代码使用MurmurHash3算法生成一个128位的哈希值，然后将其转换成一个<code>long</code>类型的数值<code>hash64</code>。</p><ul><li><code>funnel</code>是一个函数式接口，用于将对象转换为字节流，以便哈希函数可以处理。</li><li><code>hash64</code>实际上包含两个32位的哈希值，它们可以从<code>hash64</code>的高32位和低32位分别提取。从<code>hash64</code>中提取两个32位的哈希值<code>hash1</code>和<code>hash2</code>。<code>hash1</code>是低32位，<code>hash2</code>是高32位。</li><li><ul><li>接下来，代码遍历从1到<code>numHashFunctions</code>（布隆过滤器要求的哈希函数数量），每次循环计算一个新的哈希值<code>nextHash</code>。这个新的哈希值是通过<code>hash1 + i * hash2</code>计算得到的，其中<code>i</code>是当前的迭代次数。</li></ul></li><li>如果<code>nextHash</code>为负数，通过位取反操作（<code>~nextHash</code>）将其转换为正数，以保证能够正确地映射到位数组的索引上。</li><li>最后，使用<code>nextHash % bits.size()</code>计算得到的索引值在位数组（<code>BitArray</code>）中对应的位置上设置位。<code>bits.size()</code>返回位数组的大小，这确保了计算得到的索引值不会超出位数组的范围。</li></ul><h3 id="321-哈希函数"><a href="#3-2-1-哈希函数" class="headerlink" title="3.2.1 哈希函数"></a>3.2.1 哈希函数</h3><p>Guava cache 采用了非加密的单向散列函数Murmur3.<br><strong>MurmurHash</strong> 由Austin Appleby设计，因其高性能和良好的分布特性而广泛应用。MurmurHash有多个版本，如MurmurHash2、MurmurHash3等。</p><p>根据最开始对bloom filter 的定义，它需要多个哈希函数对数据进行哈希映射， 但Guava Cache bloom filter 实现中其实没有使用多个不同的哈希函数，而是采用了一种叫做“双哈希技术”的方法。</p><p>“双哈希技术”的基本思想是利用两个哈希函数<code>h1(x)</code>和<code>h2(x)</code>生成任意数量的哈希值，对于第<code>i</code>个哈希位置，使用<code>h1(x) + i*h2(x)</code>的方式来生成。这种方法只需要两次哈希操作，就可以模拟出多个哈希函数的效果，且生成的哈希序列具有很好的均匀分布性，既保证了布隆过滤器的效率，又避免了寻找多个好的哈希函数的复杂性，是一种在实际应用中非常实用的解决方案。</p><p>效率和复杂性具体指</p><ol><li><strong>性能和效率</strong>：使用单个哈希函数后通过算法变换生成多个哈希值，可以大大减少计算的复杂度和时间。多个独立的哈希函数意味着每个元素都需要被多次独立哈希，这会增加计算成本和时间。通过使用单个哈希函数并通过数学方法派生出多个伪随机的哈希值，可以在保持布隆过滤器错误率不变的前提下，显著提高效率。</li><li><strong>简化实现</strong>：多个不同的哈希函数难以选取，而且还需保证它们相互之间的独立性和分布的均匀性，这在实践中是非常挑战性的。</li></ol><h2 id="33-mightcontains"><a href="#3-3-mightContains" class="headerlink" title="3.3 mightContains"></a>3.3 mightContains</h2><p>和put 处理过程保持一致</p><h2 id="34-guava-cache-误报率-位数组长度固定"><a href="#3-4-guava-cache-误报率-位数组长度固定" class="headerlink" title="3.4 guava cache 误报率-位数组长度固定"></a>3.4 guava cache 误报率-位数组长度固定</h2><p>在使用Guava的布隆过滤器时，预先估计将要插入的数据量非常重要。布隆过滤器在创建时会根据这个预估的数据量和指定的误判率来决定位数组的大小和使用的哈希函数数量。这些参数共同决定了布隆过滤器的性能和准确性。</p><p>如果实际插入的元素数量超过了最初的预估，过滤器的实际误判率会高于预期的误判率。这是因为当位数组变得过于饱和时，不同元素的哈希值更有可能映射到已经被设置为1的位上，从而增加了误判的几率。</p><p>Guava的文档明确指出了这一点，强调在创建布隆过滤器时应该准确预估元素数量，并考虑到这一点在其API设计中。<code>BloomFilter.create()</code>方法允许开发者在创建过滤器时指定预期插入的元素数量和可接受的误判率。</p><p><a href="https://guava.dev/releases/20.0/api/docs/com/google/common/hash/BloomFilter.html">https://guava.dev/releases/20.0/api/docs/com/google/common/hash/BloomFilter.html</a></p><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/errorrate.png" class><p>为了保证布隆过滤器的效果，应该根据实际使用场景仔细估算元素数量。如果预计数据量存在不确定性，建议预估一个上限，或者在实际元素数量超过预估时重新创建一个新的布隆过滤器。这当然会带来额外的成本，因此在设计初期做出准确估计非常关键。</p><p>总结来说，正确估计将要处理的数据量对于使用Guava布隆过滤器来说是非常重要的。如果实际数据量超过了预估，将会导致高于预期的误判率，可能影响到应用的准确性和可靠性。</p><h1 id="4-分布式-redis-bloom-filter"><a href="#4-分布式-Redis-bloom-filter" class="headerlink" title="4. 分布式 Redis bloom filter"></a>4. 分布式 Redis bloom filter</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BF.RESERVE &#123;key&#125; &#123;error_rate&#125; &#123;capacity&#125; [EXPANSION expansion] [NONSCALING]</span><br></pre></td></tr></table></figure><h2 id="41-参数解释"><a href="#4-1-参数解释" class="headerlink" title="4.1 参数解释"></a>4.1 参数解释</h2><h3 id="411-expansion-expansion"><a href="#4-1-1-EXPANSION-expansion" class="headerlink" title="4.1.1 EXPANSION expansion"></a>4.1.1 EXPANSION expansion</h3><p><code>BF.RESERVE</code>命令是RedisBloom模块中用来创建一个新的布隆过滤器的命令。这个命令允许用户预先为布隆过滤器指定参数，以便在插入元素之前就确定其大小和其他重要的行为特性。以下是<code>BF.RESERVE</code>命令各个参数的含义：</p><ul><li><p>**<code>&#123;key&#125;</code>**：这是将要创建的布隆过滤器的名称或键值。在Redis中，每个数据结构都通过一个唯一的键来标识和访问。</p></li><li><p>**<code>&#123;error_rate&#125;</code>**：预期的误报率。这是一个0到1之间的浮点数，表示允许的误判概率的上限。误报率越低，布隆过滤器所需的空间就越大。</p></li><li><p>**<code>&#123;capacity&#125;</code>**：布隆过滤器预期要存储的元素的数量。这个数值用于在保持误报率不变的情况下，预先计算布隆过滤器所需的最小大小。</p></li><li><p>**<code>[EXPANSION expansion]</code>**（可选）：这个可选参数用于指定当布隆过滤器的容量不足以容纳更多元素时，自动扩展的行为。<code>expansion</code>是一个大于1的整数，表示每次扩展增加的比例或容量。如果未指定，布隆过滤器可能会使用默认的扩展策略。</p></li><li><p>**<code>[NONSCALING]</code>**（可选）：这个可选标志用来指示创建的布隆过滤器不应自动扩展。这意味着一旦达到其容量上限，就不会尝试扩大过滤器以容纳更多的元素。这通常用于那些对空间使用有严格限制的应用场景。</p></li><li><p><strong>作用</strong>：这个参数用于设置布隆过滤器在达到容量限制并需要扩展时，新创建的布隆过滤器层的大小。<code>expansion</code>的值决定了新层的容量是前一层容量的多少倍。这是一种自动扩展布隆过滤器容量的机制，以适应不断增长的元素数量，同时控制误报率。</p></li><li><p><strong>场景</strong>：适用于那些元素数量不确定或可能会超出初始设定容量的场合。通过适当设置<code>expansion</code>参数，可以在维持误报率的同时动态增加布隆过滤器的容量。</p></li><li><p><strong>举例</strong>：如果设置<code>[EXPANSION 2]</code>，那么每次扩展时，新的布隆过滤器层的容量将是前一层的两倍。</p></li></ul><h3 id="412-nonscaling"><a href="#4-1-2-NONSCALING" class="headerlink" title="4.1.2 NONSCALING"></a>4.1.2 NONSCALING</h3><ul><li><strong>作用</strong>：指定创建的布隆过滤器为非扩展型（Non-scaling）。即，一旦创建，布隆过滤器的容量固定，不会根据元素的增加而自动增加新的层。这意味着所有元素都将被添加到这个固定大小的布隆过滤器中，不管其容量是否已满。</li><li><strong>场景</strong>：适用于元素数量预先已知且不会超出初始设定容量的场合。这种方式可以避免因为扩展而可能带来的额外内存使用，但要求用户必须更准确地预估所需的容量和误报率。</li></ul><p><strong>注意</strong>：当使用<code>[NONSCALING]</code>参数时，<code>[EXPANSION expansion]</code>参数将无效，因为非扩展型的布隆过滤器不会进行任何扩展操作。</p><h2 id="42-可拓展特性是如何实现"><a href="#4-2-可拓展特性是如何实现" class="headerlink" title="4.2 可拓展特性是如何实现"></a>4.2 可拓展特性是如何实现</h2><p>redis 可扩展布隆过滤(Scalable Bloom Filters)可以理解成是由多个位数组&#x2F;子过滤器（布隆过滤器实例）链接在一起形成的链表(SBChain)。</p><p>每个子过滤器都有其自己的容量和误报率设置。当前的子过滤器达到容量限制时，就会动态地添加一个新的子过滤器。</p><p>这种方法的关键优势是，它可以在不断增加元素的情况下，动态地扩展总容量，同时控制整体误报率。</p><p>然而，这种动态扩展的能力也意味着查询操作可能需要遍历链表中的多个布隆过滤器实例，这可能会对性能产生一定影响。</p><p>redis bloom filter 的整体上的基本逻辑，比如位数组的大小、选择的哈希函数、哈希函数的数量、多个哈希函数的模拟与Guava cache  bloom filter基本保持一致， 接下来只重点分析其可拓展性是如何实现的</p><h3 id="421-bloom-结构体"><a href="#4-2-1-bloom-结构体" class="headerlink" title="4.2.1 bloom 结构体"></a>4.2.1 bloom 结构体</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">bloom.h</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bloom</span> &#123;</span>  </span><br><span class="line"><span class="type">uint32_t</span> hashes;  </span><br><span class="line"><span class="type">uint8_t</span> force64;  </span><br><span class="line"><span class="type">uint8_t</span> n2;  </span><br><span class="line"><span class="type">uint64_t</span> entries;  </span><br><span class="line">  </span><br><span class="line"><span class="type">double</span> error;  </span><br><span class="line"><span class="type">double</span> bpe;  </span><br><span class="line">  </span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> *bf;  </span><br><span class="line"><span class="type">uint64_t</span> bytes;  </span><br><span class="line"><span class="type">uint64_t</span> bits;  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个<code>struct bloom</code>定义了一个布隆过滤器的基本数据结构，用于在RedisBloom模块中表示一个布隆过滤器实例。下面是对各个成员变量的详细解释：</p><ul><li>**<code>uint32_t hashes;</code>**：这表示布隆过滤器使用的哈希函数的数量。在布隆过滤器中，元素的存在是通过多个哈希函数映射到位数组的不同位置来表示的。因此，哈希函数的数量直接影响布隆过滤器的误判率和效率。</li><li>**<code>uint8_t force64;</code>**：这是一个标志位，用于指示是否强制使用64位哈希函数。在某些情况下，为了保证在不同平台上的一致性和性能，可能需要强制使用64位哈希函数。</li><li>**<code>uint8_t n2;</code>**：这个成员可能用于表示与位数组大小相关的一个参数，具体含义取决于实现细节。在一些布隆过滤器的实现中，这个参数可能与位数组大小为2的幂次方有关。</li><li>**<code>uint64_t entries;</code>**：这表示预期存储在布隆过滤器中的元素数量。这个数值对于计算位数组的大小和哈希函数数量非常重要。</li><li>**<code>double error;</code>**：这是预期的误判率（false positive rate），是设计布隆过滤器时的一个关键参数。误判率越低，所需的位数组大小和哈希函数数量就越多。</li><li>**<code>double bpe;</code>**：这表示每个元素平均占用的位数（Bits Per Entry）。这个值是根据预期的误判率和元素数量计算得出的，用于确定位数组的大小。</li><li>**<code>unsigned char *bf;</code>**：这是一个指向位数组的指针。位数组是布隆过滤器的核心，用于存储元素的哈希值映射。<code>unsigned char</code>类型被用来表示位数组，每个字节包含8位。</li><li>**<code>uint64_t bytes;</code>**：这表示位数组占用的字节数。由于位数组是以字节为单位进行分配的，因此这个数值表示整个位数组的大小。</li><li>**<code>uint64_t bits;</code>**：这表示位数组中的位数。这个数值是根据<code>entries</code>、<code>error</code>和<code>bpe</code>计算得出的，决定了布隆过滤器可以有效存储的元素数量和误判率。</li></ul><h3 id="422-sblink结构体"><a href="#4-2-2-SBLink结构体" class="headerlink" title="4.2.2 SBLink结构体"></a>4.2.2 <code>SBLink</code>结构体</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sb.h</span><br><span class="line"><span class="comment">/** Single link inside a scalable bloom filter */</span>  </span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">SBLink</span> &#123;</span>  </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bloom</span> <span class="title">inner</span>;</span> <span class="comment">//&lt; Inner structure  </span></span><br><span class="line"><span class="type">size_t</span> size; <span class="comment">// &lt; Number of items in the link  </span></span><br><span class="line">&#125; SBLink;  </span><br></pre></td></tr></table></figure><p><code>SBLink</code>代表了可扩展布隆过滤器中的单个链接，即单个布隆过滤器实例。</p><ul><li>**<code>struct bloom inner;</code>**：这是一个嵌套的结构体，表示单个布隆过滤器的内部结构。这个<code>inner</code>结构体可能包含了实现布隆过滤器所需的所有数据，如位数组、哈希函数数量等。</li><li>**<code>size_t size;</code>**：表示当前链接（即单个布隆过滤器实例）中的元素数量。这是为了快速访问单个过滤器内元素的数量，而无需遍历整个位数组。</li></ul><h3 id="423-sbchain结构体"><a href="#4-2-3-SBChain结构体" class="headerlink" title="4.2.3 SBChain结构体"></a>4.2.3 <code>SBChain</code>结构体</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sb.h  </span><br><span class="line"><span class="comment">/** A chain of one or more bloom filters */</span>  </span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">SBChain</span> &#123;</span>  </span><br><span class="line">SBLink *filters; <span class="comment">//&lt; Current filter  </span></span><br><span class="line"><span class="type">size_t</span> size; <span class="comment">//&lt; Total number of items in all filters  </span></span><br><span class="line"><span class="type">size_t</span> nfilters; <span class="comment">//&lt; Number of links in chain  </span></span><br><span class="line"><span class="type">unsigned</span> options; <span class="comment">//&lt; Options passed directly to bloom_init  </span></span><br><span class="line"><span class="type">unsigned</span> growth;  </span><br><span class="line">&#125; SBChain;</span><br></pre></td></tr></table></figure><p><code>SBChain</code>代表了一系列（一个或多个）<code>SBLink</code>结构体的链表，构成了一个可扩展的布隆过滤器。</p><ul><li>**<code>SBLink *filters;</code>**：这是一个指向<code>SBLink</code>数组的指针，表示当前所有的过滤器链。每个<code>SBLink</code>代表链中的一个布隆过滤器实例。</li><li>**<code>size_t size;</code>**：表示所有过滤器中元素的总数量。这个数字是所有单个<code>SBLink</code>中<code>size</code>成员的总和。</li><li>**<code>size_t nfilters;</code>**：表示链中<code>SBLink</code>实例的数量，即当前有多少个布隆过滤器被链接在一起。</li><li>**<code>unsigned options;</code>**：这是传递给每个布隆过滤器初始化函数<code>bloom_init</code>的选项。这些选项可能控制如布隆过滤器的误报率、是否自动扩展等行为。</li><li>**<code>unsigned growth;</code>**：这个成员变量控制链的增长行为。它可能指定当当前的布隆过滤器填满时，如何增加新的<code>SBLink</code>实例，例如，增加的大小或比例等。</li></ul><h2 id="43-可扩展bloom-filter的工作流程"><a href="#4-3-可扩展bloom-filter的工作流程" class="headerlink" title="4.3 可扩展bloom filter的工作流程"></a>4.3 可扩展bloom filter的工作流程</h2><ol><li><strong>初始化</strong>：当创建一个新的可扩展布隆过滤器时，会指定初始容量、误报率等参数。基于这些参数，创建第一个子过滤器。</li><li><strong>添加元素</strong>：向布隆过滤器添加元素时，会从当前子过滤器开始尝试添加。如果当前子过滤器已满（即达到了其容量限制），则创建一个新的子过滤器，并在新的子过滤器中添加元素。每个新添加的子过滤器都可以根据配置的规则调整大小和误报率，以适应不断增加的元素。</li><li><strong>检查元素</strong>：检查一个元素是否存在时，需要查询所有的子过滤器。如果任何子过滤器表示元素可能存在（即对应的位都为1），则认为元素可能存在于布隆过滤器中。虽然可扩展布隆过滤器可以动态增加容量，但查询操作的成本随之增加，因为可能需要检查多个布隆过滤器实例。</li><li><strong>参数调整</strong>：随着子过滤器的增加，每个新的子过滤器通常会有更大的容量。这是通过调整如比特数、哈希函数数量等参数来实现的。这种方法旨在平衡误报率和内存使用，即使在不断添加元素的情况下也能维持相对稳定的误报率。</li></ol><h1 id="5-可删除-bloom-filter"><a href="#5-可删除-bloom-filter" class="headerlink" title="5. 可删除 bloom filter"></a>5. 可删除 bloom filter</h1><h2 id="51-哪些场景使用布隆过滤器时需要删除"><a href="#5-1-哪些场景使用布隆过滤器时需要删除" class="headerlink" title="5.1 哪些场景使用布隆过滤器时需要删除"></a>5.1 哪些场景使用布隆过滤器时需要删除</h2><p>以上， guava 和 redis 的bloom filter 都没有实现删除功能，不能删除的原因已经解释过，元素的存在是通过多个位的“1”状态来表示的，而将这些位重置为“0”可能会错误地影响其他元素的存在检测。</p><p>但是在某些场景还是需要删除，比如，<br>查看一张优惠券是否已被使用？创建一个包含所有存在但还未被使用优惠券的filter。每次校验时</p><ul><li>如果否，则优惠券不存在。</li><li>如果是，则优惠券有效。检查主数据库。如果有效，则使用后从 Cuckoo 过滤器中删除。</li></ul><h2 id="52-实现删除布隆过滤器的思路"><a href="#5-2-实现删除布隆过滤器的思路" class="headerlink" title="5.2 实现删除布隆过滤器的思路"></a>5.2 实现删除布隆过滤器的思路</h2><h3 id="521-计数型布隆过滤器counting-bloom-filter"><a href="#5-2-1-计数型布隆过滤器（Counting-Bloom-Filter）" class="headerlink" title="5.2.1 计数型布隆过滤器（Counting Bloom Filter）"></a>5.2.1 计数型布隆过滤器（Counting Bloom Filter）</h3><p>这是最直接的方法之一，它通过为每个位使用一个计数器而不是简单的布尔标记来实现。当插入一个元素时，它经过多个哈希函数映射到多个计数器上，并将这些计数器的值增加。相应地，删除一个元素时，这些计数器的值会被减少。如果任何计数器的值达到零，则表示没有任何元素映射到这个位上。这种方法的缺点是需要更多的空间来存储计数器。</p><h3 id="522-双布隆过滤器"><a href="#5-2-2-双布隆过滤器" class="headerlink" title="5.2.2 双布隆过滤器"></a>5.2.2 双布隆过滤器</h3><p>这种方法涉及到使用两个独立的布隆过滤器：一个用于添加操作，另一个用于删除操作。当添加一个元素时，它被添加到第一个布隆过滤器中；当删除一个元素时，该元素被添加到第二个布隆过滤器中。检查元素是否存在时，如果它在第一个布隆过滤器中并且不在第二个布隆过滤器中，则认为该元素存在。这种方法的问题是误报率会增加，因为删除过滤器中的元素也可能错误地阻止对实际存在于集合中的元素的正确判断。</p><h3 id="523-d-left-计数哈希"><a href="#5-2-3-d-left-计数哈希" class="headerlink" title="5.2.3 d-left 计数哈希"></a>5.2.3 d-left 计数哈希</h3><p>d-left计数哈希是一种高效的数据结构，它将元素映射到固定数量的桶中，并在每个桶内维护一个计数器。这种方法可以实现快速的插入、查询和删除操作，并且相比于计数型布隆过滤器，它可以更有效地利用空间。不过，实现起来比较复杂，且当桶填满时性能会下降。</p><h3 id="524-布谷鸟过滤器cuckoo-filter"><a href="#5-2-4-布谷鸟过滤器（Cuckoo-Filter）" class="headerlink" title="5.2.4 布谷鸟过滤器（Cuckoo Filter）"></a>5.2.4 布谷鸟过滤器（Cuckoo Filter）</h3><p>布谷鸟过滤器是另一种支持删除操作的布隆过滤器变种，它基于布谷鸟哈希和部分键存储。每个元素通过哈希函数映射到一个或多个位置，并存储其“指纹”。插入、查询和删除操作都基于这些指纹。布谷鸟过滤器相比计数型布隆过滤器在空间效率上有所提高，且支持删除操作，但在极端情况下可能需要重建过滤器。</p><p>总体上可以看出可删除bloom filter 的实现都是需要额外的空间去存储额外的信息， 那么其实现方式的好坏的评判标准就是 额外空间的大小、性能 以及对误报率的影响。</p><p>以下是一张表格，总结了几种支持删除操作的布隆过滤器变体的优点和缺点：</p><table><thead><tr><th>过滤器类型</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>计数型布隆过滤器</td><td>- 直接支持删除操作<br>- 实现相对简单</td><td>- 更多空间需求<br>- 计数器溢出问题</td></tr><tr><td>双布隆过滤器</td><td>- 实现简单<br>- 通过额外布隆过滤器跟踪删除操作</td><td>- 增加空间需求<br>- 误判率增加</td></tr><tr><td>布谷鸟过滤器</td><td>- 高效的插入、删除和查询<br>- 空间效率高</td><td>- 实现复杂<br>- 负载因子高时性能可能下降</td></tr><tr><td>d-left计数哈希过滤器</td><td>- 高空间效率<br>- 性能优于传统计数型布隆过滤器</td><td>- 实现复杂，需要精心设计</td></tr></tbody></table><ul><li>如果应用对空间效率要求不是特别高，且需要频繁进行删除操作，计数型布隆过滤器是一个简单有效的选择。</li><li>对于需要最小化误报率而且对空间有一定要求的应用，布谷鸟过滤器提供了一个较好的平衡点。</li><li>在需要极致空间效率且能够接受实现复杂度的高性能应用场景中，d-left 计数哈希过滤器可能是最佳选择。</li></ul><p>关于空间的使用，有如下比对效果</p><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/spacecompare.png" class><p>redis 实现了cuckoo 变体bloom filter， 下面来讲一下 cuckoo  filter 的原理</p><h1 id="6-cuckoo-filter"><a href="#6-Cuckoo-Filter" class="headerlink" title="6. Cuckoo Filter"></a>6. Cuckoo Filter</h1><p><a href="https://www.cs.cmu.edu/~binfan/papers/conext14_cuckoofilter.pdf">Cuckoo Filter 论文</a></p><p>the basic unit of the cuckoo hash tables used for our cuckoo filters is called an entry. Each entry stores one fingerprint. The hash table consists of an array of buckets, where a bucket can have multiple entries.</p><p>在Cuckoo Filter 中，最基本的存储单元是entry,  每个单元存储一个 fingerprint。cuckoo hashing 哈希表由一组桶（buckets）组成，每个桶可以包含多个条目（entries）。</p><p>Cuckoo Filter的关键特性</p><ol><li><strong>双哈希函数</strong>：对于任何一个给定的键，Cuckoo Hashing使用两个独立的哈希函数 <code>h1</code> 和 <code>h2</code> 来计算两个候选桶的位置。这两个位置是键可能被存储的地方。</li><li><strong>指纹存储</strong>：与传统的哈希表不同，Cuckoo Hashing不存储完整的键，而是存储键的指纹。这允许在不牺牲太多空间效率的情况下进行高效的查找和删除操作。</li><li><strong>动态插入</strong>：当插入一个新键时，如果候选桶中没有足够的空间，Cuckoo Hashing会通过一系列置换操作来为新键腾出空间。这涉及到将现有的指纹移动到它们的替代位置，从而为新键腾出空间。已占用位置的元素会被移动到其它哈希函数确定的位置，可能导致一个连锁的重新放置过程。这个算法的名字来源于布谷鸟，因为布谷鸟会将自己的蛋放入其他鸟类的巢中，迫使其他鸟类的蛋被移位或丢弃。</li><li><strong>查找操作</strong>：给定一个键，Cuckoo Hashing通过检查两个候选桶中的指纹来确定键是否存在于表中。如果任一桶中存在匹配的指纹，则认为键存在于表中。</li><li><strong>删除操作</strong>：删除操作相对简单，Cuckoo Hashing检查两个候选桶，如果找到匹配的指纹，则移除该指纹。这种删除方法不会影响其他键的存储位置。</li><li><strong>高空间效率</strong>：Cuckoo Hashing通过存储指纹而不是完整的键来优化空间使用，同时保持较高的表占用率，从而实现高空间效率。</li></ol><h2 id="61-fingerprint"><a href="#6-1-fingerprint" class="headerlink" title="6.1 fingerprint"></a>6.1 fingerprint</h2><p>“fingerprint”是存储在Cuckoo Filter中的数据。，一个哈希函数处理数据后得到的哈希串。</p><h2 id="62-partial-key-cuckoo-hashing"><a href="#6-2-Partial-Key-Cuckoo-Hashing" class="headerlink" title="6.2 Partial-Key Cuckoo Hashing"></a>6.2 Partial-Key Cuckoo Hashing</h2><p>A cuckoo filter is a compact variant of a cuckoo hash table that stores only fingerprints-a bit string derived from the item using a hash function。</p><p>在cuckoo filter 中，哈希表中存储的数据发生了变化，由原始数据变成了fingerprint。<br><code>注意这里的（basic/standard） cuckoo hash tables指的是存储原始数据的做法。</code></p><p>partial-key cuckoo hashing 是一种仅使用指纹，而不需要原始数据就可以在置换操作中来确定元素存储位置的哈希技术。由于仅存储fingerprint 比存储原始数据所占内存空间小，所以 Partial-Key Cuckoo Hashing为优化Cuckoo Filter的空间效率和操作性能而设计。</p><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/PartialKey.png" class><p>如上代码所示，Partial-Key Cuckoo Hashing使用两个哈希函数 <code>h1</code> 和 <code>h2</code> 来计算两个候选桶位置。第一个哈希函数 <code>h1</code> 直接作用于元素的指纹，而第二个哈希函数 <code>h2</code> 则是 <code>h1</code> 与指纹的哈希值的异或（XOR）结果。<br>这种XOR的处理结果 可以根据其中任意一个已知的候选桶位置（i）计算出另外一个候选桶位置（j）<br>j &#x3D; i XOR fingerprint</p><h2 id="63-insert"><a href="#6-3-Insert" class="headerlink" title="6.3 Insert"></a>6.3 Insert</h2><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/cuckooinsert.png" class><p><strong>cuckoo 哈希的插入过程：</strong></p><ol><li>计算元素的指纹。</li><li>确定两个候选桶位置 <code>i1</code> 和 <code>i2</code>。</li><li>如果 <code>i1</code> 或 <code>i2</code> 有空闲条目，则将指纹插入到该条目中。</li><li>如果两个桶都满，则选择一个桶，随机选择一个条目并将其指纹与新元素的指纹交换。</li><li>Partial-Key Cuckoo Hashing ，更新候选桶位置 <code>i</code> 为 <code>i</code> XOR 指纹的哈希值。</li><li>如果找到空闲条目，则插入指纹；否则继续置换过程，直到找到空闲条目或达到最大置换次数。</li></ol><h2 id="64-lookup"><a href="#6-4-Lookup" class="headerlink" title="6.4 Lookup"></a>6.4 Lookup</h2><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/Lookup.png" class><h2 id="65-delete"><a href="#6-5-Delete" class="headerlink" title="6.5 Delete"></a>6.5 Delete</h2><img src="/2024/03/31/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90bloomfilter%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E7%8E%B0/delete.png" class><p>为什么cuckoo filter 可以删除元素但是又不影响其他元素的判断， 其实就是每个entry 只存储了一个元素的信息，删除后自然不会影响其他元素的判断。</p><h2 id="66-空间优化"><a href="#6-6-空间优化" class="headerlink" title="6.6 空间优化"></a>6.6 空间优化</h2><p>Cuckoo Filter进行空间优化（SPACE OPTIMIZATIONS）的方法主要涉及对哈希表参数的选择和配置，以及对桶（buckets）的编码策略。以下是论文中提到的一些关键的空间优化策略：</p><ol><li><strong>选择合适的桶大小（Bucket Size）</strong>：<ul><li>桶大小（b）对Cuckoo Filter的空间效率有显著影响。较大的桶可以提高哈希表的占用率（α），但同时也需要更长的指纹来维持相同的误报率。</li><li>论文中通过实验确定了对于不同的目标误报率（ϵ），最优的桶大小是不同的。例如，当误报率大于0.002时，每个桶有2个条目可能比4个条目更有效；而当误报率降低到0.00001至0.002时，每个桶有4个条目可以最小化空间使用。</li></ul></li><li><strong>半排序桶编码（Semi-Sorting Buckets）</strong>：<ul><li>对于每个桶中的指纹进行排序，然后使用一个预先计算好的表来编码这些排序后的指纹序列。由于桶内指纹的顺序不影响查询结果，这种方法可以通过索引来节省空间。</li><li>例如，如果每个桶有4个指纹，每个指纹是4比特长，那么未压缩的桶将占用16比特。通过排序和编码，可以使用一个12比特的索引来代替原来的16比特桶，因为可以预先计算出所有可能的桶值（例如，3876种），并将每个桶表示为一个索引，从而节省1比特每个指纹。</li></ul></li><li><strong>平衡桶的负载（Balancing Bucket Loads）</strong>：<ul><li>通过合理配置哈希函数和桶大小，可以减少哈希表中的冲突和空桶，从而提高空间利用率。</li><li>论文中提到，通过适当的配置，Cuckoo Filter可以以高概率达到95%的表空间占用率。</li></ul></li><li><strong>指纹长度的优化</strong>：<ul><li>指纹长度（f）与桶大小和目标误报率有关。通过调整指纹长度，可以在保持目标误报率的同时，优化空间使用。</li><li>论文中的分析表明，对于实际应用中的集合大小，较短的指纹（例如6比特或更长）通常足以确保哈希表的高利用率。</li></ul></li></ol><p>通过这些空间优化策略，Cuckoo Filter能够在保持高效动态操作的同时，实现紧凑的数据存储。这些优化使得Cuckoo Filter在很多实际应用中比传统的Bloom Filter和Counting Bloom Filter更加空间高效</p><h2 id="67-redis-cuckoo-filter"><a href="#6-7-Redis-cuckoo-filter" class="headerlink" title="6.7 Redis cuckoo filter"></a>6.7 Redis cuckoo filter</h2><p>redis 实现了 cuckoo filter ，基本实现逻辑和论文中表现一致，有兴趣大家可以自己去看一下</p><h1 id="7-自己如何实现一个布隆过滤器"><a href="#7-自己如何实现一个布隆过滤器" class="headerlink" title="7. 自己如何实现一个布隆过滤器"></a>7. 自己如何实现一个布隆过滤器</h1><p>基于以上对3种bloom filter的分析，可以总结出自己实现bloom filter时需要考虑的因素<br><a href="https://github.com/sysunyan1699/BloomFilterPractice">本项目代码可点击这里查看</a></p><h2 id="71-位数组的实现"><a href="#7-1-位数组的实现" class="headerlink" title="7.1 位数组的实现"></a>7.1 位数组的实现</h2><p>首先参考BitSet。<br>BitSet类是Java标准库中提供的一个用于处理位数组的类，基本可以认为是bitmap 在Java 的中的实现，其原理是是long[] 数组+ 位操作。<br>在自己实现布隆过滤器时，可以直接使用BitSet ， 也可以像guava cache 一样，自己用long[] + 位操作自己封装一个bitarray，而不是直接使用的BitSet。</p><h2 id="72-位数组的大小"><a href="#7-2-位数组的大小" class="headerlink" title="7.2 位数组的大小"></a>7.2 位数组的大小</h2><p>在简单的自己实现的版本中，可以直接指定bitarray 大小。</p><p>但在实际线上生产环境中可用的bloom filter 实现，一般都是根据预期插入的数据量 和 可接受的误报率两个数字通过 一个数学公式算出的，而不是直接用预期插入的数据量。</p><p>同时我们在线上生产环境使用布隆过滤器时，根据业务特性和流量去估算预期插入的数据量 和衡量  可接受的误报率 也是非常重要的步骤。 如果估算数据量比实际值大很多，就会浪费内存空间。如果估算数据量比实际值小很多，那么误报率很可能就无法控制在可接受的范围内。</p><ol><li>guava cache bloom filter 位数组大小一旦确定时无法修改的，所以实际数据量如果过大，那么误报率肯定会上升</li><li>redis bloom filter 位数组大小可以scale, 但是判断元素是否存在的这个步骤性能会受到影响</li></ol><h2 id="73-用哪个哈希函数"><a href="#7-3-用哪个哈希函数" class="headerlink" title="7.3 用哪个哈希函数"></a>7.3 用哪个哈希函数</h2><p>这个哈希函数在密码学中叫做单向散列函数。单向散列函数有两类<br>加密与非加密散列，其主要区别如下。</p><h3 id="731-加密散列函数"><a href="#7-3-1-加密散列函数" class="headerlink" title="7.3.1 加密散列函数"></a>7.3.1 加密散列函数</h3><p>设计用于加密应用，强调安全性。它们需要具备一定的性质，如抗碰撞（两个不同的输入不应该产生同一个输出）、隐藏性（无法从输出推断任何信息关于输入）和抗篡改（对输入的微小变化会在输出中产生不<br>可预测的、大的变化）。</p><ul><li><strong>SHA家族（SHA-1、SHA-256、SHA-512等）</strong>：安全哈希算法（Secure Hash Algorithm）家族，广泛用于加密、数据完整性校验和数字签名等安全相关的应用。</li><li><strong>MD5</strong>：消息摘要算法5（Message Digest Algorithm 5），尽管因为安全性问题不再推荐用于加密安全领域，但在一些非安全性要求的场合仍然可以见到其身影。</li><li><strong>RIPEMD</strong>：一系列的加密哈希函数，包括RIPEMD-160、RIPEMD-256和RIPEMD-320，其中RIPEMD-160设计用于替代MD5和SHA-1。</li><li></li></ul><h3 id="732-非加密散列函数"><a href="#7-3-2-非加密散列函数" class="headerlink" title="7.3.2 非加密散列函数"></a>7.3.2 非加密散列函数</h3><p>设计重点是高效率和均匀分布的输出，以支持快速数据检索、数据分布平衡等，而不是安全性。在某些情况下，允许存在碰撞，但碰撞的概率要尽可能低。</p><p>常见的非加密单向散列函数：</p><ol><li><strong>MurmurHash</strong>：由Austin Appleby设计，因其高性能和良好的分布特性而广泛应用。MurmurHash有多个版本，如MurmurHash2、MurmurHash3等。</li><li><strong>CityHash</strong>：由Google开发，专为哈希字符串数据设计，适用于构建哈希表等数据结构。后续Google又推出了FarmHash，作为CityHash的改进版，提供更好的性能和更广的适用范围。</li><li><strong>xxHash</strong>：是一种非常快的哈希算法，提供了极高的数据处理速度，同时保持了良好的散列分布特性，适用于需要快速散列大量数据的场景。</li><li><strong>Jenkins哈希函数（如一致性哈希）</strong>：Bob Jenkins所设计的一系列哈希函数，包括lookup3、SpookyHash等，它们广泛用于软件开发中，特别是在需要快速且分布均匀的哈希算法的场合。</li><li><strong>FNV（Fowler-Noll-Vo）</strong>：是一系列设计简单、性能良好的哈希函数，特别适合于散列单个文本字符串。FNV-1和FNV-1a是两个最著名的变种。</li></ol><p>在以上分析原理分析中，guava cache和Redis  都是用了MurmurHash<br>如果我们自己也想要用MurmurHash，目前Java并没有提供实现，可以引入guava cache 包使用MurmurHash。</p><h2 id="74-用多少个哈希函数"><a href="#7-4-用多少个哈希函数" class="headerlink" title="7.4 用多少个哈希函数"></a>7.4 用多少个哈希函数</h2><p>前面说过用多个哈希函数可以减少误报率，那么到底要用多少个哈希函数呢， 这也是可以通过 预期插入的数据量+ 可接受的误报率 通过固定的数学公式计算得出。<br>同时多个哈希结果可以通过像Guava cache一样，用双哈希技术模拟得到。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;0什么场景下会用到bloom-filter&quot;&gt;&lt;a href=&quot;#0-什么场景下会用到bloom-filter&quot; class=&quot;headerlink&quot; title=&quot;0.什么场景下会用到bloom filter&quot;&gt;&lt;/a&gt;0.什么场景下会用到bloom filte</summary>
      
    
    
    
    
    <category term="Programming" scheme="http://example.com/tags/Programming/"/>
    
  </entry>
  
</feed>
