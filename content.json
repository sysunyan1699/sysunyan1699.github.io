{"meta":{"title":"Sun Yan","subtitle":"","description":"","author":"Sun Yan","url":"http://example.com","root":"/"},"pages":[{"title":"tags","date":"2024-04-28T09:06:01.000Z","updated":"2024-04-28T09:07:08.242Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"InnoDB事务-持久性的实现,binglog & redo log","slug":"InnoDB事务-持久性的实现，-binglog-redo-log","date":"2024-05-02T14:47:18.000Z","updated":"2024-05-10T15:24:50.204Z","comments":true,"path":"6cb5dc64/","permalink":"http://example.com/6cb5dc64/","excerpt":"","text":"在MySQL InnoDB 这个语境下， crash safe、数据不丢失 都指的是事务的持久性特性，即事务一旦提交，应当保证所有被成功提交的数据修改都能够正确地被持久化，不丢失数据, 即使宕机也能够恢复数据 在InnoDB 中，持久性 基于binlog 和redo log 实现， 且binlog 与redo log 的写入通过2PC 协调. 0 XA 事务：binlog 和redo log 的两阶段提交 在MySQL中，InnoDB存储引擎 的 redo log 和MySQL服务器层binlog 之间的一致性是通过内部的XA机制（即分布式事务）来实现的，任何一个数据出现问题都会进行会滚。 XA事务是一种分布式事务。通过两阶段提交协议和XA接口标准，事务管理器和资源管理器能够可靠地协同工作，实现跨系统的事务处理，确保多个独立资源的一致性。 在binlog 和redo log 的两阶段提交， binlog 充当协调者的角色。 关于XA 事务具体可在这篇文章中查看 binlog 和 redo log 各自写入的过程还有很多细节，接下来进行讲解 1 binlogbinlog是 MySQL 服务器层使用的日志文件，记录了所有修改数据库内容的SQL语句（如 INSERT, UPDATE, DELETE）,也被称为逻辑日志。 binlog 主要用于主备复制同步、崩溃恢复等功能。 1.1 binlog 的三种日志格式 格式 定义 优点 缺点 Statement-Based Logging (SBL) 记录执行的 SQL 语句本身，而不是每行数据的变更。 1. 空间效率高：通常占用更少的空间，因为记录的是 SQL 语句。 2. 易于审计：直接记录 SQL 语句，易于阅读和理解。 1. 非确定性行为：可能在主从复制中导致数据不一致，特别是涉及到非确定性函数（如 NOW()、RAND()）的 SQL 语句。2. 复制错误：某些特定情况下可能引起从服务器的复制错误。 Row-Based Logging (RBL) 记录数据变更前后的每行数据的具体变化，而不是执行的 SQL 语句。 1. 数据一致性：在复制过程中提供高度的数据一致性。2. 安全性更高：不记录 SQL 语句，降低了 SQL 注入的风险。 1. 空间占用大：因为记录了每一行的变化，可能导致 binlog 文件迅速增大。2. 可读性差：不记录 SQL 语句，对于人类审计不友好。 Mixed-Based Logging (MBL) 结合了 SBL 和 RBL 的特点，根据操作的类型自动选择使用基于语句的格式或基于行的格式记录。 1. 灵活性高：根据 SQL 语句的特性选择最合适的日志格式。2. 平衡性能和一致性：在确保数据一致性的同时考虑日志大小和性能。 1. 配置复杂：需要适当配置以确保效率和准确性。2. 预测性差：自动切换日志格式可能使得日志的结果难以预测。 1.2 binlog写入过程binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。 1.2.1 binlog cache对于每个客户端会话，MySQL 服务器为其分配一个 binlog cache。这个缓存是用来临时存储一个事务中产生的所有 binlog 事件。 但是binlog cache 刷新到磁盘时 多个线程是共写同一份 binlog 文件。 当一个新事务开始时，根据binlog 日志格式记录 每个修改SQL 语句到binlog cache 中 1.2.2 page cache 与 磁盘刷新持久化当事务到达提交阶段时，首先将 binlog cache 中的内容 写入到binlog 文件中，然后提交事务到 InnoDB，即 commit redo log 。 注意，这里的写入并不是直接写到到磁盘，而是先写入到文件系统的page cache, 然后通过sync_binlog 参数来决定 何时把数据写入到 磁盘。 磁盘刷新频率通过 sync_binlog 配置参数， sync_binlog&#x3D;0 的时候，表示每次提交事务都不主动刷新磁盘，由文件系统自己控制刷盘频率 sync_binlog&#x3D;1 的时候，表示每次提交事务都会将 binlog cache 中的内容刷新到磁盘 sync_binlog&#x3D;N(N&gt;1) 的时候，表示累积 N 个提交事务后才将多个binlog cache中的内容刷新到磁盘。 可以看到如果sync_binlog不设置为1 ，有有助于提高刷盘效率， 但是有丢失binlog 的风险。 1.2.3 binlog cache 不够用怎么办如果binlog cache 写满了怎么办？需要把数据暂存到磁盘 每个事务的 binlog 事件首先被写入到 binlog cache 中，这个缓存的大小由 binlog_cache_size 系统变量控制。 如果一个事务非常大，涉及大量的数据修改，导致binlog cache不足以存储当前事务的所有事件时，MySQL采用的处理机制是将缓存中的数据写入到磁盘上的一个临时文件中。这一过程可以分为以下几个步骤： 检测缓存溢出：当试图向binlog cache中写入数据，而缓存空间不足以容纳更多数据时，将触发溢出处理机制。 数据写入临时文件：MySQL将当前binlog cache中的数据写入到一个临时文件中。这个临时文件通常位于MySQL的数据目录下，具有唯一标识，确保数据的隔离和安全。 清空binlog cache：将数据写入临时文件后，binlog cache会被清空，为接下来的日志数据腾出空间。 继续事务日志的记录：事务继续执行，新的日志事件会再次被记录到现在已经被清空的binlog cache中。 事务提交：事务如果最终被提交，MySQL会将临时文件中的日志数据以及现在binlog cache中的数据一并写入到全局的binlog文件中。如果事务回滚，则临时文件和binlog cache中的数据都将被丢弃。 1.3 xidXID（Transaction Identifier） 可以理解成时MySQL server 层的事务唯一标识。 MySQL服务器内部维护一个全局事务ID计数器，每个新事务都会分配一个唯一的ID。该计数器在内存中递增，保证每个事务ID在实例中是唯一的。 当一个新事务开始时，MySQL服务器层会从全局计数器中获取一个新的事务ID，将其赋予该事务，并存储在该事务的上下文中。 2 redo logredo log是 InnoDB 存储引擎特有的日志文件，用于记录对数据库做出的更改前的数据页状态,也被称作物理日志，确保在数据库系统发生崩溃后能够恢复这些更改。记录内容：Redo log 记录的是数据页修改的物理操作，而非具体的 SQL 语句。 循环使用：Redo log 是固定大小的，通常配置为一组文件，工作在循环写入的方式。 崩溃恢复：系统重启后，InnoDB 通过回放 redo log 来恢复未完成的事务，确保数据的完整性和一致性。 提高性能：Redo log 允许 InnoDB 在事务提交时不必将所有数据页写回磁盘，只需确保 redo log 已被写入磁盘。 记录的是数据页的物理修改。 不论数据页是否在buffer pool 中， redo log 都要记录修改， 因为不记不能保证crash safe. 保存自增值 2.1 为什么要记录redo log2.1.1 buffer poolMySQL 为了实现高性能，是不可能每次都从磁盘读数据或者把对数据的修改持久化到磁盘上的,所以 InnoDB 申请了一块连续的内存，用于存储从磁盘上读取的pages, 这个内存就是buffer pool。 buffer pool 有一块内存叫做，change buffer 用于暂存对数据的修改 那么在修改数据时，就会遇到两种情况 数据所在的page 在buffer pool 中， 就会直接更新page 数据所在的page 不在buffer pool 中， 如果不需要加载对应page, 就会先把对数据的修改先记在change buffer 中 不论是buffer pool, 还是 buffer pool 中的change buffer, 都是内存，一旦发生宕机，那就数据的修改的修改就会丢失，此时就违背了事务的持久性。 为了能把修改过的数据持久化又不影响性能，InnoDB 给出的方案是优先把修改操作记下来并持久化， 事务提交后，万一宕机丢失了buffer pool 中已修改但是未持久化的内容，就可以根据持久化的修改操作重新得到修改后数据。 这里记录下来的修改操作就是redo log, 而这种先记录修改操作，再记录修改后的技术叫做WAL。 2.1.2 WALWAL（Write-Ahead Logging）是一种在数据库系统中广泛采用的日志管理技术，用于保证数据库的事务持久性和恢复能力。 它的关键点就是先写日志，再写真正的数据。 redo log 直接应用了 WAL 技术，确保在任何数据被写入数据库页之前，相应的日志信息（如数据页的修改）先被写入到 redo log 中。 总的来说WAL 技术的优势有以下3项， 恢复能力：WAL 提供了强大的数据恢复能力。在发生系统故障后，可以利用日志文件中的记录来重做或撤销事务，恢复到最后一致的状态。 性能优化：通过将对磁盘数据的随机写转换为顺序写 ， 同时利用 组提交 ，WAL 可以显著提高数据库的写性能。 事务原子性和持久性：WAL 通过确保所有日志记录在实际数据写入前被提交到磁盘，从而支持数据库事务的原子性和持久性。 2.2 redo log 记录的内容之所以说redo log 是物理日志， 是因为其记录了对特定数据page 数据的修改。该例子来自极客专栏《MySQL 实战45讲》 12mysql&gt; create table t(ID int primary key, c int);mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2); 这条更新语句做了如下的操作（按照图中的数字顺序）： Page 1 在内存中，直接更新内存； Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息 将上述两个动作记入 redo log 中（图中 3 和 4）。 Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。 2.3 redo log 写入过程# 23 | MySQL是怎么保证数据不丢的？ redo log 的写入机制-redo log buffer redo log 的写入机制和 binlog 类型， 需要经历 MySQL 系统内存cache ， redo lo buffer 文件系统page cache 刷新持久化到磁盘 2.3.1 redo log bufferadd(id1,k1) to page1, new change buffer item add(id2,k2) to page2 都是先写入redo log buffer 中 相比较 每个线程都拥有自己一块独立的 binlog cache ， 而 redo log buffer 是全局共用的。 2.3.2 redo log持久化到磁盘事务提交，执行commit redo log 后，会触发redo log buffer 中内容写入到redo log 中。 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值： 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 所以想要确保MySQL异常重启之后redo log 数据不丢失，innodb_flush_log_at_trx_commit 这个参数 建议设置成1. 前面在binlog部分说到， 在事务提交前，事务binlog 是不会被写入到真正的binlog 文件中的。 redo log 不一样，在事务提交前，redo log 有可能备持久化磁盘。有以下3种情况 后台线程,每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。， redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑， 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上未提交事务 在 redo log buffer 里的日志一起持久化到磁盘。 2.3.3 2PC的细化过程2.4 日志文件组InnoDB 的 redo log 是以日志文件组的形式组织的。一个日志文件组通常包含两个或更多的日志文件，这些文件在物理上是连续的，并且循环使用。当一个日志文件写满后，InnoDB 会自动切换到下一个日志文件继续写入。当最后一个文件写满后，它会回到第一个文件并开始覆盖旧的日志记录，这就是所谓的“环形写入”。 2.5 LSNLSN（Log Sequence Number）,日志序列号,是一个不断增长的全局变量， 用来记录当前redo log 文件中 已经写入的日志量， 单位是字节。 图片中的write pos LSN 指当前已经产生的的日志量，随着更多的事务数据被写入，write pos LSN 会不断增加 checkpoint LSN 是redo log 中的一个位置，表示所有之前的日志记录都已经被应用（或说是“刷新”）到了磁盘的数据页上，因此，从这个位置以前的日志数据可以安全地被覆写， 不会出现数据丢失的情况。 redo log 会有多个检查点 write pos LSN 和 checkpoint LSN之间空着的部分，可以用来记录新的操作。 如果 write pos LSN 赶上了最一个checkpoint LSN 位置，这意味着 redo log 的空间不足，可能会导致数据库操作停顿，因为系统需要等待足够的日志空间来记录新的事务数据。 2.6 组提交前面提过，redo log 提升性能，一个是把对磁盘的随机写转换成了顺序写，一个是组提交机制。 组提交机制（Group Commit）是一种通过合并多个事务的日志提交操作来提高I&#x2F;O效率的策略。这一机制基于LSN（Log Sequence Number，日志序列号）来追踪和管理日志提交。 以下图为例解释 事务trx1开始： trx1进入事务队列并被选为组的领导者，日志记录的LSN开始增加。 事务trx2和trx3加入 在trx1进入队列之后，trx2和trx3紧随其后进入提交队列。 LSN更新到160： 随着trx2和trx3的日志写入缓冲区，整个组的最后一个日志序列号LSN变为160。 领导者trx1执行写盘： trx1作为组的领导者，携带LSN=160去执行一次性日志写盘（fsync）操作。 写盘完成： trx1的fsync操作完成后，所有LSN &lt;= 160的日志记录都被持久化到磁盘。 事务返回提交成功： trx1、trx2和trx3都标记为提交成功并从提交队列中移除。 3 事务执行过程中的binlog 和redolog 和undo log下面将结合MySQL 的逻辑架构 和具体SQL , 来具体地看一下binlog 和redo log 的写入 SQL 12mysql&gt; create table T(ID int primary key, c int);mysql&gt; update T set c=c+1 where ID=2; 结果MySQL 的逻辑架构， 该update sql的执行过程如下 执行器先找InnoDB取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在buffer pool 中，就直接返回给执行器；否则，需要先从磁盘读入buffer pool，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 InnoDB引擎记录该行数据的undo log, 然后新数据更新到内存中，如果数据本来就在内存中，则直接修改数据页，如果不再内存中，则将修改记录在change buffer 中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。 然后告知执行器执行完成了，随时可以提交事务。执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。根据 innodb_flush_log_at_trx_commit 决定redo log 是否持久化到磁盘 buffer pool 中对数据页的更新 ,等待脏页刷线操作持久化到磁盘 14.prepare阶段,将事务的xid写入，将binlog_cache里的进行flush以及sync操作(大事务的话这步非常耗时)15.commit阶段，由于之前该事务产生的redo log已经sync到磁盘了。所以这步只是在redo log里标记commit 4 崩溃恢复的逻辑崩溃恢复过程中，InnoDB 会从最近的 checkpoint LSN开始，应用 redo log 中的更改，直到达到崩溃时的 write pos LSN，以此来恢复数据库到最后一次提交的状态。 看一下崩溃恢复时的判断规则 如果 redo log 里面的事务是完整的，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整： 如果完整，则提交事务； 否则，回滚事务。&#x3D;&#x3D;此处事务回滚基于undo log &#x3D;&#x3D; 如果redo log 没有完整的prepare, 则事务基于undo log 回滚 ⚠️说明一下，innodb_flush_log_at_trx_commit 实际上控制了redo prepare 和commit 两个阶段的刷盘策略，比如innodb_flush_log_at_trx_commit &#x3D;1 时在 prepare 阶段和 commit 阶段，redo log 都会持久化写入磁盘。所以才会出现第二种磁盘有且只有完整prepare 的情况。 接下来根据一些具体的问题来详细说明崩溃恢复时的细节 4.1 如何判断 redo log 是完整的redo log commit 阶段会有commit 标识 4.2. 如果判断binlog 完整性一个事务的 binlog 是有完整格式的：statement 格式的 binlog，最后会有 COMMIT；row 格式的 binlog，最后会有一个 XID event。 4.3. redo log 和 binlog 是怎么关联起来的在崩溃恢复时，通过读取Redo Log中的Xid，能够将其与Binlog中的Xid进行匹配。 XID（Transaction Identifier） 可以理解成时MySQL server 层的事务唯一标识。redo log 中会记录XID 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。 4.4. 为什么要用2PC 协调binlog和redo log类似的问题还有，为什么处于 prepare 阶段的 redo log 加上完整 binlog 就可以提交事务。 这两个问题本质上都是数据一致性的问题。 binlog 是server 层日志， 是MySQL 一开始就有的功能，被用在了很多地方，比如备份、主备同步复制。redo log 是InnoDB 层日志，是InnoDB 为了实现事务功能新增的。使用2PC可以维护两份之间的逻辑一致。 那么，为什么要维护两份日志间的逻辑一致呢。 binlog 是server 层日志， 是MySQL 一开始就有的功能，被用在了很多地方，比如备份、主备同步复制。redo log 是InnoDB 层日志，是InnoDB 为了实现事务功能新增的。如果两份日志逻辑或者说数据不一致， 那么用日志恢复出来的数据库状态就有可能和它本来应该的状态不一致。 具体举例来讲，如果不用2PC，两种日志要么是先写 redo log 再写 binlog，或者先写binlog 再写redo log 。仍然用前面的 update 语句来做例子。假设当前 ID&#x3D;2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？ 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 同理，为什么处于 prepare 阶段的 redo log 加上完整 binlog 就可以提交事务。因为如果binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。如果redo log 事务不提交的话，就会发生数据不一致的情况 4.5. 不要binlog 可以吗仅从事务持久化&#x2F;崩溃恢复这个功能来讲， 只要redo log 是可以完成的。但是binlog 作为 MySQL 一开始就有的功能，被用在了很多地方，有redo log 无法替代的功能 。 归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。 主从复制同步 MySQL 高可用 在一些业务场景中， 也会使用binlog做数据同步，比如使用canal 同步binlog数据 到ES 4.6 数据一定不会丢失吗-双1 设置在介绍binlog和redo log 写入过程的时候，有两个参数sync_binlog 控制binlog 持久化到磁盘的频率 sync_binlog&#x3D;0 的时候，表示每次提交事务都不主动刷新磁盘，由文件系统自己控制刷盘频率 sync_binlog&#x3D;1 的时候，表示每次提交事务都会将 binlog cache 中的内容刷新到磁盘 sync_binlog&#x3D;N(N&gt;1) 的时候，表示累积 N 个提交事务后才将多个binlog cache中的内容刷新到磁盘。 innodb_flush_log_at_trx_commit 控制redo log 持久化到磁盘的频率 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 可以看到吗，只有在双1设置的时候，sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1， 才能确保一定不会丢数据 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 如果不设置成双1， 有助于提高性能。 5. binlog vs redo log差异 层级差异：Binlog 工作在 MySQL 服务器层，所有引擎都可以使用；而 redo log 是 InnoDB 存储引擎层特有的。 记录形式：Binlog 可以记录 SQL 语句或行变更，redo log 记录的是数据页的物理变化，即“在某个数据页上做了什么修改” 目的和用途：Binlog 主要用于数据复制和崩溃恢复，而 redo log 主要用于事务的持久性和崩溃恢复。 大小管理：Redo log 的大小是固定的，循环使用循环写；binlog 是追加写，可以不断增长，需要定期进行清理。 日志写入：每个线程都拥有自己一块独立的 binlog cache ， 而 redo log buffer 是全局共用的 共同点 事务安全：两者都是为了保证事务的持久性和原子性。 恢复支持：在系统或硬件故障后，两者都能被用来恢复数据。 写前日志：都采用了写前日志（write-ahead logging, WAL）的技术，即在实际修改数据库内容前先记录日志。 从生产到写入磁盘均有内存page - 到page cache - 磁盘，刷新到磁盘的时机均有参数控制 相关文章Intro to 事务Intro to InnoDB 事务InnoDB事务-原子性的实现,undo logInnoDB事务-隔离性的实现,MVCC &amp; 锁","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"InnoDB事务-隔离性的实现, MVCC & 锁","slug":"InnoDB事务-隔离性的实现-MVCC-锁","date":"2024-05-02T14:42:57.000Z","updated":"2024-05-10T15:24:50.199Z","comments":true,"path":"9faedfe0/","permalink":"http://example.com/9faedfe0/","excerpt":"","text":"隔离性，还有一个说法就是 数据可见性。 隔离性、数据可见性是一个在并发事务下才需要考虑的问题，并发事务可以分3种情况考虑 读-读， 读操作不会对数据产生影响，所以不需要关注 读-写 or 写-读， 可能会出现脏读、不可重复读、幻读 写-写，可能会脏写的情况 并发事务下的数据的一致性写问题 脏写：一个事务修改了另一个未提交事务修改过的数据。 并发事务下的数据的一致性读问题 脏读：事务读取了未提交的数据，可能造成数据不一致。 不可重复读：事务在内部的多次读取中看到了同一数据的不同版本，主要由于其他事务的更新操作。 幻读：事务在两次查询同一个范围时看到了不一样的行，通常是因为其他事务添加或删除了行。 MySQL 的 4种 事务隔离级别 隔离级别 解决的问题 未解决的问题 原理描述 读未提交 无 脏读、不可重复读、幻读 允许事务读取其他事务未提交的修改，可能导致脏读。 读已提交 脏读 不可重复读、幻读 只能看到已经被其他事务提交的数据，避免了脏读，但不能防止在同一事务中看到不一致的数据。 可重复读 脏读、不可重复读 MySQL 在该隔离级别下加上gap 锁可部分解决幻读问题 在事务开始后所有SELECT操作都看到一致的快照，避免了不可重复读，但无法防止其他事务插入新行（幻读）。 串行化 脏读、不可重复读、幻读 无 “写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。通过强制事务串行执行，防止了脏读、不可重复读和幻读，提供了最高级别的隔离。 由于脏写导致的数据一致性问题非常严重，任何一种隔离级别下都不允许发生，对数据的修改操作必须通过锁串行执行 InnoDB 在解决 并发事务时，分成两种情况对应不同的解决方案 快照读-MVCC 当前读- 锁 1 快照读的隔离性-MVCC 一致性视图：在快照读中，事务会创建一个一致性视图（Consistent Read View），确保当前事务读取到的都是事务开始时的数据状态。它依赖于MVCC的实现。 无需锁定：快照读是一种无锁的读取，即读取数据时不需要对行记录进行锁定，因此它不会阻塞事务的读写，同时也不会被其他事务的读写操作阻塞。 隔离级别影响：快照读的行为受事务隔离级别的影响，不同的隔离级别会影响读取到的版本。 在读未提交隔离级别下，所有事务都读取最新事务； 在串行化隔离级别下，使用锁控制数据的访问。 在读已提交和可重复读隔离级别下，使用MVCC 来控制数据的可见性。 InnoDB存储引擎的MVCC（多版本并发控制）机制是基于ReadView和Undo Log共同实现的，关键是通过TRX_ID和ROLL_PTR两个行记录隐藏列来跟踪和管理每一行的修改版本。 1.1 版本链 -undo log在基于undo log 实现原子性 一文中，可以看到 行记录中有roll_pointer, update 操作中TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC 类型的undo log 中，也有roll_pointer,通过这些roll_pointer, 可以形成一条行记录的版本链。 insert 操作中，对应的undo log没有roll_pointer 属性，因为insert 操作就是一个行记录的初始版本，没有比它更早的操作了。 以下是一个通过roll_pointer 组成的版本链，每个undo log 进行了内容省略以展示链接的重点内容 1.2 readview有了版本链，那么该如何判断哪个版本的数据对当前事务可见呢，这里需要引入readview 概念。 Read View 主要包含以下几个关键的部分： m_ids：当前系统中活跃的事务ID列表。这些事务在生成 Read View 时已经开始但尚未提交。 min_trx_id：生成 Read View 时，活跃事务ID中的最小值。这是因为任何 ID 小于此值的事务在 Read View 生成前已经提交。 max_trx_id：生成 Read View 时，已知的下一个事务ID。任何大于或等于此 ID 的事务在生成 Read View 后开始的。 creator_trx_id：生成这个 Read View 的事务的事务ID。 一个事务只有进行修改操作时，才会被分配trx_id, 否则一个事务的trx_id 默认都是0， 所以 creator_trx_id 也有可能时0 运作方式： 当事务执行查询操作时，它会根据自己的 Read View 来判断数据行的可见性。具体来说，每行数据都有自己的系统版本号（trx_id，即事务ID）。Read View 通过以下逻辑来确定行的可见性： 如果行及记录的trx_id 和creator_trx_id 相等，说明当前事务在访问自己修改的数据，数据可见。 如果行的版本号小于 min_trx_id，说明行是在 Read View 生成之前被创建或最后修改的，因此对当前事务可见。 如果行的版本号大于或等于 max_trx_id，说明行是在 Read View 生成之后被创建或修改的，因此对当前事务不可见。 如果行的版本号在 min_trx_id 和 max_trx_id 之间，还需要检查这个版本号是否属于 m_ids 列表中的某个事务： 如果属于，说明该行可能由尚未提交的事务修改，对当前事务不可见。 如果不属于，说明该行由已提交的事务修改，对当前事务可见。 如果某个版本的数据对当前事务不可见，那就顺着版本链找洗一个版本的数据，并按照上面的步骤进行判断。如果一个数据直到最后一个版本都不可见，那就说明该条数据对当前事务完全不可见 1.2.1 readview 和 读已提交（Read Committed） 生成时机：在 RC 隔离级别下，Read View 不是在事务开始时生成，而是在一个事务内每次执行 SQL 查询时都会生成新的readview, 所以该事务内是可以看到其他事务已提交的对数据的修改，这在数据一致性上就表现为不可重复读 行为：每次查询都创建一个新的 Read View，包含当前时刻所有未完成的事务ID。这确保了查询只能看到那些在执行查询前已经提交的事务所做的更改。 1.2.2 readview 和 可重复读（Repeatable Read）InnoDB 的 默认隔离级别。 生成时机：在 RR 隔离级别下，Read View 是在事务的第一次查询操作开始时创建的，且在整个事务期间保持不变。这意味着整个事务中所有的查询都将看到相同的数据快照。 行为：一旦生成，这个 Read View 将包含事务开始时刻的所有活跃事务ID。无论这些事务后来如何提交或回滚，当前事务的后续查询都不会感知到这些变化。 1.2.3 两者的对比 数据可见性：在读已提交中，事务可能看到其他事务提交的更新（即事务中的查询可能返回不同的结果），而在可重复读中，事务保证了始终对数据的一致视图。 Read View 的生成频率：读已提交每次查询都重新生成 Read View，而可重复读只在事务开始时生成一次。 系统开销：由于读已提交每次查询都需要生成 Read View，可能会有更高的系统开销，尤其是在查询频繁的场景中。相比之下，可重复读的开销主要集中在事务开始阶段。 2 当前读的隔离型-锁当前读指的是读取数据时总是获取数据的最新版本，并通过加锁（行级别的排他锁，S锁或X锁）以确保一致性，防止其他事务修改或删除这些数据。 当前读通常用于需要修改数据的查询，如 select…lock in share mode (共享读锁) select…for update UPDATE DELETE 关于行锁和间隙锁的具体加锁规则，和隔离级别和索引有关，大家可以参考何登成的加锁分析文章MySQL 加锁分析 3. 幻读bad case在前面介绍隔离级别时，提到 在可重复读隔离级别下 加上 间隙锁， 可以一定程度上解决幻觉。但是如果一个事务中 快照读和当前读混用，就会出现幻读bad case. 幻读被完全解决了吗？ 这篇文章中例举两个幻读 bad case,讲的比较清晰，可以参考 4. 当前读vs快照读 快照读（Snapshot Read）： 读取数据时使用的是某一时间点的快照，不会加锁。 使用MVCC机制，根据事务的隔离级别和版本号返回合适的行版本。 通常用于SELECT查询。 当前读（Current Read）： 始终读取最新版本的行。 可能会加锁，防止其他事务修改或删除读取的数据。 通常用于修改数据的查询操作，如SELECT ... FOR UPDATE、SELECT ... LOCK IN SHARE MODE、UPDATE和DELETE。 相关文章Intro to 事务Intro to InnoDB 事务InnoDB事务-原子性的实现,undo logInnoDB事务-持久性的实现, binglog &amp; redo log&amp;undo log","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"InnoDB事务-原子性的实现,undo log","slug":"InnoDB事务-原子性的实现，undo-log","date":"2024-05-02T14:22:30.000Z","updated":"2024-05-10T15:24:50.194Z","comments":true,"path":"b36b0ce9/","permalink":"http://example.com/b36b0ce9/","excerpt":"","text":"原子性指的是事务要么完全成功执行，要么完全失败回滚，不允许部分执行。 这本质上是在要求具有rollback 回滚能力。 InnoDB中的事务可能会由用户主动触发Rollback；也可能因为遇到死锁异常Rollback；或者发生Crash，重启后对未提交的事务回滚。 InnoDB 的 rollback回滚能力 是基于 undo log 实现的。undo log 记录了修改操作前的旧版本数据，以便在回滚时恢复数据。 1 一条 undo log 的结构1.1 undo log 的分类只有在事务中对数据进行修改（如 INSERT、DELETE、UPDATE）的时候， 才需要记录undo log，快照读 select 不需要记录。 不同的修改操作产生的 undo log 记录的内容和结构会有所不同，因为每种操作对数据的影响不同, 所以undo log 也会有不同的类型。 InnoDB 的 undo log 主要分为两大类： TRX_UNDO_INSERT：此类主要包括 TRX_UNDO_INSERT_REC 类型的日志，专门用于记录插入操作的撤销信息。 TRX_UNDO_UPDATE：此类包括 TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC，用于记录更新存在的记录和标记删除操作的撤销信息。 共同点：所有类型的操作都需要且只需要记录足够的信息来逆转所执行的操作。这些记录都存储在 InnoDB 的 undo 表空间或者系统表空间中 差异：不同操作类型的 undo 日志记录的具体内容根据操作的性质而异。INSERT 主要关注标记新增行的删除，DELETE 需要记录完整的行数据以便恢复，而 UPDATE 记录修改前的字段值。 ⚠️：对于 undo log 的记录并不是基于每条修改 SQL 语句，而是基于 修改SQL 语句影响的每一条记录。这意味着每条被修改的记录都会有对应的 undo log 。如果一个 SQL 语句影响修改了多行数据，那么将会有多条 undo log 生成。 1.2 INSERT 操作的 Undo log对于 INSERT 操作，undo 日志通常记录较少的信息，主要是把这条记录的主键信息记上。 1.2.1 end of record 和 start of record在InnoDB的undo日志结构中，end of record和start of record 两个字段共同起到链接undo日志记录的作用，使这些记录形成一个双向链表，并提供顺序遍历和反向遍历的功能 end of record 定义： end of record字段指示当前undo日志记录的结束位置，并提供下一条undo日志记录的起始地址。 当最后一条undo日志记录没有后继时，则下一条undo日志记录的起始地址为NULL 目的： 指向链表中的下一条记录，方便顺序遍历日志记录，可以用于回放或者重做日志，特别是在恢复阶段 start of record 定义： start of record字段指示当前undo日志记录的起始位置，并提供上一条undo日志记录的结束地址。 如果当前undo日志记录是链表中的第一条，则上一条undo日志记录的结束地址为NULL。 目的： 指向链表中的上一条记录，方便反向遍历日志记录，用于事务回滚 1.2.2 undo type该字段指定undo日志记录的类型, 用于区分不同类型的undo操作，如TRX_UNDO_INSERT_REC 、 TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC 1.2.3 undo no日志编号， 在一个事务内从0开始递增，每生成一条日志，undo no 就加1 1.2.4 table id原始记录所在表的标识符，使undo日志能够与原始记录所在的表关联。 1.2.5 &lt;len, value&gt;此部分以&lt;长度，值&gt;的形式保存每个主键列的信息，以便在回滚插入操作时恢复主键值： len：表示对应列的存储空间大小。 value：存储主键的实际值。 1.3 DELETE 操作的 Undo log-标记删除 trx_id记录上一个旧版本数据的trx_id, 该值从行记录的隐藏列trx_id 中获取 目的： 在回滚过程中，这个字段可以帮助恢复被删除的记录的原始事务信息，确保在恢复期间不会出现不一致的问题。 roll_pointer记录上一个旧版本数据的roll_pointer, 该值从行记录的隐藏列roll_pointer 中获取 描述： 指向被删除记录的原始回滚指针 (roll_pointer)。 在InnoDB中，每条行记录都有一个位（bit）标记来指示该记录的状态，包括是否已被删除。这是通过记录头（Record Header）中的info bits字段实现的。 1.3.1 标记删除TRX_UNDO_DEL_MARK_REC 日志 指的是对记录的逻辑删除，逻辑删除指的是只被标记为删除状态，并不会立即将其物理删除，因为还要支持事务回滚，以及MVCC。 被标记删除的数据如果真的需要删除，会在适当的时候由后台线程实际清理 1.3.2 行记录的删除标记每条行记录的头部都有一个info bits字段，用来存储记录的状态信息，包括是否已被删除。 在info bits字段的第5个bit位上，标记记录是否已被删除， 当此bit位为1时，表示该记录已被标记删除；为0时，表示该记录是正常的。 1.4 UPDATE 操作的 Undo logupdate 的操作 分为两种 不更新主键的update, 这种操作 一条记录 只会TRX_UNDO_UPD_EXIST_REC 一条undo log 更新主键的update ，这种update在实际执行时， 会先删除旧记录，再insert 一条新纪录， 所以会记录两条undo log, 一条TRX_UNDO_DEL_MARK_REC， 一条TRX_UNDO_INSERT_REC 具体字段信息和前面两种类似，不再详述。 2一个事务中的多条undo log如何组织在一起2.1 undo page -分类型存储undo logInnoDB 对数据的管理是以 page 为单位进行的，undo log 也遵循这一原则，即存储在专门的 undo pages 中。 每个 undo page 中的日志记录是专用的，不同类型的undo log 不能混着存储， 即一个 page 中不能同时记录 TRX_UNDO_INSERT 类型和 TRX_UNDO_UPDATE 类型的日志。 这样设计的理由是为了避免在回滚时需要在同一页面上搜索不同类型的日志记录，从而提高了回滚操作的效率。 可是 一个事务内可以同时存在insert undo log和update undo log, 如果事务需要回滚则所有操作都需要回滚，那为什么还要分开存储呢？ 优化事务回滚的逻辑 操作依赖性减少：插入操作的回滚仅涉及到删除之前插入的行，而更新或删除操作的回滚需要恢复原始数据。将这些操作的日志分开，可以在回滚时减少对不同类型日志处理逻辑的依赖，使得回滚过程更加模块化和有序。 执行效率：分开存储使得处理各自的回滚逻辑时可以更加高效，因为每种类型的回滚处理只需关注其对应类型的日志页。这减少了在单一日志页中搜索和处理不同类型日志的复杂性和时间。 并行处理尽管一个事务中可能存在多种类型的 undo 日志，但在并发环境中，不同的回滚任务可能由不同的系统进程或线程处理。例如，某些情况下系统可能并行地处理 insert undo log 和 update undo log。分开存储可以减少锁的竞争和管理的复杂性，提高并发处理的效率。 空间和性能管理 简化空间回收：在事务提交后，insert undo log 可以立即被丢弃和回收，因为插入操作生成的记录一旦提交即视为有效。而 update undo log 可能需要被保留以支持其他事务的一致性读（由于 MVCC）。分开存储使得空间管理更为高效，因为可以针对性地处理和回收日志空间。 优化读取性能：在事务处理过程中，尤其是在一些只涉及到特定类型操作的查询或回滚操作中，分开存储可以优化日志的读取性能，因为系统可以直接定位到相关类型的日志页。 日志维护的简化 分开存储有助于简化日志维护和日志生命周期管理。系统可以更容易地追踪和管理不同类型日志的生成、使用和清理周期。 2.2 undo page 链表在一个事务中，可能会产生多条 undo log。 如果一个 undo page 填满了，事务会向系统申请新的undo page,并将其通过链表（通常是使用类似于前驱（previous）和后继（next）指针的机制）连接起来。 前面提到过，一个 undo page 不能混合存储不能类型的链接， 所以对于一个事务它可以有insert undo page 和update undo page 两个链表。 每个事务都会分配单独的页面链表。 下面简单介绍下链表中第一个 undo page file header 如前面介绍，会有一个字段来标识该page 是undo page, 用来存储undo log。 undo page header 会记录该页面存储的undo log 类型， insert or update undo log segment header , 会记录该链表所属的segment undo log header ,理论上，每个事务都会分配自己的页面链表， 但如果一个事务产生的undo log很少，那么这个页面链表就有可能被重用。所以实际上一个页面链表中实际可能存储多个事务的undo log, undo log header 中记录了不同事务间日志的分隔信息。 2.3 回滚段InnoDB默认创建128个回滚段（Rollback Segments），用于管理undo日志。 元数据存储： 每个回滚段的元数据存储在系统表空间第5号页面中。 Slot结构：每个回滚段包含1024个slot，每个slot可以映射到一个Undo页。 事务与回滚段的关联： 事务会在需要的时候分配一个回滚段。 轮询策略： InnoDB使用轮询方式将回滚段分配给新事务，以实现负载均衡。 2.4 Undo页链表的形成与维护 事务开始： 新的事务开始时，会分配一个插入段和一个更新段。 在分配的回滚段头页中，初始化undo页链表的头指针和尾指针。 查找可用的Slot： 事务在开始写入undo日志时，会首先查找一个可用的slot，并初始化一个新的undo页链表。 分配新的Undo页： 分配新的undo页，将其添加到undo页链表的末尾。 如果这是链表的第一个undo页，回滚段头页的first指针和last指针会同时指向该页。 维护Undo页链表： 当undo页链表中的最后一个undo页已满时，分配一个新的undo页并链接到链表的末尾。 回滚段头页的last指针会指向新分配的undo页。 新undo页的prev指针指向链表的前一个undo页，形成链表结构。 3 行记录如何与undo log 关联 -roll_pointer roll_pointer 是存储在每个行记录中的一个指针，指向该行记录相关的最近一次undo log 记录。 注意这个undo 记录指的是具体的 undo log，而不是整个页面链表。 当行记录被修改（包括更新、删除或作为多步操作的一部分的插入）时，InnoDB 首先会在 undo 日志中写入一条记录，这条记录包含了行修改前的数据，和行记录中的的roll_pointer, InnoDB 更新行记录中的 roll_pointer，使其指向新写入的 undo 日志记录。如果这个行再次被修改，新的 undo 日志将被写入，roll_pointer 会更新为指向这条新的记录。新的undo 日志中会记录之前的roll_pointer 4. 一条记录的版本链如何形成InnoDB 通过 roll_ptr 把每一行的历史版本串联在一起 行记录中有roll_pointer, update 操作中TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC 类型的undo log 中，也有roll_pointer,通过这些roll_pointer, 可以形成一条行记录的版本链。 insert 操作中，对应的undo log没有roll_pointer 属性，因为insert 操作就是一个行记录的初始版本，没有比它更早的操作了。 以下是一个通过roll_pointer 组成的版本链，每个undo log 进行了内容省略以展示链接的重点内容 5. undo log 的持久化undo日志刷盘时机的参数，但通过控制Redo日志、脏页刷新和Purge线程的参数，可以间接影响undo日志的刷盘策略。 WAL技术在数据实际修改前，先将undo日志持久化到磁盘。 刷盘时机： 事务提交： 当事务提交时，相关的undo日志会被写入磁盘。 脏页刷盘： 在InnoDB将脏页（dirty page）写入磁盘之前，首先会确保所有相关的undo日志已经被持久化。 Redo日志同步： 当一个Redo日志被同步到磁盘时，所有相关的undo日志也必须被同步。 6 基于undo log 的回滚操作InnoDB中的事务 可能会由用户主动触发Rollback； 也可能因为遇到死锁异常Rollback； 或者发生Crash，重启后对未提交的事务回滚。 6.1. 用户&#x2F;应用程序主动回滚 反向遍历（start of record）当前事务的undo日志链表，按逆序恢复每个更改。 插入操作： 在数据页中删除已插入的记录。 删除操作： 恢复已删除的记录。 更新操作： 恢复更新前的记录。 每个操作恢复完成后，从undo日志链表中移除相应的undo日志记录。 6.2. 死锁异常回滚InnoDB通过死锁检测算法发现两个或多个事务之间的锁等待，形成死锁，,选择最小代价，即持有锁资源最少的事务务进行回滚。 与主动回滚类似，遍历当前事务的undo日志链表，按逆序恢复每个更改。 6.3 崩溃恢复MySQL服务器或操作系统崩溃后，InnoDB通过Undo日志与Redo日志结合，确保崩溃时数据页的状态恢复到一致的状态， undo日志用来 回滚未提交的事务。 7 undo log 的清理事务提交后，相关的Undo日志记录仍需保留一段时间以支持多版本并发控制（MVCC） 7.1 Purge 线程InnoDB 通过一个后台线程称为 Purge，来清理不再需要的 undo log。 触发条件：Purge 进程会定期检查那些已提交事务的 undo log。它会确定这些 undo log 是否还被其他活跃事务作为 MVCC 的一部分所需。 删除操作：如果一个 undo log 记录不再被任何事务所需要，Purge 进程会将其从 undo 表空间中删除，释放相关资源。 undo log 的清理机制是区分操作类型的。 7.2 Insert Undo LogInsert undo log 主要记录插入操作的信息。因为插入操作仅仅添加新的记录，不涉及已存在数据的修改，所以这种类型的 undo log 主要用于在事务失败时撤销插入操作。 清理时机：当一个事务进行插入操作并成功提交后，相应的 insert undo log 立即变得无用，因为插入的数据已经被确认并不需要再被撤销。此时，这些 undo log 可以被安全地清理掉，因为它们不再被任何事务所需。 清理过程：Purge 线程会检测到这些 insert undo log 与已提交的事务关联，并将它们标记为可清理。然后，这些 log 会从 undo 表空间中删除，相关的磁盘空间得以回收。 7.3 Update Undo LogUpdate undo log 记录了对现有数据的修改（包括更新和删除操作）。这些记录对于事务回滚和多版本并发控制（MVCC）至关重要。 清理时机：与 insert undo log 不同，即使相关事务已经提交，update undo log 也不能立即被清理。这是因为在 InnoDB 中实现 MVCC 时，其他并发事务可能需要访问这些 log 中的旧数据版本来维持一致性读。 清理过程：Purge 线程会周期性地检查 update undo log。只有当这些 log 记录不再被任何其他活跃事务所需时（即没有更早的读视图需要这些数据），它们才会被标记为可清理。然后，Purge 操作会逐步从 undo 表空间中删除这些记录。 7.4 长事务对undo log 清理的影响长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 相关文章Intro to 事务Intro to InnoDB 事务InnoDB事务-隔离性的实现,MVCC &amp; 锁InnoDB事务-持久性的实现,binglog &amp; redo log&amp;undo log","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"Intro to InnoDB事务","slug":"Intro-to-InnoDB事务","date":"2024-05-02T14:15:42.000Z","updated":"2024-05-10T15:17:42.616Z","comments":true,"path":"9cd551f5/","permalink":"http://example.com/9cd551f5/","excerpt":"","text":"在Intro to 事务中介绍过， 一致性是事务的核心特征，或者说最终目的，原子性、隔离性和持久性都是实现一致性的手段。 所以在介绍InnoDB 事务时，主要介绍AID 特性的实现InnoDB事务-原子性的实现， undo logInnoDB事务-隔离性的实现, MVCC &amp; 锁InnoDB事务-持久性的实现， binglog &amp; redo log&amp;undo log 在具体看InnoDB 事务实现AID 特性之前，可以先看以下这些前置知识 1. InnoDB 数据管理1.1 Pagepage 是 InnoDB 存储数据的基本单位，也是数据在磁盘和内存之间交换的最小单位。每个页通常的大小为 16KB针对不同的数据有不同的Page类型进行存储，如index page 索引页， undo page 等 File Header 中 有fil_page_type 来标识该页的类型 File Trailer 用来校验页面数据是否完成 1.2 区（extent）为了更好地管理page, InnoDB引入了区的概念， 连续的64个page 是一个区，大小默认是1MB。 可以认为extent 是一个物理上概念 一个区（Extent）是由连续的页组成的数据块，每个区包含 64 个连续的页，因此每个区的大小为 1MB （16KB * 64）。使用区的目的是为了优化磁盘空间的分配和管理，通过批量处理连续的页,减少随机IO来提高数据存取效率。 1.3 段 （segment ）InnoDB 中的段（Segment）作为一个逻辑结构，起着将数据库的高层逻辑结构（如表和索引）与低层物理存储结构（如页和区）连接起来的桥梁作用。 以下是几个详细的例子，通过这些例子可以更好地理解段是如何在数据库管理系统中发挥作用的。 1.3.1 数据表段假设您在数据库中创建了一个新表，这个表将需要存储数据行。InnoDB 会为这个表创建一个数据段： 逻辑层面：在逻辑层面，这个数据段代表了表中所有数据行的集合。 物理层面：物理上，这个数据段开始时可能只包含几个区，每个区由 64 个连续的页组成。随着表中数据的增加，段可以动态地分配更多的区来存储更多的数据页。 操作：当你执行 INSERT 操作向表中添加数据时，InnoDB 将在这个数据段中找到适当的页来存储新的行。如果必要的页不存在或页已满，段管理逻辑将请求分配新的区，并继续数据插入。 1.3.2 索引段当你为表创建一个索引时，无论是主键索引还是辅助索引，InnoDB 都会为每个索引创建一个单独的索引段： 逻辑层面：索引段逻辑上表示索引的结构，这包括维护键值和指向表中对应行的指针。 物理层面：物理上，索引段存储索引树（B-tree）的结构，其中每个节点（或页）包含索引键和指向行的指针。随着索引的增长，可能需要更多的页和区来扩展索引树。 操作：进行查询优化时，如执行基于索引的查找，InnoDB 通过索引段快速访问相关页，有效地定位到数据行。 1.3.3 Undo 日志段Undo 日志也是使用段来管理的，每当数据被修改时，修改前的数据将存储在 undo 日志段中： 逻辑层面：逻辑上，undo 日志段保存了数据修改前的状态，支持事务的回滚操作。 物理层面：物理上，undo 日志段由一系列的页组成，这些页按需分配，并在事务回滚时提供必要的历史数据。 操作：如果事务失败或执行 ROLLBACK 命令，InnoDB 通过访问 undo 日志段中的记录来恢复数据到其原始状态。 1.4 表空间（Tablespace）表空间是 InnoDB 数据存储的最高层级，它可以包含多个段。表空间是磁盘上的物理文件，可以看作是一个容器，内部组织着数据库的数据和索引。InnoDB 默认有一个主表空间，即 ibdata 文件，它包含了系统数据、数据字典、undo 日志等。此外，InnoDB 还支持每个表使用单独的文件作为独立表空间（file-per-table），这有助于数据库的扩展和管理。 2.行记录格式数据表中的行存放在 数据page 中， 以compact 行格式为例， 每一条数据记录的存储格式如下， 其中真实数据部分，除了数据表中定义的列之外，InnoDB 会默认为每条记录添加隐藏列 列名 是否必须 占据空间 描述 row_id 否 6 字节 行ID，唯一标识一条记录 trx_id 是 6 字节 事务ID roll_pointer 是 7 字节 回滚指针 roll_pointer 是存储在每个行记录中的一个指针，指向该行记录相关的最近一次undo log 记录。trx_id 是 InnoDB 存储引擎内部用来唯一标识每个事务的标识符，它记录了最近修改该记录的事务。 3. InnoDB 事务trx_idtrx_id 是 InnoDB 存储引擎内部用来唯一标识每个事务的标识符。这个事务ID是一个递增的数字，由 InnoDB 内部自动生成和管理。 trx_id 存储在行记录的隐藏列中。 MySQLserver 层也有一个事务唯一标识叫XID。 InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。 功能和作用 事务的唯一标识：trx_id 为 InnoDB 提供了一种方式来唯一地识别和跟踪每个活动的或已完成的事务。 多版本并发控制（MVCC）：在 InnoDB 的 MVCC 实现中，trx_id 被用来标记每条记录的版本，以此来支持事务的隔离级别。不同事务看到的数据视图依赖于记录的 trx_id 与事务的 trx_id 比较。 回滚和恢复：在事务处理过程中，如果需要回滚，InnoDB 通过 trx_id 来确定哪些更改需要被撤销。此外，在系统崩溃后的恢复过程中，trx_id 也被用来重建活跃事务的状态。","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"Intro to 事务","slug":"Intro-to-事务","date":"2024-05-01T13:57:16.000Z","updated":"2024-05-08T14:05:03.875Z","comments":true,"path":"5b064db6/","permalink":"http://example.com/5b064db6/","excerpt":"","text":"1. 什么是事务事务（Transaction）的概念起源于数据库领域，最早由美国计算机科学家 E. F. Codd 在其关于关系数据库（Relational Database）的论文中提出。 他提出了 ACID（原子性、一致性、隔离性和持久性）属性，这些属性成为事务的核心特征。 在今天的软件开发中，事务的概念已不仅仅应用于数据库领域，还拓展到了业务开发的各个领域，包括但不限于数据库、缓存、消息队列等。 1.1 ACID 特性 原子性(Atomicity): 保证事务中的所有操作要么全部完成，要么全部不发生，有助于处理系统错误或故障时的数据恢复，确保事务执行的完整性。 一致性(Consistency)：系统从一个正确态转移到另一个正确态，由应用通过 AID 来保证，可以说是事务的核心特性 隔离性(Isolation): 处理并发事务带来的各种问题，确保每个事务看到的是一致的数据视图，防止交叉事务的干扰。 持久性(Durability): 确保事务一旦提交，其结果就就会被持久化，这保证了数据的稳定性和可靠性。 定义本身不再赘述，这里重点强调一点：一致性是事务的核心特征，或者说最终目的。原子性、隔离性和持久性都是实现一致性的手段，因此这 4 个特性并不是并列关系。 2. 事务的分类下面将把事务按照服务和数据源数量进行分类，这种分类有助于理解事务管理的复杂性以及在不同场景下的设计和实现。 2.1 本地事务-单服务单数据源事务在实际业务开发中，单个服务操作单个数据源的事务被归类为本地事务。这种事务类型是最简单的，因为它直接依赖于数据库本身的事务能力来完成，应用无需进行额外操作 示例：库存服务：当用户下单时，库存服务负责检查和更新商品库存。这个服务可能只与一个库存数据库交互，进行减库存的操作。如果库存足够，事务提交，否则回滚。这个操作只涉及库存数据库，因此是一个典型的本地事务。 2. 2 分布式事务分布式事务可以从跨多个数据源的事务和跨多个服务的事务两个角度理解。它既可以是多个数据库实例之间的分布式事务，也可以是跨不同中间件的业务层面分布式事务。 2.2.1 单服务多数据源这种情况通常发生在单个应用或服务需要同时操作多个数据库或存储系统。 例如，一个电子商务应用可能需要在处理订单的同时，在一个数据库中更新库存信息，在另一个数据库中更新用户账户信息。这要求事务管理机制能够跨越这些数据库，确保所有数据库操作要么全部成功，要么全部失败，以保证数据的一致性 在这种场景下，可以使用如XA协议这样的分布式事务协议，通过2PC等机制来协调和管理跨多个数据源的事务。 2.2.2 多服务多数据源随着微服务架构的发展，单个业务操作往往需要多个微服务协作完成，而这些服务可能各自使用独立的数据库。例如，在电商下单过程中，订单服务、库存服务、账务服务、物流服务和优惠服务需要协同处理同一业务请求，并进行交互和数据更新。 在这种场景下，分布式事务的管理比单个服务场景更为复杂，因为它不仅涉及数据一致性，还涉及网络调用的可靠性和服务间的协调。这类分布式事务通常可以通过可靠消息队列、TCC 和 SAGA 等模式来实现。 2.3 共享事务-多服务单数据源在微服务架构下，通常不允许多服务共享同一数据源。理想的微服务架构是每个微服务都有其专属数据库（即服务与数据源一一对应），这种设计被称为数据库隔离。 因此，本文及本系列不会涉及该类型事务。 3. 两种分布式事务的区别在事务分类中，单服务多数据源 和 多服务多数据源 都被归类为分布式事务，那么这两种分布式事务有什么区别呢？ 首先，单服务多数据源事务是多个数据库实例之间的分布式事务， 也被称为全局事务。当它被称为分布式事务时，这里的“分布式”是相对于数据源而言的，并不涉及服务。 而多服务多数据源事务是跨不同中间件的业务层面分布式事务。 这两种分布式事务的一个重要区别在于一致性的实现方式不同： 单服务多数据源事务通常可以追求 强一致性。 多服务多数据源事务由于其复杂性和分布式特性，通常只能追求 最终一致性。 下面将详细解释这两种情况及其原因。 3.1 单服务多数据源 与 强一致性在单服务多数据源的场景中，尽管涉及多个数据源，但所有操作都由一个单一服务控制。这种配置允许使用两阶段提交（2PC）等传统的分布式事务协议来确保强一致性，即在任何时刻，所有数据源都能反映出相同的事务状态。 为什么可以实现强一致性： 集中式协调：单个服务可以作为事务的中央协调者，管理所有数据源的事务提交或回滚。 锁定资源：事务处理过程中可以在各个数据源上锁定必要的资源，直到事务完成，确保事务的原子性和一致性。 同步更新：所有数据源的更新操作可以同步进行，确保在事务提交时，所有的变更都能一次性反映出来。 3.2 多服务多数据源 与 最终一致性多服务多数据源事务涉及多个独立的服务，每个服务可能管理自己的数据源。在这种架构下，实现强一致性变得非常复杂和成本高昂，因此通常采用最终一致性模型。 为什么通常只能实现最终一致性： 服务自治：每个服务都是自治的，独立管理自己的数据源，它们之间的通信可能是异步的，不能立即反映其他服务的状态变更。 复杂的协调机制：需要跨服务协调复杂的事务可能涉及网络延迟和服务间通信失败，使得同步更新所有数据源变得不切实际。 使用补偿事务：多服务事务常采用如SAGA等模式，通过一系列的本地事务和补偿事务来处理业务流程，每个事务独立提交，仅通过补偿机制来撤销错误操作，逐步达到数据的一致性。 4. 强一致性 vs 最终一致性4.1 一致性的分类4.1.1 强一致性（Strong Consistency）强一致性意味着系统在更新数据后，任何随后的访问都将立即看到这一更新。在强一致性模型中，所有节点上的数据在任何时间点都是一致的。这通常要求在数据更新过程中进行严格的协调，确保所有副本在继续操作前都同步更新。 优点： 数据一致性和用户体验最为理想。 易于理解和使用，因为它模拟了单个系统的行为。 缺点： 可能严重影响系统的可用性和性能，尤其在网络延迟较高的情况下。 在 CAP 定理中，通常需要在遇到网络分区时牺牲可用性。 4.1.2 线性一致性（Linearizability）线性一致性是强一致性的一个特例，它不仅保证所有节点看到相同的数据，还要求系统表现得就像所有操作都是顺序发生的。这意味着如果操作A在操作B之前完成，那么系统中的所有节点都应该首先看到A的结果，然后是B的结果。优点： 提供了强一致性的最高标准，适用于需要严格数据顺序的应用。 简化了系统的编程模型。缺点： 对系统性能和可用性的影响比一般的强一致性还要大。 4.1.3 弱一致性（Weak Consistency）弱一致性不保证在数据更新后立即反映这一变化。在更新操作和其影响被所有用户观察到之间，存在一个不确定的时间窗口。这种模型通常用于对实时一致性要求不高的系统。优点： 提高了系统的可用性和性能。 在处理高并发操作时更加有效。缺点： 用户可能会读到旧数据。 应用逻辑可能需要处理数据不一致的问题。 4.1.4 最终一致性（Eventual Consistency）最终一致性保证，在没有新的更新的情况下，所有的数据副本最终将会是一致的。系统不保证达到一致状态的具体时间。优点： 高度可用和可扩展。 适用于分布广泛的系统，可以容忍数据在短时间内的不一致。缺点： 应用需要能够处理数据一段时间内的不一致。 开发者需要设计有效的数据同步和冲突解决策略。 4.2 CAP 与 ACID的微妙平衡-分布式系统只能追求最终一致性根据 CAP 定理，一个分布式系统不可能同时满足一致性（Consistency）、可用性（Availability）和分区容忍性（Partition Tolerance）三个属性，最多只能满足其中两个，必须牺牲一个。 一致性（Consistency）：在任何时刻，任何分布式节点中看到的数据都保持一致。 可用性（Availability）：系统能够不间断地提供服务的能力。 分区容忍性（Partition Tolerance）：在分布式环境中，当部分节点因网络原因失联（即形成“网络分区”）时，系统仍能正确提供服务的能力。 4.2.1 为什么说 分布式系统 必须接受 分区容忍性理解为什么分区容忍性在分布式环境下必然存在，需要从分布式系统的基本构成和网络通信的不可靠性两个角度探讨。 分布式系统的基本构成 分布式系统由多个相互协作的独立组件组成，这些组件可能位于物理上分散的不同位置。该架构的主要优势是提高系统的可扩展性、容错性和资源利用率。然而，这也意味着系统的各个部分必须通过网络通信。 网络通信的不可靠性 网络本身存在不可靠性，可能因多种原因导致通信失败： 网络故障：网络设备或连接可能出现故障，如路由器故障、连接断开等。 网络延迟：消息在传输过程中可能遭遇不可预测的延迟。 带宽限制：网络的带宽限制可能导致数据包延迟到达或丢失。 网络安全：网络攻击（如分布式拒绝服务攻击，DDoS）可能导致网络部分或完全不可用。 如果一个系统设计选择不接受网络分区，那么一旦网络分区发生，系统将无法正常工作，这在大多数业务场景中是不可接受的。 因此，在分布式系统中，分区容忍性（Partition Tolerance）是必然存在的特性。 基于分区容忍性必须满足的现状以及 CAP 理论，系统只能在一致性和可用性之间做出选择。通常，系统会选择高可用性，强一致性因此被牺牲，系统只能追求最终一致性。 5. 理解分布式事务中的各种协议5.1 DTP 模型和 XA 规范5.1.1 DTP 模型DTP（Distributed Transaction Processing，分布式事务处理）模型是由 X&#x2F;Open（后来的 Open Group）提出的一种分布式事务处理架构模型。它定义了一套标准，使得不同厂商的分布式事务处理系统能够互操作。 在标准的 DTP 模型中，定义了以下四个主要组件： Application Program（AP，应用程序）： 发起分布式事务的主体，由最终用户或开发者编写。 通过调用事务管理器的接口（例如 TX 接口）开始、提交或回滚事务。 应用程序与事务管理器和资源管理器交互。 Transaction Manager（TM，事务管理器）： 负责管理分布式事务的开始、提交和回滚等操作。 维护事务的状态，并使用两阶段提交协议（2PC）协调所有参与的资源管理器。 提供对外的 TX 接口供应用程序使用，并通过 XA 接口与资源管理器交互。 Resource Manager（RM，资源管理器）： 负责管理和控制对特定资源的访问，例如数据库管理系统（DBMS）、文件系统、消息队列等。 接收事务管理器的请求以进行资源操作，并确保数据一致性。 实现 XA 接口与事务管理器通信。 Communication Resource Manager（CRM，通信资源管理器）： 可选组件，负责管理与外部系统的通信资源。 在分布式事务中协调和同步事务状态，确保跨系统的事务一致性。 管理跨网络的事务传播，确保分布式环境中的事务处理一致性。 主要接口： TX 接口： 应用程序 AP 与事务管理器 TM 之间的桥梁，负责事务的开始、提交和回滚等操作。 例如，在 Java EE 中，TX 接口通常对应 javax.transaction.UserTransaction。 XA 接口： 事务管理器 TM 与资源管理器 RM 之间的接口，协调资源管理器在两阶段提交协议中的操作。 常见的 XA 接口方法包括 xa_open、xa_start、xa_end、xa_prepare、xa_commit、xa_rollback 等。 CRM 接口： 事务管理器与通信资源管理器之间的接口，确保分布式事务在网络通信中保持一致性。 没有明确的标准接口，由各系统厂商自行实现。 5.1.2 XA规范XA 规范是 X&#x2F;Open 组织在 DTP（Distributed Transaction Processing）模型中定义的，用于描述事务管理器（TM）和资源管理器（RM）之间交互的接口标准。 接口标准：XA 规范定义了一套标准接口，包括 xa_start、xa_end、xa_prepare、xa_commit、xa_rollback 等。 2PC 协议：XA 接口实现了两阶段提交协议（2PC），以确保分布式事务的一致性和完整性。 5.1.3 XA 事务XA事务是一种分布式事务。通过两阶段提交协议和XA接口标准，事务管理器和资源管理器能够可靠地协同工作，实现跨系统的事务处理，确保多个独立资源的一致性。 实际应用 数据库系统： 大多数主流数据库系统都支持XA事务，如Oracle、MySQL、DB2、SQL Server等。 通过实现XA接口，数据库可以参与分布式事务并与事务管理器协同工作。 消息中间件： 一些消息队列和消息中间件也支持XA事务，如IBM MQ、ActiveMQ等。 能够确保消息发送与其他资源操作的一致性。 Java EE环境： 在Java EE应用程序中，javax.transaction.UserTransaction和javax.transaction.TransactionManager接口提供了对XA事务的支持。 5.2 两阶段提交（2PC）两阶段提交是一种具体的事务协议，用于在分布式系统中协调多个事务参与者的行为，以确保事务的原子性。它包含以下两个阶段： 准备阶段：协调者询问所有参与者，是否准备好提交事务。 提交&#x2F;回滚阶段：基于各参与者的答复和超时情况，协调者决定是否全局提交或回滚， 只有全部参与者回答了prepared 才会commit; 若有一个参与者回答和non-prepared 或者超时未回答，则rollback 5.2.1 协调者宕机：单点问题，参与者阻塞在2PC中，一个重要特点是参与者缺乏超时机制。因此，在第一阶段结束后，他们必须原地等待协调者的第二阶段指令。一旦协调者宕机，所有参与者都会受到影响。如果协调者长时间未恢复或未发送正常的提交或回滚指令，所有参与者都将被阻塞。 为何参与者缺乏超时处理机制呢？因为这可能引发数据一致性问题。当参与者迟迟未收到提交或回滚指令时，无论其默认为提交还是回滚，都可能导致全局数据不一致。 这也给了我们业务开发一些启示：在任何不确定情况下，都不应随意指定默认操作，最佳做法是启动警报，让人工介入处理。 5.2.2 回滚性能差所有的操作都已经完成，回滚需要全部推翻。 5.2.3 一致性问题5.2.4.1 协调者宕机如上面单点问题中描述，协调者宕机后，由于参与者没有超时处理机制，会一直阻塞等待，直到协调者宕机恢复后， 根据持久化的数据判断该事务状态，进而发送commit 或者 rollback ， 所以在协调者宕机恢复前 协调者和参与者的数据是不一致的 5.2.3.2 参与者宕机如果参与者收到commit后，宕机了。此时数据也是不一致的参与者宕机恢复后，可以检查自己的持久化信息，来判断事务的状态。 5.2.3.3 网络问题有的参与者收到了commit,有的参与者收不到；参与者的ack 消息，协调者有的收到了，有的没收到。其中参与者收不到第二阶段的消息，自然不会有ack, 表现上也是协调者收不到ack。这里的解决方案就是 协调者超时处理机制-重试，在重试成功之前，数据是不一致的。 5.2.4 梳理下 DTP、XA、2PC 之间的关系DTP（Distributed Transaction Processing，分布式事务处理）模型是由X&#x2F;Open（后来的Open Group）提出的一种分布式事务处理的体系结构模型。它定义了一套标准，使得不同厂商的分布式事务处理系统能够互操作。 XA规范是X&#x2F;Open组织 在DTP（Distributed Transaction Processing）模型中定义的，用于描述事务管理器（TM）和资源管理器（RM）之间的交互的接口标准。 XA 规范基于2PC 实现。 但是 2PC协议是一种通用的事务提交协议，可以在任何实现中使用。除了XA规范，2PC协议还可以用于其他事务管理协议和框架，如： Seata：阿里巴巴开源的分布式事务框架，提供全局事务管理服务，支持2PC但不直接使用XA接口。 Atomikos：支持两阶段提交协议的独立事务管理器。 Bitronix：另一个独立事务管理器，也支持2PC协议。 在某些场景下，可以直接在应用程序代码中实现简化版的2PC协议，而无需遵循XA规范。 5.3 三阶段提交（3PC）3PC 的3个阶段， CanCommit PreCommit DoCommit 3PC 相比2PC 的变化 3PC提交把2PC的prepare 阶段细分为两个阶段，分别称为 CanCommit、PreCommit 参与者增加了超时处理机制，超时默认会提交事务 3PC 的提出是为了改进2PC 存在的问题 5.3.1 CanCommit 优化回滚操作性能新增的 CanCommit 是一个询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。这可以解决提高precommit 阶段的成功率，万一失败了，回滚操作也比较轻，因为还没开始做实质性的操作 但是这里要注意一个性能问题，在事务需要回滚的场景中，三段式的性能通常要比两段式好很多，但在事务能够正常提交的场景中，两段式和三段式提交的性能都很差，三段式因为多了一次询问，性能还要更差一些。 5.3.2 解决协调者单点问题通过增加参与者超时处理机制，默认会提交事务，相当于解决了协调者宕机参与者阻塞等待的单点问题 5.3.3 加重数据一致性问题在2PC中已经讨论过,为什么2PC参与者没有超时处理机制？因为超时处理机制可能引发数据一致性问题，当 参与者迟迟收不到commit or rollback 指令时， 参与者不论是 默认提交 还是默认回滚，都有可能导致全局数据不一致。 3PC 增加了超时机制， 会默认提交事务，这会加重数据一致性的问题 5.4 TCC（Try-Confirm&#x2F;Cancel）TCC是一种应用层事务协议，它分为三个阶段：Try（尝试）、Confirm（确认）、Cancel（取消）。在Try阶段，每个参与者尝试执行事务并锁定必要资源；在Confirm阶段，如果所有参与者的Try操作都成功，那么执行Confirm操作提交事务；如果任何Try失败，则执行Cancel操作回滚事务。TCC适用于业务逻辑复杂，需要长时间运行的事务。 个人认为，TCC可以被理解为是2PC的一种变体，具有两阶段的结构，但它在实施和操作上更适合处理复杂的业务逻辑和提高系统的灵活性与效率。 5.5 可靠消息队列使用可靠消息队列来解决分布式事务问题是一种被称为“最终一致性”的策略，它通过异步消息传递的方式，确保在分布式系统中多个服务之间的数据一致性。 使用可靠消息队列解决分布式事务的核心思想在于： 异步与最终一致性：通过异步的方式处理分布式事务，并确保最终一致性。 可靠消息传递：确保消息传递的可靠性，包括重试机制、幂等处理等。 5.6 SAGASAGA是一种将长期事务分解为一系列较小的、独立的子事务的方法。每个子事务都可以单独提交或回滚。如果某个子事务失败，SAGA通过执行补偿事务（即逆操作）来恢复之前的状态。SAGA降低了资源锁定的时间，适用于微服务架构中的事务管理。 参考文章《周志明的软件架构课》https://www.51cto.com/article/648668.html","categories":[],"tags":[{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"使用github page+hexo 创建个人网站","slug":"使用githubpage-hexo创建个人网站","date":"2024-04-29T01:29:29.000Z","updated":"2024-05-14T04:03:44.427Z","comments":true,"path":"5fe6baa/","permalink":"http://example.com/5fe6baa/","excerpt":"","text":"关于使用 github page + hexo 创建个人网站， hexo官网上的步骤已经非常详细，网上也有非常多相关的文章， 所以基础步骤就不写了。 这里记录一些个性化过程中遇到的问题。 1. TOC 锚点失效文章目录正常生成了，但是点击目录无法跳转到文章对应位置。解决办法点这里查看 2. 文章的短链接生成hexo 文章标题默认的格式是:year&#x2F;:month&#x2F;:day&#x2F;:title&#x2F;,这个格式的标题在我看来有2个主要问题 太长，可以考虑只取默认格式中的一部分，如:title&#x2F; 易变化， 写文章时有可能会修改标题,所以文章的url就会发生变化。 url 一旦发生变化就会对网站排名产生负面影响 综上，我希望每篇文章都有一个 固定且短的 url。 hexo-abbrlink:create one and only link for every post for hexo 插件可以实现该功能， 它根据文章标题和创建时间为文章生成一个abbrlink， 如果文章已经有该属性则不会重复生成。 3. custom domain 消失记在github pages 配置了custom domain ，但是我发现每次deploy新内容后，配置好的custom domain 都会消失，经过排查发现是缺失来 CNAME文件。 3.1 CNAME是什么CNAME（Canonical Name）记录是一种DNS（Domain Name System）记录类型，用于将一个域名别名映射到另一个真正的域名。它的作用是简化域名管理、实现负载均衡、支持CDN集成等。CNAME记录的工作流程包括DNS查询、递归查询、权威DNS服务器响应和IP地址返回等步骤。通过正确配置CNAME记录，可以有效管理和优化网站的域名解析。 3.2 CNAME记录的作用 域名重定向：允许多个域名指向同一个目标域名，简化了域名管理。例如，将www.example.com和blog.example.com都指向example.com。 负载均衡：通过CNAME记录可以将流量分布到不同的服务器，实现负载均衡。 内容分发网络（CDN）集成：CDN提供商通常要求将用户的子域名（如cdn.example.com）CNAME到他们的CDN域名（如cdn.provider.com），以便进行流量管理和内容分发。 3.3 CNAME记录的工作流程CNAME记录的工作流程可以分为两个主要阶段：解析CNAME记录本身和解析CNAME记录指向的目标域名，直到最终得到一个IP地址。 DNS查询开始：用户在浏览器中输入域名，如www.example.com，并发送DNS查询请求。 递归DNS服务器处理请求：用户的计算机向递归DNS服务器（通常由ISP提供）发送请求。递归DNS服务器查询根DNS服务器，获取顶级域名服务器（如.com的服务器）的信息。 递归查询过程：递归DNS服务器查询顶级域名服务器，获取该域的权威DNS服务器信息（如example.com的DNS服务器）。递归DNS服务器接着查询权威DNS服务器。 权威DNS服务器响应：权威DNS服务器查找www.example.com的DNS记录。如果www.example.com有一个CNAME记录指向example.com，权威DNS服务器返回这个CNAME记录。 CNAME解析：递归DNS服务器接收到CNAME记录后，再次进行DNS查询，以解析CNAME记录指向的目标域名example.com。递归DNS服务器最终获取目标域名example.com的A记录（IP地址）。 返回IP地址：递归DNS服务器将目标域名example.com的A记录返回给用户的计算机。用户的计算机使用该IP地址与目标服务器建立连接，加载网站内容。 3.4 Hexo 中CNAME 文件的作用当你使用自定义域名而不是username.github.io来访问网站时，需要在在source目录中创建一个文件CNAME 文件，并写入自定义域名 CNAME文件的存在和内容会告知GitHub Pages你希望通过哪个自定义域名访问你的网站。 例如，如果你的自定义域名是www.example.com，你需要在CNAME文件中写入www.example.com。","categories":[],"tags":[]},{"title":"TrustMessage-基于2PC+MySQL+泛化调用实现的可靠消息中心","slug":"基于2PC-MySQL-泛化调用实现的可靠消息中心","date":"2024-04-09T08:41:05.000Z","updated":"2024-05-08T14:06:28.633Z","comments":true,"path":"99d433fa/","permalink":"http://example.com/99d433fa/","excerpt":"","text":"0. 项目结构介绍 Module Description trustmessage-mysql 基于2PC+MySQL表实现的可靠消息中心，业务操作+消息表操作均存在于同一个项目中 turstmessage-middleware 可靠消息中心中间件，基于RPC接口提交消息+2PC+MySQL 表实现 turstmessage-middlewareapi 可靠消息中心中间件， 回查接口定义 Turstmessage-middlewareclient 可靠消息中心中间件， 消息生产者，提供了HTTP回查接口、Dubbo泛化回查接口的示例 以下是项目正式介绍。 在业务处理中，经常会有重要但没那么紧急的数据需要同步给下游，比如 订单侧完成消息后给优惠侧发一个消息，优惠侧做一个单向对账的功能，确保券被正确核销 在这种场景中，需要把本地业务操作 + 消息发送当成一个事务处理，即满足原子性， 一般常见的解决方案会有两种 本地事务+本地消息表 RocketMQ 本项目将从本地事务+本地消息表 出发， 一步步探讨如何用 MySQL 实现一个支持分布式事务的可靠消息中心，即TrustMessage。 项目github链接，点击可查看代码 1. 本地事务+ 本地消息表由于Spring 的事务机制只保证数据库操作的原子性，所以当涉及到 数据库的业务操作 和 其他中间件如kafka操作 具有原子性的时候，就要用其他的方案来保证。 本地事务+ 本地消息表 这种方案是把 需要发送的消息作为数据库操作的一部分，保存到数据库中的一个表里，然后通过另外的逻辑，将消息的真正发送 稍后异步进行，比如用一个定时任务将消息异步发送到Kafka。 这种方法确保了数据库操作和消息发送在逻辑语义上的原子性，因为它们都在同一个数据库事务中处理。 这里需要注意，这种方案的实时性是比较差的，所以你需要判断的业务场景场景是否能够容忍这样的异步操作。 1.1 业务流程 以上流程中，在本地事务提交后，有一个定时任务轮询消息表将需要发送的消息消息发送出去。有4个点需要注意一下 事务提交后了，消息发送失败， 定时任务的重试机制，会找出这条消息进行异步补发 事务提交后了，消息发送成功，但是消息状态修改状态， 定时任务会找出这条再次发送 重试异步补发过程中，如果消息依然发送失败，那么会继续重试补发 重试异步补发过程中，消息发送成功，但是数据库消息已发送状态修改失败，那么定时任务又会再次找到这条消息再发一遍 以上 2和4 均会面临消息重复的情况， 个人认为在业务常见中消息重复是一种可接受的情况，有时候业务自己甚至会消息重放， 所以消息消费者做好幂等逻辑就可以了。 1.2 消息发送重试次数消息发送不能无限次重试 浪费资源，重试了那么多次都未成功，可能是逻辑出现问题了或者宕机了，赶紧去查问题吧 上下游业务数据迟迟无法达到最终一致性 ， 本身我们使用消息其终极目的就是为了让系统数据达到最终一致性， 如果一直无限制发送，这个目的是无法达到的, 所以赶紧停下去查问题吧 基于以上两个考虑，系统对于重试都应该有个次数限制，达到次数限制后就应该告警让人工介入处理。 1.3 消息表设计在本地事务+ 本地消息表 方案中，其消息表的设计一般如下， 1234567891011CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, message text COMMENT &#x27;消息内容&#x27;, send_status INT DEFAULT 0 COMMENT &#x27;0-投递中 1-投递成功 2-投递失败&#x27;, send_try_count INT DEFAULT 0 COMMENT &#x27;commit 消息发送 当前重试次数&#x27;, send_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息发送 下次重试时间&#x27;, create_time DATETIME DEFAULT CURRENT_TIMESTAMP, update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_messageKey(message_key)) ENGINE=InnoDB; 2. 如果消息表和业务表操作是分布式事务但是如果保证不了这两个表不在同一个库 &#x2F;数据库实例中，那就会在业务操作和消息表写入两个操作中遇到分布式事务。这在分库分表的业务中是很容易出现的情况。 针对对分布式事务，常见的解决方案就是 2PC、3PC、TCC、SAGA。 接下来将讲解以 2PC+MySQL消息表 实现的可靠消息中心 2.1 业务流程以MySQL消息表+ 2PC 来实现可靠消息中心， 其整体实现流程如下 2.2 消息可见性消息可见性， 在涉及分布式事务的场景中，消息增加了一个可见性概念， 这是因为在引入2PC 后，写入消息表的消息不再像本地事务+本地消息表一样写入即可见，必须是commit后才对消费者可见， 所以在数据表的设计中需要增加一个状态字段来维护消息可见性。 1message_status INT COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;, 其状态流转如图所示 2.3 如果业务执行消息commit or rollback 失败怎么办-消息回查如流程图中所示，在2PC 阶段，拿到业务执行结果修改消息状态失败有可能是失败。 一个操作执行失败后，一种常见的解决方案方案就是重试，尽最大努力交付。 但是对于业务处理来讲，一般有超时时间的限制，因为这种同步重试可能并不适用，即使可以，一般重试次数都会限定在3次。 除了同步重试，还有一种方案就是 消息回查，我个人理解这相当于一种异步重试。 在本项目中，消息回查指的就是开启一个定时任务去全表扫描，找出insert一定时间后，其状态仍然是 prepare的消息 ，通过业务逻辑判断该条消息是否已经执行完成 or 失败，对应地把消息状态更改为 commit or rollback。 为了进行消息回查，肯定要有一个业务唯一标识来识别该条消息需要对应业务数据，从而判断对应业务是否执行完成。 1message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, 2.4 消息回查不能无限次 浪费资源，回查了这么多次的都没拿到结果，一种可能就是业务逻辑出现问题了，适可而止赶紧去查问题吧 系统数据迟迟无法达到最终一致性 ， 本身我们使用消息其终极目的就是为了让系统数据达到最终一致性， 如果一直无限制查询，这个目的是无法达到的, 所以赶紧停下去查问题吧 所有消息回查应该有个次数限制， 这就是表中以下两个字段的作用 12verify_try_count INT COMMENT &#x27;消息状态回查 下次重试次数&#x27;, verify_next_retry_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息状态回查 下次重试时间 1-未发送 2-已发送&#x27;, 2.5 消息回查次数达到上限怎么办有两种参考方案 默认修改消息状态为commit 或者 rollback， 将消息状态置为回查失败状态 ， 告警人工介入处理 默认修改消息状态为commit 或者 rollback 这个方案，一个最大的问题就是针对状态不确定的消息，不论将其默认修改为那种状态， 都是有可能引起业务上下游数据不一致问题。 一旦上下游数据产生了数据不一致性，必然导致很长的排查链路和大量的数据修复工作。 所以本项目中我选择第二种方案，消息回查达到上限后直接告警，让消息生产者这一方人工介入处理。 此处说明一下，这种方案当然也会有数据不一致的问题，因为下游业务始终还未拿到消息修改自己的状态，但是相比拿到了随机确定的的状态 导致的数据不一致性，此时问题还被控制在消息生产者这一环，问题排查会相对简单。 2.6 消息发送重试与本地事务+本地消息表方案一致 2.7 消息表设计123456789101112131415CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, message text COMMENT &#x27;消息内容&#x27;, message_status INT DEFAULT 1 COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;, verify_try_count INT DEFAULT 0 COMMENT &#x27;消息状态回查 当前重试次数&#x27;, verify_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息状态回查 下次重试时间&#x27;, send_status INT DEFAULT 0 COMMENT &#x27;0-投递中 1-投递成功 2-投递失败&#x27;, send_try_count INT DEFAULT 0 COMMENT &#x27;commit 消息发送 当前重试次数&#x27;, send_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息发送 下次重试时间&#x27;, create_time DATETIME DEFAULT CURRENT_TIMESTAMP, update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_messageKey(message_key)) ENGINE=InnoDB; 2.8 消费者消费消息针对可见， 即已经commit 的消息，消费者该如何获取到消息消费呢，有两种方案 消息者直接查询消息表 消费者从消息队列队列消费 2.8.1 消息者轮训消息表这种方案最大的问题就是，在微服务架构下，上下游两个不同的服务 操作 同一个数据表 是一个不合理且不推荐的做法。 2.8.2 消息队列消费和本地事务+本地消息表一样，已经commit 的消息可以由一个定时任务轮训发送到业务创建的消息队列中供订阅的消费者消费发送过程也可以有一个重试的过程。 3. 如果这是一个公共中间件-基于RPC 接口实现的可靠消息中心以上讨论的方案， 都是基于消息表逻辑和业务逻辑同一个服务中， 如果把该功能做成一个公共中间件，那么在技术方案上会略有变化。 中间件需要提供的功能 两阶段提交功能 回查功能 消息转发 以上3个功能和上一种方案没有本质上的区别， 只是基于一个中间件的定位，支持这3种功能需要更多的封装与数据信息。 3.1 业务流程 3.2 两阶段提交功能提供3个RPC 接口， prepare， commit, rollback, 接口底层封装对数据表的操作 3.3 消息唯一性当作为一个公共中间件，接受多个业务数据的时候，消息的唯一性应该有业务标识 + 消息标识共同确定，即bizId + messageKey 3.4 回查功能相比于直接在业务服务里集成可靠消息的功能时，可以简单直接的在服务内部查询，当作为公共中间件时， 只能通过服务间调用完成，服务间调用有两种形式 HTTP RPC 为了增加可维护性和拓展型， 无论是哪种形式，中间件都应该定义好调用的格式，让消息生产者按照统一格式提供回查接口。 这个格式包括 接口定义 接口入参 接口返回值 其中接口定义信息需要生产消息时提供 在实现消息生产者按照统一格式提供回查接口 这一点是，HTTP接口的回查相对简单， 如果RPC 接口， 要注意使用泛化调用。 本项目实现了HTTP 接口的回查和 Dubbo 协议的泛化调用回查 HTTP接口格式为 1http://127.0.0.1:8082/verifyMessage?bizID=1&amp;messageKey=key1 Dubbo RPC 接口定义为 12345public interface VerifyMessageService &#123; // 消息回查接口 int verifyMessage(Integer bizID,String messageKey); &#125; 3.5 消息转发在一个公共中间件里实现消息转发，必然也需要生产消息时提供这部分信息 12forward_topic VARCHAR(255) COMMENT &#x27;业务转发topic&#x27;, forward_key VARCHAR(255) COMMENT &#x27;业务转发指定key&#x27;, 3.6 消息表设计12345678910111213141516171819CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, biz_id INT NOT NULL COMMENT &#x27;业务ID&#x27;, message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, message text COMMENT &#x27;消息内容&#x27;, message_status INT DEFAULT 1 COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-verify fail&#x27;, forward_topic VARCHAR(255) NOT NULL COMMENT &#x27;业务转发topic&#x27;, forward_key VARCHAR(255) COMMENT &#x27;业务转发指定key&#x27;, verify_info VARCHAR(2000) COMMENT &#x27;回查信息&#x27;, verify_try_count INT DEFAULT 0 COMMENT &#x27;消息状态回查 当前重试次数&#x27;, verify_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息状态回查 下次重试时间&#x27;, send_status INT DEFAULT 0 COMMENT &#x27;0-投递中 1-投递成功 2-投递失败&#x27;, send_try_count INT DEFAULT 0 COMMENT &#x27;commit消息发送 当前重试次数&#x27;, send_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息发送 下次重试时间&#x27;, create_time DATETIME DEFAULT CURRENT_TIMESTAMP, update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_message_key_biz_id (message_key, biz_id)) ENGINE=InnoDB; 4. 基于kafka 提交消息实现的可靠事件中心在实现消息回查的可靠消息中心方案中，另外一种常见的方案是 业务代码直接把消息提交给kafka, 然后中间件消费消息并持久化道数据库中，等待消息提交commit 或者rollback , 没有的话就进行回查。如下图，图片源自极客时间专栏 我认为两种技术方案没有本质的区别， 其差异只是消息的prepare 、commit、rollback 的提交是由RPC 接口完成还是由消息生产消费完成， 其他回查的逻辑、发送逻辑、以及需要的信息基本无差异。 不过在使用Kafka 提交时，有以下两种需要考虑 4.1 中间件如何识别一条消息是事务消息 Topic命名约定 一种简单的方法是通过Topic命名来区分。例如，所有需要支持回查的Topic可以遵循一个特定的命名模式，如添加前缀或后缀（例如，replayable-myTopic）。这种方法的优点是简单易实施，但缺点是灵活性较低，且对现有系统可能需要更多的改动。 特定主题或分区 将需要回查的消息发送到Kafka的特定主题或分区中。这样，中间件只需监听这个特定的主题或分区来处理需要回查的消息。这种方法要求生产者在发送消息时知道哪些消息需要回查，并据此发送到正确的主题或分区。 Topic配置属性 Kafka允许为每个Topic设置自定义配置属性。可以引入一个自定义属性（如replayable=true）来标识一个Topic需要支持消息回查。这种方式比命名约定更为灵活和隐蔽，但要求应用层和消息生产者遵循这一约定，并且需要在应用层实现逻辑来处理这些属性。 消息元数据标记 在消息发送时，可以在消息的元数据（Metadata）中添加特定的标记或字段来指示这条消息需要进行回查。 设计考虑： 性能：确定这些方法中哪一种对生产和消费的性能影响最小。 易用性：选择易于实施和维护的方法。 灵活性：评估是否需要对单个消息进行标记，还是以Topic为单位进行区分。 4.2 如何识别消息类型、转发信息、回查信息消息类型包括 prepare、commit、rollback转发信息,需要转发至的真正业务tpoic、 如果需要指定分区的话还包括key信息回查信息，包括回查方式如HTTP、RPC, 回查地址，回查接口等 使用Kafka消息头 优点： 保持了消息体的纯净和独立性。 灵活性高，易于添加或修改额外的控制信息和元数据。 性能考虑，对于小到中等大小的消息，使用消息头的性能开销相对较小缺点： 新版本依赖：较旧版本的Kafka客户端可能不支持消息头功能，这要求生产者和消费者使用支持消息头的Kafka版本。 额外处理：消费者需要额外的步骤来读取和解析消息头。 预先定义消息格式 优点： 直接且简单，易于实现。 不依赖Kafka特定的功能，具有较好的兼容性。缺点： 增加了消息体的大小。 需要在消费端进行消息解析，略微增加了处理的复杂性。 本项目以指定topic+预定义消息格式的方式简单实现了消息的提交，消息格式如下， 大家可以参考。 12345678910111213141516171819202122232425262728package com.example.trustmessage.middlewareapi.common;public class MiddlewareMessage &#123; // 要给到业务方的真正消息 private String message; private int bizID; // 用于消息回查的业务唯一标识 private String messageKey; private int messageStatus; private String forwardTopic; // 向业务方转发时需要指定的key，没有则说明按照kafka 默认分区策略进行分区 private String forwardKey; private VerifyInfo verifyInfo; public static class VerifyInfo &#123; private int protocolType; // 1-http, 2-rpc-dubbo private String registryProtocol; private String registryAddress; private String url; private String version; &#125; &#125; 5. 基于RPC接口 vs 基于Kafka提交基于两种不同消息提交方式实现的中间件， 将从以下两方面进行比较 消息的顺序性 流量增加后扩容 5.1 消息的顺序性使用中间件回查机制，由于网络原因，有可能出现 某条业务的commit or rollback 消息比prepare 先到达中间件，面对这种情况,commit or rollback的处理逻辑是需要报错的，client 只能重试或者等待回查机制更新消息状态 但是由于kafka 可以在一个分区内的保证消息的有序性，所以基于Kafka提交的方案可以有一种优雅的方式保证prepare消息和commit&#x2F;rollback 消息的有序性。 解决方案很简单，生产者在发送消息按照业务 唯一标识指定key ,即指定目标分区即可。 5.2 流量增加后扩容以下比较基于在代码层面已经做好分库分表、异步处理、批量处理、cache 等性能优化的基础上 假设已经分库分表，数据库处理不是瓶颈万一流量激增，基于Kafka提交的方案 可能会产生产生必须要处理的消息积压，针对消息积压常见的解决方案中 增加消费者数量，不过一般来讲，线上生产环境都会已经把消费者数量和分区数量设置成一样的，所以这个方案无法发挥功能 增加分区数量，假设公司的工作流程里允许增加，如果使用场景对消息顺序性有要求，你又要考虑新增分区后对消息顺序性的影响 新建一个更多分区的topic, 涉及到生产者、消费者的代码变更 消费者性能优化， 比如异步处理、批量处理， 但是如果项目已经做好这些措施，面对消息积压，只能回到下面3种方式 综合以上，我个人认为基于RPC接口的方案可以用自动扩容策略直接应对， 简单直接优雅。 6. 作为中间件的技术设计6.1 性能提升 线程池异步处理 cache 存储回查接口 基于bizID + messageKey 的分库分表 6.2 幂等性 prepare 消息的幂等性， 唯一索引","categories":[],"tags":[{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"深入解析bloom filter的原理与实现","slug":"深入解析bloomfilter的原理与实现","date":"2024-03-31T08:16:17.000Z","updated":"2024-05-02T01:35:18.938Z","comments":true,"path":"b4fa673f/","permalink":"http://example.com/b4fa673f/","excerpt":"","text":"0.什么场景下会用到bloom filter 缓存穿透 爬虫重复 URL 检测， 避免爬虫过程形成环 假设有 10 亿条手机号，然后判断某条手机号是否在列表内 唯一昵称判断 这些场景可以用什么方式解决 hashmap, hashset MySQL：正常情况下，如果数据量不大，我们可以考虑使用 mysql 存储。将所有数据存储到数据库，然后每次去库里查询判断是否存在。但是如果数据量太大，超过千万，mysql 查询效率是很低的，特别消耗性能。 bitmap bloom filter 1.bloom filter 是什么？布隆过滤器是一种概率性数据结构，它提供了一种空间效率极高的方法来测试一个元素是否属于一个集合。 其基本原理是使用多个不同的哈希函数对元素进行哈希，然后将得到的哈希值对应到位数组上。一个元素被加入到集合中，那么所有哈希函数计算出的位置都会被置为1。检查元素是否存在于集合中时，使用这些哈希函数计算哈希值，并检查对应的位是否都是1。如果都是1，那么元素可能存在于集合中；如果任何一个位不是1，那么元素肯定不在集合中。 其主要特点是： 高空间效率：相比于传统的集合数据结构，布隆过滤器使用极少的空间来处理大量数据。 误报率&#x2F;假阳：布隆过滤器有一定的误报概率，这意味着它可能会错误地认为某个不在集合中的元素存在于集合中。 零漏报率：不会遗漏集合中真正存在的元素 不可删除：标准的布隆过滤器不支持从集合中删除元素，尽管存在变种（如计数布隆过滤器）支持这一操作。 多哈希函数：布隆过滤器通过多个哈希函数来减少误报率，每个元素被多个哈希函数映射到位数组的多个位置。 1.1 为什么空间效率高bloom filter 采用 位数组（bit array）作为核心的数据结构。 位数组是一个非常紧凑的数据结构，它可以有效地表示大量的布尔值（true或false），每个值只占用一个位（bit），而不是使用更传统的数据类型会占用更多的空间。 比如在爬虫场景中，假设有1亿个URL，每个URL算4字节, 如果用hashmap 实现，一个URL所占空间至少4bytes;如果用位数组实现，每个URL 所占的空间仅1bit，空间效率提升了32倍（存储空间不考虑误判率的前提下）。不可谓不高效。 1.2 为什么会有误报率&#x2F;假阳既然用到了哈希函数，肯定会遇到哈希冲突。所以一个元素对应 的n 个位置， 可能因为其他元素的哈希冲突 而导致判断时发现等于1， 从而产生假阳现象。 1.3 误报如何解决假阳问题无法被避免，只能尽可能减少。 减少的途径是选择合适的哈希函数以及指定合适的空间大小 1.4 为什么需要多个哈希函数布隆过滤器的设计使用多个哈希函数来解决单个哈希函数可能带来的局限性，提高其效率和准确性。具体来说，使用多个哈希函数的原因包括： 降低误报率 通过使用多个哈希函数独立地映射每个元素到位数组中的多个位置，并在所有这些位置上标记为1，可以显著降低不同元素映射到相同位置（即产生冲突）的概率，从而降低误报率 均匀分布 多个哈希函数可以将元素更均匀地分布在位数组上，减少了集中冲突的可能性。如果只使用一个哈希函数，即使其分布性质良好，也难以保证对于所有可能的输入集合都能保持良好的均匀性。多个哈希函数的组合，如果设计得当，可以相互补偿，实现更为均匀的分布。 1.5 为什么数据不可删除在布隆过滤器中，元素的存在是通过多个位的“1”状态来表示的，而将这些位重置为“0”可能会错误地影响其他元素的存在检测。 如果需要支持删除，可以考虑使用 变体Bloom Filter， 如cuckoo filter 2. bitmap 和 bloom filter 的区别Bitmap（位图）和布隆过滤器都是使用空间效率高的数据结构，它们通过利用位操作来实现存储和查询，但它们的设计目的和应用场景有所不同。 2.1 Bitmap（位图）位图是一种数据结构，用于高效地存储和查询状态信息。在位图中，每个元素的存在或状态是由单独的位来表示的，即使用1位二进制数（0或1）来表示每个元素是否存在或某种特定状态。 主要特点和用途： 简单直接：适用于需要追踪大量元素（如整数）存在与否的场景。 空间效率：对于大规模数据集，位图使用的空间远小于传统的数据结构（如数组或列表）。 随机访问：可以非常快速地检查任何一个元素的存在与否或状态。 固定大小：位图的大小在创建时由最大元素值决定，因此其空间效率依赖于数据的分布。 BitMap 的实现java BitSetredis setbit、getbit 2.2 区别 用途：位图主要用于精确表示一个大型数据集中元素的存在与否或状态信息，而布隆过滤器用于以极小的空间成本判断元素是否可能存在于集合中。 错误率：位图提供了100%准确的结果（假设足够的空间来表示所有元素），而布隆过滤器允许一定的误报率。 操作：位图支持添加、查询和删除（通过位反转）操作，而标准布隆过滤器不支持删除操作。 空间效率与数据规模：布隆过滤器在表示大型集合成员资格时通常比位图更加空间效率，尤其是当元素范围非常大但实际元素数量相对较少时。 总之，位图和布隆过滤器各有优势和应用场景，选择哪种数据结构取决于具体需求，包括对空间效率、准确率和操作类型的要求。 3. 单机版本Guava Cache 源码解析3.1 create1234567public static &lt;T&gt; BloomFilter&lt;T&gt; create(Funnel&lt;T&gt; funnel, int expectedInsertions /* n */, double falsePositiveProbability) &#123; int numBits = optimalNumOfBits(expectedInsertions, falsePositiveProbability); int numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits); return new BloomFilter&lt;T&gt;(new BitArray(numBits), numHashFunctions, funnel, BloomFilterStrategies.MURMUR128_MITZ_32); &#125; 3.1.1 参数解释 **funnel**：Funnel类型的参数，用于将任意类型的数据转化成布隆过滤器内部使用的一种形式。Funnel定义了如何把对象转换成二进制流，然后布隆过滤器使用这个二进制流来计算元素的哈希值。 **expectedInsertions**：这个参数指定了预期要插入布隆过滤器的元素数量。这个数值是为了优化布隆过滤器内部数据结构的大小。 **falsePositiveProbability**（false positive probability）：误判率。这是指一个不存在集合中的元素被判断为存在的概率。值得注意的是，随着实际插入数量的增加，实际的误判率可能会上升。 3.1.2 optimalNumOfBits123static int optimalNumOfBits(int expectedInsertions, double falsePositiveProbability) &#123; return (int) (-n * Math.log(p) / LN2_SQUARED); &#125; optimalNumOfBits通过计算,可以得到一个在满足特定假阳性率（falsePositiveProbability）要求下，对于给定数量的元素预期插入量（expectedInsertions），所需的最少位数。这使得布隆过滤器能够在保证误判率的前提下，使用最少的空间。这种计算对于设计高效且空间节约的布隆过滤器至关重要 3.1.3 计算逻辑optimalNumOfBits函数的计算基于以下公式，这个公式可以从布隆过滤器的理论误判率公式推导而来： m 是位数组的长度（即函数的返回值）。 n 是expectedInsertions，即预期的插入数量。 p 是falsePositiveProbability，即期望的假阳性概率。 ln⁡2 表示自然对数。这个公式利用了布隆过滤器的误判率特性，通过指定的假阳性率和预期插入数量来计算出一个最优的位数组长度。这个长度能够在满足误判率要求的同时，尽可能地减小布隆过滤器所需的空间。 3.1.4 实现注意实际实现时，可能还需要对计算结果进行取整处理，并确保结果是一个正整数。此外，实现可能还会考虑到性能和存储效率的平衡，比如通过限制位数组的长度为2的幂等。 3.1.5 optimalNumOfHashFunctions123static int optimalNumOfHashFunctions(int n, int m) &#123; return Math.max(1, (int) Math.round(m / n * LN2)); &#125; optimalNumOfHashFunctions(expectedInsertions, numBits)这个函数用于计算给定条件下布隆过滤器的最优哈希函数数量。这个计算基于预期要插入的元素数量（expectedInsertions）和布隆过滤器内部位数组的大小（numBits）。目的是为了平衡空间使用和误判率，确保布隆过滤器在给定条件下工作得最有效率。 计算逻辑 布隆过滤器的效率和误判率与使用的哈希函数数量有很大关系。太少的哈希函数会增加碰撞的概率，导致误判率升高；而太多的哈希函数又会导致位数组快速填满，同样增加误判率，同时还会增加计算的开销。 最优哈希函数数量的计算公式是： 这个公式基于以下原理：给定一个固定大小的位数组，存在一个最优的哈希函数数量，可以最小化给定元素数量条件下的误判率。这个最优数量直接关联于位数组的大小和要处理的元素数量。 其中： k 是最优的哈希函数数量， m 是位数组的大小（numBits）， n 是预期插入的元素数量（expectedInsertions）， ln⁡(2) 是自然对数2的值，大约等于0.693。 3.1.6 new BitArray(numBits)Guava cache bloom filter 在实现位数组是采用创建long[] + 位移操作 1234567891011121314151617181920212223242526static class BitArray &#123; final long[] data; BitArray(int bits) &#123; this(new long[IntMath.divide(bits, 64, RoundingMode.CEILING)]); &#125; // Used by serialization BitArray(long[] data) &#123; checkArgument(data.length &gt; 0, &quot;data length is zero!&quot;); this.data = data; &#125; void set(int index) &#123; data[index &gt;&gt; 6] |= (1L &lt;&lt; index); &#125; boolean get(int index) &#123; return (data[index &gt;&gt; 6] &amp; (1L &lt;&lt; index)) != 0; &#125; /** Number of bits */ int size() &#123; return data.length * Long.SIZE; &#125; &#125; 3.2 put12345678910111213141516MURMUR128_MITZ_32() &#123; @Override public &lt;T&gt; void put(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits) &#123; // TODO(user): when the murmur&#x27;s shortcuts are implemented, update this code long hash64 = Hashing.murmur3_128().newHasher().putObject(object, funnel).hash().asLong(); int hash1 = (int) hash64; int hash2 = (int) (hash64 &gt;&gt;&gt; 32); for (int i = 1; i &lt;= numHashFunctions; i++) &#123; int nextHash = hash1 + i * hash2; if (nextHash &lt; 0) &#123; nextHash = ~nextHash; &#125; // up to here, the code is identical with the next method bits.set(nextHash % bits.size()); &#125; &#125; 首先，这行代码使用MurmurHash3算法生成一个128位的哈希值，然后将其转换成一个long类型的数值hash64。 funnel是一个函数式接口，用于将对象转换为字节流，以便哈希函数可以处理。 hash64实际上包含两个32位的哈希值，它们可以从hash64的高32位和低32位分别提取。从hash64中提取两个32位的哈希值hash1和hash2。hash1是低32位，hash2是高32位。 接下来，代码遍历从1到numHashFunctions（布隆过滤器要求的哈希函数数量），每次循环计算一个新的哈希值nextHash。这个新的哈希值是通过hash1 + i * hash2计算得到的，其中i是当前的迭代次数。 如果nextHash为负数，通过位取反操作（~nextHash）将其转换为正数，以保证能够正确地映射到位数组的索引上。 最后，使用nextHash % bits.size()计算得到的索引值在位数组（BitArray）中对应的位置上设置位。bits.size()返回位数组的大小，这确保了计算得到的索引值不会超出位数组的范围。 3.2.1 哈希函数Guava cache 采用了非加密的单向散列函数Murmur3.MurmurHash 由Austin Appleby设计，因其高性能和良好的分布特性而广泛应用。MurmurHash有多个版本，如MurmurHash2、MurmurHash3等。 根据最开始对bloom filter 的定义，它需要多个哈希函数对数据进行哈希映射， 但Guava Cache bloom filter 实现中其实没有使用多个不同的哈希函数，而是采用了一种叫做“双哈希技术”的方法。 “双哈希技术”的基本思想是利用两个哈希函数h1(x)和h2(x)生成任意数量的哈希值，对于第i个哈希位置，使用h1(x) + i*h2(x)的方式来生成。这种方法只需要两次哈希操作，就可以模拟出多个哈希函数的效果，且生成的哈希序列具有很好的均匀分布性，既保证了布隆过滤器的效率，又避免了寻找多个好的哈希函数的复杂性，是一种在实际应用中非常实用的解决方案。 效率和复杂性具体指 性能和效率：使用单个哈希函数后通过算法变换生成多个哈希值，可以大大减少计算的复杂度和时间。多个独立的哈希函数意味着每个元素都需要被多次独立哈希，这会增加计算成本和时间。通过使用单个哈希函数并通过数学方法派生出多个伪随机的哈希值，可以在保持布隆过滤器错误率不变的前提下，显著提高效率。 简化实现：多个不同的哈希函数难以选取，而且还需保证它们相互之间的独立性和分布的均匀性，这在实践中是非常挑战性的。 3.3 mightContains和put 处理过程保持一致 3.4 guava cache 误报率-位数组长度固定在使用Guava的布隆过滤器时，预先估计将要插入的数据量非常重要。布隆过滤器在创建时会根据这个预估的数据量和指定的误判率来决定位数组的大小和使用的哈希函数数量。这些参数共同决定了布隆过滤器的性能和准确性。 如果实际插入的元素数量超过了最初的预估，过滤器的实际误判率会高于预期的误判率。这是因为当位数组变得过于饱和时，不同元素的哈希值更有可能映射到已经被设置为1的位上，从而增加了误判的几率。 Guava的文档明确指出了这一点，强调在创建布隆过滤器时应该准确预估元素数量，并考虑到这一点在其API设计中。BloomFilter.create()方法允许开发者在创建过滤器时指定预期插入的元素数量和可接受的误判率。 https://guava.dev/releases/20.0/api/docs/com/google/common/hash/BloomFilter.html 为了保证布隆过滤器的效果，应该根据实际使用场景仔细估算元素数量。如果预计数据量存在不确定性，建议预估一个上限，或者在实际元素数量超过预估时重新创建一个新的布隆过滤器。这当然会带来额外的成本，因此在设计初期做出准确估计非常关键。 总结来说，正确估计将要处理的数据量对于使用Guava布隆过滤器来说是非常重要的。如果实际数据量超过了预估，将会导致高于预期的误判率，可能影响到应用的准确性和可靠性。 4. 分布式 Redis bloom filter1BF.RESERVE &#123;key&#125; &#123;error_rate&#125; &#123;capacity&#125; [EXPANSION expansion] [NONSCALING] 4.1 参数解释4.1.1 EXPANSION expansionBF.RESERVE命令是RedisBloom模块中用来创建一个新的布隆过滤器的命令。这个命令允许用户预先为布隆过滤器指定参数，以便在插入元素之前就确定其大小和其他重要的行为特性。以下是BF.RESERVE命令各个参数的含义： **&#123;key&#125;**：这是将要创建的布隆过滤器的名称或键值。在Redis中，每个数据结构都通过一个唯一的键来标识和访问。 **&#123;error_rate&#125;**：预期的误报率。这是一个0到1之间的浮点数，表示允许的误判概率的上限。误报率越低，布隆过滤器所需的空间就越大。 **&#123;capacity&#125;**：布隆过滤器预期要存储的元素的数量。这个数值用于在保持误报率不变的情况下，预先计算布隆过滤器所需的最小大小。 **[EXPANSION expansion]**（可选）：这个可选参数用于指定当布隆过滤器的容量不足以容纳更多元素时，自动扩展的行为。expansion是一个大于1的整数，表示每次扩展增加的比例或容量。如果未指定，布隆过滤器可能会使用默认的扩展策略。 **[NONSCALING]**（可选）：这个可选标志用来指示创建的布隆过滤器不应自动扩展。这意味着一旦达到其容量上限，就不会尝试扩大过滤器以容纳更多的元素。这通常用于那些对空间使用有严格限制的应用场景。 作用：这个参数用于设置布隆过滤器在达到容量限制并需要扩展时，新创建的布隆过滤器层的大小。expansion的值决定了新层的容量是前一层容量的多少倍。这是一种自动扩展布隆过滤器容量的机制，以适应不断增长的元素数量，同时控制误报率。 场景：适用于那些元素数量不确定或可能会超出初始设定容量的场合。通过适当设置expansion参数，可以在维持误报率的同时动态增加布隆过滤器的容量。 举例：如果设置[EXPANSION 2]，那么每次扩展时，新的布隆过滤器层的容量将是前一层的两倍。 4.1.2 NONSCALING 作用：指定创建的布隆过滤器为非扩展型（Non-scaling）。即，一旦创建，布隆过滤器的容量固定，不会根据元素的增加而自动增加新的层。这意味着所有元素都将被添加到这个固定大小的布隆过滤器中，不管其容量是否已满。 场景：适用于元素数量预先已知且不会超出初始设定容量的场合。这种方式可以避免因为扩展而可能带来的额外内存使用，但要求用户必须更准确地预估所需的容量和误报率。 注意：当使用[NONSCALING]参数时，[EXPANSION expansion]参数将无效，因为非扩展型的布隆过滤器不会进行任何扩展操作。 4.2 可拓展特性是如何实现redis 可扩展布隆过滤(Scalable Bloom Filters)可以理解成是由多个位数组&#x2F;子过滤器（布隆过滤器实例）链接在一起形成的链表(SBChain)。 每个子过滤器都有其自己的容量和误报率设置。当前的子过滤器达到容量限制时，就会动态地添加一个新的子过滤器。 这种方法的关键优势是，它可以在不断增加元素的情况下，动态地扩展总容量，同时控制整体误报率。 然而，这种动态扩展的能力也意味着查询操作可能需要遍历链表中的多个布隆过滤器实例，这可能会对性能产生一定影响。 redis bloom filter 的整体上的基本逻辑，比如位数组的大小、选择的哈希函数、哈希函数的数量、多个哈希函数的模拟与Guava cache bloom filter基本保持一致， 接下来只重点分析其可拓展性是如何实现的 4.2.1 bloom 结构体123456789101112131415bloom.hstruct bloom &#123; uint32_t hashes; uint8_t force64; uint8_t n2; uint64_t entries; double error; double bpe; unsigned char *bf; uint64_t bytes; uint64_t bits; &#125;; 这个struct bloom定义了一个布隆过滤器的基本数据结构，用于在RedisBloom模块中表示一个布隆过滤器实例。下面是对各个成员变量的详细解释： **uint32_t hashes;**：这表示布隆过滤器使用的哈希函数的数量。在布隆过滤器中，元素的存在是通过多个哈希函数映射到位数组的不同位置来表示的。因此，哈希函数的数量直接影响布隆过滤器的误判率和效率。 **uint8_t force64;**：这是一个标志位，用于指示是否强制使用64位哈希函数。在某些情况下，为了保证在不同平台上的一致性和性能，可能需要强制使用64位哈希函数。 **uint8_t n2;**：这个成员可能用于表示与位数组大小相关的一个参数，具体含义取决于实现细节。在一些布隆过滤器的实现中，这个参数可能与位数组大小为2的幂次方有关。 **uint64_t entries;**：这表示预期存储在布隆过滤器中的元素数量。这个数值对于计算位数组的大小和哈希函数数量非常重要。 **double error;**：这是预期的误判率（false positive rate），是设计布隆过滤器时的一个关键参数。误判率越低，所需的位数组大小和哈希函数数量就越多。 **double bpe;**：这表示每个元素平均占用的位数（Bits Per Entry）。这个值是根据预期的误判率和元素数量计算得出的，用于确定位数组的大小。 **unsigned char *bf;**：这是一个指向位数组的指针。位数组是布隆过滤器的核心，用于存储元素的哈希值映射。unsigned char类型被用来表示位数组，每个字节包含8位。 **uint64_t bytes;**：这表示位数组占用的字节数。由于位数组是以字节为单位进行分配的，因此这个数值表示整个位数组的大小。 **uint64_t bits;**：这表示位数组中的位数。这个数值是根据entries、error和bpe计算得出的，决定了布隆过滤器可以有效存储的元素数量和误判率。 4.2.2 SBLink结构体123456sb.h/** Single link inside a scalable bloom filter */ typedef struct SBLink &#123; struct bloom inner; //&lt; Inner structure size_t size; // &lt; Number of items in the link &#125; SBLink; SBLink代表了可扩展布隆过滤器中的单个链接，即单个布隆过滤器实例。 **struct bloom inner;**：这是一个嵌套的结构体，表示单个布隆过滤器的内部结构。这个inner结构体可能包含了实现布隆过滤器所需的所有数据，如位数组、哈希函数数量等。 **size_t size;**：表示当前链接（即单个布隆过滤器实例）中的元素数量。这是为了快速访问单个过滤器内元素的数量，而无需遍历整个位数组。 4.2.3 SBChain结构体123456789sb.h /** A chain of one or more bloom filters */ typedef struct SBChain &#123; SBLink *filters; //&lt; Current filter size_t size; //&lt; Total number of items in all filters size_t nfilters; //&lt; Number of links in chain unsigned options; //&lt; Options passed directly to bloom_init unsigned growth; &#125; SBChain; SBChain代表了一系列（一个或多个）SBLink结构体的链表，构成了一个可扩展的布隆过滤器。 **SBLink *filters;**：这是一个指向SBLink数组的指针，表示当前所有的过滤器链。每个SBLink代表链中的一个布隆过滤器实例。 **size_t size;**：表示所有过滤器中元素的总数量。这个数字是所有单个SBLink中size成员的总和。 **size_t nfilters;**：表示链中SBLink实例的数量，即当前有多少个布隆过滤器被链接在一起。 **unsigned options;**：这是传递给每个布隆过滤器初始化函数bloom_init的选项。这些选项可能控制如布隆过滤器的误报率、是否自动扩展等行为。 **unsigned growth;**：这个成员变量控制链的增长行为。它可能指定当当前的布隆过滤器填满时，如何增加新的SBLink实例，例如，增加的大小或比例等。 4.3 可扩展bloom filter的工作流程 初始化：当创建一个新的可扩展布隆过滤器时，会指定初始容量、误报率等参数。基于这些参数，创建第一个子过滤器。 添加元素：向布隆过滤器添加元素时，会从当前子过滤器开始尝试添加。如果当前子过滤器已满（即达到了其容量限制），则创建一个新的子过滤器，并在新的子过滤器中添加元素。每个新添加的子过滤器都可以根据配置的规则调整大小和误报率，以适应不断增加的元素。 检查元素：检查一个元素是否存在时，需要查询所有的子过滤器。如果任何子过滤器表示元素可能存在（即对应的位都为1），则认为元素可能存在于布隆过滤器中。虽然可扩展布隆过滤器可以动态增加容量，但查询操作的成本随之增加，因为可能需要检查多个布隆过滤器实例。 参数调整：随着子过滤器的增加，每个新的子过滤器通常会有更大的容量。这是通过调整如比特数、哈希函数数量等参数来实现的。这种方法旨在平衡误报率和内存使用，即使在不断添加元素的情况下也能维持相对稳定的误报率。 5. 可删除 bloom filter5.1 哪些场景使用布隆过滤器时需要删除以上， guava 和 redis 的bloom filter 都没有实现删除功能，不能删除的原因已经解释过，元素的存在是通过多个位的“1”状态来表示的，而将这些位重置为“0”可能会错误地影响其他元素的存在检测。 但是在某些场景还是需要删除，比如，查看一张优惠券是否已被使用？创建一个包含所有存在但还未被使用优惠券的filter。每次校验时 如果否，则优惠券不存在。 如果是，则优惠券有效。检查主数据库。如果有效，则使用后从 Cuckoo 过滤器中删除。 5.2 实现删除布隆过滤器的思路5.2.1 计数型布隆过滤器（Counting Bloom Filter）这是最直接的方法之一，它通过为每个位使用一个计数器而不是简单的布尔标记来实现。当插入一个元素时，它经过多个哈希函数映射到多个计数器上，并将这些计数器的值增加。相应地，删除一个元素时，这些计数器的值会被减少。如果任何计数器的值达到零，则表示没有任何元素映射到这个位上。这种方法的缺点是需要更多的空间来存储计数器。 5.2.2 双布隆过滤器这种方法涉及到使用两个独立的布隆过滤器：一个用于添加操作，另一个用于删除操作。当添加一个元素时，它被添加到第一个布隆过滤器中；当删除一个元素时，该元素被添加到第二个布隆过滤器中。检查元素是否存在时，如果它在第一个布隆过滤器中并且不在第二个布隆过滤器中，则认为该元素存在。这种方法的问题是误报率会增加，因为删除过滤器中的元素也可能错误地阻止对实际存在于集合中的元素的正确判断。 5.2.3 d-left 计数哈希d-left计数哈希是一种高效的数据结构，它将元素映射到固定数量的桶中，并在每个桶内维护一个计数器。这种方法可以实现快速的插入、查询和删除操作，并且相比于计数型布隆过滤器，它可以更有效地利用空间。不过，实现起来比较复杂，且当桶填满时性能会下降。 5.2.4 布谷鸟过滤器（Cuckoo Filter）布谷鸟过滤器是另一种支持删除操作的布隆过滤器变种，它基于布谷鸟哈希和部分键存储。每个元素通过哈希函数映射到一个或多个位置，并存储其“指纹”。插入、查询和删除操作都基于这些指纹。布谷鸟过滤器相比计数型布隆过滤器在空间效率上有所提高，且支持删除操作，但在极端情况下可能需要重建过滤器。 总体上可以看出可删除bloom filter 的实现都是需要额外的空间去存储额外的信息， 那么其实现方式的好坏的评判标准就是 额外空间的大小、性能 以及对误报率的影响。 以下是一张表格，总结了几种支持删除操作的布隆过滤器变体的优点和缺点： 过滤器类型 优点 缺点 计数型布隆过滤器 - 直接支持删除操作- 实现相对简单 - 更多空间需求- 计数器溢出问题 双布隆过滤器 - 实现简单- 通过额外布隆过滤器跟踪删除操作 - 增加空间需求- 误判率增加 布谷鸟过滤器 - 高效的插入、删除和查询- 空间效率高 - 实现复杂- 负载因子高时性能可能下降 d-left计数哈希过滤器 - 高空间效率- 性能优于传统计数型布隆过滤器 - 实现复杂，需要精心设计 如果应用对空间效率要求不是特别高，且需要频繁进行删除操作，计数型布隆过滤器是一个简单有效的选择。 对于需要最小化误报率而且对空间有一定要求的应用，布谷鸟过滤器提供了一个较好的平衡点。 在需要极致空间效率且能够接受实现复杂度的高性能应用场景中，d-left 计数哈希过滤器可能是最佳选择。 关于空间的使用，有如下比对效果 redis 实现了cuckoo 变体bloom filter， 下面来讲一下 cuckoo filter 的原理 6. Cuckoo FilterCuckoo Filter 论文 the basic unit of the cuckoo hash tables used for our cuckoo filters is called an entry. Each entry stores one fingerprint. The hash table consists of an array of buckets, where a bucket can have multiple entries. 在Cuckoo Filter 中，最基本的存储单元是entry, 每个单元存储一个 fingerprint。cuckoo hashing 哈希表由一组桶（buckets）组成，每个桶可以包含多个条目（entries）。 Cuckoo Filter的关键特性 双哈希函数：对于任何一个给定的键，Cuckoo Hashing使用两个独立的哈希函数 h1 和 h2 来计算两个候选桶的位置。这两个位置是键可能被存储的地方。 指纹存储：与传统的哈希表不同，Cuckoo Hashing不存储完整的键，而是存储键的指纹。这允许在不牺牲太多空间效率的情况下进行高效的查找和删除操作。 动态插入：当插入一个新键时，如果候选桶中没有足够的空间，Cuckoo Hashing会通过一系列置换操作来为新键腾出空间。这涉及到将现有的指纹移动到它们的替代位置，从而为新键腾出空间。已占用位置的元素会被移动到其它哈希函数确定的位置，可能导致一个连锁的重新放置过程。这个算法的名字来源于布谷鸟，因为布谷鸟会将自己的蛋放入其他鸟类的巢中，迫使其他鸟类的蛋被移位或丢弃。 查找操作：给定一个键，Cuckoo Hashing通过检查两个候选桶中的指纹来确定键是否存在于表中。如果任一桶中存在匹配的指纹，则认为键存在于表中。 删除操作：删除操作相对简单，Cuckoo Hashing检查两个候选桶，如果找到匹配的指纹，则移除该指纹。这种删除方法不会影响其他键的存储位置。 高空间效率：Cuckoo Hashing通过存储指纹而不是完整的键来优化空间使用，同时保持较高的表占用率，从而实现高空间效率。 6.1 fingerprint“fingerprint”是存储在Cuckoo Filter中的数据。，一个哈希函数处理数据后得到的哈希串。 6.2 Partial-Key Cuckoo HashingA cuckoo filter is a compact variant of a cuckoo hash table that stores only fingerprints-a bit string derived from the item using a hash function。 在cuckoo filter 中，哈希表中存储的数据发生了变化，由原始数据变成了fingerprint。注意这里的（basic/standard） cuckoo hash tables指的是存储原始数据的做法。 partial-key cuckoo hashing 是一种仅使用指纹，而不需要原始数据就可以在置换操作中来确定元素存储位置的哈希技术。由于仅存储fingerprint 比存储原始数据所占内存空间小，所以 Partial-Key Cuckoo Hashing为优化Cuckoo Filter的空间效率和操作性能而设计。 如上代码所示，Partial-Key Cuckoo Hashing使用两个哈希函数 h1 和 h2 来计算两个候选桶位置。第一个哈希函数 h1 直接作用于元素的指纹，而第二个哈希函数 h2 则是 h1 与指纹的哈希值的异或（XOR）结果。这种XOR的处理结果 可以根据其中任意一个已知的候选桶位置（i）计算出另外一个候选桶位置（j）j &#x3D; i XOR fingerprint 6.3 Insert cuckoo 哈希的插入过程： 计算元素的指纹。 确定两个候选桶位置 i1 和 i2。 如果 i1 或 i2 有空闲条目，则将指纹插入到该条目中。 如果两个桶都满，则选择一个桶，随机选择一个条目并将其指纹与新元素的指纹交换。 Partial-Key Cuckoo Hashing ，更新候选桶位置 i 为 i XOR 指纹的哈希值。 如果找到空闲条目，则插入指纹；否则继续置换过程，直到找到空闲条目或达到最大置换次数。 6.4 Lookup 6.5 Delete 为什么cuckoo filter 可以删除元素但是又不影响其他元素的判断， 其实就是每个entry 只存储了一个元素的信息，删除后自然不会影响其他元素的判断。 6.6 空间优化Cuckoo Filter进行空间优化（SPACE OPTIMIZATIONS）的方法主要涉及对哈希表参数的选择和配置，以及对桶（buckets）的编码策略。以下是论文中提到的一些关键的空间优化策略： 选择合适的桶大小（Bucket Size）： 桶大小（b）对Cuckoo Filter的空间效率有显著影响。较大的桶可以提高哈希表的占用率（α），但同时也需要更长的指纹来维持相同的误报率。 论文中通过实验确定了对于不同的目标误报率（ϵ），最优的桶大小是不同的。例如，当误报率大于0.002时，每个桶有2个条目可能比4个条目更有效；而当误报率降低到0.00001至0.002时，每个桶有4个条目可以最小化空间使用。 半排序桶编码（Semi-Sorting Buckets）： 对于每个桶中的指纹进行排序，然后使用一个预先计算好的表来编码这些排序后的指纹序列。由于桶内指纹的顺序不影响查询结果，这种方法可以通过索引来节省空间。 例如，如果每个桶有4个指纹，每个指纹是4比特长，那么未压缩的桶将占用16比特。通过排序和编码，可以使用一个12比特的索引来代替原来的16比特桶，因为可以预先计算出所有可能的桶值（例如，3876种），并将每个桶表示为一个索引，从而节省1比特每个指纹。 平衡桶的负载（Balancing Bucket Loads）： 通过合理配置哈希函数和桶大小，可以减少哈希表中的冲突和空桶，从而提高空间利用率。 论文中提到，通过适当的配置，Cuckoo Filter可以以高概率达到95%的表空间占用率。 指纹长度的优化： 指纹长度（f）与桶大小和目标误报率有关。通过调整指纹长度，可以在保持目标误报率的同时，优化空间使用。 论文中的分析表明，对于实际应用中的集合大小，较短的指纹（例如6比特或更长）通常足以确保哈希表的高利用率。 通过这些空间优化策略，Cuckoo Filter能够在保持高效动态操作的同时，实现紧凑的数据存储。这些优化使得Cuckoo Filter在很多实际应用中比传统的Bloom Filter和Counting Bloom Filter更加空间高效 6.7 Redis cuckoo filterredis 实现了 cuckoo filter ，基本实现逻辑和论文中表现一致，有兴趣大家可以自己去看一下 7. 自己如何实现一个布隆过滤器基于以上对3种bloom filter的分析，可以总结出自己实现bloom filter时需要考虑的因素本项目代码可点击这里查看 7.1 位数组的实现首先参考BitSet。BitSet类是Java标准库中提供的一个用于处理位数组的类，基本可以认为是bitmap 在Java 的中的实现，其原理是是long[] 数组+ 位操作。在自己实现布隆过滤器时，可以直接使用BitSet ， 也可以像guava cache 一样，自己用long[] + 位操作自己封装一个bitarray，而不是直接使用的BitSet。 7.2 位数组的大小在简单的自己实现的版本中，可以直接指定bitarray 大小。 但在实际线上生产环境中可用的bloom filter 实现，一般都是根据预期插入的数据量 和 可接受的误报率两个数字通过 一个数学公式算出的，而不是直接用预期插入的数据量。 同时我们在线上生产环境使用布隆过滤器时，根据业务特性和流量去估算预期插入的数据量 和衡量 可接受的误报率 也是非常重要的步骤。 如果估算数据量比实际值大很多，就会浪费内存空间。如果估算数据量比实际值小很多，那么误报率很可能就无法控制在可接受的范围内。 guava cache bloom filter 位数组大小一旦确定时无法修改的，所以实际数据量如果过大，那么误报率肯定会上升 redis bloom filter 位数组大小可以scale, 但是判断元素是否存在的这个步骤性能会受到影响 7.3 用哪个哈希函数这个哈希函数在密码学中叫做单向散列函数。单向散列函数有两类加密与非加密散列，其主要区别如下。 7.3.1 加密散列函数设计用于加密应用，强调安全性。它们需要具备一定的性质，如抗碰撞（两个不同的输入不应该产生同一个输出）、隐藏性（无法从输出推断任何信息关于输入）和抗篡改（对输入的微小变化会在输出中产生不可预测的、大的变化）。 SHA家族（SHA-1、SHA-256、SHA-512等）：安全哈希算法（Secure Hash Algorithm）家族，广泛用于加密、数据完整性校验和数字签名等安全相关的应用。 MD5：消息摘要算法5（Message Digest Algorithm 5），尽管因为安全性问题不再推荐用于加密安全领域，但在一些非安全性要求的场合仍然可以见到其身影。 RIPEMD：一系列的加密哈希函数，包括RIPEMD-160、RIPEMD-256和RIPEMD-320，其中RIPEMD-160设计用于替代MD5和SHA-1。 7.3.2 非加密散列函数设计重点是高效率和均匀分布的输出，以支持快速数据检索、数据分布平衡等，而不是安全性。在某些情况下，允许存在碰撞，但碰撞的概率要尽可能低。 常见的非加密单向散列函数： MurmurHash：由Austin Appleby设计，因其高性能和良好的分布特性而广泛应用。MurmurHash有多个版本，如MurmurHash2、MurmurHash3等。 CityHash：由Google开发，专为哈希字符串数据设计，适用于构建哈希表等数据结构。后续Google又推出了FarmHash，作为CityHash的改进版，提供更好的性能和更广的适用范围。 xxHash：是一种非常快的哈希算法，提供了极高的数据处理速度，同时保持了良好的散列分布特性，适用于需要快速散列大量数据的场景。 Jenkins哈希函数（如一致性哈希）：Bob Jenkins所设计的一系列哈希函数，包括lookup3、SpookyHash等，它们广泛用于软件开发中，特别是在需要快速且分布均匀的哈希算法的场合。 FNV（Fowler-Noll-Vo）：是一系列设计简单、性能良好的哈希函数，特别适合于散列单个文本字符串。FNV-1和FNV-1a是两个最著名的变种。 在以上分析原理分析中，guava cache和Redis 都是用了MurmurHash如果我们自己也想要用MurmurHash，目前Java并没有提供实现，可以引入guava cache 包使用MurmurHash。 7.4 用多少个哈希函数前面说过用多个哈希函数可以减少误报率，那么到底要用多少个哈希函数呢， 这也是可以通过 预期插入的数据量+ 可接受的误报率 通过固定的数学公式计算得出。同时多个哈希结果可以通过像Guava cache一样，用双哈希技术模拟得到。","categories":[],"tags":[{"name":"Programming","slug":"Programming","permalink":"http://example.com/tags/Programming/"}]}],"categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"Programming","slug":"Programming","permalink":"http://example.com/tags/Programming/"}]}