{"meta":{"title":"Sun Yan","subtitle":"","description":"","author":"Sun Yan","url":"http://example.com","root":"/"},"pages":[{"title":"tags","date":"2024-04-28T09:06:01.000Z","updated":"2024-04-28T09:07:08.242Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"从HTTP到HTTPs, 如何实现加密传输","slug":"从HTTP到HTTPs-如何实现加密传输","date":"2024-09-13T11:36:38.000Z","updated":"2024-09-22T11:51:12.024Z","comments":true,"path":"79674443/","permalink":"http://example.com/79674443/","excerpt":"","text":"本文参考《图解密码技术》， 从HTTPs 为什么比HTTP 安全的角度梳理多个和密码相关的知识点， 希望对你有帮助。 以下内容介绍，均基于Alice 向Bob 发送邮件为基础进行介绍 1. 前置知识1.1 计算机网络在了解密码具体知识前，需要先了解一下传输信息的计算机网络。主要有2点 计算机网络是分层的 网络传输依赖一系列中间设备 网络传输并不是简单的A点到B点的直接通信，而是依赖于一系列中间设备。 当我们在互联网上发送数据时（例如发送一封电子邮件），数据不会以单一的整体方式进行传输。相反，它会被拆分成许多小的“数据包”（packets），每个数据包包含发送方、接收方以及数据本身的一部分。这些数据包会经过复杂的路径传输，最终在目标设备处重新组合，恢复成完整的消息。 1.1.1 计算机网络是分层的 1.1.2 网络传输依赖于一系列中间设备网络传输并不是简单的A点到B点的直接通信，而是依赖于一系列中间设备。这些中间设备包括路由器、交换机、服务器、网关等，它们共同协作以确保数据包能够从源点传输到目标点。 在此过程中，每个中间设备都有可能成为窃听的切入点。为了理解这些中间设备如何导致窃听的可能性，我们先从网络的工作原理开始，然后逐步深入探讨中间设备如何影响数据的安全性。 为了使数据从A点传输到B点，它必须经过多个中间设备，这些设备主要包括： 路由器（Router）：路由器在不同网络之间转发数据，它通过读取数据包中的目标地址来决定数据包应该被发送到哪个下一跳路由器。路由器实际上是决定数据传输路径的关键设备。 交换机（Switch）：交换机通常在局域网（LAN）中使用，它负责根据数据包中的MAC地址在局域网内部的设备之间转发数据。 防火墙（Firewall）：防火墙用于监控网络流量，阻止不安全或未经授权的通信。虽然防火墙并不负责路由，但它是数据包在传输时必须经过的设备之一，它在数据包进入或离开网络时检查流量。 网关（Gateway）：网关是网络中的特殊设备，它负责在不同网络协议或不同网络之间转换数据。它们通常位于不同类型网络的边界上。 服务器：在某些情况下，数据包可能会通过中间服务器进行处理。例如，当你发送电子邮件时，邮件首先被发送到邮件服务器，然后服务器根据接收者的地址将其传送到目标邮件服务器。 数据包在互联网中传输时，必须经过这些中间设备，依靠它们来找到最终的目标地址。因此，网络传输并不是简单的两台设备直接通信，而是通过一系列中间设备和多次转发实现的。 1.2 加密安全特性现代加密系统关注的一些安全特性： 消息的机密性（Confidentiality）：指确保消息在传输过程中不会被未授权的第三方窃取，即使被窃取，也无法解读消息的真正含义。 消息的完整性/防篡改（Integrity）： 是指确保消息在传输过程中没有被修改。如果消息被篡改，接收方应该能够识别出这一点。 消息的认证（Authentication）：认证是指确认消息的发送者是谁，确保接收方能够识别消息的合法发送者。这意味着接收方可以确信消息确实是来自声称的发送者，而不是来自其他未授权的第三方。 消息发送者的认证与防止否认（Non-repudiation）：指一旦确定消息来自某个发送者，发送者就不能否认自己发送了这条消息。也就是说，发送方在发送消息后，无法声称自己没有发送过该消息。 1.3 密码学工具箱 对称加密 非对称加密 消息认证码 数字签名 单向散列函数 伪随机数 1.4 加密算法-机密性加密与摘要的本质区别就在于，摘要是不可逆的，而加密是可逆的，逆过程就是解密。 在经典密码学时代，加密的安全主要是依靠机密性来保证的，也就是依靠保护加密算法或算法的执行参数不被泄露，来保障信息的安全。而现代密码学并不依靠机密性，加解密算法都是完全公开的，信息的安全是建立在特定问题的计算复杂度之上。具体来说，就是算法根据输入端计算输出结果，这里耗费的算力资源很小；但根据输出端的结果反过来推算原本的输入，耗费的算力就极其庞大。 1.4.1 对称加密算法加密、解密使用同一个密钥 称之为对称加密。 就像我们用保险箱存取贵重物品一样，存的时候用一把钥匙打开门把贵重物品放进去，取的时候 也是用同一把钥匙打开门把贵重物品取出来。 常见的对称加密算法DES DES 是一种分组加密算法，采用64位的明文分组进行加密，并且使用56位的密钥进行加密操作（虽然密钥的实际长度是64位，但其中8位用于校验）。现代计算能力可以在短时间内通过暴力破解尝试所有可能的密钥，从而解密DES加密的数据。因此，DES在现代已被视为不安全的加密算法。 三重DES3DES是为了增强DES的安全性而设计的。它通过重复DES加密过程三次来提高加密强度，从而克服了DES密钥过短的问题。3DES使用三个不同的56位密钥，进行三轮DES加密解密操作：首先使用第一个密钥加密数据，然后用第二个密钥解密，最后再用第三个密钥加密。这个过程可以有效地增强DES的加密强度。 虽然3DES比DES安全，但是计算速度也更慢，所以在现代应用中，除一些遗留系统外，它已经被更新的加密标准AES所取代 AESAES是目前最常用的对称加密算法，并被广泛用于政府、金融、军事和商业应用中。它已经取代了DES和3DES，成为主流的加密标准。 AES是一种分组加密算法，支持128位、192位或256位的密钥长度，且使用128位的固定分组大小。 分组加密从前面的描述中可以看到，DES 和AES 都属于分组加密算法，他们只能加密固定长度的明文， 如果需要加密任意长度的明文，就需要将明文分组然后加密迭代。 分组加密算法有多种工作模式，包括ECB、CBC、CFB、OFB、CTR 1.4.2 非对称加密算法加密、解密使用不同的密钥 称之为非对称加密。加密过程使用的密钥通常称之为私钥，解密过程使用的密钥通常称之为公钥 公钥和私钥确实是通过特定的数学算法生成的密钥对，它们紧密相连 公钥加密、私钥解密：在典型的加密场景中（如RSA加密），公钥用于加密数据，私钥用于解密数据。这使得任何拥有公钥的人都可以加密数据，但只有拥有私钥的人可以解密。 私钥签名、公钥验证：在数字签名场景中，私钥用于对数据进行签名，公钥用于验证签名的真实性。也就是说，私钥生成的签名可以被公钥验证，而不泄露私钥。 公钥加密，私钥解密，这种就是加密，用于向私钥所有者发送信息，这个信息可能被他人篡改，但是无法被他人得知。举个例子，如果甲想给乙发一个安全保密的数据，那么应该甲乙各自有一个私钥，甲先用乙的公钥加密这段数据，再用自己的私钥加密这段加密后的数据，最后再发给乙。这样确保了内容既不会被读取，也不能被篡改。 私钥加密，公钥解密，这种就是签名，用于让所有公钥所有者验证私钥所有者的身份，并能用来防止私钥所有者发布的内容被篡改。但是它不用来保证内容不被他人获得。 缺点 加密效率低且不能直接用于大量数据的加密。因此非对称加密算法，并不适合直接用户加密传输大量明文 无法解决中间人攻击，具体内容放在下面说 密传输问题公钥的传输依然有可能被第三方获取， 从而导致中间人攻击，后面会具体介绍。 1.4.3 单向散列函数-识别篡改一般这个性质叫做防篡改， 我觉得叫做识别篡改更准确。 单向散列函数（也称为哈希函数）不能主动防止内容的篡改，但它可以通过生成固定长度的哈希值来检测内容是否被篡改。 单向散列函数的主要特点： 固定长度输出：无论输入数据的长度如何，散列函数生成的哈希值长度总是固定的。比如SHA-256总是输出256位的哈希值。 单向性：散列函数是单向的，意味着很难从哈希值反推原始数据。 相同输入相同输出：如果两次输入的数据相同，那么散列函数的输出也一定相同。 微小的输入变化会导致完全不同的输出：称为“雪崩效应”，即使输入数据只有一个比特的变化，生成的哈希值也会完全不同。 单向散列函数是一种将任意长度的输入（如文件、消息）映射为固定长度输出（称为哈希值、消息摘要）的算法。常见的单向散列函数有： MD5（虽然已经被认为不安全） SHA-1（也已不推荐使用） SHA-256、SHA-3 等较新的哈希算法 1.4.4 消息认证码-识别篡改 &amp; 认证消息认证码（MAC, Message Authentication Code） 是一种通过共享的对称密钥生成的固定长度的校验值，用于确保消息的完整性和认证性。MAC的主要功能是： 完整性：指的是数据在传输过程中是否被篡改。MAC通过计算消息的哈希值并结合共享密钥生成一个认证码（MAC值）。接收方使用同样的密钥计算MAC值并与接收到的MAC值进行对比，从而确认消息是否被篡改。 认证性：由于MAC是基于双方共享的对称密钥生成的，只有持有该密钥的合法发送者才能生成正确的MAC值，因此接收方可以通过验证MAC值来确认消息的发送者是持有密钥的合法参与者。 消息认证码（MAC） 的两个主要特性都是基于共享密钥的安全性来实现的。如果共享的密钥被第三方窃取，MAC的这两个特性就不复存在。 尽管在密钥安全的前提下，MAC能够识别篡改和认证消息的发送者身份，但它存在一个明显的局限性：无法防止消息发送者的否认，这在密码学中称为不可否认性（Non-repudiation）。 在使用MAC时，发送方和接收方都持有相同的对称密钥，这意味着： 接收方和发送方都可以生成和验证相同的MAC值。由于双方共享相同的密钥，任何一方都可以计算出有效的MAC。 如果发送方之后否认曾发送过某条消息，接收方没有办法证明发送方确实发送了这条消息，因为接收方自己也可以生成相同的MAC值。 因此，消息认证码不能提供不可否认性。在法律或信任系统中，接收方无法向第三方（如法庭）证明某个特定消息是由发送方发出的，因为双方共享同一个密钥，任何一方都可以生成有效的MAC。这使得发送者有可能否认曾发送消息，或者接收方可能伪造消息并声称是发送方发送的。 1.4.5 数字签名-认证 &amp; 防止否认数字签名依赖于非对称加密的核心机制，即使用私钥进行签名、使用公钥进行验证，从而能够完成认证不可否认两个特性。 如果签名验证通过，接收方可以确认消息确实来自持有该私钥的发送者。这就是认证性，即确保消息的发送者身份是真实的。 由于只有私钥持有者能够生成有效的签名，发送方无法否认自己曾经对消息进行过签名。这就是不可否认性。 1.4.6 消息认证码认证 vs 数字签名认证MAC（消息认证码）通过共享的密钥，认证消息确实来自通信对方，但是它一个非常大的缺点就是没有强身份认证，即不认证具体身份 由于双方共享同一个密钥，MAC 只能证明消息来自拥有该密钥的一方，但如果多个实体共享同一个密钥，无法确定到底是哪一个实体发送的消息。也就是说，MAC 没有强身份认证功能，无法防止发送者后来否认自己发出的消息（不可否认性问题）。 同时由于没有身份认证，在密钥泄漏的情况下，也无法识别中间人攻击 数字签名则提供了一种强身份认证的认证类型，确保消息来自某个具体的发送者， 同时可以防止否认 2. HTTP -通信使用明文可能会被窃听Alice 发出的邮件通过计算机网络传输给Bob, 邮件传输的过程中需要经过一系列中间设备。这些设备或节点被恶意控制或监控，那么邮件就有可能被窃听。黑客或其他有恶意意图的人，可以在这些节点上安装窃听软件，或者通过物理方式接入网络来截获数据, 进而做篡改或者中间人攻击等 既然窃听是因为网络传输需要经过设备造成的，那么一种理想的解决办法就是，点对点通信。 如果Alice和Bob的计算机之间有一个完全物理隔离的、私有的连接（比如一根专线或者光纤），且中间没有任何其他设备介入，那么窃听的风险将会大幅减少。 这样的情况在一些高安全性、需要严格保密的环境中确实有可能实现，像是军事用途、金融系统内部的特殊通信等。但实现成本非常高。 且即便完全避免中间设备的参与没有经过加密处理的数据在传输过程中被截获（例如通过物理入侵或电磁信号泄漏），信息同样可能被窃听。 因此，关键的问题不仅在于是否经过中间设备，而是 通信的安全性依赖于数据加密技术的有效性。 而现代密码学并不依靠机密性，加解密算法都是完全公开的，信息的安全是建立在特定问题的计算复杂度之上。具体来说，就是算法根据输入端计算输出结果，这里耗费的算力资源很小；但根据输出端的结果反过来推算原本的输入，耗费的算力就极其庞大。 2.1 对称加密-保证消息机密性由于在HTTP中一切信息都是明文传输，一旦发生窃听，第三个人立马就能读懂其中的含义。 那如果信息发送者Alice 将内容加密，Bob 收到信息解密后再阅读内容， 则第三方即使窃听到传输内容，也读不懂，是不是就可以保证传输内容不泄漏了？ 是的，这是一个思路，这里可以使用高效的对称加密算法算法。 2.2 非对称加密算法-安全传输密钥在使用对称加密算法高效加密明文时保证机密性的思路中，存在一个问题， 这个密钥如何被Alice 和Bob 双方安全共享。 假设Alice 生成了密钥，Bob 也必须获取到才能进行解密，否则就和窃听者一样即使拿到邮件内容也无法得知其含义。 Bob 如何获取到密钥，无非就2种方式 俩人见面，线下给密钥 网络传输密钥 本文我们可以规定一切行为都发生在网络上， 那么通过网络传输密钥时依然是明文，也就是说窃听者可以通过和窃听邮件内容一样的方式获取到明文传递的密钥。 关于密钥被窃听有2种应对方式 钻牛角尖思考，到底有什么方法可以让密钥安全传输呢 - 基本无解，有解的话直接传输内容本身就可以了 换个思路，即使密钥被窃听到也不影响内容加密传输是不是也可以 。 那这里就可以非对称加密算法 非对称加密算法 有2种用法 公钥加密，私钥解密 - 对应加密场景 私钥加密，公钥解密 - 对应数字签名场景 在本小节中，先关注公钥加密、私钥解密这种场景， 如下图， 如果Alice 想给Bob 发送加密消息，需要Bob先将他的公钥通过网络明文传输给Alice, 这个过程公钥即使被窃听到也没关系 因为窃听者没有解密私钥，后面即使窃听到Alice 发给Bob 的加密信息，也无法解密用公钥加密后的内容。 2.3 混合加密系统-既安全又高效根据前面的内容可以看出 对称加密算法可以使用分组方式，对大量明文进行高效加密，但是其密钥本身的安全传输是一个问题 非对称密钥 很好的解决了对称加密密钥被窃取的问题，但是它又不适合用户对大量明文进行加密 可以考虑将二者的优点结合形成混合加密系统。 混合加密系统通过利用非对称加密的强大安全性和对称加密的高效性，能够实现既安全又高效的数据加密。 其核心思想是分为2步 密钥交换：使用非对称加密（如RSA或ECC）来加密和交换对称加密密钥。由于非对称加密仅用于加密短小的对称密钥（如AES的256位密钥），计算开销较小，速度相对可接受。 数据加密：一旦通过非对称加密安全地交换了对称密钥，实际的数据传输就使用高效的对称加密算法（如AES）。对称加密的加密速度非常快，能够处理大量的数据，适用于文件加密、实时视频流加密等场景。 安全性和性能的平衡：这种方法兼具了非对称加密的安全性（用于密钥交换）和对称加密的效率（用于大数据加密），是现代安全通信的基础。HTTPS、SSH、PGP等安全协议都采用了这种混合加密模型。 2.4 消息认证码-既防篡改又能认证防篡改和认证性质的实现见上文。 2.5 数字签名-无法否认且能认证如果Alice使用Bob 的公钥加密消息发送给Bob, 如何能确定这条消息一定是Alice发出的，因为窃听者同样可以拿到Bob 的公钥，然后以Alice 的口吻向Bob 发送消息。Bob 如何确定一条消息一定是Alice 发出的， 而不是窃听者冒充Alice 发出的。 这里可以使用非对称加密：私钥加密，公钥验证这个流程 ， 完成数字签名的功能，来保证消息一定是Alice 发出的， 且Alice 无法否认自己发出过这条消息。 关于私钥加密，公钥验证为什么就能保证消息就一定是私钥持有者发出的 当然，物理世界中私钥被窃取，在加密这样的网络世界是管不到的 2.6 中间人攻击下，公钥的认证问题由于非对称加密中公钥需要通过网络明文传输给Alice， 那么就是可以被窃听获取到的。 此时如果有一个主动攻击者Molly 自己也生成一个非对称加密密钥对， 他在窃取到Bob传递给Alice 后公钥后， 篡改成自己的公钥发送非Alice， 此时Alice 没有什么手段可以判断这个公钥到底是不是Bob, 他如果直接拿来加密内容，传输给Bob, Molly 继续窃取这个内容，由于Alice实际用来加密的公钥匙Molly 的， 此时Molly 就可以用自己的私钥进行解密获取具体内容。 中间人攻击的风险： 公钥篡改：如果 Alice 想与 Bob 通信，但攻击者（Mallory）冒充 Bob 拦截了 Alice 请求的公钥，并替换为自己的公钥。Alice 会误以为她在使用 Bob 的公钥加密信息，但实际上传输的对称密钥被 Mallory 用自己的私钥解密。 认证性问题：Alice 需要确认她收到的公钥确实是 Bob 的，而不是来自攻击者。因此，公钥的认证是一个关键问题。 基于以上解释，你应该可以理解， 公钥的“安全配送”并不是像对称加密密钥的安全配送那样，不被人窃取， 而是在明文传输的前提下，即使被窃取，收到公钥的人也要能识别出来，也就是说Alice 在收到公钥后，要能100%确定 这个公钥一定是Bob 的， 如果被中间人窃听篡改了，Alice 需要识别出来，不用这个公钥。 如果仍然考虑公钥的网络安全传输问题，将继续陷入“如果能安全传输密钥，那就肯定能安全传输明文”的死循环。 为了打破这个循环，引入第三方可信机构成为了解决方案的关键。具体来说，这一机构就是证书颁发机构（CA, Certificate Authority），它的作用是通过公钥基础设施（PKI, Public Key Infrastructure）来验证和管理公钥，确保公钥的传输是安全的。 2.6.1 CA-公钥的数字签名数字证书认证机构(CA,Certificate Authority)。数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。 证书颁发机构（CA）如何工作： 身份验证：Bob 向 CA 提交身份信息和公钥，申请一个数字证书。CA 验证 Bob 的身份，确认公钥确实属于 Bob。这个身份验证可以是电话、邮箱等方式 签发证书：CA使用自己的私钥 对 Bob 的身份和公钥进行数字签名，生成一个数字证书，并将该证书发给 Bob。证书中包含 Bob 的身份信息、他的公钥，以及 CA 的数字签名。 公钥验证：Alice 在与 Bob 通信时，收到 Bob 提供的数字证书。她可以使用 CA 的公钥验证证书的签名，确保她获得的公钥没有被篡改，从而防止中间人攻击。即使攻击者在传输过程中试图篡改公钥，Alice 也能通过验证 CA 的签名识别出这种篡改。 2.6.2 CA公钥的获取-操作系统和浏览器预装的根证书在证书颁发机构（CA） 的工作流程中，Alice 需要使用 CA 的公钥来验证 Bob 的数字证书是否有效，从而确保 Bob 的公钥未被篡改。那么Alice 如何获取 CA 的公钥呢？实际上，Alice 不需要主动从网络上获取 CA 的公钥，因为这样会产生安全隐患。相反，CA 的公钥通常通过操作系统和浏览器预装的根证书 现代操作系统和浏览器（如 Windows、macOS、Linux，Chrome、Firefox、Safari 等）通常都会预装一组可信任的根证书，这些根证书由全球广泛认可的证书颁发机构（CA）提供。每个根证书都包含 CA 的公钥，并被操作系统或浏览器标记为可信任的。 根证书的作用： CA 的身份认证：根证书是 CA 的自签名证书，它包含 CA 的身份信息和公钥，以及 CA 自己用其私钥对证书签名的数字签名。因为这些证书是由操作系统或浏览器厂商直接植入的，Alice 可以信任这些根证书中的公钥。 验证链证书的可信度：当 Alice 收到 Bob 的数字证书时，Bob 的证书通常是由中间 CA 签发的，而中间 CA 的证书会由上一级的 CA 签发，最终形成一个信任链。通过验证链中的证书，Alice 可以逐级追溯到操作系统或浏览器中内置的根证书，从而验证 Bob 的证书。 预装根证书的好处： 安全性：根证书是直接通过操作系统和浏览器厂商提供的，因此这些公钥的获取过程是安全的，不需要通过网络传输，避免了中间人攻击的风险。 自动验证：当 Alice 在浏览器中访问一个网站（如 Bob 的网站）时，浏览器会自动使用系统或浏览器中的根证书来验证该网站证书的可信度，无需 Alice 手动获取或验证 CA 的公钥。 3. 密钥交换方法通过CA 解决了公钥的认证问题，下面来总结一下，对称加密算法中密钥的安全传输问题。密钥交换一般有以下4种方式 公钥密码交换算法 Diffie-Hellman 密钥交换算法 使用密钥分配中心 事先共享密钥 3.1 公钥密码交换算法即我们在前面介绍的混合加密系统中，在公钥认证问题解决的前提下， 通过非对称加密算法加密传输密钥 3.2 Diffie-Hellman 密钥交换Diffie-Hellman（DH）密钥交换协议是一种安全密钥交换的方法，它允许两个不相互信任的实体在不预先共享密钥的情况下，通过一个不安全的信道生成共享的加密密钥。该方法依赖于特定的数学问题（如大整数的离散对数问题），这些问题在现有计算能力下很难快速破解，因此确保了密钥交换的安全性。 公用参数选择：首先，通信双方A和B选择一个公共的素数p和一个基数g，这些值可以在公共信道中传输，无需保密。 生成私钥：双方分别选择一个私有的随机数a（A的私钥）和b（B的私钥），这些值不会在通信中公开。 计算共享值：A计算A_value = g^a mod p，B计算B_value = g^b mod p。然后A和B将各自的计算结果通过公共信道交换 3.3 事先共享密钥（Pre-shared Key, PSK）事先共享密钥（PSK）是一种传统的加密方法。在这种方式中，通信双方需要预先通过某种安全途径共享一个密钥。这个密钥可以通过线下物理方式进行传输，例如通过安全的信道、面对面的会晤、信件或电话。这种方式通常用于小范围或高度安全的环境中，例如在公司内部网络、军事通信或物联网设备之间。 密钥生成：首先，通信的双方需要决定一个共享的加密密钥。这通常是在一个安全的环境中产生的。 线下共享：这个密钥不能通过不安全的渠道传输，因此通常通过物理方式或事先商定的安全信道传递。双方在建立通信前必须获取该密钥。 使用密钥加密通信：一旦双方获得密钥，通信过程便使用该密钥进行加密和解密。通常是使用对称加密算法（如AES或DES），因为这些算法对加密和解密使用的是同一个密钥。 更新或更换密钥：如果密钥有泄露的风险，双方需要通过安全的方式再次共享新的密钥。 3.4 使用密钥分配中心（Key Distribution Center, KDC）密钥分配中心（KDC）是一种集中化的密钥共享方式，适用于大规模网络环境，尤其是对称加密的环境中。KDC 是一个专用的服务器，负责管理和分发加密密钥。在这种架构中，参与通信的各方不需要直接相互共享密钥，而是通过一个可信的第三方KDC来管理密钥的分发和验证。这种方式可以有效减少直接共享密钥的复杂性和安全风险。 注册：首先，每个通信方需要在KDC注册，KDC为每个实体分配一个唯一的密钥（通常是与KDC共享的会话密钥）。 请求通信密钥：当两个实体（比如A和B）想要通信时，A会向KDC请求与B通信所需的会话密钥。 密钥分发：KDC生成一个新的会话密钥，并通过加密的方式分别传递给A和B。例如，KDC会用A的密钥加密会话密钥并发送给A，用B的密钥加密会话密钥并发送给B。 安全通信：在获得会话密钥后，A和B可以使用该密钥进行加密通信。 密钥刷新：KDC可以在需要时生成新的密钥，并通知通信双方。 优点 安全集中管理：所有密钥的管理和分配由一个可信的中心控制，简化了密钥管理过程，减少了潜在的泄露风险。 扩展性好：在大规模网络中，无需每对通信方直接共享密钥，可以由KDC动态生成和分发密钥。 灵活性高：可以灵活地控制密钥的生效时间和使用权限，提高安全性。 缺点 单点故障问题：KDC 作为系统中的核心，如果KDC出现故障，整个系统将无法正常工作，甚至可能导致所有通信被中断。 需要高度信任的第三方：通信双方必须完全信任KDC，任何KDC的漏洞或恶意行为都会破坏系统的安全性。 性能瓶颈：KDC 需要处理大量的密钥分发请求，可能会成为系统的性能瓶颈。 4. 网络传输安全层 -SSL/TLS由以上分步骤一一解决HTTP 明文传输中存在的问题可以看出，解决过程是复杂且繁琐的， 但是沿用网络分层的概念，在传输层和应用层之间抽象出一个安全层，可以隐藏这个复杂且繁琐的过程， 这个安全层就是我们熟悉的SSL/TLS。 SSL/TLS 是用于保护通信安全的协议，旨在提供机密性（通过加密）、完整性（防止数据篡改）、身份认证（确认通信双方的身份）和不可否认性（防止消息发送者否认发送过消息）。这些目标依赖于多种密码学工具的有机组合。 加密传输的HTTPs =HTTP + SSL/TLS 4.1 SSL/TLS 发展历史构建传输安全层这个想法，几乎可以说是和万维网的历史一样长，早在 1994 年，就已经有公司开始着手去实践了： 1994 年，网景（Netscape）公司开发了 SSL 协议（Secure Sockets Layer）的 1.0 版，这是构建传输安全层的起源，但是 SSL 1.0 从未正式对外发布过。 1995 年，Netscape 把 SSL 升级到 2.0 版，正式对外发布，但是刚刚发布不久，就被发现有严重漏洞，所以并未大规模使用。 1996 年，修补好漏洞的 SSL 3.0 对外发布，这个版本得到了广泛的应用，很快成为 Web 网络安全层的事实标准。 1999 年，互联网标准化组织接替网景公司，将 SSL 改名为 TLS（Transport Layer Security），随即就形成了传输安全层的国际标准。第一个正式的版本是RFC 2246定义的 TLS 1.0，该版 TLS 的生命周期极长，直到 2020 年 3 月，主流浏览器（Chrome、Firefox、IE、Safari）才刚刚宣布同时停止 TLS 1.0/1.1 的支持。而讽刺的是，由于停止后许多政府网站被无法被浏览，此时又正值新冠病毒的爆发期，Firefox 紧急发布公告宣布撤回该改动，因此目前 TLS 1.0 的生命还在顽强延续。 2006 年，TLS 的第一个升级版 1.1 发布（RFC 4346），但它除了增加对 CBC 攻击的保护外，几乎没有任何改变，沦为了被遗忘的孩子，当时也很少有人会使用 TLS 1.1，甚至 TLS 1.1 根本都没有被提出过有啥已知的协议漏洞。 2008 年，TLS 1.1 发布 2 年之后，TLS 1.2 标准发布（RFC 5246），迄今超过 90% 的互联网 HTTPS 流量都是由 TLS 1.2 所支持的，现在我们仍在使用的浏览器几乎都完美支持了该协议。 2018 年，最新的 TLS 1.3（RFC 8446）发布，比起前面版本相对温和的升级，TLS 1.3 做出了一些激烈的改动，修改了从 1.0 起一直没有大变化的两轮四次（2-RTT）握手，首次连接仅需一轮（1-RTT）握手即可完成；在有连接复用支持的时候，甚至可以把 TLS 1.2 原本的 1-RTT 下降到 0-RTT，显著提升了访问速度。 SL/TLS 工作在传输层和应用层之间的安全层。它能够为 HTTP（即 HTTPS）、SMTP、FTP 等应用层协议提供加密和身份验证功能。通过 SSL/TLS，应用层的通信变得安全透明，开发者无需在应用层实现复杂的安全机制，只需使用 SSL/TLS 来保护通信。 4.2 SSL/TLS 工作流程SSL/TLS 协议通过将密码学工具箱中的六个关键工具（对称加密、非对称加密、消息认证码、数字签名、散列函数、密钥交换协议）有机结合，提供了高效的加密通信解决方案。这些工具的具体实现可以根据实际情况灵活替换，如选择不同的加密套件。SSL/TLS 保障了传输的机密性、完整性和身份认证，为上层应用层协议（如 HTTP、SMTP 等）提供了安全通信的基础。 现在广泛使用的是TLS 1.2，下面将以其为基础介绍一些袭击嗯 4.3 TLS协议分层结构 TLS 协议 由 TLS 记录协议和TLS 握手协议组成，可以将其理解为握手阶段和通信阶段。 TLS 握手协议中的握手协议负责双方的身份认证（即基于公钥的CA）、协商通信双方间的密码算法、密钥。 记录协议负责数据根据协商出密钥进行加密、数据认证 4.4 握手协议 根据《图解密码技术》一书提供的流程，将进行握手阶段的概括描述： 客户端问候（Client Hello）： 客户端发送支持的 SSL/TLS 版本、加密套件列表（包括对称加密算法、散列算法、密钥交换方法等）和随机数 ClientRandom。 服务器问候（Server Hello）： 服务器选择一个客户端支持的加密套件，并生成自己的随机数 ServerRandom，然后将这些信息返回客户端。 服务器发送数字证书（包含服务器的公钥），用于证明其身份。 客户端密钥交换： 客户端生成一个预主密钥（Pre-Master Secret），然后根据使用的密钥交换算法， 使用 RSA 时：客户端会用服务器的公钥加密预主密钥，并发送给服务器。 生成主密钥： 客户端和服务器使用预主密钥，以及之前生成的 ClientRandom 和 ServerRandom，通过伪随机函数（PRF）生成主密钥（Master Secret）。 握手完成： 客户端和服务器确认握手成功，握手阶段结束。此时，双方已经协商出了用于后续加密通信的对称密钥。 握手阶段的作用： 身份认证：通过服务器的数字证书，客户端确认服务器的身份。如果需要双向认证，客户端也可能提供自己的证书。 密钥协商：根据主密钥可以生成对称加密需要的密钥、消息认证码需要的密钥。 4.5 记录协议-通信阶段握手阶段完成后，SSL/TLS 进入通信阶段，双方开始通过协商好的对称密钥进行安全通信。此时，所有的消息都会使用对称密钥加密，并通过消息认证码（MAC）来保证数据的完整性和防篡改。 加密数据传输： 客户端和服务器使用协商生成的对称密钥（例如 AES、ChaCha20）对传输的数据进行加密，确保通信内容的机密性。 消息完整性验证： 每条加密的数据都会附带一个 MAC（消息认证码），接收方使用相同的对称密钥计算 MAC 来验证数据的完整性，确保数据未被篡改。 数据传输和解密： 双方在通信过程中反复使用对称加密进行数据的加密和解密操作。加密的数据经过传输后，接收方使用对称密钥解密消息并验证其完整性。 SSL/TLS 并不会对每条发送的消息进行数字签名。数字签名仅在 握手阶段 用于身份认证和密钥协商，而 数据传输阶段 主要依赖 对称加密和 MAC 来确保数据的机密性和完整性。这样设计是为了在保证安全性的前提下，最大程度提升传输效率。 4.6 TLS 中的密钥交换在HTTP 明文传输的问题 一节中，我的表达是使用非对称加密算法直接加密传输共享密钥，但其实在TLS的实际工作中并不直接传输密钥， 从对握手协议的描述中可以看出， 在TLS1.2 中， 使用RSA加密传输的是预主密码。然后客户端和服务器基于这个共享的预主密钥，再结合双方各自生成的随机数，使用规定的算法生成主密码，最后基于主密码生成对称加密需要的密钥、消息认证码需要的密钥。 如果使用Diffie-Hellman 密钥交换算法, 则不需要使用非对称密钥加密传递信息，双方通过数学公式和公开值计算出相同的共享密钥，从而避免直接传输密钥相关信息并提供更强的安全性。 在TLS1.3中，相比 TLS 1.2，TLS 1.3 默认采用 ECDHE（椭圆曲线 Diffie-Hellman 临时密钥交换），这一算法相比传统的 RSA 密钥交换或静态的 Diffie-Hellman 提供了更高的安全性和效率。ECDHE 通过使用临时密钥对，确保即使未来服务器的私钥被泄露，过去的通信内容仍然是安全的。前向安全性通过每次通信协商临时的 Diffie-Hellman 公私钥对来实现，即使私钥泄露，之前的通信记录也无法被解密。（这是前向安全性）","categories":[],"tags":[]},{"title":"不懂前端？用cursor 1小时也能写出一个可用的浏览器插件","slug":"不懂前端？用cursor-1小时也能写出一个可用的浏览器插件","date":"2024-09-04T11:32:33.000Z","updated":"2024-09-05T11:35:35.882Z","comments":true,"path":"62d611ce/","permalink":"http://example.com/62d611ce/","excerpt":"","text":"这2周，cursor 因为下面这条推特,又爆火了一波 cursor 是什么根据官网的介绍， cursor is a AI Code Editor。 它可以辅助你更好得进行代码开发，甚至根据自然语言完成开发。 用cursor 实现一个浏览器插件现在有cursor 2周免费体验时间，2周需要每月需要付费20美元。 作为一名后端工程师，我对前端的掌握程度就是能看懂一点点，但是几乎没有实际编写的能力。所以准备用cursor 完成一个 chrome 浏览器插件来体验AI 编程。 由于本人是一个网页目录的重度使用者，所以这次准备用它来实现了一个 网页目录生成器。 关于网页目录生成器，目前已经有很多成熟的插件可以使用。这次用cursor 来实现这个不算新的idea, 是因为暂时没有其他更好的idea,所以用这个来体验一下。 用自然语言提出要求如下图，我用自然语言描述了想要实现的插件功能 然后cursor 就给出一个插件项目完整的代码。 如果你完全不懂chrome 插件开发，一定会为这一步感到震惊。如果你懂一点chrome 插件开发， 那更能意识到它对不懂chrome 开发的人节省了多少前置知识的准备时间。 用报错信息与cursor 沟通上面给出的代码实际往往不能一步到位，我在开发者模式下导入生成的代码。随便找了一个网页生成目录，出现了3个报错信息，我依次将报错信息提供给cursor 修改代码 修改后代码已经完成了基本功能，生成了如下目录 功能优化完成基本功能后，让cursor 以此为基础完成进一步功能，比如比如点击目录跳转到相应内容、网页滑动时对应目录高亮显示、显示内容的细节 目录点击跳转 标题高亮 标题展示差异 到这里，一个基本可用的网页目录生成器chrome 插件已经完成， 当然也可以提出更多的要求，比如自由拖动等。 chatGPT 写代码 vs cursor 写代码去年在chatGPT3.5 的帮助下，曾经开发过一个女书插件。 但是它不能根据我的描述生成完整的代码，为了调试，我依然需要去学习一些关于chrome 开发的知识，虽然chatGPT 当然可以帮助我提高学习这些知识的速度。 但是在错误调试的过程中比较痛苦， 在修改代码的过程中也需要不断的复制粘贴。 对比下来，用 cursor 写代码，一个几乎完全不懂编程的人也是可以实现一个功能的， cursor 确实强。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"}]},{"title":"在Spring事务管理下，使用Synchronized   为什么会出现并发问题","slug":"在Spring事务管理下，使用Synchronized-为什么会出现并发问题","date":"2024-07-23T09:58:56.000Z","updated":"2024-07-23T10:00:01.633Z","comments":true,"path":"2a483461/","permalink":"http://example.com/2a483461/","excerpt":"","text":"理解了Spring事务实现原理， 现在来解决一个实际问题。 在实际业务开发中，我们经常会遇到在一个事务内执行多个业务操作保证原子性， 同时希望这段逻辑是并发安全的。 比如在商品售卖场景中，非常重要的一件事就是防止超卖，且要保证多个业务操作之间的原子性。以下示例代码，明显会出现超卖问题（查询是否有库存时有库存并不代码真正扣减库存时还有库存，假设扣减库存时SQL 中没有乐观锁） 12345678910111213@Transactional(rollbackFor = Exception.class) public void buy() &#123; // 查看是商品否有库存 Integer count = getProductCount(); if(count &lt;= 0) &#123; throw new RuntimeException(&quot;库存为 0&quot;); &#125; // 减库存 productRepository.reductCount(); // 生成订单 createOrder();&#125; 那么修改该段代码的一个常见思路就是给buy加锁，确保buy 在任意时刻只会被一个线程操作，从而保证库存的正确扣减。12345678910111213@Transactional(rollbackFor = Exception.class) public synchronized void buy() &#123; // 查看是商品否有库存 Integer count = getProductCount(); if(count &lt;= 0) &#123; throw new RuntimeException(&quot;库存为 0&quot;); &#125; // 减库存 productRepository.reductCount(); // 生成订单 createOrder();&#125; 我们想要实现的逻辑是： 加锁-开始事务-执行方法-事务commit-释放锁 但是这段加锁后的代码，其实际执行效果是，开始事务-（加锁-执行方法-释放锁）- 事务commit。 依然有可能出现 也就是说在事务commit 之前，synchronized锁就已经释放，其他线程已经可以进入到该段逻辑，读到旧数据的快照库存，发现还有库存然后进行库存扣减。 如果此时库存为1 ，那么又会出现超卖现象。造成超卖的原因就是事务的开启和提交并不是在 Synchronized 锁定的范围内 下面就加锁后的代码，其实际执行效果为什么是，开始事务-（加锁-执行方法-释放锁）- 事务commit 进行解释。 Synchronized关键字Synchronized是Java语言级别的关键字，用于实现线程同步，确保多个线程对共享资源的访问是有序的。它主要通过以下两种方式实现同步： 同步方法：在方法声明上使用Synchronized关键字，确保同一时间只有一个线程可以执行该方法。 同步代码块：在方法内部使用Synchronized关键字对特定代码块进行同步，指定一个对象锁。 Synchronized仅仅是在JVM层面上对对象加锁，与数据库的锁机制无关。 基于事务的动态代理对象在Spring事务实现原理中已经详细介绍过基于事务的动态代理对象的生成和执行目标方法的过程。 1234567891011121314151617181920212223242526272829303132333435363738394041public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // 处理标准事务管理， 这是本次重点关心的 PlatformTransactionManager ptm = asPlatformTransactionManager(tm); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); // 如果事务属性为null或者事务管理器不支持回调 if (txAttr == null || !(ptm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. // 则执行标准的事务边界控制（即通过`getTransaction`和`commit/rollback`调用）。 //开始一个新的事务或者加入现有的事务。（如果有必要） TransactionInfo txInfo = createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); Object retVal; try &#123; // 执行目标方法，这是一个环绕通知，通常会导致目标对象的方法被调用。 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // 如果方法抛出异常，调用`completeTransactionAfterThrowing`方法来处理事务回滚，并重新抛出异常。 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; // - 在finally块中调用`cleanupTransactionInfo`来清理事务信息。 cleanupTransactionInfo(txInfo); &#125; if (retVal != null &amp;&amp; vavrPresent &amp;&amp; VavrDelegate.isVavrTry(retVal)) &#123; // Set rollback-only in case of Vavr failure matching our rollback rules... TransactionStatus status = txInfo.getTransactionStatus(); if (status != null &amp;&amp; txAttr != null) &#123; retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); &#125; &#125; commitTransactionAfterReturning(txInfo); return retVal; &#125; &#125;&#125; 结果以上信息可以看出事务是在代理对象中开始和结束的， 但是锁是加在目标对象方法上的，也就是说只有在真正执行目标方法时才会加锁。 总结一句话， 就是事务的开启与提交并不是在 加锁范围内的，锁在事务的范围内就释放了，所以会出现加锁锁不住的问题。要解决就应该确保 事务的开启与提交在锁的范围内。 加ReentrantLock 锁也是同样的道理 解决方案使用数据库乐观锁乐观锁通过版本号机制控制并发，在更新数据时检查版本号是否一致，防止并发更新导致的数据不一致问题。 使用悲观锁悲观锁在读取数据时加锁，确保在事务执行期间其他事务无法并发访问和修改被锁定的数据。通常通过数据库的 SELECT FOR UPDATE 语句实现。 扩大加锁范围将加锁范围扩大到事务开启之前，确保在事务开始之前就获取到锁。在进入事务管理逻辑之前就获得锁，从而避免并发问题。具体做法 可以将synchronized关键字应用于一个外层方法，然后在该方法内调用实际的事务方法。 12345678910111213141516171819// 外层加锁方法 public synchronized void buySynchronized(String productName, int quantity) &#123; // 调用实际事务方法 buy(productName, quantity); &#125;@Transactional(rollbackFor = Exception.class) public synchronized void buy() &#123; // 查看是商品否有库存 Integer count = getProductCount(); if(count &lt;= 0) &#123; throw new RuntimeException(&quot;库存为 0&quot;); &#125; // 减库存 productRepository.reductCount(); // 生成订单 createOrder();&#125; 手动管理事务在加锁的方法内手动管理事务， 确保事务结束后才释放锁通过手动管理事务，可以精确控制事务的开始和结束时机，并在加锁之前开启事务，从而确保事务的一致性和线程安全性。 手动管理事务可以使用Spring的PlatformTransactionManager和TransactionTemplate。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Servicepublic class InventoryService &#123; @Autowired private ProductRepository productRepository; @Autowired private PlatformTransactionManager transactionManager; // 外层加锁方法 public synchronized void buySynchronized(String productName, int quantity) &#123; // 手动管理事务 TransactionTemplate transactionTemplate = new TransactionTemplate(transactionManager); transactionTemplate.execute(status -&gt; &#123; try &#123; performBuy(productName, quantity); &#125; catch (Exception e) &#123; status.setRollbackOnly(); throw e; &#125; return null; &#125;); &#125; // 内层事务方法 public void performBuy(String productName, int quantity) &#123; // 查看商品是否有库存 Integer count = getProductCount(productName); if (count &lt;= 0) &#123; throw new RuntimeException(&quot;库存为 0&quot;); &#125; // 减库存 productRepository.reduceCount(productName, quantity); // 生成订单 createOrder(productName, quantity); &#125; private Integer getProductCount(String productName) &#123; // 查询库存逻辑 return productRepository.findStockByProductName(productName); &#125; private void createOrder(String productName, int quantity) &#123; // 生成订单逻辑 System.out.println(&quot;Order created for &quot; + quantity + &quot; of &quot; + productName); &#125;&#125;","categories":[],"tags":[{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring事务实现原理","slug":"Spring事务实现原理","date":"2024-07-23T07:55:30.000Z","updated":"2024-07-25T02:37:02.448Z","comments":true,"path":"1a0f7094/","permalink":"http://example.com/1a0f7094/","excerpt":"","text":"1. 数据库事务1.1 数据库事务实现原理Spring提供了灵活方便的事务管理功能，但这些功能都是基于底层数据库本身的事务处理机制工作的。要想深入了解Spring的事务管理和配置，有必要先学习数据库事务的基础知识。有需要可以阅读以下文章Intro to 事务Intro to InnoDB事务InnoDB事务-原子性的实现， undo logInnoDB事务-隔离性的实现, MVCC &amp; 锁InnoDB事务-持久性的实现， binglog &amp; redo log&amp;undo log 1.2 JDBC 事务在介绍Spring 事务实现原理之前，先来看一下使用JDBC如何实现和数据库交互的事务功能。这可以帮助理解Spring事务的工作原理和优势。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import java.sql.Statement;// JDBC事务代码public class JDBCTransactionExample &#123; public static void main(String[] args) &#123; String url = &quot;jdbc:mysql://localhost:3306/mydatabase&quot;; String user = &quot;username&quot;; String password = &quot;password&quot;; Connection conn = null; Statement stmt = null; try &#123; // 1. 获取数据库连接 conn = DriverManager.getConnection(url, user, password); // 2. 关闭自动提交模式 conn.setAutoCommit(false); // 设置事务隔离级别 conn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ); // 3. 创建Statement对象 stmt = conn.createStatement(); // 4. 执行SQL操作 stmt.executeUpdate(&quot;INSERT INTO accounts (name, balance) VALUES (&#x27;Alice&#x27;, 1000)&quot;); stmt.executeUpdate(&quot;INSERT INTO accounts (name, balance) VALUES (&#x27;Bob&#x27;, 1000)&quot;); // 5. 提交事务 conn.commit(); System.out.println(&quot;Transaction committed successfully.&quot;); &#125; catch (SQLException e) &#123; // 6. 发生异常时回滚事务 if (conn != null) &#123; try &#123; conn.rollback(); System.out.println(&quot;Transaction rolled back.&quot;); &#125; catch (SQLException ex) &#123; ex.printStackTrace(); &#125; &#125; e.printStackTrace(); &#125; finally &#123; // 7. 关闭资源 if (stmt != null) &#123; try &#123; stmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 通过了解JDBC事务处理的基本步骤，可以更好地理解Spring提供的事务管理功能如何简化和增强这些操作。 Spring事务管理通过编程式事务 和 声明式事务管理，极大地简化了事务管理的复杂性，并提供了更强大的功能，例如事务传播行为、隔离级别设置等。 2. Spring 事务抽象层 2.1 TransactionDefinitionTransactionDefinition 是一个接口，定义了事务的相关属性，如隔离级别、传播行为、超时时间和只读标志等。这些属性可以通过 XML 配置或注解进行声明配置。 隔离级别（Isolation Level）：定义事务在多个事务同时访问数据库时的隔离程度。 传播行为（Propagation Behavior）：定义方法如何参与现有事务。 超时时间（Timeout）：定义事务必须在多长时间内完成。 只读（Read-Only）：标志事务是否只执行读操作1234567891011121314151617181920212223242526272829303132333435363738394041424344public interface TransactionDefinition &#123; // 事务传播行为 int PROPAGATION_REQUIRED = 0; int PROPAGATION_SUPPORTS = 1; int PROPAGATION_MANDATORY = 2; int PROPAGATION_REQUIRES_NEW = 3; int PROPAGATION_NOT_SUPPORTED = 4; int PROPAGATION_NEVER = 5; int PROPAGATION_NESTED = 6; // 事务隔离级别 int ISOLATION_DEFAULT = -1; int ISOLATION_READ_UNCOMMITTED = 1; int ISOLATION_READ_COMMITTED = 2; int ISOLATION_REPEATABLE_READ = 4; int ISOLATION_SERIALIZABLE = 8; int TIMEOUT_DEFAULT = -1; default int getPropagationBehavior() &#123; return PROPAGATION_REQUIRED; &#125; default int getIsolationLevel() &#123; return ISOLATION_DEFAULT; &#125; default int getTimeout() &#123; return TIMEOUT_DEFAULT; &#125; default boolean isReadOnly() &#123; return false; &#125; @Nullable default String getName() &#123; return null; &#125; static TransactionDefinition withDefaults() &#123; return StaticTransactionDefinition.INSTANCE; &#125; &#125; 2.2 TransactionStatusTransactionStatus 是一个接口，表示事务的当前状态。它包含了事务的一些控制信息，如是否新建事务、是否只读、是否已完成等。 isNewTransaction()：检查是否是一个新的事务 setRollbackOnly()：将当前事务标记为仅回滚 isRollbackOnly()：检查当前事务是否被标记为仅回滚 isCompleted()：检查事务是否已完成（提交或回滚） 1234public interface TransactionStatus extends TransactionExecution, SavepointManager, Flushable &#123; boolean hasSavepoint(); void flush();&#125; 2.3 PlatformTransactionManagerPlatformTransactionManager 定义了一组用于事务管理的标准方法，使得不同的事务管理器实现可以通过这个统一的接口进行交互。 PlatformTransactionManager 定义了三种基本的事务操作： getTransaction：获取一个事务 commit：提交事务 rollback：回滚事务 123456789101112public interface PlatformTransactionManager extends TransactionManager &#123; TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException; void commit(TransactionStatus status) throws TransactionException; void rollback(TransactionStatus status) throws TransactionException; &#125;public interface TransactionManager &#123; &#125; Spring 提供了多种 PlatformTransactionManager 的实现，适用于不同的持久化技术。无论使用的是哪种持久化技术，开发人员都可以通过统一的事务管理接口来处理事务。 不同持久化技术对应的事务管理器实现类 2.3.1 DataSourceTransactionManagerDataSourceTransactionManager 是针对 MyBatis 的事务管理器实现。它通过 SqlSessionFactory 与 MyBatis 会话交互，实现事务管理。 2.4 Spring 编程式事务-TransactionTemplateSpring为编程式事务管理提供了模板类org.springframework.transaction.support.TransactionTemplate 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class TransactionTemplate extends DefaultTransactionDefinition implements TransactionOperations, InitializingBean &#123; @Nullable private PlatformTransactionManager transactionManager; public TransactionTemplate(PlatformTransactionManager transactionManager) &#123; this.transactionManager = transactionManager; &#125; public TransactionTemplate(PlatformTransactionManager transactionManager, TransactionDefinition transactionDefinition) &#123; super(transactionDefinition); this.transactionManager = transactionManager; &#125; public void setTransactionManager(@Nullable PlatformTransactionManager transactionManager) &#123; this.transactionManager = transactionManager; &#125; @Nullable public PlatformTransactionManager getTransactionManager() &#123; return this.transactionManager; &#125; @Override @Nullable public &lt;T&gt; T execute(TransactionCallback&lt;T&gt; action) throws TransactionException &#123; Assert.state(this.transactionManager != null, &quot;No PlatformTransactionManager set&quot;); if (this.transactionManager instanceof CallbackPreferringPlatformTransactionManager) &#123; return ((CallbackPreferringPlatformTransactionManager) this.transactionManager).execute(this, action); &#125; else &#123; TransactionStatus status = this.transactionManager.getTransaction(this); T result; try &#123; result = action.doInTransaction(status); &#125; catch (RuntimeException | Error ex) &#123; // Transactional code threw application exception -&gt; rollback rollbackOnException(status, ex); throw ex; &#125; catch (Throwable ex) &#123; // Transactional code threw unexpected exception -&gt; rollback rollbackOnException(status, ex); throw new UndeclaredThrowableException(ex, &quot;TransactionCallback threw undeclared checked exception&quot;); &#125; this.transactionManager.commit(status); return result; &#125; &#125; private void rollbackOnException(TransactionStatus status, Throwable ex) throws TransactionException &#123; &#125; &#125; TransactionTemplate 需要设置抽象层的PlatformTransactionManager TransactionDefinition。execute 是TransactionTemplate 中模版方法， 它是完成在事务中执行目标方法的核心逻辑 开启事务 在事务中执行目标方法 根据目标方法执行结果处理事务commit or rollback execute 方法接受一个 TransactionCallback 作为参数，并在事务上下文中执行该回调。 TransactionCallback 是一个泛型函数式接口，用于定义在事务上下文中执行的目标方法。它有一个方法 doInTransaction，该方法包含具体的事务逻辑。123456@FunctionalInterface public interface TransactionCallback&lt;T&gt; &#123; @Nullable T doInTransaction(TransactionStatus status); &#125;在实际使用时，可以使用匿名内部类或 Java 8 引入的 lambda 表达式进行传参。示例代码 1234567891011121314151617181920212223242526272829public class TransactionTemplateExample &#123; private final TransactionTemplate transactionTemplate; private final MessageService messageService; public TransactionTemplateExample(TransactionTemplate transactionTemplate, MessageService messageService) &#123; this.transactionTemplate = transactionTemplate; this.messageService = messageService; &#125; public void performTransaction() &#123; transactionTemplate.execute(new TransactionCallback&lt;Void&gt;() &#123; @Override public Void doInTransaction(TransactionStatus status) &#123; try &#123; Message message = new Message(); message.setMessage(&quot;test message&quot;); messageService.insertMessage(message); messageService.insertMessage(message); // 如果需要，可以在这里添加更多数据库操作 &#125; catch (Exception e) &#123; status.setRollbackOnly(); throw e; &#125; return null; &#125; &#125;); &#125;&#125; 也可以使用lambda 表达式1234567891011121314transactionTemplate.execute(status -&gt; &#123; try &#123; Message message = new Message(); message.setMessage(&quot;test message&quot;); messageService.insertMessage(message); messageService.insertMessage(message); // 如果需要，可以在这里添加更多数据库操作 &#125; catch (Exception e) &#123; status.setRollbackOnly(); throw e; &#125; return null;&#125;); 2.5 声明式事务可以看到，编程式事务实现方式中，事务管理代码对业务代码有明显入侵，Spring支持通过声明式事务，使业务代码和事务管理代码完全解耦。 Spring 的声明式事务管理通过 Spring AOP 实现，使得业务代码和事务管理代码完全解耦。通过使用 @Transactional 注解和 AOP 代理机制，Spring 在方法调用前后自动织入事务管理逻辑，包括获取线程绑定资源、开始事务、提交/回滚事务、进行异常转换和处理等工作。这种方式极大地简化了事务管理，使代码更简洁、易读和易维护。 关于Spring AOP 的实现原理，可以阅读以下内容了解Java 动态代理Spring AOP 实践Spring AOP XML配置方式原理详解Spring AOP 注解方式原理详解 声明式事务有3种 TransactionProxyFactoryBean XML 配置 aop:config XML 配置 @Transactional 注解配置 从循序渐进的学习角度来看，了解TransactionProxyFactoryBean有助于更直观地理解Spring声明式事务的内部工作原理。 总是来说，不论是哪种声明式 方式，都可以从以下3个角度考虑其实现原理 事务Advisor 是如何生成的（Advisor 包含 pointcut 和 advice 2个概念） 基于事务的动态代理对象是如何生成的 基于事务的动态代理对象是如何执行目标方法的 3. 声明式事务-TransactionProxyFactoryBean1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 public class TransactionProxyFactoryBean extends AbstractSingletonProxyFactoryBean implements BeanFactoryAware &#123; // 事务拦截器，用于拦截方法调用 private final TransactionInterceptor transactionInterceptor = new TransactionInterceptor(); // Pointcut 定义了一个切入点，它决定了哪些方法调用应该被拦截，并应用事务管理。 @Nullable private Pointcut pointcut; // 设置事务管理器, public void setTransactionManager(PlatformTransactionManager transactionManager) &#123; this.transactionInterceptor.setTransactionManager(transactionManager); &#125; // 设置事务属性。事务属性通过方法名和事务配置（如传播行为、隔离级别等）进行映射。 // 这个方法接受一个 Properties 对象，其中键是方法名，值是事务属性描述符。 public void setTransactionAttributes(Properties transactionAttributes) &#123; this.transactionInterceptor.setTransactionAttributes(transactionAttributes); &#125; public void setTransactionAttributeSource(TransactionAttributeSource transactionAttributeSource) &#123; this.transactionInterceptor.setTransactionAttributeSource(transactionAttributeSource); &#125; public void setPointcut(Pointcut pointcut) &#123; this.pointcut = pointcut; &#125; //设置 Bean 工厂。 // 如果在运行时没有显式设置事务管理器，这个方法会从 Bean 工厂中获取一个类型为 PlatformTransactionManager 的 bean 作为默认的事务管理器。 @Override public void setBeanFactory(BeanFactory beanFactory) &#123; this.transactionInterceptor.setBeanFactory(beanFactory); &#125; // 创建Advisor 将事务拦截器和切入点（如果有的话）组合起来。 // DefaultPointcutAdvisor 是一个将切入点和拦截器组合在一起的 Advisor。如果没有设置切入点，使用 TransactionAttributeSourceAdvisor，它会自动应用事务属性源。 @Override protected Object createMainInterceptor() &#123; this.transactionInterceptor.afterPropertiesSet(); if (this.pointcut != null) &#123; return new DefaultPointcutAdvisor(this.pointcut, this.transactionInterceptor); &#125; else &#123; // Rely on default pointcut. return new TransactionAttributeSourceAdvisor(this.transactionInterceptor); &#125; &#125; @Override protected void postProcessProxyFactory(ProxyFactory proxyFactory) &#123; proxyFactory.addInterface(TransactionalProxy.class); &#125;&#125; 下面将分析TransactionProxyFactoryBean 的继承实现图谱和重要变量 3.1 实现FactoryBean 接口TransactionProxyFactoryBean是一个FactoryBean , 这意味着当调用它的getObject 方法时，可以获取到它创建的对象，在这里这个对象指的就是==基于事务的动态代理对象== 3.2 实现InitializingBean 接口InitializingBean是 Spring 启动过程中的一个拓展点，用于bean实例化 的init 阶段，使得bean可以在属性注入完成后但在使用之前执行一些自定义的初始化工作。 123public interface InitializingBean &#123; void afterPropertiesSet() throws Exception; &#125; 关于Spring bean init 阶段的拓展点，更多内容可以点击这里阅读： Spring bean 实例化过程-initializebean 看下TransactionProxyFactoryBean 重写的InitializingBean.afterPropertiesSet 方法，简化了代码，只保留重点部分，可以看到主要分成3个步骤 准备代理工厂 创建Advisor 生成代理对象123456789101112public abstract class AbstractSingletonProxyFactoryBean extends ProxyConfig implements FactoryBean&lt;Object&gt;, BeanClassLoaderAware, InitializingBean &#123; @Override public void afterPropertiesSet() &#123; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.addAdvisor(this.advisorAdapterRegistry.wrap(createMainInterceptor())); this.proxy = proxyFactory.getProxy(this.proxyClassLoader); &#125;&#125; 也就是说，TransactionProxyFactoryBean 在自身实例化的init 阶段就把需要的生成的代理对象对象先生成了。 在 Spring AOP XML配置方式原理详解 一文中具体讲过ProxyFactoryBean 如何在重写的FactoryBean.getObject方法中生成代理对象。 所以TransactionProxyFactoryBean 和ProxyFactoryBean 这两个都是用于生成代理对象的FactoryBean ，实际生成代理对象的时机是不一样的。 观察下ProxyFactoryBean 的继承实现图谱，可以看到ProxyFactoryBean 并没有实现InitializingBean ， 所以无法像TransactionProxyFactoryBean 一样在自身实例化的init 阶段就把代理对象生产出来 3.2.1 createMainInterceptor- 创建事务AdvisorcreateMainInterceptor 用于创建事务管理中的环绕增强 TransactionInterceptor， 关于TransactionInterceptor见下面3.2 TransactionInterceptor - 环绕增强 部分。 1234567891011121314151617181920public abstract class AbstractSingletonProxyFactoryBean extends ProxyConfig implements FactoryBean&lt;Object&gt;, BeanClassLoaderAware, InitializingBean &#123; protected abstract Object createMainInterceptor();&#125;public class TransactionProxyFactoryBean extends AbstractSingletonProxyFactoryBean implements BeanFactoryAware &#123; @Override protected Object createMainInterceptor() &#123; this.transactionInterceptor.afterPropertiesSet(); if (this.pointcut != null) &#123; return new DefaultPointcutAdvisor(this.pointcut, this.transactionInterceptor); &#125; else &#123; // Rely on default pointcut. return new TransactionAttributeSourceAdvisor(this.transactionInterceptor); &#125; &#125;&#125; createMainInterceptor是 AbstractSingletonProxyFactoryBean中的一个抽象方法，TransactionProxyFactoryBean 实现了它。 在不指定切点表达式 pointcut 的时候， 会使用TransactionAttributeSourceAdvisor。 TransactionAttributeSourceAdvisorTransactionAttributeSourceAdvisor 管理TransactionInterceptor这个环绕增强。通过它可以获取到 pointcut 和Advice12345678910111213141516171819202122232425262728293031323334353637383940public class TransactionAttributeSourceAdvisor extends AbstractPointcutAdvisor &#123; @Nullable private TransactionInterceptor transactionInterceptor; private final TransactionAttributeSourcePointcut pointcut = new TransactionAttributeSourcePointcut() &#123; @Override @Nullable protected TransactionAttributeSource getTransactionAttributeSource() &#123; return (transactionInterceptor != null ? transactionInterceptor.getTransactionAttributeSource() : null); &#125; &#125;; public TransactionAttributeSourceAdvisor() &#123; &#125; public TransactionAttributeSourceAdvisor(TransactionInterceptor interceptor) &#123; setTransactionInterceptor(interceptor); &#125; public void setTransactionInterceptor(TransactionInterceptor interceptor) &#123; this.transactionInterceptor = interceptor; &#125; public void setClassFilter(ClassFilter classFilter) &#123; this.pointcut.setClassFilter(classFilter); &#125; @Override public Advice getAdvice() &#123; Assert.state(this.transactionInterceptor != null, &quot;No TransactionInterceptor set&quot;); return this.transactionInterceptor; &#125; @Override public Pointcut getPointcut() &#123; return this.pointcut; &#125;&#125; 3.2.2 proxyFactory.getProxy -创建动态代理对象123public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); &#125; 又来到熟悉的动态代理创建的流程 判断代理类型 根据代理类型创建代理对象具体创建流程可以参考文章 Spring AOP XML配置方式原理详解 下面来介绍一下TransactionProxyFactoryBean中的变量 3.3 TransactionInterceptor - 环绕增强12345678910111213141516171819public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable &#123; public TransactionInterceptor() &#123; &#125; public TransactionInterceptor(TransactionManager ptm, TransactionAttributeSource tas) &#123; setTransactionManager(ptm); setTransactionAttributeSource(tas); &#125; @Override @Nullable public Object invoke(MethodInvocation invocation) throws Throwable &#123; Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); &#125;&#125; TransactionInterceptor 继承了org.aopalliance.intercept.MethodInterceptor。 org.aopalliance.intercept.MethodInterceptor是一个环绕增强，表示在目标方法执行前后实施增强。符合事务要在方法执行前开启 和执行后的关闭或者异常处理的使用场景。12345org.aopalliance.intercept@FunctionalInterface public interface MethodInterceptor extends Interceptor &#123; Object invoke(MethodInvocation invocation) throws Throwable; &#125; TransactionInterceptor 重写的invoke 方法中， 通过调用父类TransactionAspectSupport中方法invokeWithinTransaction 完成在事务中执行目标方法这一功能。 invokeWithinTransaction 方法，用于在事务范围内调用目标方法，它处理了事务的开始、提交和回滚，并确保目标方法在事务上下文中执行。 3.4 TransactionAspectSupportTransactionAspectSupport是 Spring事务管理的基类，包含了事务管理汇总大多数真正的逻辑，具体的事务管理类，TransactionInterceptor继承它并实现具体的事务管理逻辑。 3.4.1 invokeWithinTransactioninvokeWithinTransaction 方法是 TransactionAspectSupport 类的一个关键方法， 用于在事务范围内调用目标方法，并处理事务的开始、提交和回滚，确保目标方法在适当的事务上下文中执行。也是TransactionInterceptor 重写invoke 实现环绕增强时的重点逻辑。 参数说明： method：要调用的方法。 targetClass：目标类，可以为空。 invocation：一个回调接口，用于实际执行目标方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // 通过事务属性源获取当前方法的事务属性。 // 如果没有事务属性，则方法是非事务性的。 TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final TransactionManager tm = determineTransactionManager(txAttr); // 处理响应式事务管理, 先不管 if (this.reactiveAdapterRegistry != null &amp;&amp; tm instanceof ReactiveTransactionManager) &#123; return txSupport.invokeWithinTransaction( method, targetClass, invocation, txAttr, (ReactiveTransactionManager) tm); &#125; // 处理标准事务管理， 这是本次重点关心的 PlatformTransactionManager ptm = asPlatformTransactionManager(tm); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); // 如果事务属性为null或者事务管理器不支持回调 if (txAttr == null || !(ptm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. // 则执行标准的事务边界控制（即通过`getTransaction`和`commit/rollback`调用）。 //开始一个新的事务或者加入现有的事务。（如果有必要） TransactionInfo txInfo = createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); Object retVal; try &#123; // 执行目标方法，这是一个环绕通知，通常会导致目标对象的方法被调用。 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // 如果方法抛出异常，调用`completeTransactionAfterThrowing`方法来处理事务回滚，并重新抛出异常。 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; // - 在finally块中调用`cleanupTransactionInfo`来清理事务信息。 cleanupTransactionInfo(txInfo); &#125; if (retVal != null &amp;&amp; vavrPresent &amp;&amp; VavrDelegate.isVavrTry(retVal)) &#123; // Set rollback-only in case of Vavr failure matching our rollback rules... TransactionStatus status = txInfo.getTransactionStatus(); if (status != null &amp;&amp; txAttr != null) &#123; retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); &#125; &#125; commitTransactionAfterReturning(txInfo); return retVal; &#125; else &#123; Object result; final ThrowableHolder throwableHolder = new ThrowableHolder(); // It&#x27;s a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in. try &#123; result = ((CallbackPreferringPlatformTransactionManager) ptm).execute(txAttr, status -&gt; &#123; TransactionInfo txInfo = prepareTransactionInfo(ptm, txAttr, joinpointIdentification, status); try &#123; Object retVal = invocation.proceedWithInvocation(); if (retVal != null &amp;&amp; vavrPresent &amp;&amp; VavrDelegate.isVavrTry(retVal)) &#123; // Set rollback-only in case of Vavr failure matching our rollback rules... retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); &#125; return retVal; &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; // A RuntimeException: will lead to a rollback. if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; // A normal return value: will lead to a commit. throwableHolder.throwable = ex; return null; &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125;); &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; catch (TransactionSystemException ex2) &#123; if (throwableHolder.throwable != null) &#123; logger.error(&quot;Application exception overridden by commit exception&quot;, throwableHolder.throwable); ex2.initApplicationException(throwableHolder.throwable); &#125; throw ex2; &#125; catch (Throwable ex2) &#123; if (throwableHolder.throwable != null) &#123; logger.error(&quot;Application exception overridden by commit exception&quot;, throwableHolder.throwable); &#125; throw ex2; &#125; // Check result state: It might indicate a Throwable to rethrow. if (throwableHolder.throwable != null) &#123; throw throwableHolder.throwable; &#125; return result; &#125; &#125;&#125; 既然是要在事务中执行方法的环绕增强，那么其逻辑显然易见包含3步 开启事务 在事务中执行目标方法 根据目标方法执行结果处理事务commit or rollback 该方法把事务的处理分成了3类 响应式事务 标准事务 回掉首选事务 CallbackPreferringPlatformTransactionManager 这里只分析标准事务的处理过程 3.4.2 invokeWithinTransaction-开启事务3.4.2.1 createTransactionIfNecessarycreateTransactionIfNecessary 负责在需要时创建一个新的事务或加入现有事务，并返回相应的事务状态（TransactionStatus） tm：事务管理器 (PlatformTransactionManager)，用于实际管理事务。 txAttr：事务属性 (TransactionAttribute)，定义事务的传播行为、隔离级别、超时时间等。 joinpointIdentification：连接点标识，用于标识当前方法调用。 在Spring AOP 实践 讲解过连接点 joinpoint123456789101112131415161718192021222324252627282930// 事务管理器 (`PlatformTransactionManager`)，用于实际管理事务。 protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // 如果事务属性存在但没有指定名称，则创建一个新的 `DelegatingTransactionAttribute`，并覆盖其 `getName` 方法，使其返回 `joinpointIdentification` 作为事务名称。这确保了每个事务都有一个唯一的标识符，便于调试和日志记录。 if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123; //创建一个新事务or加入到现有事务中，取决于事务属性的配置 status = tm.getTransaction(txAttr); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Skipping transactional joinpoint [&quot; + joinpointIdentification + &quot;] because no transaction manager has been configured&quot;); &#125; &#125; &#125; // 保存与当前事务相关的所有信息,并返回 `TransactionInfo` 对象。 return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); &#125; 设置事务名称 检查事务属性 txAttr 是否为空，并且事务属性中是否指定了事务名称。 如果事务属性存在但没有指定名称，则创建一个新的 DelegatingTransactionAttribute，并覆盖其 getName 方法，使其返回 joinpointIdentification 作为事务名称。这确保了每个事务都有一个唯一的标识符，便于调试和日志记录。 获取事务状态TransactionStatus如果事务属性 txAttr 不为空： 检查是否提供了事务管理器 tm。 如果事务管理器存在，调用 tm.getTransaction(txAttr) 来获取事务状态（TransactionStatus）。这一步可能会创建一个新事务，或者加入到现有事务中，具体取决于事务属性的配置。 如果没有配置事务管理器，并且日志级别为调试，则记录一条调试信息，表示跳过事务处理。 准备事务信息 TransactionInfo 调用 prepareTransactionInfo 方法来准备并返回 TransactionInfo 对象。 TransactionInfo 是一个内部类，用于保存与当前事务相关的所有信息，包括tm-事务管理器、txAttr-事务属性、joinpointIdentification-连接点标识、status-事务状态 getTransaction-获取当前事务getTransaction(TransactionAttribute txAttr) 方法是由PlatformTransactionManager接口定义的一个关键方法，用于根据定义好的事务传播行为来判断获取或创建一个事务。 AbstractPlatformTransactionManager 实现了PlatformTransactionManager 并重写了getTransaction方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public interface PlatformTransactionManager extends TransactionManager &#123; TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException;&#125;public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123;@Override public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException &#123; // Use defaults if no transaction definition given. // 如果传入的事务定义为 `null`，则使用默认的事务定义 TransactionDefinition def = (definition != null ? definition : TransactionDefinition.withDefaults()); // 获取当前事务对象。 Object transaction = doGetTransaction(); boolean debugEnabled = logger.isDebugEnabled(); // 检查给定的事务对象是否表示一个已经存在的事务 // 在事务管理中，确定是否存在现有事务对于决定如何处理新事务至关重要。例如，根据传播行为，新事务可能需要挂起现有事务或者参与现有事务。 if (isExistingTransaction(transaction)) &#123; // Existing transaction found -&gt; check propagation behavior to find out how to behave. // 如果存在当前事务，则根据传播行为处理现有事务，调用 `handleExistingTransaction(def, transaction, debugEnabled)` 方法，并返回相应的事务状态。 return handleExistingTransaction(def, transaction, debugEnabled); &#125; // Check definition settings for new transaction. // 检查事务定义中的超时时间 if (def.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) &#123; throw new InvalidTimeoutException(&quot;Invalid transaction timeout&quot;, def.getTimeout()); &#125; // No existing transaction found -&gt; check propagation behavior to find out how to proceed. // 根据事务定义中的传播行为（`PropagationBehavior`）决定如何处理新事务。 if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123; throw new IllegalTransactionStateException( &quot;No existing transaction found for transaction marked with propagation &#x27;mandatory&#x27;&quot;); &#125; else if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; SuspendedResourcesHolder suspendedResources = suspend(null); if (debugEnabled) &#123; logger.debug(&quot;Creating new transaction with name [&quot; + def.getName() + &quot;]: &quot; + def); &#125; try &#123; return startTransaction(def, transaction, debugEnabled, suspendedResources); &#125; catch (RuntimeException | Error ex) &#123; resume(null, suspendedResources); throw ex; &#125; &#125; else &#123; // Create &quot;empty&quot; transaction: no actual transaction, but potentially synchronization. if (def.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(&quot;Custom isolation level specified but no actual transaction initiated; &quot; + &quot;isolation level will effectively be ignored: &quot; + def); &#125; boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus(def, null, true, newSynchronization, debugEnabled, null); &#125; &#125;&#125; 这个方法的主要功能是根据事务定义（TransactionDefinition）来获取或创建一个事务，并返回相应的事务状态（TransactionStatus） definition：事务定义（TransactionDefinition），描述事务的传播行为、隔离级别、超时时间等属性。可以为空，如果为空则使用默认的事务定义。 返回一个 TransactionStatus 对象，表示当前事务的状态。 doGetTransaction 方法在 Spring 事务管理中用于获取当前的事务对象。它返回一个包含当前事务状态信息的对象，后续方法（如 getTransaction）会根据这个对象决定是否需要创建新的事务或加入现有事务。通过这种设计，Spring 提供了灵活且可扩展的事务管理机制，确保事务的正确性和一致性。 123public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; protected abstract Object doGetTransaction() throws TransactionException;&#125; 123456789101112public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; @Override protected Object doGetTransaction() &#123; DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); txObject.setConnectionHolder(conHolder, false); return txObject; &#125;&#125; TransactionSynchronizationManager 是一个用来管理与当前线程关联的资源（如连接、事务状态等）的工具类。它使用线程局部变量（ThreadLocal）来存储这些资源，从而确保每个线程都有自己的独立资源副本。 事务传播行为处理Spring 的事务传播行为定义在 TransactionDefinition.Propagation 枚举中，包括以下几种常见的类型： REQUIRED：如果当前没有事务，被嵌套调用的方法会创建一个新的事务；如果已经存在一个事务，嵌套调用的方法将加入到现有事务中执行。 REQUIRES_NEW：被嵌套调用的方法每次都创建一个新的事务；如果当前已经存在一个事务，则暂停当前事务，待新事务完成后再恢复。 NESTED：如果当前没有事务，则被嵌套调用的方法创建一个新的事务；如果已经存在一个事务，则在现有事务中创建一个嵌套事务。 MANDATORY：被嵌套调用的方法必须在现有事务中运行，如果当前没有事务，则抛出异常。 SUPPORTS：如果当前有事务，被嵌套调用的方法则在当前事务中运行；如果当前没有事务，被嵌套调用的方法则以非事务方式运行。 NOT_SUPPORTED：被嵌套调用的方法以非事务方式运行，如果当前有事务，则暂停当前事务。 NEVER：被嵌套调用的方法 以非事务方式运行，如果当前有事务，则抛出异常。 在getTransaction 中，事务传播行为 要分成2种情况处理 没有当前事务，根据事物传播行为如何处理当前方法的调用 存在当前事务，根据事物传播行为如何处理当前方法的调用, handleExistingTransaction没有当前事务省略getTransaction中其他逻辑，只看和事务传播行为相关的代码。在没有当前事务时， 当前方法的调用按照以下逻辑处理MANDATORY：被嵌套调用的方法必须在现有事务中运行，当前没有事务，则抛出异常。REQUIRED、REQUIRES_NEW、NESTED：当前没有事务，创建一个新事务SUPPORTS、NOT_SUPPORTED、NEVER：当前没有事务，以非事务方式运行当前方法。12345678910111213141516171819202122232425262728293031323334353637383940414243 public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123;@Override public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException &#123; Object transaction = doGetTransaction(); // 检查给定的事务对象是否表示一个已经存在的事务 // 在事务管理中，确定是否存在现有事务对于决定如何处理新事务至关重要。例如，根据传播行为，新事务可能需要挂起现有事务或者参与现有事务。 if (isExistingTransaction(transaction)) &#123; //存在当前事务，则根据传播行为处理现有事务，调用 `handleExistingTransaction(def, transaction, debugEnabled)` 方法，并返回相应的事务状态。 return handleExistingTransaction(def, transaction, debugEnabled); &#125; //不存在当前事务，根据事务定义中的传播行为（`PropagationBehavior`）决定如何处理新事务。 if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123; throw new IllegalTransactionStateException( &quot;No existing transaction found for transaction marked with propagation &#x27;mandatory&#x27;&quot;); &#125; else if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW || def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; SuspendedResourcesHolder suspendedResources = suspend(null); if (debugEnabled) &#123; logger.debug(&quot;Creating new transaction with name [&quot; + def.getName() + &quot;]: &quot; + def); &#125; try &#123; return startTransaction(def, transaction, debugEnabled, suspendedResources); &#125; catch (RuntimeException | Error ex) &#123; resume(null, suspendedResources); throw ex; &#125; &#125; else &#123; // Create &quot;empty&quot; transaction: no actual transaction, but potentially synchronization. if (def.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(&quot;Custom isolation level specified but no actual transaction initiated; &quot; + &quot;isolation level will effectively be ignored: &quot; + def); &#125; boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus(def, null, true, newSynchronization, debugEnabled, null); &#125; &#125;&#125; 存在当前事务handleExistingTransaction整体逻辑比较容易理解，也是按照各种传播行为定义进行相应处理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; private TransactionStatus handleExistingTransaction( TransactionDefinition definition, Object transaction, boolean debugEnabled) throws TransactionException &#123; // 该方法要以非事务方式运行，如果当前有事务，则抛出异常。 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) &#123; throw new IllegalTransactionStateException( &quot;Existing transaction found for transaction marked with propagation &#x27;never&#x27;&quot;); &#125; // 该方法要以非事务方式运行，如果当前有事务，则暂停当前事务。 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) &#123; if (debugEnabled) &#123; logger.debug(&quot;Suspending current transaction&quot;); &#125; Object suspendedResources = suspend(transaction); boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS); return prepareTransactionStatus( definition, null, false, newSynchronization, debugEnabled, suspendedResources); &#125; // 该方法调用需要创建一个新的事务；如果当前已经存在一个事务，则暂停当前事务，待新事务完成后再恢复。 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) &#123; if (debugEnabled) &#123; logger.debug(&quot;Suspending current transaction, creating new transaction with name [&quot; + definition.getName() + &quot;]&quot;); &#125; SuspendedResourcesHolder suspendedResources = suspend(transaction); try &#123; return startTransaction(definition, transaction, debugEnabled, suspendedResources); &#125; catch (RuntimeException | Error beginEx) &#123; resumeAfterBeginException(transaction, suspendedResources, beginEx); throw beginEx; &#125; &#125; // 如果当前没有事务，则该方法创建一个新的事务； // 如果已经存在一个事务，则在现有事务中创建一个嵌套事务。 if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123; if (!isNestedTransactionAllowed()) &#123; throw new NestedTransactionNotSupportedException( &quot;Transaction manager does not allow nested transactions by default - &quot; + &quot;specify &#x27;nestedTransactionAllowed&#x27; property with value &#x27;true&#x27;&quot;); &#125; if (debugEnabled) &#123; logger.debug(&quot;Creating nested transaction with name [&quot; + definition.getName() + &quot;]&quot;); &#125; if (useSavepointForNestedTransaction()) &#123; // Create savepoint within existing Spring-managed transaction, // through the SavepointManager API implemented by TransactionStatus. // Usually uses JDBC 3.0 savepoints. Never activates Spring synchronization. DefaultTransactionStatus status = prepareTransactionStatus(definition, transaction, false, false, debugEnabled, null); status.createAndHoldSavepoint(); return status; &#125; else &#123; // Nested transaction through nested begin and commit/rollback calls. // Usually only for JTA: Spring synchronization might get activated here // in case of a pre-existing JTA transaction. return startTransaction(definition, transaction, debugEnabled, null); &#125; &#125; // Assumably PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED. // 在已经有事务的前提下PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED 都需要新建一个事务， if (debugEnabled) &#123; logger.debug(&quot;Participating in existing transaction&quot;); &#125; if (isValidateExistingTransaction()) &#123; // 判断将要新建的事务和已存在的事务其隔离等级是否匹配 if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) &#123; Integer currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel(); //如果当前事务的隔离级别为 `null` 或者与新的事务定义中的隔离级别不一致，则抛出 `IllegalTransactionStateException` 异常。这表示新的事务定义中的隔离级别与现有事务不兼容。 if (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) &#123; Constants isoConstants = DefaultTransactionDefinition.constants; throw new IllegalTransactionStateException(&quot;Participating transaction with definition [&quot; + definition + &quot;] specifies isolation level which is incompatible with existing transaction: &quot; + (currentIsolationLevel != null ? isoConstants.toCode(currentIsolationLevel, DefaultTransactionDefinition.PREFIX_ISOLATION) : &quot;(unknown)&quot;)); &#125; &#125; // 如果当前事务是只读的，而新的事务定义不是只读的，则2个事务不兼容，需要抛出异常 if (!definition.isReadOnly()) &#123; if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) &#123; throw new IllegalTransactionStateException(&quot;Participating transaction with definition [&quot; + definition + &quot;] is not marked as read-only but existing transaction is&quot;); &#125; &#125; &#125; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); return prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null); &#125;&#125; 这段代码的主要作用是验证参与的事务定义（TransactionDefinition）是否与现有事务的属性兼容。它具体执行以下验证： 隔离级别验证：确保新的事务定义中的隔离级别与现有事务的隔离级别一致。如果不一致，则抛出异常。 只读属性验证：确保新的事务定义中的只读属性与现有事务的只读属性一致。如果不一致，则抛出异常。 通过这种验证机制，Spring 能够确保在事务传播过程中，新的事务定义不会破坏现有事务的设置，从而保证事务管理的正确性和一致性。 3.4.2.1 开始事务: startTransaction-&gt;doBegin不论是否存在当前事务， 都要有一个事务启动的步骤1234567891011public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable &#123; private TransactionStatus startTransaction(TransactionDefinition definition, Object transaction, boolean debugEnabled, @Nullable SuspendedResourcesHolder suspendedResources) &#123; boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER); DefaultTransactionStatus status = newTransactionStatus( definition, transaction, true, newSynchronization, debugEnabled, suspendedResources); doBegin(transaction, definition); prepareSynchronization(status, definition); return status; &#125;&#125; 重点逻辑在doBegin 中，还是看我们更常用到的DataSourceTransactionManager 如何实现的该方法，可以看到其整体流程和JDBC 事务中的流程保持一致,只是DataSourceTransactionManager 中多了更多的包装层。 获取数据库连接 设置自动提交、隔离级别、只读属性 执行目标方法 结束事务：commit or rollback 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class DataSourceTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, InitializingBean &#123; @Override protected void doBegin(Object transaction, TransactionDefinition definition) &#123; DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try &#123; if (!txObject.hasConnectionHolder() || txObject.getConnectionHolder().isSynchronizedWithTransaction()) &#123; Connection newCon = obtainDataSource().getConnection(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Acquired Connection [&quot; + newCon + &quot;] for JDBC transaction&quot;); &#125; txObject.setConnectionHolder(new ConnectionHolder(newCon), true); &#125; txObject.getConnectionHolder().setSynchronizedWithTransaction(true); // 1. 获取数据库连接 con = txObject.getConnectionHolder().getConnection(); Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); // 设置事务隔离级别 txObject.setPreviousIsolationLevel(previousIsolationLevel); // 设置只读属性 txObject.setReadOnly(definition.isReadOnly()); // 设置自动提交属性 if (con.getAutoCommit()) &#123; txObject.setMustRestoreAutoCommit(true); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Switching JDBC Connection [&quot; + con + &quot;] to manual commit&quot;); &#125; con.setAutoCommit(false); &#125; prepareTransactionalConnection(con, definition); txObject.getConnectionHolder().setTransactionActive(true); int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; // Bind the connection holder to the thread. if (txObject.isNewConnectionHolder()) &#123; // 将与当前线程的事务相关信息保存到TransactionSynchronizationManager工具类中，方便后续使用 TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); &#125; &#125; catch (Throwable ex) &#123; if (txObject.isNewConnectionHolder()) &#123; DataSourceUtils.releaseConnection(con, obtainDataSource()); txObject.setConnectionHolder(null, false); &#125; throw new CannotCreateTransactionException(&quot;Could not open JDBC Connection for transaction&quot;, ex); &#125; &#125;&#125; 3.4.2 invokeWithinTransaction 执行目标方法-InvocationCallbackinvokeWithinTransaction在对当前的方法有了合适的事务后，就可以通过InvocationCallback.proceedWithInvocation执行对目标方法的调用了。 InvocationCallback 是invokeWithinTransaction的第三个参数。 12protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) InvocationCallback 是一个位于TransactionAspectSupport内部的函数式接口，可以通过匿名内部类或者lambda表达式实现该接口。 1234567public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; @FunctionalInterface protected interface InvocationCallback &#123; @Nullable Object proceedWithInvocation() throws Throwable; &#125;&#125; 在调用TransactionInterceptor.invoke方法中调用invokeWithinTransaction 时,InvocationCallback 传入了一个lambda 表达式123456789101112131415161718public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable &#123;@Override @Nullable public Object invoke(MethodInvocation invocation) throws Throwable &#123; Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); &#125;&#125;public abstract class TransactionAspectSupport implements BeanFactoryAware, InitializingBean &#123; @Nullable protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // 执行目标方法 retVal = invocation.proceedWithInvocation(); &#125;&#125; 说明在invokeWithinTransaction中执行目标方式时， 实际上调用的是MethodInvocation.proceed方法。 ReflectiveMethodInvocation 实现了MethodInvocation， 所以这里在调用ReflectiveMethodInvocation.proceed ReflectiveMethodInvocation.proceed 及其子类CglibMethodInvocation.proceed 可以通过递归调用完成Advice 增强逻辑的执行和目标方法的执行。 3.4.3 invokeWithinTransaction-事务结束处理 如果目标方法正常完成执行，那就要执行commit 操作， commitTransactionAfterReturning 如果目标方法执行出现异常，那就要执行回滚操作 3.5 再看事务传播行为在方法嵌套调用的情况下，Spring 的事务传播行为（Transaction Propagation Behaviors）决定了嵌套方法是新建事务、加入现有事务、开始非事务执行，还是创建嵌套事务。在方法正常执行结束时，不同传播行为的区别不大，但在业务操作失败/部分失败并需要回滚时，这些传播行为的差异变得至关重要。 PROPAGATION_REQUIRED 描述：如果当前没有事务，则创建一个新事务；如果已经存在一个事务，则加入该事务。 正常执行：方法正常执行结束，事务提交。 失败回滚：无论是外层方法还是内层方法抛出异常，整个事务都会回滚，因为它们属于同一个事务边界。 PROPAGATION_REQUIRES_NEW 描述：每次都创建一个新的事务。如果已经存在一个事务，则暂停当前事务，创建一个新事务。 正常执行：每个方法都有自己独立的事务，方法执行结束，各自的事务提交。 失败回滚：如果内层方法抛出异常，只有内层方法的事务回滚，外层事务不会受到影响。如果外层方法抛出异常，外层事务回滚，内层事务不受影响（已提交）。 PROPAGATION_NESTED 描述：如果当前没有事务，则创建一个新的事务；如果已经存在一个事务，则在当前事务中创建一个嵌套事务。 正常执行：嵌套方法成功执行，其嵌套事务提交，主事务继续。 失败回滚：如果内层方法抛出异常，内层事务回滚到保存点，外层事务可以决定是否继续执行或回滚到整个事务。如果外层方法抛出异常，整个事务（包括嵌套事务）都会回滚。 PROPAGATION_SUPPORTS 描述：如果当前有事务，则在事务中运行；如果当前没有事务，则以非事务方式运行。 正常执行：在事务中执行则提交事务；非事务执行则正常完成。 失败回滚：在事务中执行时，如果抛出异常，事务回滚；非事务执行时，抛出异常不会回滚。 PROPAGATION_NOT_SUPPORTED 描述：总是以非事务方式执行，如果当前有事务，则暂停当前事务。 正常执行：方法总是非事务方式执行，正常完成。 失败回滚：由于没有事务，即使抛出异常，也不会触发回滚。 PROPAGATION_NEVER 描述：以非事务方式执行，如果当前有事务，则抛出异常。 正常执行：在没有事务的情况下正常执行。 失败回滚：如果在事务中调用，则直接抛出异常，操作不会执行。 PROPAGATION_MANDATORY 描述：必须在事务中执行，如果当前没有事务，则抛出异常。 正常执行：必须在事务中执行，正常完成。 失败回滚：如果在非事务情况下调用，则抛出异常，操作不会执行；在事务中调用时，抛出异常回滚事务。 3.6 示例代码有了以上内容了解，下面我们将基于以下代码，并跟随debug 信息，来具体看下基于事务的动态代理对象的生成和目标方法执行过程applicationContext.xml123456789101112131415161718192021222324252627282930&lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;messageService&quot; class=&quot;com.example.codingInAction.service.MessageService&quot;/&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/trust_message&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;XXXXXX&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置事务代理 --&gt; &lt;bean id=&quot;messageServiceProxy&quot; class=&quot;org.springframework.transaction.interceptor.TransactionProxyFactoryBean&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot;/&gt; &lt;property name=&quot;target&quot; ref=&quot;messageService&quot;/&gt; &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;insertMessage&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;prop key=&quot;findByMessageKey&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; 1234567891011121314151617181920212223public class MessageService &#123; public int insertMessage(Message message)&#123; // 模拟数据库操作 System.out.println(&quot;insertMessage 执行&quot;); return 1; &#125; public Message findByMessageKey(Map&lt;String, Object&gt; params)&#123; // 模拟数据库操作 System.out.println(&quot;findByMessageKey 执行&quot;); return new Message(); &#125;&#125;public class CodingInActionApplication &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); MessageService messageService = (MessageService) context.getBean(&quot;messageServiceProxy&quot;); Message message = new Message(); message.setMessage(&quot;test message&quot;); messageService.insertMessage(message); &#125;&#125; 3.7 基于事务的动态代理对象和 Spring AOP XML配置方式原理详解 一文讲解过使用ProxyFactoryBean 配置代理对象的过程框架基本一致, 以下会省略大部分内容，只重点强调不一致的细节 getBean(“&amp;messageServiceProxy”)1ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); getBean(“&amp;messageServiceProxy”) 意味着是在以上代码的Spring 容器启动过程中实例化了messageServiceProxy 这个TransactionProxyFactoryBean本身。 3.7.1 TransactionProxyFactoryBean init 阶段 -InitializingBean在messageServiceProxy本身实例化的过程中，会在init 阶段就生成代理对象 3.7.2 获取代理对象-getBean(“messageServiceProxy”)1MessageService messageService = (MessageService) context.getBean(&quot;messageServiceProxy&quot;); 直接跳过各种细节来到FactoryBean.getObject,可以看到由于在afterPropertiesSet中已经生成了代理对象，所以在getObject逻辑中是直接返回已经生成的代理对象的， 不像ProxyFactoryBean 是在getObject逻辑中才生成代理对象12345678910public abstract class AbstractSingletonProxyFactoryBean extends ProxyConfig implements FactoryBean&lt;Object&gt;, BeanClassLoaderAware, InitializingBean &#123; @Override public Object getObject() &#123; if (this.proxy == null) &#123; throw new FactoryBeanNotInitializedException(); &#125; return this.proxy; &#125;&#125; 3.8 createMainInterceptor -事务Advisor 还是在afterPropertiesSet 方法中，会创建事务Advisor。在不指定切点表达式 pointcut 的时候， 会使用TransactionAttributeSourceAdvisor TransactionInterceptor 本身也是在Spring 容器启动过程中，并且按照XML 文件中的信息进行实例化，相当于把编程式事务实现中通过代码设置的属性，全部在XML 文件中通过配置实现了。 从以上代码可以看出， 从TransactionAttributeSourceAdvisor可以获取到需要的切点 Pointcut （这里pointcut 就是前面填充的TransactionAttributeSource 属性）和Advice 增强 , 切点可以过滤出需要执行增强的类及方法， 筛选出目标方法后应用增强完成事务自动管理的功能。 以上步骤执行完毕后，可以看下实例化完成的TransactionProxyFactoryBean 包含的内容 proxy: 在init 阶段提前生成好的动态代理对象， 这是一个CGLIB 动态对象 transactionInterceptor, 包含了在XML文件中指定的transactionManager、transactionAttributes信息 3.9 基于事务的动态代理对象执行目标方法1messageService.insertMessage(message) 最终获取到的是一个CGLIB 动态代理对象， 执行方法时， 直接来到DynamicAdvisedInterceptor.intercept方法 3.9.1 DynamicAdvisedInterceptor.intercept 3.9.2 getInterceptorsAndDynamicInterceptionAdvice获取档案方法可用的interceptor. advisor 就是前面创建的TransactionAttributeSourceAdvisor实例， 经过ClassFilter.matches 和MethodMatcher.matches处理后后， 最终返回了可以用在当前bean 上interceptor 3.9.3 ReflectiveMethodInvocation.proceedReflectiveMethodInvocation.proceed 是CGLIB 动态代理处理目标方法调用 核心逻辑,它根据currentInterceptorIndex来判断运行以下逻辑 执行目标方法 执行目标方法上的interceptor1234567891011121314151617181920212223242526272829public class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable &#123; private int currentInterceptorIndex = -1; @Override @Nullable public Object proceed() throws Throwable &#123; // We start with an index of -1 and increment early. if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; return proceed(); &#125; &#125; else &#123; return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125;&#125; CglibAopProxy中有一个内部类CglibMethodInvocation继承了`ReflectiveMethodInvocation 并重写了proceed方法12345678class CglibAopProxy implements AopProxy, Serializable &#123; private static class CglibMethodInvocation extends ReflectiveMethodInvocation &#123; @Override @Nullable public Object proceed() throws Throwable &#123; return super.proceed(); &#125;&#125; 所以当DynamicAdvisedInterceptor.intercept中执行到new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed()，会首先来到父类 ReflectiveMethodInvocation.proceed来到递归处理Advisor 和目标方法的核心逻辑 前面已经说了，TransactionInterceptor 继承了org.aopalliance.intercept.MethodInterceptor， 所以逻辑会走到这里调用invoke 方法。 来到TransactionInterceptor 重写的invoke 方法， 进入前面重点讲过的invokeWithTransaction 这里invokeWithTransaction 的第4个参数是InvocationCallback， 这里传入了 传入了一个labada 表达式， 说明在调用InvocationCallback.proceedWithInvocation 的实现逻辑是调用MethodInvocation.proceed 方法 所以在invokeWithTransaction 方法中获取到事务信息后，执行InvocationCallback.proceedWithInvocation 实际还是在继续执行ReflectiveMethodInvocation.proceed再次进入ReflectiveMethodInvocation.proceed在此代码示例中， Advisor 只有一个，且已经访问过，所以这里开始执行目标方法的调用执行完目标方法后，一层层出栈，又回到invokeWithTransaction方法，此时开始执行事务结束的逻辑， 此次调用方法正常执行完毕，所以这里走正常commit 关闭逻辑即可。 4. 声明式事务 aop:configTransactionProxyFactoryBean 需要手动配置和获取代理对象，尤其是在需要为多个 bean 配置事务时，每个 bean 都需要手动配置，这在实际应用中会变得繁琐且易出错。 而 aop:config 和 @Transactional 注解通过 AbstractAutoProxyCreator这个BeanPostProcessor 可以在实例化的init 阶段自动生成代理对象。 4.1 示例代码12345678910111213141516171819202122232425262728293031323334 &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;messageService&quot; class=&quot;com.example.codingInAction.service.MessageService&quot;/&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/trust_message&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;24048@Ms&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt;&lt;!-- 配置事务拦截器 --&gt; &lt;bean id=&quot;transactionInterceptor&quot; class=&quot;org.springframework.transaction.interceptor.TransactionInterceptor&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot;/&gt; &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;insertMessage&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;prop key=&quot;findByMessageKey&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置事务增强 --&gt; &lt;aop:config&gt; &lt;aop:pointcut id=&quot;serviceMethods&quot; expression=&quot;execution(* com.example.codingInAction.service.*.*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;transactionInterceptor&quot; pointcut-ref=&quot;serviceMethods&quot;/&gt; &lt;/aop:config&gt; 123456789public class CodingInActionApplication &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); MessageService messageService = (MessageService) context.getBean(&quot;messageService&quot;); Message message = new Message(); message.setMessage(&quot;test message&quot;); messageService.insertMessage(message); &#125;&#125; 4.2 生成基于事务的动态代理对象AspectJAwareAdvisorAutoProxyCreator在Spring AOP 注解方式原理详解-## AbstractAutoProxyCreator 中讲过，AbstractAutoProxyCreator 是一个抽象类，它有多个具体实现。 在使用aop:config 方式，实现事务功能时，使用的是AspectJAwareAdvisorAutoProxyCreator AspectJAwareAdvisorAutoProxyCreator和 AnnotationAwareAspectJAutoProxyCreator 类似，但主要用于处理通过 XML 配置文件或其他非注解方式配置的 AspectJ 切面。 来看Spring 容器启动过程， 当进行业务bean 的初始化之前，已经有一些bean 提前初始化完成存放在singletonObjects 这个一级缓存中了 从beanName 可以看出，messageService、dataSource、transactionManager、transactionInterceptor、serviceMethods 均是在XML 出现的bean 定义。 org.springframework.aop.support.DefaultBeanFactoryPointcutAdvisor 和 org.springframework.aop.config.internalAutoProxyCreator 比较特殊 4.2.1 internalAutoProxyCreatororg.springframework.aop.config.internalAutoProxyCreator 不是一个实际的类，而是一个特殊的 bean 名称。Spring 使用这个名称在内部标识和注册用于自动代理创建的组件。 这个 bean 名称指向的是一个具体的 AbstractAutoProxyCreator实现类，在使用aop:config 配置基于事务的代理对象时，指的是AspectJAwareAdvisorAutoProxyCreator， 通过上面的debug 信息也可以确认这一点。 4.2.2 BeanPostProcessor.postProcessAfterInitializationAspectJAwareAdvisorAutoProxyCreator直接在Spring 容器启动过程中，通过BeanPostProcessor.postProcessAfterInitialization在init阶段介入为MessageService 生成基于事务的动态代理对象 4.3 事务Advisor-DefaultBeanFactoryPointcutAdvisor从Spring 启动完成后的singletonObjects 中可以看出aop:config 这个标签配置对应DefaultBeanFactoryPointcutAdvisor 。 DefaultBeanFactoryPointcutAdvisor 的主要作用是将一个切点（Pointcut）和一个切面（Advice）结合起来，形成一个完整的 AOP 配置。根据Spring 容器启动完成的数据看DefaultBeanFactoryPointcutAdvisor 就对应aop:config 配置，里面包含了定义的pointcut 和Advice. Advisor 实例化完成后，在生成代理对象的wrapIfNecessary中就可以获取到能应用到当前类的Advisor 了。 通过getAdvicesAndAdvisorsForBean 获取在当前类上可以的Advisor , 从debug 信息上可以看到specificInterceptors 4.4 基于事务的动态代理对象执行目标方法前面生成的代理对象是CGLIB 动态代理对象， 执行目标方法时，直接来到DynamicAdvisedInterceptor.intercept方法 。通过ReflectiveMethodInvocation.proceed 方法进入递归执行Advisor和目标方法 的逻辑。和3.9.3 中内容完成一致，此处略过 5. 声明式事务-@Transactional注解@Transactional 注解 类级别和方法级别：可以在类上或方法上使用 @Transactional 注解。如果在类上标注，则该类的所有方法都将受事务管理。 事务传播行为：通过 propagation 属性定义事务的传播行为，如 REQUIRED、REQUIRES_NEW、MANDATORY 等。 隔离级别：通过 isolation 属性定义事务的隔离级别，如 READ_COMMITTED、REPEATABLE_READ、SERIALIZABLE 等。 超时和只读属性：可以通过 timeout 和 readOnly 属性设置事务的超时时间和只读特性。 回滚规则：通过 rollbackFor 和 noRollbackFor 属性指定哪些异常会导致事务回滚。 5.1 示例代码1234567891011121314151617181920@Transactional@Servicepublic class MessageService &#123; public int insertMessage(Message message)&#123; System.out.println(&quot;insertMessage 执行&quot;); return 1; &#125; public Message findByMessageKey(Map&lt;String, Object&gt; params)&#123; System.out.println(&quot;findByMessageKey 执行&quot;); return new Message(); &#125;&#125;@SpringBootApplicationpublic class CodingInActionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CodingInActionApplication.class, args); &#125;&#125; 5.2 生成基于事务的动态代理对象AnnotationAwareAspectJAutoProxyCreator 使用@Transactional注解时，基于事务的代理对象时通过AnnotationAwareAspectJAutoProxyCreator这个BeanPostProcessor在init 阶段生成的 5.3 BeanFactoryTransactionAttributeSourceAdvisor`5.3.1 internalTransactionAdvisororg.springframework.transaction.config.internalTransactionAdvisor 并不是一个实际存在的类，而是一个特殊的 bean 名称。 在Spring 项目中， 当使用 @EnableTransactionManagement 或 &lt;tx:annotation-driven&gt; 配置时，Spring 会自动注册并配置internalTransactionAdvisor 这个特殊Bean, 其对应的实例是BeanFactoryTransactionAttributeSourceAdvisor。 在 Spring Boot 项目中，即使不显式使用 @EnableAutoConfiguration，Spring Boot 仍会自动注册和配置许多默认的组件和功能，包括事务管理。这是因为 Spring Boot 的自动配置机制默认包含在 @SpringBootApplication 注解中。 @SpringBootApplication 是一个组合注解，它包含了多个注解，其中一个关键注解就是 @EnableAutoConfiguration。因此，使用 @SpringBootApplication 时，Spring Boot 的自动配置机制会被自动启用。 1234567891011121314151617181920212223242526272829303132public class BeanFactoryTransactionAttributeSourceAdvisor extends AbstractBeanFactoryPointcutAdvisor &#123; @Nullable private TransactionAttributeSource transactionAttributeSource; private final TransactionAttributeSourcePointcut pointcut = new TransactionAttributeSourcePointcut() &#123; @Override @Nullable protected TransactionAttributeSource getTransactionAttributeSource() &#123; return transactionAttributeSource; &#125; &#125;; public void setTransactionAttributeSource(TransactionAttributeSource transactionAttributeSource) &#123; this.transactionAttributeSource = transactionAttributeSource; &#125; public void setClassFilter(ClassFilter classFilter) &#123; this.pointcut.setClassFilter(classFilter); &#125; @Override public Pointcut getPointcut() &#123; return this.pointcut; &#125;&#125;public abstract class AbstractBeanFactoryPointcutAdvisor extends AbstractPointcutAdvisor implements BeanFactoryAware &#123; @Nullable private String adviceBeanName; @Nullable private BeanFactory beanFactory;&#125; BeanFactoryTransactionAttributeSourceAdvisor和前面讲过的TransactionProxyFactoryBean有相似之处， TransactionAttributeSourceAdvisor 和 BeanFactoryTransactionAttributeSourceAdvisor 都是用于应用事务管理的 AOP Advisor，但在实现细节和使用场景上有所不同。 TransactionAttributeSourceAdvisor 适用于XML 配置配置和使用场景，而 BeanFactoryTransactionAttributeSourceAdvisor 增加了BeanFactory 属性， 适合用于Spring 容器启动过程中使用 两者都通过定义切点和应用事务增强，实现了 Spring 事务管理的核心功能。 通过getAdvicesAndAdvisorsForBean,可以看到在获取应用到当前类的Advisor 时， 通过getBean方法从Spring 容器获取Advisor 实例时， beanName使用的是org.springframework.transaction.config.internalTransactionAdvisor , 最终返回的实例是 BeanFactoryTransactionAttributeSourceAdvisor 5.4 基于事务的动态代理对象如何执行方法和3.9.3 中内容完成一致，此处略过 6.在Spring中实现跨资源事务前面已经说过，Spring 的事务机制只保证数据库操作的原子性，所以当需要数据库操作和其他中间件操作如kafka操作具有原子性的时候，就要用其他的方案来保证。关于这种情况，可以点击阅读TrustMessage-基于2PC+MySQL+泛化调用实现的可靠消息中心","categories":[],"tags":[{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring中三级缓存无法解决的循环依赖","slug":"Spring中三级缓存无法解决的循环依赖","date":"2024-07-16T13:57:56.000Z","updated":"2024-07-16T14:34:43.100Z","comments":true,"path":"bccbdfb8/","permalink":"http://example.com/bccbdfb8/","excerpt":"","text":"建议了解以下内容后再阅读本文 Spring IOC容器 和 Spring beanSpring IOC 容器启动过程拓展点Spring bean 实例化Java 动态代理Spring AOP 实践Spring AOP XML配置方式原理详解Spring AOP 注解方式原理详解 关于Spring 循环依赖， 在 Spring bean 实例化一文中讲解了使用三级缓存+暴露早期引用机制 解决循环依赖问题，但其实不是所有的循环依赖都可以被解决，即使三级缓存+暴露早期引用机制，在Spring 启动过程中依然有可能遇到一下循环依赖错误, 该报错信息位于doCreateBean方法中。1org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#x27;springTransactionService&#x27;: Bean with name &#x27;springTransactionService&#x27; has been injected into other beans [userService] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using &#x27;getBeanNamesForType&#x27; with the &#x27;allowEagerInit&#x27; flag turned off, for example. 在单例bean（单例bean 才能使用缓存）且不使用构造器注入（构造器注入无法使用早期引用）的前提下 普通不需要代理的bean 之间 循环依赖一定可以解决 需要代理的bean 之间产生循环依赖不一定能解决。 1. 再看doCreateBeandoCreateBean 方法中包含了bean 实例化的全过程，在 Spring bean 实例化 一文中，已经说明了实例化的整个流程，并对三层缓存的内容和缓存添加时机都进行了详细介绍，本文将在这些内容之外介绍更多细节，来更好理解循环依赖的过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107AbstractAutowireCapableBeanFactory.java protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)&#123; Object beanInstance = doCreateBean(beanName, mbdToUse, args);&#125;protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. //检查是否已经对 Bean 定义进行了后处理，如果没有，则调用 applyMergedBeanDefinitionPostProcessors 方法应用后处理器。 synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Post-processing of merged bean definition failed&quot;, ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); //如果允许循环引用，并且当前 Bean 是单例，则调用 addSingletonFactory 方法，提供一个回调以获取早期 Bean 引用。 if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Eagerly caching bean &#x27;&quot; + beanName + &quot;&#x27; to allow for resolving potential circular references&quot;); &#125; // 添加第3级缓存， 此处第二个参数又是一个ObjectFactory的匿名类实现 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex); &#125; &#125; // 验证循环引用的处理过程是否正确 if (earlySingletonExposure) &#123; // 尝试获取早期引用，那么这个早期引用肯定是因为循环依赖，其他bean在getSingleton(beanName, true)生产出来的 // 因为该bean 自己的生产过程中，只会主动添加一级、三级缓存 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; // 表示init后，Bean实例未被代理,在未代理的情况下，exposedObject 和 bean 是相同的引用 if (exposedObject == bean) &#123; // 如果存在早期暴露的单例引用，并且exposedObject未被代理，将exposedObject替换为早期暴露的单例引用。 exposedObject = earlySingletonReference; &#125; // 如果在暴露早期引用的情况下，init阶段还存在代理操作时，要确保依赖当前bean 的其他bean 引用到了正确的版本 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; // 获取所有依赖当前Bean的Bean名称。 String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; // 尝试移除只为类型检查而创建的单例Bean。如果成功移除，表示这个Bean只是为类型检查而创建的，不是实际使用的Bean。 // 通过这个循环，Spring会过滤掉那些只为类型检查而创建的Bean，保留那些实际依赖当前Bean的Bean。 if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; // 这段逻辑确保在处理循环依赖时，确保依赖的Bean使用的是最终版本的Bean，而不是中间状态的原始Bean。 // 如果存在实际依赖当前Bean的Bean。抛出BeanCurrentlyInCreationException异常 // 因为这意味着有Bean在循环依赖的过程中使用了当前Bean的原始版本，但最终当前Bean被包装（如被AOP代理）。 // 这意味着被依赖的Bean使用的不是最终版本的Bean，这可能导致一些问题。 throw new BeanCurrentlyInCreationException(beanName, &quot;Bean with name &#x27;&quot; + beanName + &quot;&#x27; has been injected into other beans [&quot; + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + &quot;] in its raw version as part of a circular reference, but has eventually been &quot; + &quot;wrapped. This means that said other beans do not use the final version of the &quot; + &quot;bean. This is often the result of over-eager type matching - consider using &quot; + &quot;&#x27;getBeanNamesForType&#x27; with the &#x27;allowEagerInit&#x27; flag turned off, for example.&quot;); &#125; &#125; &#125; &#125; return exposedObject; &#125; 1.1 if(earlySingletonExposure)关于更多的细节，重点来看init 阶段完成后的以下代码这段逻辑中抛出的异常即是指循环依赖处理失败 123456789101112131415161718192021222324252627282930313233343536373839 // 验证循环引用的处理过程是否正确if (earlySingletonExposure) &#123; // 尝试获取早期引用，那么这个早期引用肯定是因为循环依赖，其他bean在getSingleton(beanName, true)生产出来的 // 因为该bean 自己的生产过程中，只会主动添加一级、三级缓存 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; // 表示init后，Bean实例未被代理,在未代理的情况下，exposedObject 和 bean 是相同的引用 if (exposedObject == bean) &#123; // 如果存在早期暴露的单例引用，并且exposedObject未被代理，将exposedObject替换为早期暴露的单例引用。 exposedObject = earlySingletonReference; &#125; // 如果在暴露早期引用的情况下，init阶段还存在代理操作时，要确保依赖当前bean 的其他bean 引用到了正确的版本 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; // 获取所有依赖当前Bean的Bean名称。 String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; // 尝试移除只为类型检查而创建的单例Bean。如果成功移除，表示这个Bean只是为类型检查而创建的，不是实际使用的Bean。 // 通过这个循环，Spring会过滤掉那些只为类型检查而创建的Bean，保留那些实际依赖当前Bean的Bean。 if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; // 这段逻辑确保在处理循环依赖时，确保依赖的Bean使用的是最终版本的Bean，而不是中间状态的原始Bean。 // 如果存在实际依赖当前Bean的Bean。抛出BeanCurrentlyInCreationException异常 // 因为这意味着有Bean在循环依赖的过程中使用了当前Bean的原始版本，但最终当前Bean被包装（如被AOP代理）。 // 这意味着被依赖的Bean使用的不是最终版本的Bean，这可能导致一些问题。 throw new BeanCurrentlyInCreationException(beanName, &quot;Bean with name &#x27;&quot; + beanName + &quot;&#x27; has been injected into other beans [&quot; + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + &quot;] in its raw version as part of a circular reference, but has eventually been &quot; + &quot;wrapped. This means that said other beans do not use the final version of the &quot; + &quot;bean. This is often the result of over-eager type matching - consider using &quot; + &quot;&#x27;getBeanNamesForType&#x27; with the &#x27;allowEagerInit&#x27; flag turned off, for example.&quot;); &#125; &#125; &#125;&#125; 1.2 bean、exposedObject、earlySingletonReference先来对这3个指向bean 实例的变量进行解释 12345678910111213BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args);// bean 指create阶段后获取的引用， 这个引用非常原始，肯定不会是代理对象Object bean = instanceWrapper.getWrappedInstance();// exposedObject 是doCreateBean方法最终会返回的数据// 经过init阶段后，如果执行了代理逻辑，则会产生一个新的代理对象赋值给 exposedObject，这时exposedObject和bean就不相等了Object exposedObject = bean;exposedObject = initializeBean(beanName, exposedObject, mbd);// bean的早期引用， 即三级缓存中第二级缓存Object earlySingletonReference = getSingleton(beanName, false); 1.3 同一个bean实例 的同一个APC不会重复执行针对AbstractAutoProxyCreator 而言，对一个bean产生对象的有两个时机 因为循环依赖被其他bean 依赖时，通过AbstractAutoProxyCreator.getEarlyBeanReference获取其早期引用，即代理对象引用 bean 正常实例化流程中, 在init 阶段通过BeanPostProcessor.postProcessAfterInitialization 方法，触发AbstractAutoProxyCreator.postProcessAfterInitialization 方法执行，该方法中包含生成代理对象的逻辑 具体代码如下12345678910111213141516171819202122232425262728293031323334public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; // 生成了早期引用的bean缓存， private final Map&lt;Object, Object&gt; earlyProxyReferences = new ConcurrentHashMap&lt;&gt;(16); @Override public Object getEarlyBeanReference(Object bean, String beanName) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); &#125; @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; // 如果 `bean` 为 `null`，则直接返回 `null`。 if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125; protected Object getCacheKey(Class&lt;?&gt; beanClass, @Nullable String beanName) &#123; if (StringUtils.hasLength(beanName)) &#123; return (FactoryBean.class.isAssignableFrom(beanClass) ? BeanFactory.FACTORY_BEAN_PREFIX + beanName : beanName); &#125; else &#123; return beanClass; &#125; &#125;&#125; 1.3.1 earlyProxyReferences之所以说对一个bean 来讲，同一个AbstractAutoProxyCreator实例的代理逻辑不会重复执行，是因为earlyProxyReferences 这个缓存的存在。 earlyProxyReferences 是一个ConcurrentHashMap， key 是beanName(先忽略对FactoryBean的处理，即使加了&amp; 前缀，也是一个字符串，继续理解成beanName就可以了)， value是bean 实例对象。 根据getEarlyBeanReference和postProcessAfterInitialization的逻辑可以看出，如果一个bean 提前获取了早期引用，则会在earlyProxyReferences 中将其记录下来。 ⚠️：注意记录的不是早期引用（早期引用可以是原始bean ,也可能是代理对象引用），早期引用是存储在三级缓存中的第二级缓存中的。 那么在bean 实例化init 阶段， 进入AbstractAutoProxyCreator.postProcessAfterInitialization 方法时，通过cacheKey读取value , 判断earlyProxyReferences 中记录的bean和当前入参bean是否一致， 如果一致，就不用重复执行wrapIfNecessary逻辑了。 1.3.2 earlyProxyReferences.remove判断earlyProxyReferences 中记录的bean和当前入参bean是否一致， 是通过以下代码逻辑完成的， 1if (this.earlyProxyReferences.remove(cacheKey) != bean) earlyProxyReferences.remove(cacheKey) 的结果有3种情况 null, 与入参bean 相等的值，与入参bean 不相等的值， 返回 null： 解释： 这表明入参bean 没有在其他 bean 的依赖注入过程中提前暴露引用。 处理： 需要对入参bean 进行代理创建，调用 wrapIfNecessary 方法。 返回与 入参bean 相等的值： 解释： 这表明该入参bean 已经因为其他 bean 的依赖注入提前执行wrapIfNecessary，所以这里不需要重复执行了 处理： 不需要对该 bean 进行代理创建，因此不调用 wrapIfNecessary 方法。 返回与入参bean 不相等的值： 解释： cacheKey 对应的bean 确实已经提前暴露了引用，但是具有相同cacheKey 的 入参bean不是当初来获取早期引用的那个bean, 所以仍然要对这个入参bean 执行wrapIfNecessary 逻辑 处理： 需要对该 bean 进行代理创建，调用 wrapIfNecessary 方法 前两种情况都比较好理解， 第3种情况需要多加解释，而且第三种也是无法解决的循环依赖。 出现的原因可以分为2种 能生成代理对象的不只AbstractAutoProxyCreator， 还有AbstractAdvisingBeanPostProcessor 存在多个AbstractAutoProxyCreator ⚠️：这个缓存的使用逻辑， 和实际开发中我们要删除缓存时思路一致， 要先判断要删除的线程是不是和当前添加缓存的线程一致，一致的话才能删除缓存，否则会造成数据不一致。 2. 有动态代理的循环引用实例2.1 有动态代理的循环引用示例代码该示例代码是Springboot 项目，构造一个依赖循环的例子 在如下代码中，userService和springTransactionService通过属性注入互相依赖， 且定义了一个Aspect , 这个Aspect 会为userService和springTransactionService 都生成代理对象 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Servicepublic class SpringTransactionService &#123; @Autowired UserService userService; public void performTransaction() &#123; // 模拟业务逻辑 System.out.println(&quot;performTransaction&quot;); &#125;&#125;@Servicepublic class UserService implements UserI &#123; @Autowired SpringTransactionService springTransactionService; @Override public void createUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); &#125; @Override public void deleteUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); &#125;&#125;@Aspect@Componentpublic class LoggingAspect &#123; //定义一个匹配userService中所有方法的切点表达式 @Pointcut(&quot;execution(* com.example.codingInAction.service.*.*(..))&quot;) public void userServiceAllMethod() &#123; &#125; // 在方法执行之前执行的通知 @Before(&quot;userServiceAllMethod()&quot;) public void logBefore(JoinPoint joinPoint) &#123; System.out.println(&quot;Before method: &quot; + joinPoint.getSignature().getName()); &#125; // 在方法执行之后执行的通知 @After(&quot;userServiceAllMethod()&quot;) public void logAfter(JoinPoint joinPoint) &#123; System.out.println(&quot;After method: &quot; + joinPoint.getSignature().getName()); &#125; // 定义一个只匹配 UserService.createUser 方法的切点表达式 @Around(&quot;execution(* com.example.codingInAction.service.UserService.createUser(..))&quot;) public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable &#123; long startTime = System.currentTimeMillis(); System.out.println(joinPoint.getSignature().getName() + &quot; 方法开始执行&quot;); Object result = joinPoint.proceed(); // 执行目标方法 long endTime = System.currentTimeMillis(); System.out.println(joinPoint.getSignature().getName() + &quot; 方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125;// 示例代码启动入口@SpringBootApplicationpublic class CodingInActionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CodingInActionApplication.class, args); 2.2 springTransactionService 实例化2.2.1 三级缓存 springTransactionService 经过createBeanInstance阶段后，放入第三级缓存，以便在需要之时提前暴露引用 2.2.2 populate with userServicespringTransactionService 在populate阶段发现需要userService, 通过getBean 获取userService 实例。 2.2.2.1 getBean(userService)此时userService 还没有进行实例化，所以在三级缓存中不存在，要走create 流程进行实例化 2.2.2.2 userService 放入第三级缓存userService 经过createBeanInstance阶段后，放入第三级缓存，以便在需要之时提前暴露引用 2.2.2.3 userService populate with springTransactionServiceuserService在populate 阶段发现需要springTransactionService ， 再次通过getBean 流程获取springTransactionService， 此时springTransactionService的三级缓存已经存在，可以获取早期引用。 2.2.2.4 获取springTransactionService早期引用获取springTransactionService 时，依然是getBean作为入口由于springTransactionService 已经完成createInstance 放入了第三级缓存，此时getSingleton(beanName )方法是可以获取到早期引用的， 获取早期引用的逻辑如下以singletonFactory.getObject 为入口，进入三级缓存获取早期引用的逻辑AbstractAutoProxyCreator.getEarlyBeanReference 经过AbstractAutoProxyCreator 这个BeanPostProcessor 处理，其earlyProxyReferences 记录了springTransactionService曾来获取过早期引用， 并最终返回了一个CGLIB 动态代理对象 ⚠️ wrapIfNecessary 只对需要产生代理的对象生成代理对象，不需要产生代理的对象会直接返回原对象.在这个例子中是springTransactionService 代理对象的引用 getEarlyBeanReference 返回的数据，即singletonFactory.getObject 获取到数据会放到第二级缓存中，同时删除第三级缓存。 2.2.2.5 userService init现在 userService populate 阶段结束，开始init 阶段，省略其他部分，只看AutoProxyCreator这个BeanPostProcessor. 由于userService 之前没有获取过早期引用， 所以earlyProxyReferences 并不存在userService,this.earlyProxyReferences.remove(cacheKey) 返回null, 需要进入wrapIfNecessary 逻辑，由于userService 符合LoggingAspect 切点表达式，经过wrapIfNecessary 后， 会生成userService的动态代理对象 2.2.2.6 earlySingletonExposure由于目前为止，userService 并没有触发早期引用的暴露逻辑，即从三级缓存中获取早期引用放到二级缓存中的逻辑，所以一级缓存，二级缓存中均不存在userService, 所以getSingleton(beanName, false)会返回null， 因此userService不需要进行早期引用暴露的特殊处理，直接返回实例化完成的bean 即可（有可能是原始bean, 也有可能是代理对象，在这个例子中是代理对象） 2.2.2.7 一级缓存实例化完成的userService 会放入一级缓存中，同时删除二、三级缓存，确保一个bean 在同一时刻只会存在于某一级缓存中 2.2.3 springTransactionService initspringTransactionService populate 阶段完成，现在来到init阶段，只看我们关心的 AbstractAutoProxyCreator.postProcessAfterInitialization由于前面在userService 的实例化过程中，我们已经通过getEarlyBeanReference获取过springTransactionService的早期引用(且是经过springTransactionService包装过的代理对象引用) 所以earlyProxyReferences中已经记录了springTransactionService相关数据，且和传进来bean数据一致，所以这里的逻辑会直接返回，而不是再走一遍wrapIfNecessary逻辑。 2.2.4 earlySingletonExposure现在springTransactionService 已经完成了实例化的3个阶段，逻辑来到doCreateBean中最后关于循环依赖和早期引用的处理逻辑 由于在userService 的实例化过程中，springTransactionService已经提前暴露了引用，且是代理对象的引用， 所以getSingleton(beanName, false)会获取到其早期引用。 此时bean 与 exposedObject相等，说明在init阶段没有执行代理逻辑，doCreateBean 最终会返回提前暴露的引用earlySingletonReference 至此springTransactionService 经过和userService 的循环依赖处理，已经成功初始化。userService 也成功初始化，后续在对userService 执行getBean 操作都会直接从一级缓存中获取。 下面来看三级缓存无法解决的循环依赖 3. AbstractAdvisingBeanPostProcessor 引发的异常在Spring 启动过程中，能为bean 生成代理对象的不止AbstractAutoProxyCreator 一个， AbstractAdvisingBeanPostProcessor也可以为bean 生成一个代理对象 AbstractAdvisingBeanPostProcessor 也是一个BeanPostProcessor ， 因此也可以在init 阶段通过postProcessAfterInitialization方法介入bean 的生命周期。 123456789101112131415161718192021222324252627282930313233343536public abstract class AbstractAdvisingBeanPostProcessor extends ProxyProcessorSupport implements BeanPostProcessor &#123; @Override public Object postProcessAfterInitialization(Object bean, String beanName) &#123; if (this.advisor == null || bean instanceof AopInfrastructureBean) &#123; // Ignore AOP infrastructure such as scoped proxies. return bean; &#125; if (bean instanceof Advised) &#123; Advised advised = (Advised) bean; if (!advised.isFrozen() &amp;&amp; isEligible(AopUtils.getTargetClass(bean))) &#123; // Add our local Advisor to the existing proxy&#x27;s Advisor chain... if (this.beforeExistingAdvisors) &#123; advised.addAdvisor(0, this.advisor); &#125; else &#123; advised.addAdvisor(this.advisor); &#125; return bean; &#125; &#125; if (isEligible(bean, beanName)) &#123; ProxyFactory proxyFactory = prepareProxyFactory(bean, beanName); if (!proxyFactory.isProxyTargetClass()) &#123; evaluateProxyInterfaces(bean.getClass(), proxyFactory); &#125; proxyFactory.addAdvisor(this.advisor); customizeProxyFactory(proxyFactory); return proxyFactory.getProxy(getProxyClassLoader()); &#125; // No proxy needed. return bean; &#125;&#125; 查看AbstractAdvisingBeanPostProcessor.postProcessAfterInitialization代码，可以看到也是生成代理对象的diamanté，其逻辑进入getProxy就和之前 讲过代理创建流程 完全一致，就不进入细节去分析了12345public class ProxyFactory extends ProxyCreatorSupport &#123; public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); &#125;&#125; 那实际生产开发中，有两个注解会用到AbstractAdvisingBeanPostProcessor ， 如果使用不当，就会引发无法解决的循环依赖，从而导致Spring 容器启动失败 3.1 @Repository注解-PersistenceExceptionTranslationPostProcessor在Spring中，@Repository 注解主要用于标记数据访问层（DAO）。相比 @Component（通用Bean 注解）、@Service（用于对Service实现类进行标注） 和 @Controller（用于对Controller实现类进行标注），@Repository 注解的一个显著区别在于它的异常处理机制。 Spring为@Repository 提供了一个特殊的处理机制，自动将数据访问异常转换为 Spring 的统一数据访问异常层次结构（如 DataAccessException）。@Service 和 @Controller 没有这种特定的异常处理机制。它们的异常处理通常依赖于全局异常处理器（如 @ControllerAdvice）或手动捕获和处理。 12345678@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Repository &#123; @AliasFor(annotation = Component.class) String value() default &quot;&quot;;&#125; 当使用 @Repository 注解时，Spring 会在后台自动注册一个 PersistenceExceptionTranslationPostProcessor。 PersistenceExceptionTranslationPostProcessor 继承了AbstractAdvisingBeanPostProcessor , 因此使用了@Repository注解的bean 在实例化完成后，最终生成的是其代理对象。 3.1.1 有动态代理的循环引用示例代码改造下SpringTransactionService , 将@Service 替换成@Repository， 其他代码保持不变。12345678910@Servicepublic class SpringTransactionService &#123; @Autowired UserService userService; public void performTransaction() &#123; // 模拟业务逻辑 System.out.println(&quot;performTransaction&quot;); &#125;&#125;启动该SpringBoot 项目，将报如下错误1org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#x27;springTransactionService&#x27;: Bean with name &#x27;springTransactionService&#x27; has been injected into other beans [userService] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using &#x27;getBeanNamesForType&#x27; with the &#x27;allowEagerInit&#x27; flag turned off, for example. 直接跟随debug 信息来到springTransactionService 实例化过程 阶段 getEarlyBeanReference在springTransactionService -&gt;userService -&gt; springTransactionService 循环依赖获取springTransactionService 的早期引用时， 在getEarlyBeanReference中，只有 AbstractAutoProxyCreator 这类BeanPostProcessor 才会执行。 AbstractAdvisingBeanPostProcessor不是 AbstractAutoProxyCreator ，所示PersistenceExceptionTranslationPostProcessor在 getEarlyBeanReference阶段是不会发挥作用的 postProcessAfterInitialization在springTransactionService 的init 阶段， 不会过滤 只有AbstractAutoProxyCreator 的子类执行，而是对所有的BeanPostProcessor 都执行其postProcessAfterInitialization 方法。AnnotationAwareAspectJAutoProxyCreator 里根据if (this.earlyProxyReferences.remove(cacheKey) != bean)判断，不会重复执行wrapIfNecessary, 直接返回入参bean 接着开始执行PersistenceExceptionTranslationPostProcessor 从图中可以看出，此时入参bean 依然是原始bean, 经过@Repository注解-PersistenceExceptionTranslationPostProcessor 处理后，原始入参bean又生成了一个的代理对象返回。 earlySingletonExposure 从图中可以看出， 最终返回的exposedObject 和提前暴露的earlySingletonReference 已经不是同一个实例了，earlySingletonReference 是经过AnnotationAwareAspectJAutoProxyCreator 生成的代对象， exposedObject 是PersistenceExceptionTranslationPostProcessor生成的地理对象，提前暴露的引用和最终生成的引用不一致，且该bean的早期引用已经被userService 依赖了，最终会走到报错逻辑 ==所以在实际生产开发中，关于注解的最佳实践一定是按照层级划分使用对应的注解== 3.2 @Async-AsyncAnnotationBeanPostProcessor@Async 是用于标识异步执行的注解，使用不当的话，会由于同样的原因造成无法解决的循环依赖。AsyncAnnotationBeanPostProcessor 同样继承了AbstractAdvisingBeanPostProcessor，因此会在init 阶段 为添加了@Async 注解的bean 生成代理对象 3.2.1 有动态代理的循环引用示例代码改造下SpringTransactionService , 将@Service 替换成@Repository， 其他代码保持不变。启动该SpringBoot 项目，会报同样的错误 12345678910111213@EnableAsync @Service public class SpringTransactionService &#123; @Autowired UserService userService; @Async public void performTransaction() &#123; // 模拟业务逻辑 System.out.println(&quot;performTransaction&quot;); &#125;&#125; 经过AsyncAnnotationBeanPostProcessor.post处理后，会为原始bean 生成一个代理对象，与暴露的早期引用不一致，最终会报错 3.3 ## BeanPostProcessor的不同过滤条件在AbstractAdvisingBeanPostProcessor 引发异常的这2个例子中，能够看出，有机会对bean 生成代理的2处逻辑，对要执行的BeanPostProcessor有不同的过滤条件 12345678910111213141516171819202122232425262728293031public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; return exposedObject; &#125; @Override public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) &#123; Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) &#123; return result; &#125; result = current; &#125; return result; &#125;&#125; getEarlyBeanReference 中只执行 AbstractAutoProxyCreator的子类，在Springboot 启动的项目中，就是AnnotationAwareAspectJAutoProxyCreator 在init 阶段的applyBeanPostProcessorsAfterInitialization 中，会执行所有BeanPostProcessor 所以在有动态代理的循环依赖+暴露引用的时候，如果其中包含了除AbstractAutoProxyCreator子类外可生成代理的BeanPostProcessor， 就会产生一个类的2个实例，违反单例模式报错。 分析到这，可以看出，一个bean 只要暴露了早期引用，那么在init 阶段就绝不能再执行任何生成代理的操作了，因为一旦有代理操作就会再生成一个新的引用，就会有问题。 如果没有暴露早期引用，init 阶段随便几个代理操作都行。 比如把SpringTransactionService 中的userService 去掉， 把前面提到的各种可以生成代理的操作全部叠加，启动都是没有问题的123456789@EnableAsync @Repositorypublic class SpringTransactionService &#123; @Async public void performTransaction() &#123; // 模拟业务逻辑 System.out.println(&quot;performTransaction&quot;); &#125;&#125; 4. 存在多个 AbstractAutoProxyCreator再来分析另外一种 有多个AbstractAutoProxyCreator spring默认保证一个容器中只能有一个AbstractAutoProxyCreator 子类存在 ，如过手动添加或者自定义会出现多个APC情况。 这里直接分析源码，假设有2个AbstractAutoProxyCreator 子类存在。 4.1 getEarlyBeanReference来看下早期引用的获取逻辑 123456789101112131415161718192021222324public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (SmartInstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().smartInstantiationAware) &#123; exposedObject = bp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; return exposedObject; &#125;&#125;public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; @Override public Object getEarlyBeanReference(Object bean, String beanName) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey); &#125;&#125; 由于在调用AbstractAutoProxyCreator.getEarlyBeanReference时， 每次入参bean 其实都是上一个AbstractAutoProxyCreator处理结果。 对于第一层代理来说earlySingletonReferences这个map 中的value 是原始bean对于第二层代理来说earlySingletonReferences这个map 中的value 是第一层代理生成的代理对象。 ⚠️ 每个AbstractAutoProxyCreator实例都有自己的earlySingletonReferences 所以那么第2层代理实际是对第一层代理生成的代理对象又代理了一层，最终生成的早期引用，即放入第二级缓存的数据也是第二层代理对象 4.2 postProcessAfterInitialization那么当来到init阶段的bean后处理逻辑当执行第一层代理的postProcessAfterInitialization时，入参bean 时原始bean, 第一层代理earlySingletonReferences 中能找到对应的值，不会重复执行wrapIfNecessary逻辑，直接返回入参原始bean。 继续执行for循环，来到第二层代理，第二层代理earlySingletonReference 存储的是bean 第一层代理的引用， 这里入参bean 还是原始bean， this.earlyProxyReferences.remove(cacheKey) != bean条件成立，会执行wrapIfNecessary逻辑次 会创建一个新的代理对象，经过第二层代理处理后，init 阶段返回的exposedObject已经和提前暴露的早期引用不一致了，会报错。 12345678910111213141516171819202122232425262728293031public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; // 生成了早期引用的bean缓存， private final Map&lt;Object, Object&gt; earlyProxyReferences = new ConcurrentHashMap&lt;&gt;(16); @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; // 如果 `bean` 为 `null`，则直接返回 `null`。 if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125;&#125;public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125;&#125; 5. 解决方案 使用合理的Bean注解 使用@Lazy 注解 重构你的代码 6.参考文章Spring循环依赖那些事儿（含Spring详细流程图） 一文详解 Spring Bean 循环依赖","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Understanding LSTM Networks","slug":"Understanding-LSTM-Networks","date":"2024-07-16T10:07:01.000Z","updated":"2024-09-05T11:49:33.684Z","comments":true,"path":"4579c6a3/","permalink":"http://example.com/4579c6a3/","excerpt":"","text":"Understanding LSTM Networks Recurrent Neural Networks递归神经网络Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.人类不会每秒都从头开始思考。当你阅读这篇文章时，你会基于对之前词语的理解来理解每个词。你不会把所有东西都丢掉然后重新开始思考。你的思维是有连续性的。 Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.传统的神经网络做不到这一点，这似乎是一个主要的缺陷。比如，想象一下你想对电影中每个时刻发生的事件类型进行分类。目前尚不清楚传统的神经网络如何利用其对电影中先前事件的推理来为后来的事件提供信息。 Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.循环神经网络解决了这个问题。它们是内部带有循环的网络，允许信息持续存在。 Recurrent Neural Networks have loops. 递归神经网络有循环。 In the above diagram, a chunk of neural network, 𝐴, looks at some input $𝑥_𝑡$ and outputs a value $ℎ_𝑡$. A loop allows information to be passed from one step of the network to the next.在上图中，神经网络的一部分 $A$ ,查看一些输入$x_t​$ 并输出一个值 $h_t$。一个循环允许信息从网络的一个步骤传递到下一个步骤。 These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren’t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop:这些循环使循环神经网络看起来有点神秘。然而，如果你多想一点，就会发现它们与普通的神经网络并没有太大的不同。递归神经网络可以被认为是同一网络的多个副本，每个副本将消息传递给继任者。考虑一下如果我们展开循环会发生什么：An unrolled recurrent neural network. 展开的循环神经网络。 This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data.这种链式结构表明，递归神经网络与序列和列表密切相关。它们是处理此类数据的自然神经网络架构。 And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning… The list goes on. I’ll leave discussion of the amazing feats one can achieve with RNNs to Andrej Karpathy’s excellent blog post, The Unreasonable Effectiveness of Recurrent Neural Networks. But they really are pretty amazing.他们当然被使用了！在过去的几年里，将RNN应用于各种问题取得了令人难以置信的成功：语音识别、语言建模、翻译、图像字幕……这样的例子不胜枚举。我将把关于RNN可以实现的惊人壮举的讨论留给Andrej Karpathy的优秀博客文章，递归神经网络的不合理有效性。但他们真的非常了不起。 Essential to these successes is the use of “LSTMs,” a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It’s these LSTMs that this essay will explore.这些成功的关键是“LSTM”的使用，这是一种非常特殊的递归神经网络，对于许多任务，它比标准版本要好得多。几乎所有基于递归神经网络的令人兴奋的结果都是通过它们实现的。本文将探讨的正是这些 LSTM。 The Problem of Long-Term Dependencies长期依赖性问题 One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they’d be extremely useful. But can they? It depends.RNN的吸引力之一是，它们可能能够将先前的信息与当前任务联系起来，例如使用以前的视频帧可能会为理解当前帧提供信息。如果RNN可以做到这一点，它们将非常有用。但是他们能做到吗？这要视情况而定。 Sometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in “the clouds are in the _sky_,” we don’t need any further context – it’s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.有时候，我们只需要查看最近的信息就可以完成当前的任务。例如，考虑一个语言模型,它尝试基于前面的单词来预测下一个单词。如果我们试图预测“the clouds are in the sky”中的最后一个单词，我们不需要任何进一步的上下文——很明显下一个单词将是sky。在这种情况下，相关信息和所需位置之间的间隔较小，RNNs可以学习使用过去的信息。 But there are also cases where we need more context. Consider trying to predict the last word in the text “I grew up in France… I speak fluent _French_.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.但在某些情况下，我们需要更多的背景信息。考虑试图预测文本“I grew up in France… I speak fluent French.”中的最后一个单词。最近的信息表明下一个单词可能是某种语言的名称，但如果我们想缩小语言范围，我们需要更早的法国这一背景信息。相关信息和需要使用该信息的点之间的间隔完全有可能变得非常大。 Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.不幸的是，随着这种间隔的扩大，RNN变得无法学习去连接信息。 In theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by Hochreiter (1991) [German] and Bengio, et al. (1994), who found some pretty fundamental reasons why it might be difficult.理论上，RNNs完全有能力处理这种“长期依赖”。人类可以仔细挑选参数，使它们解决这种形式的玩具问题。遗憾的是，在实际应用中，RNNs似乎无法学会它们。这个问题在Hochreiter（1991）和Bengio等人（1994）的研究中得到了深入探讨，他们发现了一些可能导致这一困难的基本原因。 Thankfully, LSTMs don’t have this problem!值得庆幸的是，LSTM 没有这个问题！ LSTM NetworksLong Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter &amp; Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.长短期记忆网络——通常简称为“LSTMs”——是一种特殊的RNN，能够学习长期依赖。它们由Hochreiter和Schmidhuber（1997）引入，并在随后的工作中被许多人改进和推广。LSTMs在大量不同的问题上表现出色，现在被广泛使用。 LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!LSTMs被明确设计用于避免长期依赖问题。记住长时间的信息几乎是它们的默认行为，而不是它们需要努力学习的东西！ All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.所有递归神经网络都具有神经网络重复模块链的形式。在标准 RNN 中，该重复模块将具有非常简单的结构，例如单个 tanh 层。 The repeating module in a standard RNN contains a single layer.标准 RNN 中的重复模块包含单层。 LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.LSTM 也具有这种链状结构，但重复模块具有不同的结构。不是只有一个神经网络层，而是有四个，以一种非常特殊的方式进行交互。 The repeating module in an LSTM contains four interacting layers.LSTM 中的重复模块包含四个交互层。 Don’t worry about the details of what’s going on. We’ll walk through the LSTM diagram step by step later. For now, let’s just try to get comfortable with the notation we’ll be using.不用担心具体的细节。我们稍后会一步步讲解LSTM的图表。现在，让我们先熟悉一下我们将要使用的符号。In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.在上图中，每条线都带有一个完整的向量，从一个节点的输出到其他节点的输入。粉红色的圆圈代表逐点运算，如向量加法，而黄色框是学习的神经网络层。合并的行表示串联，而分叉的行表示正在复制其内容并将副本发送到不同的位置。 The Core Idea Behind LSTMsLSTM 背后的核心思想 The key to LSTMs is the cell state, the horizontal line running through the top of the diagram.LSTMs的关键是单元状态，这条横线贯穿了图表的顶部。 The cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for information to just flow along it unchanged.单元状态有点像传送带。它直接沿着整个链条运行，只有一些小的线性交互。信息可以非常容易地沿着它不变地流动。 The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.LSTM确实具有从单元状态中移除或添加信息的能力，这些操作由称为门控的结构严格调控。 Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.门控是一种选择性地让信息通过的方式。它们由一个sigmoid神经网络层和一个逐点乘法操作组成。The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”sigmoid 层输出介于 0 和 1 之间的数字，描述每个组件应通过多少。值为零表示“什么都不让通过”，而值为 1 表示“让所有东西都通过！” An LSTM has three of these gates, to protect and control the cell state.LSTM 有三个这样的门，用于保护和控制单元状态。 Step-by-Step LSTM Walk Through循序渐进的 LSTM 演练 forget gate layerThe first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “forget gate layer.” It looks at $h_{t−1}$ and $x_t$, and outputs a number between 00 and 11 for each number in the cell state $C_{t−1}$. A 1 represents “completely keep this” while a 0 represents “completely get rid of this.”LSTM的第一步是决定要从单元状态中丢弃哪些信息。这个决策是由一个名为“遗忘门层”的sigmoid层做出的。它查看 $h_{t-1}​$ 和 $x_t$，并为单元状态 $C_{t-1}$ 中的每个数字输出一个介于0和1之间的数值。1表示“完全保留这个”，而0表示“完全丢弃这个”。 Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.让我们回到我们的例子，一个语言模型试图基于所有前面的单词来预测下一个单词。在这样的问题中，单元状态可能包含当前主语的性别，以便使用正确的代词。当我们看到一个新的主语时，我们想忘记旧主语的性别。 input gate layerThe next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a sigmoid layer called the “input gate layer” decides which values we’ll update. Next, a tanh layer creates a vector of new candidate values, $\\tilde{C}_t$, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.下一步是决定要在单元状态中存储哪些新信息。这包括两个部分。首先，一个名为“输入门层”的sigmoid层决定我们将更新哪些值。接下来，一个tanh层创建一个新的候选值向量$\\tilde{C}_t$，这些候选值可以被添加到状态中。在下一步中，我们将结合这两部分来更新状态。 In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.在我们的语言模型示例中，我们希望将新主语的性别添加到单元格状态中，以替换我们忘记的旧主语。 It’s now time to update the old cell state$C_{t-1}$, into the new cell state $C_t$​. The previous steps already decided what to do, we just need to actually do it.现在是时候将旧的单元格状态$C_{t-1}$更新为新的单元格状态 $C_t$​了。前面的步骤已经决定了要做什么，我们只需要实际去执行它。 We multiply the old state by $𝑓_𝑡$, forgetting the things we decided to forget earlier. Then we add $i_t \\ast \\tilde{C}_t$. This is the new candidate values, scaled by how much we decided to update each state value.我们将旧状态乘以 $f_t$，忘记我们之前决定忘记的内容。然后我们加上 $i_t \\ast \\tilde{C}_t$。这些是新的候选值，按我们决定更新每个状态值的程度进行缩放。 In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.在语言模型的情况下，正如我们在前面的步骤中决定的那样，我们实际上会删除有关旧主题性别的信息并添加新信息。 output layerFinally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.最后，我们需要决定输出什么。这个输出将基于我们的单元状态，但会是一个过滤后的版本。首先，我们运行一个sigmoid层来决定要输出单元状态的哪些部分。然后，我们将单元状态通过tanh（将值压缩到-1到1之间），并将其与sigmoid门的输出相乘，这样我们只输出我们决定输出的部分。 For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.对于语言模型的例子，由于它刚刚看到一个主语，它可能想输出与动词相关的信息，以防接下来需要动词。例如，它可能会输出主语是单数还是复数，这样我们就知道如果接下来是动词，该动词应该变成什么形式。 Variants on Long Short Term Memory长短期记忆的变体 What I’ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it’s worth mentioning some of them.我到目前为止描述的是一个相当普通的LSTM。但并不是所有的LSTM都与上述相同。实际上，几乎每篇涉及LSTM的论文都使用了稍微不同的版本。这些差异很小，但值得一提。 One popular LSTM variant, introduced by Gers &amp; Schmidhuber (2000), is adding “peephole connections.” This means that we let the gate layers look at the cell state.一个由Gers和Schmidhuber（2000）引入的流行LSTM变体是添加“窥视连接”。这意味着我们让门控层查看单元状态。 The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.上图为所有门控添加了窥视连接，但许多论文会只为部分门控添加窥视连接，而不是全部。 Another variation is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.另一种变体是使用耦合的遗忘门和输入门。我们不是分别决定要忘记什么以及要添加什么新信息，而是将这些决策结合在一起。我们只有在要输入新信息时才会忘记某些内容。只有在忘记旧信息时，我们才会将新值输入到状态中。 A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by Cho, et al. (2014). It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.LSTM的一个稍微更显著的变体是门控循环单元（GRU），由Cho等人（2014）引入。它将遗忘门和输入门组合成一个“更新门”。它还合并了单元状态和隐藏状态，并做了一些其他的改变。最终的模型比标准的LSTM模型更简单，并且越来越受欢迎。 These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by Yao, et al. (2015). There’s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by Koutnik, et al. (2014).这些只是一些最著名的LSTM变体。还有许多其他变体，例如Yao等人（2015）提出的深度门控RNN。此外，还有一些完全不同的方法来解决长期依赖问题，例如Koutnik等人（2014）提出的时钟式RNN。 Which of these variants is best? Do the differences matter? Greff, et al. (2015) do a nice comparison of popular variants, finding that they’re all about the same. Jozefowicz, et al. (2015) tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.这些变体中哪一个最好？差异重要吗？Greff等人（2015）对流行变体进行了很好的比较，发现它们的表现几乎相同。Jozefowicz等人（2015）测试了超过一万种RNN架构，发现其中一些在某些任务上的表现比LSTMs更好。 Conclusion 结论Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!前面，我提到了人们用递归神经网络（RNNs）取得的显著成果。基本上所有这些成果都是使用LSTMs实现的。对于大多数任务，LSTMs的效果确实要好得多！ Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.作为一组方程写下来，LSTMs看起来相当令人生畏。希望通过在本文中一步一步地讲解它们，使它们变得更容易理解。 LSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, Xu, _et al._ (2015) do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…LSTMs是我们用RNNs能实现的一个大进步。很自然地会有人问：还有另一个大进步吗？研究人员的一个普遍看法是：“是的！下一个进步是注意力机制！”这个想法是让RNN的每一步都从一些更大的信息集合中选择要看的信息。例如，如果你使用RNN来创建描述图像的标题，它可能会为它输出的每个单词选择图像的一部分。事实上，Xu等人（2015）正是这样做的——如果你想探索注意力机制，这可能是一个有趣的起点！使用注意力机制已经取得了许多非常令人兴奋的成果，似乎还会有更多的成果即将到来…… Attention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by Kalchbrenner, _et al._ (2015) seem extremely promising. Work using RNNs in generative models – such as Gregor, _et al._ (2015), Chung, _et al._ (2015), or Bayer &amp; Osendorfer (2015) – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!注意力机制并不是RNN研究中唯一令人兴奋的方向。例如，Kalchbrenner等人（2015）的Grid LSTMs看起来非常有前途。在生成模型中使用RNN的工作——例如Gregor等人（2015）、Chung等人（2015）或Bayer和Osendorfer（2015）的工作——也非常有趣。过去几年是递归神经网络的激动人心的时期，未来几年只会更加激动人心！ Acknowledgments 确认I’m grateful to a number of people for helping me better understand LSTMs, commenting on the visualizations, and providing feedback on this post.我感谢许多人帮助我更好地理解 LSTM，对可视化进行评论，并对这篇文章提供反馈。 I’m very grateful to my colleagues at Google for their helpful feedback, especially Oriol Vinyals, Greg Corrado, Jon Shlens, Luke Vilnis, and Ilya Sutskever. I’m also thankful to many other friends and colleagues for taking the time to help me, including Dario Amodei, and Jacob Steinhardt. I’m especially thankful to Kyunghyun Cho for extremely thoughtful correspondence about my diagrams.我非常感谢 Google 同事提供的有益反馈，尤其是 Oriol Vinyals、Greg Corrado、Jon Shlens、Luke Villnis 和 Ilya Sutskever。我还要感谢许多其他朋友和同事抽出时间帮助我，包括 Dario Amodei 和 Jacob Steinhardt。我特别感谢 Kyunghyun Cho 对我的图表进行了非常周到的通信。 Before this post, I practiced explaining LSTMs during two seminar series I taught on neural networks. Thanks to everyone who participated in those for their patience with me, and for their feedback.在这篇文章之前，我在我教授的关于神经网络的两个系列研讨会上练习了解释 LSTM。感谢所有参与活动的人对我的耐心和反馈。 注释-如何理解门控结构的计算根据前面的文章， 我们已经知道基础 神经网络和 基础RNN 中，数据从输入层到隐藏层到输出层的计算，这里再复习一下 基础神经网络隐藏层$h_t​=f(W_{xh​}x_t​+b_h​)$ $x_t$​：当前输入 $W_{xh}$：输入层到隐藏层的权重矩阵 $b_h$​：偏置 $f$：激活函数（如tanh或ReLU） 计算隐藏状态分为2个步骤 计算隐藏层的输入加权和： 应用激活函数，计算隐藏层的输出基础RNN RNN的隐藏层具有循环连接，即多了一个隐藏层到隐藏层的权重矩阵参与计算 ，使得每个隐藏状态依赖于前一时间步的隐藏状态和当前时间步的输入。公式如下：$h_t​=f(W_{hh}​h_{t−1}​+W_{xh​}x_t​+b_h​)$ $h_t​$：当前时间步的隐藏状态 $h_{t-1}$：前一时间步的隐藏状态 $x_t$​：当前时间步的输入 $W_{hh}$​：隐藏状态到隐藏状态的权重矩阵 $W_{xh}$：输入到隐藏状态的权重矩阵 $b_h$​：偏置 $f$：激活函数（如tanh或ReLU） 从上面文章中可以看到， 不论计算过程在复杂，都是要根据输入求输出。。 而在LSTM 中， 复杂的点在于。隐藏层的计算由简单的隐藏层-隐藏层权重矩阵参与计算 拆分成了多个步骤 LSTM1. 遗忘门（Forget Gate）遗忘门控制单元状态中哪些信息需要被保留或丢弃。遗忘门接收当前时间步的输入 $x_t$和前一时间步的隐藏状态 $h_{t-1}$，通过一个$Sigmoid$函数计算得到一个介于0和1之间的标量（或向量），用于缩放前一时间步的细胞状态。 公式如下： $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$如果把层级关系也在公式中体现出来，该公式可以细化成如下格式：$f_t^l = \\sigma(W_f \\cdot [h_{t-1}^l, x_t^{l-1}] + b_f)$ 其中 $x$ 也可以替换成其他变量，只要是代表当前时间步的输入即可。例如在 RECURRENT NEURAL NETWORK REGULARIZATION 该公式就表示成了 $f_t^l = \\sigma(W_f \\cdot [h_{t-1}^l, h_t^{l-1}] + b_f)$ $[h_t, x_{t-1}]$或者$[h_t^{l-1}, h_{t-1}^l]$表示将当前输入和前一时间步的隐藏状态向量拼接成一个向量。 $W_f​$ 是该遗忘门的权重矩阵。 $b_f$​ 是偏置向量。 $\\sigma$ 是$sigmoid$ 非线性激活函数，输出范围在0到1之间。 2. 输入门（Input Gate）输入门控制新信息写入单元状态的过程。输入门同样接收当前时间步的输入 $x_t$和前一时间步的隐藏状态 $h_{t-1}$，并通过Sigmoid函数生成一个介于0和1之间的标量，表示允许多少新信息进入细胞状态。0表示完全不允许新信息进入，1表示完全允许新信息进入。$tanh$层生成候选单元状态。 公式如下：$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$ $\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$ $W_i​$：输入门的权重矩阵，用于将前一时间步的隐藏状态和当前时间步的输入进行线性变换。$W_C​$：候选细胞状态的权重矩阵，用于将前一时间步的隐藏状态和当前时间步的输入进行线性变换。 3. 单元状态（Cell State）单元状态 $C_t$​ 是LSTM单元内部的长期记忆，它在时间步之间几乎直接传递，通过遗忘门和输入门的调节进行更新。新的单元状态由前一时间步的单元状态乘以遗忘门的输出加上输入门输出和候选值的乘积得到。 公式如下：$C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t$ 4. 输出门（Output Gate）- 得到隐藏状态输出门决定哪些信息从细胞状态传递到隐藏状态（LSTM单元的输出）。输出门通过Sigmoid函数决定哪些信息将被输出，并将细胞状态通过Tanh层处理后乘以该输出。 公式如下：$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$h_t = o_t \\cdot \\tanh(C_t)$","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"}]},{"title":"RECURRENT NEURAL NETWORK REGULARIZATION","slug":"RECURRENT-NEURAL-NETWORK-REGULARIZATION","date":"2024-06-12T10:10:58.000Z","updated":"2024-06-16T14:23:22.616Z","comments":true,"path":"7057a5e3/","permalink":"http://example.com/7057a5e3/","excerpt":"","text":"RECURRENT NEURAL NETWORK REGULARIZATION ABSTRACT 摘要We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most suc- cessful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation.我们提出了一种用于长短期记忆（LSTM）单元的循环神经网络（RNN）的简单正则化技术。最成功的正则化神经网络技术——Dropout，在RNN和LSTM上效果不好。在本文中，我们展示了如何正确地将Dropout应用于LSTM，并证明它在各种任务上显著减少了过拟合。这些任务包括语言建模、语音识别、图像描述生成和机器翻译。 1 INTRODUCTION 引言The Recurrent Neural Network (RNN) is neural sequence model that achieves state of the art per- formance on important tasks that include language modeling Mikolov (2012), speech recognition Graves et al. (2013), and machine translation Kalchbrenner &amp; Blunsom (2013). It is known that successful applications of neural networks require good regularization. Unfortunately, dropout Srivastava (2013), the most powerful regularization method for feedforward neural networks, does not work well with RNNs. As a result, practical applications of RNNs often use models that are too small because large RNNs tend to overfit. Existing regularization methods give relatively small improvements for RNNs Graves (2013). In this work, we show that dropout, when correctly used, greatly reduces overfitting in LSTMs, and evaluate it on three different problems. The code for this work can be found in https://github.com/wojzaremba/lstm. 递归神经网络（RNN）是一种神经序列模型，可在重要任务上实现最先进的性能，包括语言建模Mikolov（2012），语音识别Graves等人（2013）和机器翻译Kalchbrenner&amp;Blunsom（2013）。众所周知，神经网络的成功应用需要良好的正则化。不幸的是，dropout Srivastava （2013） 是前馈神经网络最强大的正则化方法，但不能很好地用于 RNN。因此，RNN 的实际应用通常使用太小的模型，因为大型 RNN 往往会过度拟合。现有的正则化方法对RNNs Graves（2013）进行了相对较小的改进。在这项工作中，我们表明，如果正确使用，压差可以大大减少LSTM中的过拟合，并在三个不同的问题上对其进行评估。 此工作的代码可以在https://github.com/wojzaremba/lstm找到。 2 RELATED WORKDropout Srivastava (2013) is a recently introduced regularization method that has been very suc- cessful with feed-forward neural networks. While much work has extended dropout in various ways Wang &amp; Manning (2013); Wan et al. (2013), there has been relatively little research in applying it to RNNs. The only paper on this topic is by Bayer et al. (2013), who focuses on “marginalized dropout” Wang &amp; Manning (2013), a noiseless deterministic approximation to standard dropout. Bayer et al. (2013) claim that conventional dropout does not work well with RNNs because the re- currence amplifies noise, which in turn hurts learning. In this work, we show that this problem can be fixed by applying dropout to a certain subset of the RNNs’ connections. As a result, RNNs can now also benefit from dropout.Dropout Srivastava（2013）是一种最近引入的正则化方法，在前馈神经网络中非常成功。尽管很多工作以各种方式扩展了Dropout Wang &amp; Manning（2013）；Wan等（2013），但在RNN上应用它的研究相对较少。关于这个主题的唯一论文是Bayer等人（2013）的，他们专注于“边缘化Dropout” Wang &amp; Manning（2013），这是标准Dropout的一种无噪声确定性近似。Bayer等人（2013）认为传统的Dropout在RNN上效果不好，因为递归放大了噪声，进而影响了学习。在这项工作中，我们展示了通过将Dropout应用于RNN连接的某个子集可以解决这个问题。因此，RNN现在也可以受益于Dropout。 Independently of our work, Pham et al. (2013) developed the very same RNN regularization method and applied it to handwriting recognition. We rediscovered this method and demonstrated strong empirical results over a wide range of problems. Other work that applied dropout to LSTMs is Pachitariu &amp; Sahani (2013).独立于我们的工作，Pham等人（2013）开发了完全相同的RNN正则化方法并将其应用于手写识别。我们重新发现了这种方法，并在广泛的问题上展示了强大的实证结果。其他将Dropout应用于LSTM的工作包括Pachitariu &amp; Sahani（2013）。 There have been a number of architectural variants of the RNN that perform better on problems with long term dependencies Hochreiter &amp; Schmidhuber (1997); Graves et al. (2009); Cho et al. (2014); Jaeger et al. (2007); Koutník et al. (2014); Sundermeyer et al. (2012). In this work, we show how to correctly apply dropout to LSTMs, the most commonly-used RNN variant; this way of applying dropout is likely to work well with other RNN architectures as well. In this paper, we consider the following tasks: language modeling, speech recognition, and machine translation. Language modeling is the first task where RNNs have achieved substantial success Mikolov et al. (2010; 2011); Pascanu et al. (2013). RNNs have also been successfully used for speech recognition Robinson et al. (1996); Graves et al. (2013) and have recently been applied to machine translation, where they are used for language modeling, re-ranking, or phrase modeling Devlin et al. (2014); Kalchbrenner &amp; Blunsom (2013); Cho et al. (2014); Chow et al. (1987); Mikolov et al. (2013).已经有许多RNN的架构变体在处理长期依赖问题上表现更好： Hochreiter &amp; Schmidhuber (1997); Graves等（2009）；Cho等（2014）；Jaeger等（2007）；Koutník等（2014）；Sundermeyer等（2012）。在这项工作中，我们展示了如何正确地将dropout应用于LSTM，这是最常用的RNN变体；这种应用dropout的方法也可能适用于其他RNN架构。在本文中，我们考虑了以下任务：语言建模、语音识别和机器翻译。语言建模是RNN首次取得显著成功的任务 Mikolov等（2010；2011）；Pascanu等（2013）。RNN也已成功应用于语音识别 Robinson等（1996）；Graves等（2013），并且最近被应用于机器翻译，在那里它们被用于语言建模、重排序或短语建模 Devlin等（2014）；Kalchbrenner &amp; Blunsom（2013）；Cho等（2014）；Chow等（1987）；Mikolov等（2013）。 3 REGULARIZING RNNS WITH LSTM CELLS 使用LSTM单元对RNN进行正则化In this section we describe the deep LSTM (Section 3.1). Next, we show how to regularize them (Section 3.2), and explain why our regularization scheme works.在本节中，我们描述了深度LSTM（3.1节）。接下来，我们展示如何对它们进行正则化（3.2节），并解释我们的正则化方案为何有效。 We let subscripts denote timesteps and superscripts denote layers. All our states are n-dimensional. Let $h_t^l \\in \\mathbb{R}^n$ be a hidden state in layer$l$ in timestep $t$. Moreover, let $T_{n,m} : \\mathbb{R}^n \\to \\mathbb{R}^m$be an affine transform ($Wx + b$ for some $W$ and $b$). Let $\\odot$ be element-wise multiplication and let $h_t^0​$ be an input word vector at timestep $k$. We use the activations $h_t^L$​ to predict $y_t$​, since $L$ is the number of layers in our deep LSTM.我们用下标表示时间步长，用上标表示层次。我们所有的状态都是n维的。令$h_t^l \\in \\mathbb{R}^n$ 为时间步$t$中层$l$的隐藏状态。此外，令$T_{n,m} : \\mathbb{R}^n \\to \\mathbb{R}^m$为仿射变换（某些$W$和$b$,$Wx + b$）。令$\\odot$为逐元素乘法，并令$h_t^0$​为时间步$k$的输入词向量。我们使用激活值$h_t^L$​来预测$y_t​$，因为$L$是我们深度LSTM的层数。 3.1 LONG-SHORT TERM MEMORY UNITS 长短期记忆单元The RNN dynamics can be described using deterministic transitions from previous to current hidden states. The deterministic state transition is a functionRNN的动态可以用从先前隐藏状态到当前隐藏状态的确定性转换来描述。确定性状态转换是一个函数 RNN : $h_t^{l-1}​$, $h_{t-1}^l \\rightarrow h_t^l$ For classical RNNs, this function is given by$h_t^l = f(T_{n,n} h_t^{l-1} + T_{n,n} h_{t-1}^l), where f \\in \\{\\text{sigm, tanh}\\}$ The LSTM has complicated dynamics that allow it to easily “memorize” information for an extended number of timesteps. The “long term” memory is stored in a vector of memory cells $c_t^l \\in \\mathbb{R}^n$. Although many LSTM architectures that differ in their connectivity structure and activation functions, all LSTM architectures have explicit memory cells for storing information for long periods of time. The LSTM can decide to overwrite the memory cell, retrieve it, or keep it for the next time step. The LSTM architecture used in our experiments is given by the following equations Graves et al. (2013):LSTM具有复杂的动态，允许它轻松地“记住”多个时间步长的信息。“长期”记忆存储在记忆单元向量$c_t^l \\in \\mathbb{R}^n$中。尽管许多LSTM架构在连接结构和激活函数上有所不同，但所有LSTM架构都有明确的记忆单元用于长时间存储信息。LSTM可以决定覆盖记忆单元、检索或者在下一个时间步中保留它。我们实验中使用的LSTM架构由以下方程给出 Graves等（2013）： LSTM : $h_t^{l-1}$, $h_{t-1}^l$, $c_{t-1}^l \\rightarrow h_t^l$​, $c_t^l$ $\\left( \\begin{array}{c} i \\ f \\ o \\ g \\end{array} \\right) = \\left( \\begin{array}{c} \\text{sigm} \\ \\text{sigm} \\ \\text{sigm} \\ \\text{tanh} \\end{array} \\right) T_{2n,4n} \\left( \\begin{array}{c} h_{t}^{l-1} \\ h_{t-1}^{l} \\end{array} \\right)​$ $c_t^l = f \\odot c_{t-1}^l + i \\odot g$ $h_t^l = o \\odot \\text{tanh}(c_t^l)$In these equations, sigm and tanh are applied element-wise. Figure 1 illustrates the LSTM equations.在这些方程中，sigm和tanh逐元素应用。图1展示了LSTM方程 3.2 REGULARIZATION WITH DROPOUTThe main contribution of this paper is a recipe for applying dropout to LSTMs in a way that success-fully reduces overfitting. The main idea is to apply the dropout operator only to the non-recurrent本文的主要贡献是提供了一种将dropout应用于LSTM的方法，从而成功地减少了过拟合。主要思想是仅将dropout操作符应用于非递归连接。Figure 1: A graphical representation of LSTM memory cells used in this paper (there are minor differences in comparison to Graves (2013)).图1：本文中使用的LSTM记忆单元的图形表示（与Graves（2013）相比有细微差别）。 Figure 2: Regularized multilayer RNN. The dashed arrows indicate connections where dropout is applied, and the solid lines indicate connections where dropout is not applied.图2：正则化的多层RNN。虚线箭头表示应用了dropout的连接，实线表示未应用dropout的连接。⚠️： x 表示输入层， y 表示输出层 connections (Figure 2). The following equation describes it more precisely, where D is the dropoutoperator that sets a random subset of its argument to zero:连接（图2）。以下方程更准确地描述了这一点，其中 $D$ 是将其参数的随机子集设置为零的dropout操作符： $\\left( \\begin{array}{c} i \\ f \\ o \\ g \\end{array} \\right) = \\left( \\begin{array}{c} \\text{sigm} \\ \\text{sigm} \\ \\text{sigm} \\ \\text{tanh} \\end{array} \\right) T_{2n,4n} \\left( \\begin{array}{c} {D}(h_{t}^{l-1}) \\ h_{t-1}^{l} \\end{array} \\right)​$ $c_t^l = f \\odot c_{t-1}^l + i \\odot g$ $h_t^l = o \\odot \\text{tanh}(c_t^l)$ Our method works as follows. The dropout operator corrupts the information carried by the units,forcing them to perform their intermediate computations more robustly. At the same time, we do not want to erase all the information from the units. It is especially important that the units rememberevents that occurred many timesteps in the past. Figure 3 shows how information could flow from an event that occurred at timestep t − 2 to the prediction in timestep t + 2 in our implementation of dropout. We can see that the information is corrupted by the dropout operator exactly L + 1 times,我们的方法如下。dropout 运算符会破坏单元携带的信息，迫使它们更稳健地执行中间计算。同时，我们不想抹去单元的所有信息。特别重要的是，单元需要记住许多时间步长之前发生的事件。图3显示了在我们实现的dropout中，信息如何从时间步 $t-2$ 传递到时间步 $t+2$ 的预测。我们可以看到，信息恰好被dropout操作符破坏了 $L+1$ 次。 Figure 3: The thick line shows a typical path of information flow in the LSTM. The information is affected by dropout L + 1 times, where L is depth of network.图 3：粗线显示了 LSTM 中信息流的典型路径。信息受 L + 1 次的dropout影响，其中 L 是网络深度。 Figure 4: Some interesting samples drawn from a large regularized model conditioned on “The meaning of life is”. We have removed “unk”, “N”, “$” from the set of permissible words.图4：从一个以“The meaning of life is”为条件的大型正则化模型中抽取的一些有趣样本。我们已经从允许的单词集中移除了“unk”、“N”、“$”。 and this number is independent of the number of timesteps traversed by the information. Standard dropout perturbs the recurrent connections, which makes it difficult for the LSTM to learn to store information for long periods of time. By not using dropout on the recurrent connections, the LSTM can benefit from dropout regularization without sacrificing its valuable memorization ability.这个数字与信息经过的时间步数无关。标准的dropout会扰乱递归连接，这使得LSTM难以学习长时间存储信息。通过不在递归连接上使用dropout，LSTM可以从dropout正则化中受益，而不牺牲其宝贵的记忆能力。 4 EXPERIMENTS 实验We present results in three domains: language modeling (Section 4.1), speech recognition (Section 4.2), machine translation (Section 4.3), and image caption generation (Section 4.4).我们在三个领域中展示了结果：语言建模（第4.1节）、语音识别（第4.2节）、机器翻译（第4.3节）和图像描述生成（第4.4节）。 4.1 LANGUAGE MODELING 语言建模We conducted word-level prediction experiments on the Penn Tree Bank (PTB) dataset Marcus et al. (1993), which consists of 929k training words, 73k validation words, and 82k test words. It has 10k words in its vocabulary. We downloaded it from Tomas Mikolov’s webpage†. We trained regularized LSTMs of two sizes; these are denoted the medium LSTM and large LSTM. Both LSTMs have two layers and are unrolled for 35 steps. We initialize the hidden states to zero. We then use the final hidden states of the current minibatch as the initial hidden state of the subsequent minibatch (successive minibatches sequentially traverse the training set). The size of each minibatch is 20.我们在Penn Tree Bank (PTB)数据集上进行了词级预测实验，该数据集包括92.9万个训练词、7.3万个验证词和8.2万个测试词。其词汇表有1万个单词。我们从Tomas Mikolov的网页下载了该数据集。我们训练了两种规模的正则化LSTM；它们分别被称为中型LSTM和大型LSTM。两个LSTM都有两层，展开35步。我们将隐藏状态初始化为零。然后我们使用当前小批量的最终隐藏状态作为后续小批量的初始隐藏状态（连续的小批量依次遍历训练集）。每个小批量的大小为20。 The medium LSTM has 650 units per layer and its parameters are initialized uniformly in [−0.05, 0.05]. As described earlier, we apply 50% dropout on the non-recurrent connections. We train the LSTM for 39 epochs with a learning rate of 1, and after 6 epochs we decrease it by a factor of 1.2 after each epoch. We clip the norm of the gradients (normalized by minibatch size) at 5. Training this network takes about half a day on an NVIDIA K20 GPU.中型LSTM每层有650个单元，其参数在[−0.05, 0.05]范围内均匀初始化。如前所述，我们在非递归连接上应用50%的dropout。我们用学习率为1训练LSTM共39个周期，在第6个周期后，每个周期将学习率按1.2的因子递减。我们将梯度的范数（按小批量大小归一化）剪裁到5。训练该网络在NVIDIA K20 GPU上大约需要半天时间。 The large LSTM has 1500 units per layer and its parameters are initialized uniformly in [−0.04, 0.04]. We apply 65% dropout on the non-recurrent connections. We train the model for 55 epochs with a learning rate of 1; after 14 epochs we start to reduce the learning rate by a factor of 1.15 after each epoch. We clip the norm of the gradients (normalized by minibatch size) at 10 Mikolov et al. (2010). Training this network takes an entire day on an NVIDIA K20 GPU.大型LSTM每层有1500个单元，其参数在[−0.04, 0.04]范围内均匀初始化。我们在非递归连接上应用65%的dropout。我们用学习率为1训练模型共55个周期；在第14个周期后，每个周期开始按1.15的因子递减学习率。我们将梯度的范数（按小批量大小归一化）剪裁到10 Mikolov等（2010）。训练该网络在NVIDIA K20 GPU上需要整整一天时间。 For comparison, we trained a non-regularized network. We optimized its parameters to get the best validation performance. The lack of regularization effectively constrains size of the network, forcing us to use small network because larger networks overfit. Our best performing non-regularized LSTM has two hidden layers with 200 units per layer, and its weights are initialized uniformly in [−0.1, 0.1]. We train it for 4 epochs with a learning rate of 1 and then we decrease the learning rate by a factor of 2 after each epoch, for a total of 13 training epochs. The size of each minibatch is 20, and we unroll the network for 20 steps. Training this network takes 2-3 hours on an NVIDIA K20 GPU.为了比较，我们训练了一个未正则化的网络。我们优化其参数以获得最佳验证性能。缺乏正则化有效地限制了网络的大小，迫使我们使用小型网络，因为较大的网络会过拟合。我们表现最好的未正则化LSTM有两层隐藏层，每层200个单元，其权重在[−0.1, 0.1]范围内均匀初始化。我们用学习率为1训练了4个周期，然后每个周期将学习率按2的因子递减，总共训练13个周期。每个小批量的大小为20，我们展开网络20步。训练该网络在NVIDIA K20 GPU上需要2-3小时。 Table 1 compares previous results with our LSTMs, and Figure 4 shows samples drawn from a single large regularized LSTM.表1比较了以前的结果和我们的LSTM，图4显示了从单个大型正则化LSTM中抽取的样本。 4.2 SPEECH RECOGNITION 语音识别Deep Neural Networks have been used for acoustic modeling for over half a century (see Bourlard &amp; Morgan (1993) for a good review). Acoustic modeling is a key component in mapping acoustic signals to sequences of words, as it models $p(s_t|X)$ where $s_t$​ is the phonetic state at time $t$ and $X$ is the acoustic observation. Recent work has shown that LSTMs can achieve excellent performance on acoustic modeling Sak et al. (2014), yet relatively small LSTMs (in terms of the number of their parameters) can easily overfit the training set. A useful metric for measuring the performance of acoustic models is frame accuracy, which is measured at each sts_tst​ for all timesteps ttt. Generally, this metric correlates with the actual metric of interest, the Word Error Rate (WER).深度神经网络已经被用于声学建模超过半个世纪（参见Bourlard &amp; Morgan (1993)的良好综述）。声学建模是将声学信号映射到单词序列中的关键组成部分，因为它对p(st∣X)p(s_t|X)p(st​∣X)建模，其中sts_tst​是时间ttt的语音状态，XXX是声学观测。最近的工作表明，LSTM在声学建模上可以取得优异的性能 Sak等（2014），但相对较小的LSTM（就参数数量而言）很容易对训练集过拟合。衡量声学模型性能的一个有用指标是帧准确率，它在所有时间步长ttt处测量每个sts_tst​的准确率。通常，这个指标与实际感兴趣的指标，即单词错误率（WER）相关。 Since computing the WER involves using a language model and tuning the decoding parameters for every change in the acoustic model, we decided to focus on frame accuracy in these experiments. Table 2 shows that dropout improves the frame accuracy of the LSTM. Not surprisingly, the training frame accuracy drops due to the noise added during training, but as is often the case with dropout, this yields models that generalize better to unseen data. Note that the test set is easier than the training set, as its accuracy is higher. We report the performance of an LSTM on an internal Google Icelandic Speech dataset, which is relatively small (93k utterances), so overfitting is a great concern.由于计算WER涉及使用语言模型并调整声学模型每次变化的解码参数，我们决定在这些实验中专注于帧准确率。表2显示了dropout提高了LSTM的帧准确率。不出所料，由于训练过程中加入的噪声，训练帧准确率下降了，但与dropout经常出现的情况一样，这使得模型在未见数据上的泛化能力更强。请注意，测试集比训练集更容易，因为它的准确率更高。我们报告了LSTM在Google内部冰岛语语音数据集上的性能，该数据集相对较小（93k句子），因此过拟合是一个很大的问题。 4.3 MACHINE TRANSLATION 机器翻译We formulate a machine translation problem as a language modelling task, where an LSTM is trained to assign high probability to a correct translation of a source sentence. Thus, the LSTM is trained on concatenations of source sentences and their translations Sutskever et al. (2014) (see also Cho et al. (2014)). We compute a translation by approximating the most probable sequence of words using a simple beam search with a beam of size 12. We ran an LSTM on the WMT’14 English to French dataset, on the “selected” subset from Schwenk (2014) which has 340M French words and 304M English words. Our LSTM has 4 hidden layers, and both its layers and word embeddings have 1000 units. Its English vocabulary has 160,000 words and its French vocabulary has 80,000 words. The optimal dropout probability was 0.2. Table 3 shows the performance of an LSTM trained with and without dropout. While our LSTM does not beat the phrase-based LIUM SMT system Schwenk et al. (2011), our results show that dropout improves the translation performance of the LSTM.我们将机器翻译问题表述为一个语言建模任务，其中LSTM被训练为对源句子的正确翻译赋予高概率。因此，LSTM在源句子及其翻译的串联上进行训练 Sutskever等（2014）（另见Cho等（2014））。我们通过使用大小为12的简单束搜索来近似最可能的单词序列来计算翻译。我们在WMT’14英法数据集上的“selected”子集（来自Schwenk（2014），包含3.4亿个法语单词和3.04亿个英语单词）上运行了一个LSTM。我们的LSTM有4个隐藏层，其层和词嵌入都有1000个单元。它的英语词汇量有160,000个单词，法语词汇量有80,000个单词。最佳的dropout概率是0.2。表3显示了使用和不使用dropout训练的LSTM的性能。虽然我们的LSTM没有击败基于短语的LIUM SMT系统 Schwenk等（2011），但我们的结果表明dropout提高了LSTM的翻译性能。 4.4 IMAGE CAPTION GENERATION图像描述生成We applied the dropout variant to the image caption generation model of Vinyals et al. (2014). The image caption generation is similar to the sequence-to-sequence model of Sutskever et al. (2014), but where the input image is mapped onto a vector with a highly-accurate pre-trained convolutional neural network (Szegedy et al., 2014), which is converted into a caption with a single-layer LSTM (see Vinyals et al. (2014) for the details on the architecture). We test our dropout scheme on LSTM as the convolutional neural network is not trained on the image caption dataset because it is not large (MSCOCO (Lin et al., 2014)).我们将dropout变体应用于Vinyals等人（2014）的图像描述生成模型。图像描述生成类似于Sutskever等人（2014）的序列到序列模型，但输入图像被映射到一个具有高精度的预训练卷积神经网络（Szegedy等人，2014）的向量，该向量通过单层LSTM转换为描述（有关架构的详细信息，请参见Vinyals等人，2014）。我们在LSTM上测试了我们的dropout方案，因为卷积神经网络并未在图像描述数据集上进行训练，因为它不是很大（MSCOCO（Lin等人，2014））。 Our results are summarized in the following Table 4. In brief, dropout helps relative to not using dropout, but using an ensemble eliminates the gains attained by dropout. Thus, in this setting, the main effect of dropout is to produce a single model that is as good as an ensemble, which is a reasonable improvement given the simplicity of the technique.我们的结果总结在以下表4中。简而言之，dropout相对于不使用dropout有帮助，但使用集成方法消除了通过dropout获得的收益。因此，在这种情况下，dropout的主要作用是产生一个与集成一样好的单一模型，考虑到该技术的简单性，这是一个合理的改进。 5 CONCLUSIONWe presented a simple way of applying dropout to LSTMs that results in large performance increases on several problems in different domains. Our work makes dropout useful for RNNs, and our results suggest that our implementation of dropout could improve performance on a wide variety of applications.我们提出了一种将dropout应用于LSTM的简单方法，这在不同领域的几个问题上导致了性能的大幅提升。我们的工作使dropout对RNN有用，并且我们的结果表明，我们实现的dropout可以提高各种应用的性能。 6 ACKNOWLEDGMENTSWe wish to acknowledge Tomas Mikolov for useful comments on the first version of the paper.我们希望感谢Tomas Mikolov对论文第一版提出的有益意见。 注释1. 元素乘法元素乘法（Element-wise multiplication），也称为Hadamard乘积（Hadamard product），是对两个同形矩阵或向量的对应元素进行逐一相乘的操作，广泛应用于各种线性代数和神经网络计算中。 用符号“⊙”表示。 公式表示给定两个相同大小的矩阵或向量 $A$ 和 $B$，其元素乘法 $C$ 计算如下：$C = A \\odot B$ 其中： $A = [a_1, a_2, …, a_n]$ $B = [b_1, b_2, …, b_n]$ $C = [c_1, c_2, …, c_n]$ $c_i = a_i \\cdot b_i$示例 假设有两个向量 $A$ 和 $B$： $A=[1,2,3]$$B=[4,5,6]$ 它们的元素乘法 $C$ 为：$C = A \\odot B = [1 \\cdot 4, 2 \\cdot 5, 3 \\cdot 6] = [4, 10, 18]$ 应用场景 神经网络中的LSTM： 用于更新单元状态，如公式 $c_t = f \\odot c_{t-1} + i \\odot \\tilde{c}_t$中。 图像处理： 用于图像滤波，将滤波器应用于图像的每个像素。 数据处理： 在数据预处理中，用于按元素缩放或调整数据。 2. 公式拆解:RNNRNN : $h_t^{l-1}​$, $h_{t-1}^l \\rightarrow h_t^l$ 表明在RNN中， 隐藏状态的计算结果依赖于当前时间步的输入 $h_t$和前一时间步的隐藏状态 $h_{t-1}$。 再细化一点， 当前时间步的输入 $h_t$ 应该来源于上一层，所以是 $h_t^{l-1}​$ 前一时间步的隐藏状态 $h_{t-1}$ ，应该是同一层的前一个时间步， 所以是$h_{t-1}^l$ 该状态转移过程，如果用具体的数学公式表示，可以如下所示$h_t^l = f(T_{n,n} h_t^{l-1} + T_{n,n} h_{t-1}^l), where f \\in \\{\\text{sigm, tanh}\\}$ 3. 公式拆解:LSTM 状态更新LSTM : $h_t^{l-1}$, $h_{t-1}^l$, $c_{t-1}^l \\rightarrow h_t^l$​, $c_t^l$描述了LSTM如何通过当前层的输入向量 $h_t^{l-1}$、前一时间步的隐藏状态 $h_{t-1}^l$和单元状态 $c_{t-1}^l$ 来生成新的隐藏状态 $h_t^l$ 和单元状态 $c_t^l$。 $h_t^{l-1}$：表示第 $l−1$ 层在时间步 $t$ 的隐藏状态向量。这是第 $l$ 层的当前输入。 $h_{t-1}^l$：表示第 $l$ 层在时间步 $t−1$ 的隐藏状态向量。这是第 $l$ 层的前一个时间步的状态。 $c_{t-1}^l$：表示第 $l$ 层在时间步 $t−1$的单元状态向量。这是第 $l$ 层的前一个时间步的单元状态。 $h_t^l$：表示第 $l$ 层在时间步 $t$ 的隐藏状态向量。这是经过第 $l$ 层计算后的新状态。 $c_t^l$：表示第 $l$ 层在时间步 $t$ 的新的单元状态向量。这是更新后的单元状态。 $\\left( \\begin{array}{c} i \\ f \\ o \\ g \\end{array} \\right) = \\left( \\begin{array}{c} \\text{sigm} \\ \\text{sigm} \\ \\text{sigm} \\ \\text{tanh} \\end{array} \\right) T_{2n,4n} \\left( \\begin{array}{c} h_{t}^{l-1} \\ h_{t-1}^{l} \\end{array} \\right)​$ 描述了输入门 $i$、遗忘门 $f$、输出门 $o$ 和候选记忆单元 $g$ 的计算。这里，矩阵 $T_{2n,4n}$​ 包含了相应的权重，输入包括当前输入 $h_t^{l-1}$和前一时间步的隐藏状态 $h_{t-1}^l$​ 输入门 $i$ 和 遗忘门 $f$ 控制信息的更新和遗忘，使用$sigmoid$激活函数。 输出门 $o$ 控制输出信息，使用$sigmoid$激活函数。 候选记忆单元 $g$ 提供新的信息内容，使用$tanh$激活函数。 权重矩阵 $T_{2n,4n}$ 一个大小为 $2n \\times 4n$ 的矩阵，其中 $n$ 是隐藏状态向量的维度。将输入向量 $h_t^{l-1}$​ 和隐藏状态向量 $h_{t-1}^l$ 拼接起来（向量长度为 $2n$），并通过矩阵 $T_{2n,4n}$​ 进行线性变换，生成一个长度为 $4n$ 的输出向量,即 $i, f, o, g$ 四个部分1. 遗忘门（Forget Gate） $f_t^l = \\sigma(W_f \\cdot [h_{t-1}^l, h_t^{l-1}] + b_f)$ $[h_t^{l-1}, h_{t-1}^l]$表示将当前输入和前一时间步的隐藏状态向量拼接成一个向量。 $W_f​$ 是该拼接向量的权重矩阵。 $b_f$​ 是偏置向量。 $\\sigma$ 是$sigmoid$激活函数，输出范围在0到1之间。 假设 $n = 4$： 当前输入向量 $h_t^{l-1}$为 $[h_1​,h_2​,h_3​,h_4​]$。 前一时间步的隐藏状态 $h_{t-1}^l$ 为 $[h_5, h_6, h_7, h_8]$ 拼接后的向量为：$[h_1, h_2, h_3, h_4, h_5, h_6, h_7, h_8]$ 权重矩阵 $W_f​$ 将此向量进行线性变换，生成一个长度为 $n$ 的向量。 线性变换进行线性变换的公式为：$z_f = W_f \\cdot [h_t^{l-1}, h_{t-1}^l] + b_f$ 具体步骤： 矩阵乘法： $W_f$是一个 $n \\times 2n$ 的矩阵，拼接向量是一个长度为 $2n$ 的向量。 通过矩阵乘法，结果是一个长度为 $n$ 的向量。 加偏置： 将得到的向量与偏置向量 $b_f$ 相加，仍然是一个长度为 $n$ 的向量。 例如，假设 $W_f$​ 和 $b_f$​ 为：$W_f = \\begin{pmatrix} w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} &amp; w_{15} &amp; w_{16} &amp; w_{17} &amp; w_{18} \\ w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} &amp; w_{25} &amp; w_{26} &amp; w_{27} &amp; w_{28} \\ w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34} &amp; w_{35} &amp; w_{36} &amp; w_{37} &amp; w_{38} \\ w_{41} &amp; w_{42} &amp; w_{43} &amp; w_{44} &amp; w_{45} &amp; w_{46} &amp; w_{47} &amp; w_{48} \\end{pmatrix}$ 拼接向量为：$[h_1, h_2, h_3, h_4, h_5, h_6, h_7, h_8]$ 矩阵乘法：$z_f = W_f \\cdot [h_1, h_2, h_3, h_4, h_5, h_6, h_7, h_8]$ 计算每个元素：$\\begin{aligned} z_{f1} &amp;= w_{11}h_1 + w_{12}h_2 + w_{13}h_3 + w_{14}h_4 + w_{15}h_5 + w_{16}h_6 + w_{17}h_7 + w_{18}h_8 \\ z_{f2} &amp;= w_{21}h_1 + w_{22}h_2 + w_{23}h_3 + w_{24}h_4 + w_{25}h_5 + w_{26}h_6 + w_{27}h_7 + w_{28}h_8 \\ z_{f3} &amp;= w_{31}h_1 + w_{32}h_2 + w_{33}h_3 + w_{34}h_4 + w_{35}h_5 + w_{36}h_6 + w_{37}h_7 + w_{38}h_8 \\ z_{f4} &amp;= w_{41}h_1 + w_{42}h_2 + w_{43}h_3 + w_{44}h_4 + w_{45}h_5 + w_{46}h_6 + w_{47}h_7 + w_{48}h_8 \\end{aligned}$ 加偏置：$z_f = \\begin{pmatrix} z_{f1} + b_1 \\ z_{f2} + b_2 \\ z_{f3} + b_3 \\ z_{f4} + b_4 \\end{pmatrix}$ sigmoid 非线性激活通过$sigmoid$激活函数得到遗忘门的激活值：$f_t^l = \\sigma(z_f)$通过 $sigmoid$ 非线性激活函数，得到遗忘门的激活值。 2. 输入门（Input Gate）计算输入门的激活值，决定新的输入信息的哪些部分将更新单元状态： $i_t^l = \\sigma(W_i \\cdot [h_{t-1}^l, h_t^{l-1}] + b_i)$ 输入调制门（Input Modulation Gate）输入调制门产生新的候选记忆内容，通过 tanh 函数进行激活。它的数学表示为：$g_t = \\tanh(W_g \\cdot [h_{t-1}, h_t] + b_g)$ 3. 单元状态结合遗忘门和输入门的信息，更新单元状态： $c_t^l = f \\odot c_{t-1}^l + i \\odot g$ 描述了如何更新单元状态。这里，$\\odot$ 表示元素乘法（Hadamard乘积）。 遗忘门$f$决定了前一时间步的单元状态 $c_{t-1}^l$有多少被保留。遗忘门的输出值在0和1之间： 当 $f$​ 接近1时，表示大部分单元状态被保留。 当 $f$接近0时，表示大部分单元状态被遗忘。 输入门 $i$ 和候选记忆单元 $g$ 决定了多少新的信息被添加到当前单元状态 $c_t^l$。 4. 输出门计算输出门的激活值，决定隐藏状态的更新：输出门：$o_t^l = \\sigma(W_o \\cdot [h_{t-1}^l, h_t^{l-1}] + b_o)$隐藏状态：$h_t^l = o_t^l * \\tanh(c_t^l)$输出门 $o$ 控制了从单元状态 $c_t^l$ 传递到隐藏状态 $h_t^l$​ 的信息，通过$tanh$函数进行非线性变换。 LSTM通过输入门、遗忘门、输出门和候选记忆单元的协同作用，有效地捕捉序列数据中的长短期依赖关系，解决了传统RNN中梯度消失和梯度爆炸的问题。这个更新机制使得LSTM在处理长序列数据时表现出色，能够有效地保留重要信息并过滤无关信息。 5. 更新隐藏状态（Hidden State Update）结合新的单元状态和输出门的激活值，更新隐藏状态： $h_t^l = o_t^l * \\tanh(c_t^l)$ 4. 应用了dropout 的LSTM从正文中可以看出，和标准的LSTM 状态更新过程相比， 其变化只是增加了一个$D$。$D$ 是将其参数的随机子集设置为零的dropout操作符。 $\\left( \\begin{array}{c} i \\ f \\ o \\ g \\end{array} \\right) = \\left( \\begin{array}{c} \\text{sigm} \\ \\text{sigm} \\ \\text{sigm} \\ \\text{tanh} \\end{array} \\right) T_{2n,4n} \\left( \\begin{array}{c} {D}(h_{t}^{l-1}) \\ h_{t-1}^{l} \\end{array} \\right)​$ 如何理解其主要思想是仅将dropout操作符应用于非递归连接。由于： $h_t^{l-1}$：表示第 $l−1$ 层在时间步 $t$ 的隐藏状态向量。这是第 $l$ 层的当前输入。 $h_{t-1}^l$：表示第 $l$ 层在时间步 $t−1$ 的隐藏状态向量。这是第 $l$ 层的前一个时间步的状态。同一层前后时间步之间的数据流转 就是递归操作， 不同层之间的数据流转是非递归操作， 根据公式，$D$ 应用在了$h_t^{l-1}$上， 所以说$D$ 是应用在非递归连接上的操作符合","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"}]},{"title":"The Unreasonable Effectiveness of Recurrent Neural Networks","slug":"The-Unreasonable-Effectiveness-of-Recurrent-Neural-Networks","date":"2024-06-11T09:59:43.000Z","updated":"2024-06-16T14:23:22.626Z","comments":true,"path":"2472be8a/","permalink":"http://example.com/2472be8a/","excerpt":"","text":"Andrej Karpathy blog:# The Unreasonable Effectiveness of Recurrent Neural Networks There’s something magical about Recurrent Neural Networks (RNNs). I still remember when I trained my first recurrent network for Image Captioning. Within a few dozen minutes of training my first baby model (with rather arbitrarily-chosen hyperparameters) started to generate very nice looking descriptions of images that were on the edge of making sense. Sometimes the ratio of how simple your model is to the quality of the results you get out of it blows past your expectations, and this was one of those times. What made this result so shocking at the time was that the common wisdom was that RNNs were supposed to be difficult to train (with more experience I’ve in fact reached the opposite conclusion). Fast forward about a year: I’m training RNNs all the time and I’ve witnessed their power and robustness many times, and yet their magical outputs still find ways of amusing me. This post is about sharing some of that magic with you.循环神经网络（RNN）有其独特的魅力。我还记得第一次训练用于图像描述生成的循环神经网络时的情景。只用了短短几十分钟，即使是随意选择的超参数，这个初步模型已经开始生成看起来非常不错的图像描述，尽管这些描述有时只是勉强合理。有时，模型的简单程度与其输出结果的质量之间的比例会远远超出预期，这次就是一个典型的例子。这次结果如此令人震惊的原因在于，当时的普遍认知是，RNN很难训练（随着经验的增加，我实际上得出了相反的结论）。时间快进大约一年：我一直在训练RNN，目睹了它们的强大和稳健，尽管如此，它们神奇的输出依然能不断带给我惊喜。这篇文章旨在与大家分享这种魔力。 We’ll train RNNs to generate text character by character and ponder the question “how is that even possible?”我们将训练循环神经网络（RNN）逐字符地生成文本，并思考这个问题：“这到底是怎么做到的？” By the way, together with this post I am also releasing code on Github that allows you to train character-level language models based on multi-layer LSTMs. You give it a large chunk of text and it will learn to generate text like it one character at a time. You can also use it to reproduce my experiments below. But we’re getting ahead of ourselves; What are RNNs anyway?顺便提一下，与这篇文章一起，我还在Github上发布了代码，这些代码可以用来训练基于多层LSTM的字符级语言模型。你只需提供一大段文本，它就会逐字符地学习生成类似的文本。你还可以使用它来重现我下面的实验。但在此之前，我们还是先回到正题上来：我们先来了解一下RNN到底是什么？ Recurrent Neural Networks 递归神经网络SequencesSequences. Depending on your background you might be wondering: _What makes Recurrent Networks so special_? A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model). The core reason that recurrent nets are more exciting is that they allow us to operate over _sequences_ of vectors: Sequences in the input, the output, or in the most general case both. A few examples may make this more concrete:序列。根据你的背景，你可能会问：循环神经网络有什么特别之处？一个显而易见的限制是Vanilla 神经网络（以及卷积神经网络）的API过于受限：它们接受固定大小的向量作为输入（例如，一张图片），并产生固定大小的向量作为输出（例如，不同类别的概率）。不仅如此，这些模型使用固定数量的计算步骤来完成这个映射（例如，模型中的层数）。循环神经网络更令人兴奋的核心原因在于它们允许我们对向量序列进行操作：输入中的序列，输出中的序列，或者在最一般的情况下，两者都是序列。几个例子可以让这一点更加具体： Each rectangle is a vector and arrows represent functions (e.g. matrix multiply). Input vectors are in red, output vectors are in blue and green vectors hold the RNN’s state (more on this soon). From left to right: (1) Vanilla mode of processing without RNN, from fixed-sized input to fixed-sized output (e.g. image classification). (2) Sequence output (e.g. image captioning takes an image and outputs a sentence of words). (3) Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment). (4) Sequence input and sequence output (e.g. Machine Translation: an RNN reads a sentence in English and then outputs a sentence in French). (5) Synced sequence input and output (e.g. video classification where we wish to label each frame of the video). Notice that in every case are no pre-specified constraints on the lengths sequences because the recurrent transformation (green) is fixed and can be applied as many times as we like.每个矩形代表一个向量，箭头代表函数（例如矩阵乘法）。输入向量用红色表示，输出向量用蓝色表示，绿色向量表示RNN的状态（稍后会详细说明）。从左到右依次是： (1) 普通模式的处理，没有使用RNN，从固定大小的输入到固定大小的输出（例如图像分类）。 (2) 序列输出（例如图像描述生成，输入一张图片，输出一个单词句子）。 (3) 序列输入（例如情感分析，将给定的句子分类为表达正面或负面情感）。 (4) 序列输入和序列输出（例如机器翻译：RNN读取一段英文句子，然后输出一段法文句子）。 (5) 同步的序列输入和输出（例如视频分类，我们希望对视频的每一帧进行标签）。 注意，在每种情况下，序列长度都没有预先指定的限制，因为循环变换（绿色）是固定的，可以根据需要应用多次。 As you might expect, the sequence regime of operation is much more powerful compared to fixed networks that are doomed from the get-go by a fixed number of computational steps, and hence also much more appealing for those of us who aspire to build more intelligent systems. Moreover, as we’ll see in a bit, RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, RNNs essentially describe programs. In fact, it is known that RNNs are Turing-Complete in the sense that they can to simulate arbitrary programs (with proper weights). But similar to universal approximation theorems for neural nets you shouldn’t read too much into this. In fact, forget I said anything.正如你所预料的那样，相较于受限于固定计算步骤的固定网络，序列操作模式要强大得多，因此对于那些希望构建更智能系统的人来说也更具吸引力。此外，正如我们稍后会看到的，RNN通过固定（但可学习）的函数将输入向量与其状态向量结合，生成一个新的状态向量。这在编程术语中可以理解为运行一个具有特定输入和一些内部变量的固定程序。从这个角度来看，RNN本质上是在描述程序。事实上，RNN被认为是图灵完备的，这意味着它们可以模拟任意程序（在适当的权重下）。但是，与神经网络的通用近似定理类似，你不应该对此过于解读。实际上，忘掉我刚才说的话吧。 If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.如果说训练普通神经网络是对函数的优化，那么训练循环网络就是对程序的优化。 Sequential processing in absence of sequences. You might be thinking that having sequences as inputs or outputs could be relatively rare, but an important point to realize is that even if your inputs/outputs are fixed vectors, it is still possible to use this powerful formalism to _process_ them in a sequential manner. For instance, the figure below shows results from two very nice papers from DeepMind. On the left, an algorithm learns a recurrent network policy that steers its attention around an image; In particular, it learns to read out house numbers from left to right (Ba et al.). On the right, a recurrent network _generates_ images of digits by learning to sequentially add color to a canvas (Gregor et al.):在没有序列的情况下进行顺序处理。您可能认为将序列作为输入或输出可能相对罕见，但需要意识到的重要一点是，即使你的输入/输出是固定向量，仍然可以使用这种强大的形式主义以顺序方式处理它们。例如，下图显示了 DeepMind 的两篇非常好的论文的结果。在左边，算法学习一个循环网络策略，将其注意力引导到图像周围;特别是，它学会了从左到右读出门牌号（Ba等人）。在右边，一个循环网络通过学习依次向画布添加颜色来生成数字图像： The takeaway is that even if your data is not in form of sequences, you can still formulate and train powerful models that learn to process it sequentially. You’re learning stateful programs that process your fixed-sized data.要点是，即使你的数据不是以序列形式存在，你仍然可以设计和训练强大的模型，使其学会以顺序方式处理这些数据。你正在学习的是处理固定大小数据的有状态程序。 RNN computationRNN computation. So how do these things work? At the core, RNNs have a deceptively simple API: They accept an input vector x and give you an output vector y. However, crucially this output vector’s contents are influenced not only by the input you just fed in, but also on the entire history of inputs you’ve fed in in the past. Written as a class, the RNN’s API consists of a single step function:RNN 计算。那么这些东西是如何工作的呢？在核心上，RNN 有一个看似简单的 API：它们接受一个输入向量 x 并给你一个输出向量 y 。然而，至关重要的是，这个输出向量的内容不仅受到你刚刚输入的输入的影响，还受到你过去输入的整个输入历史的影响。RNN 的 API 编写为一个类，由一个 step 函数组成：12rnn = RNN()y = rnn.step(x) # x is an input vector, y is the RNN&#x27;s output vectorThe RNN class has some internal state that it gets to update every time step is called. In the simplest case this state consists of a single _hidden_ vector h. Here is an implementation of the step function in a Vanilla RNN:RNN 类具有一些内部状态，每次调用时 step 都会更新。在最简单的情况下，此状态由单个隐藏向量组成 h 。以下是 Vanilla RNN 中 step 函数的实现： 12345678class RNN: # ... def step(self, x): # update the hidden state self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x)) # compute the output vector y = np.dot(self.W_hy, self.h) return y The above specifies the forward pass of a vanilla RNN. This RNN’s parameters are the three matrices W_hh, W_xh, W_hy. The hidden state self.h is initialized with the zero vector. The np.tanh function implements a non-linearity that squashes the activations to the range [-1, 1]. Notice briefly how this works: There are two terms inside of the tanh: one is based on the previous hidden state and one is based on the current input. In numpy np.dot is matrix multiplication. The two intermediates interact with addition, and then get squashed by the tanh into the new state vector. If you’re more comfortable with math notation, we can also write the hidden state update as $ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$, where tanh is applied elementwise.上述内容描述了一个基础RNN的前向传播过程。这个RNN的参数是三个矩阵W_hh、W_xh和W_hy。隐藏状态self.h初始化为零向量。np.tanh函数实现了一种非线性激活函数，将激活值压缩到[-1, 1]范围内。简要说明其工作原理：tanh内部有两个项，一个基于前一个时间步隐藏状态，另一个基于当前时间步输入。在numpy中，np.dot表示矩阵乘法。这两个中间结果通过加法相互作用，然后通过tanh函数压缩为新的状态向量。如果你对数学表示法更熟悉，我们也可以将隐藏状态的更新写成 $ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$，其中tanh逐元素应用。 ⚠️：numpy是Python中一个非常流行的数值计算库。np.tanh函数和np.dot函数都是numpy库中的函数。np.tanh函数用于计算元素级的双曲正切，而np.dot函数用于执行矩阵乘法。 We initialize the matrices of the RNN with random numbers and the bulk of work during training goes into finding the matrices that give rise to desirable behavior, as measured with some loss function that expresses your preference to what kinds of outputs $y$ you’d like to see in response to your input sequences $x$.我们用随机数初始化RNN的矩阵，在训练过程中，大部分工作是找到能够产生理想行为的矩阵，这通过某种损失函数来衡量，该损失函数表达了你对输入序列$x$对应输出$y$的期望。 Going deepGoing deep. RNNs are neural networks and everything works monotonically better (if done right) if you put on your deep learning hat and start stacking models up like pancakes. For instance, we can form a 2-layer recurrent network as follows:深入研究。RNN是神经网络的一种，如果方法得当，采用深度学习的方法并像叠煎饼一样将模型堆叠起来，一切都会单调地变得更好。例如，我们可以如下构建一个两层的循环神经网络：12y1 = rnn1.step(x)y = rnn2.step(y1) In other words we have two separate RNNs: One RNN is receiving the input vectors and the second RNN is receiving the output of the first RNN as its input. Except neither of these RNNs know or care - it’s all just vectors coming in and going out, and some gradients flowing through each module during backpropagation.换句话说，我们有两个独立的 RNN：一个 RNN 接收输入向量，第二个 RNN 接收第一个 RNN 的输出作为其输入。除了这些 RNN 都不知道或不关心之外——它们都只是进出的向量，以及在反向传播过程中流过每个模块的一些梯度。 Getting fancyGetting fancy. I’d like to briefly mention that in practice most of us use a slightly different formulation than what I presented above called a _Long Short-Term Memory_ (LSTM) network. The LSTM is a particular type of recurrent network that works slightly better in practice, owing to its more powerful update equation and some appealing backpropagation dynamics. I won’t go into details, but everything I’ve said about RNNs stays exactly the same, except the mathematical form for computing the update (the line self.h = ... ) gets a little more complicated. From here on I will use the terms “RNN/LSTM” interchangeably but all experiments in this post use an LSTM.更复杂的模型。在实践中，我们大多数人使用的公式与我上面提到的稍有不同，被称为长短期记忆网络（LSTM）。LSTM是一种特定类型的循环神经网络，实际上效果更好，因为它具有更强大的更新方程和一些更具吸引力的反向传播动态。我不会深入讨论细节，但我所说的关于RNN的一切都完全相同，除了计算更新的数学形式（即self.h = …这一行）变得稍微复杂了一些。从现在开始，我会交替使用“RNN/LSTM”这两个术语，但本文中的所有实验都使用LSTM。 Character-Level Language Models字符级语言模型 Okay, so we have an idea about what RNNs are, why they are super exciting, and how they work. We’ll now ground this in a fun application: We’ll train RNN character-level language models. That is, we’ll give the RNN a huge chunk of text and ask it to model the probability distribution of the next character in the sequence given a sequence of previous characters. This will then allow us to generate new text one character at a time.好的，所以我们已经对RNN是什么、为什么它们非常令人兴奋以及它们如何工作有了一定的了解。现在，我们将把这些知识应用到一个有趣的实际应用中：我们将训练RNN字符级别的语言模型。也就是说，我们会给RNN提供一大段文本，并让它根据前面字符的序列来建模下一个字符的概率分布。这样一来，我们就可以一次生成一个字符的新文本。 As a working example, suppose we only had a vocabulary of four possible letters “helo”, and wanted to train an RNN on the training sequence “hello”. This training sequence is in fact a source of 4 separate training examples: 1. The probability of “e” should be likely given the context of “h”, 2. “l” should be likely in the context of “he”, 3. “l” should also be likely given the context of “hel”, and finally 4. “o” should be likely given the context of “hell”.作为一个实际例子，假设我们只有四个可能的字母“helo”的词汇表，并且想要在训练序列“hello”上训练一个RNN。这个训练序列实际上是四个独立的训练示例的来源： 在“h”的上下文中，“e”的概率应该很大。 在“he”的上下文中，“l”的概率应该很大。 在“hel”的上下文中，“l”的概率也应该很大。 最后，在“hell”的上下文中，“o”的概率应该很大。 Concretely, we will encode each character into a vector using 1-of-k encoding (i.e. all zero except for a single one at the index of the character in the vocabulary), and feed them into the RNN one at a time with the step function. We will then observe a sequence of 4-dimensional output vectors (one dimension per character), which we interpret as the confidence the RNN currently assigns to each character coming next in the sequence. Here’s a diagram:具体来说，我们将使用1-of-k编码将每个字符编码成一个向量（即，除了在词汇表中字符索引处为1，其余全为0），然后用step函数将它们逐一输入RNN。随后，我们会得到一系列4维输出向量（每个字符一个维度），我们将这些输出向量解释为RNN当前对序列中下一个字符的置信度。以下是一个示意图： An example RNN with 4-dimensional input and output layers, and a hidden layer of 3 units (neurons). This diagram shows the activations in the forward pass when the RNN is fed the characters “hell” as input. The output layer contains confidences the RNN assigns for the next character (vocabulary is “h,e,l,o”); We want the green numbers to be high and red numbers to be low.具有 4 维输入和输出层的示例 RNN，以及 3 个单元（神经元）的隐藏层。此图显示了将字符“hell”作为输入馈送 RNN 时前向传递中的激活。输出层包含 RNN 为下一个字符分配的置信度（词汇为“h，e，l，o”）;我们希望绿色数字高，红色数字低。 ⚠️： W_xh 指输入层和隐藏层之间的权重矩阵， W_hh 指隐藏层之间的权重矩阵， W_hy 指隐藏层和输出层之间的权重矩阵 For example, we see that in the first time step when the RNN saw the character “h” it assigned confidence of 1.0 to the next letter being “h”, 2.2 to letter “e”, -3.0 to “l”, and 4.1 to “o”. Since in our training data (the string “hello”) the next correct character is “e”, we would like to increase its confidence (green) and decrease the confidence of all other letters (red). Similarly, we have a desired target character at every one of the 4 time steps that we’d like the network to assign a greater confidence to. Since the RNN consists entirely of differentiable operations we can run the backpropagation algorithm (this is just a recursive application of the chain rule from calculus) to figure out in what direction we should adjust every one of its weights to increase the scores of the correct targets (green bold numbers). We can then perform a _parameter update_, which nudges every weight a tiny amount in this gradient direction. If we were to feed the same inputs to the RNN after the parameter update we would find that the scores of the correct characters (e.g. “e” in the first time step) would be slightly higher (e.g. 2.3 instead of 2.2), and the scores of incorrect characters would be slightly lower. We then repeat this process over and over many times until the network converges and its predictions are eventually consistent with the training data in that correct characters are always predicted next.例如，我们看到在第一个时间步中，当RNN看到字符“h”时，它对下一个字符的置信度分配为：字符“h”是1.0，字符“e”是2.2，字符“l”是-3.0，字符“o”是4.1。由于在我们的训练数据（字符串“hello”）中，下一个正确字符是“e”，我们希望增加“e”的置信度（用绿色表示），并降低所有其他字符的置信度（用红色表示）。类似地，在每一个时间步上，我们都有一个期望的目标字符，希望网络能对其分配更高的置信度。由于RNN完全由可微操作组成，我们可以运行反向传播算法（这只是微积分中链式法则的递归应用）来确定应调整每个权重的方向，以提高正确目标的得分（绿色加粗数字）。然后，我们可以执行参数更新，将每个权重在该梯度方向上微调一个小量。如果在参数更新后再次将相同的输入提供给RNN，我们会发现正确字符的得分（例如，第一个时间步中的“e”）会略有提高（例如，从2.2提高到2.3），而错误字符的得分会略有降低。然后，我们反复进行这个过程多次，直到网络收敛，其预测最终与训练数据一致，即总是预测出正确的下一个字符。 ⚠️：图中output 层 数字并不是置信度，而是logits, 这些logits并不直接表示概率/置信度,要将这些logits转化为概率（置信度），我们通常使用Softmax函数。 A more technical explanation is that we use the standard Softmax classifier (also commonly referred to as the cross-entropy loss) on every output vector simultaneously. The RNN is trained with mini-batch Stochastic Gradient Descent and I like to use RMSProp or Adam (per-parameter adaptive learning rate methods) to stablilize the updates.更技术性的解释是，我们在每个输出向量上 同时使用标准的Softmax分类器（也常被称为交叉熵损失）。RNN使用小批量随机梯度下降法进行训练，我喜欢使用RMSProp或Adam（每个参数的自适应学习率方法）来稳定更新。 Notice also that the first time the character “l” is input, the target is “l”, but the second time the target is “o”. The RNN therefore cannot rely on the input alone and must use its recurrent connection to keep track of the context to achieve this task.另请注意，第一次输入字符“l”时，目标是“l”，但第二次目标是“o”。因此，RNN 不能单独依赖输入，必须使用其循环连接来跟踪上下文以实现此任务。 At test time, we feed a character into the RNN and get a distribution over what characters are likely to come next. We sample from this distribution, and feed it right back in to get the next letter. Repeat this process and you’re sampling text! Lets now train an RNN on different datasets and see what happens.在测试时，我们将一个字符输入RNN，并获得下一个字符可能出现的概率分布。我们从这个分布中采样，并将采样得到的字符再次输入RNN以获取下一个字符。重复这个过程，就可以生成文本了！现在，让我们在不同的数据集上训练一个RNN，看看会发生什么。 To further clarify, for educational purposes I also wrote a minimal character-level RNN language model in Python/numpy. It is only about 100 lines long and hopefully it gives a concise, concrete and useful summary of the above if you’re better at reading code than text. We’ll now dive into example results, produced with the much more efficient Lua/Torch codebase.为了进一步说明，我还用Python和numpy编写了一个最小的字符级RNN语言模型。它只有大约100行代码，希望能为你提供一个简洁、具体且有用的总结，如果你更擅长阅读代码而不是文字。现在，我们将深入探讨使用更加高效的Lua/Torch代码库生成的示例结果。 Fun with RNNsAll 5 example character models below were trained with the code I’m releasing on Github. The input in each case is a single file with some text, and we’re training an RNN to predict the next character in the sequence.下面的所有 5 个示例字符模型都是使用我在 Github 上发布的代码训练的。每种情况下的输入都是一个包含一些文本的单个文件，我们正在训练一个 RNN 来预测序列中的下一个字符。 Paul Graham generator 保罗·格雷厄姆发电机Lets first try a small dataset of English as a sanity check. My favorite fun dataset is the concatenation of Paul Graham’s essays. The basic idea is that there’s a lot of wisdom in these essays, but unfortunately Paul Graham is a relatively slow generator. Wouldn’t it be great if we could sample startup wisdom on demand? That’s where an RNN comes in.让我们首先尝试一个小型的英文数据集来进行基本检查。我最喜欢的有趣数据集是保罗·格雷厄姆（Paul Graham）的文章合集。基本想法是，这些文章中有很多智慧，但遗憾的是，保罗·格雷厄姆的写作速度相对较慢。如果我们能按需采样创业智慧，那不是很棒吗？这正是RNN的用武之地。 Concatenating all pg essays over the last ~5 years we get approximately 1MB text file, or about 1 million characters (this is considered a very small dataset by the way). _Technical:_ Lets train a 2-layer LSTM with 512 hidden nodes (approx. 3.5 million parameters), and with dropout of 0.5 after each layer. We’ll train with batches of 100 examples and truncated backpropagation through time of length 100 characters. With these settings one batch on a TITAN Z GPU takes about 0.46 seconds (this can be cut in half with 50 character BPTT at negligible cost in performance). Without further ado, lets see a sample from the RNN:将过去大约5年间的所有保罗·格雷厄姆的文章合并起来，我们得到了一个大约1MB的文本文件，约100万个字符（顺便说一下，这被认为是一个非常小的数据集）。技术细节：让我们训练一个具有2层、每层512个隐藏节点的LSTM（大约350万个参数），并在每层之后使用0.5的dropout。我们将使用100个样本的批次和长度为100字符的截断时间反向传播进行训练。在这些设置下，在TITAN Z GPU上处理一个批次大约需要0.46秒（使用50字符的截断时间反向传播，几乎不会影响性能，可以将时间减半）。事不宜迟，让我们看看RNN生成的一个样本： _“The surprised in investors weren’t going to raise money. I’m not the company with the time there are all interesting quickly, don’t have to get off the same programmers. There’s a super-angel round fundraising, why do you can do. If you have a different physical investment are become in people who reduced in a startup with the way to argument the acquirer could see them just that you’re also the founders will part of users’ affords that and an alternation to the idea. [2] Don’t work at first member to see the way kids will seem in advance of a bad successful startup. And if you have to act the big company too.”__“投资者的惊讶是，他们并不打算筹集资金。我不是那个有时间的公司，有趣的事情很快就会出现，不需要让相同的程序员离开。有一个超级天使轮的融资，你为什么要这样做。如果你有不同的实体投资，会成为那些在初创公司里减少的人中争论的方式，收购者可能会看到他们只是创始人将成为用户努力的一部分，这是对想法的一种替代。[2] 一开始不要在成员身上工作，看孩子们将如何提前在一个失败的成功初创公司中表现出来。而且，如果你必须行动，那么大公司也一样。”_ Okay, clearly the above is unfortunately not going to replace Paul Graham anytime soon, but remember that the RNN had to learn English completely from scratch and with a small dataset (including where you put commas, apostrophes and spaces). I also like that it learns to support its own arguments (e.g. [2], above). Sometimes it says something that offers a glimmer of insight, such as _“a company is a meeting to think to investors”_. Here’s a link to 50K character sample if you’d like to see more.好的，很明显，以上内容暂时还无法替代保罗·格雷厄姆，但请记住，RNN必须从零开始学习英语，而且是用一个小数据集（包括逗号、撇号和空格的位置）。我也喜欢它学会了支持自己的论点（例如，上文中的[2]）。有时，它会说出一些略带启发性的话，比如“a company is a meeting to think to investors”（公司是与投资者思考的会议）。如果你想查看更多，这里有一个50K字符的样本链接。 Temperature. We can also play with the temperature of the Softmax during sampling. Decreasing the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, etc). In particular, setting temperature very near zero will give the most likely thing that Paul Graham might say:温度。我们也可以在采样过程中调整Softmax的温度。将温度从1降低到某个较低的数值（例如0.5），会使RNN更有信心，但也更保守于其采样结果。相反，较高的温度会带来更多的多样性，但代价是会有更多的错误（例如拼写错误等）。特别是，将温度设置得非常接近零，会产生最有可能是保罗·格雷厄姆会说的话： _“is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same”“他们都是一样的，创业公司是，他们都是创业公司，他们都是一样的创业公司，他们都是一样的，创业公司是一样的”_ looks like we’ve reached an infinite loop about startups.看起来我们已经达到了一个关于初创公司的无限循环。 Shakespeare 莎士比亚It looks like we can learn to spell English words. But how about if there is more structure and style in the data? To examine this I downloaded all the works of Shakespeare and concatenated them into a single (4.4MB) file. We can now afford to train a larger network, in this case lets try a 3-layer RNN with 512 hidden nodes on each layer. After we train the network for a few hours we obtain samples such as:看起来我们可以学会拼写英语单词。但如果数据中有更多的结构和风格呢？为此，我下载了莎士比亚的所有作品，并将它们合并成一个单一的（4.4MB）文件。我们现在有能力训练一个更大的网络，在这种情况下，让我们尝试一个3层的RNN，每层有512个隐藏节点。经过几个小时的训练，我们得到如下样本：123456789101112131415161718192021222324PANDARUS:Alas, I think he shall be come approached and the dayWhen little srain would be attain&#x27;d into being never fed,And who is but a chain and subjects of his death,I should not sleep.Second Senator:They are away this miseries, produced upon my soul,Breaking and strongly should be buried, when I perishThe earth and thoughts of many states.DUKE VINCENTIO:Well, your wit is in the care of side and that.Second Lord:They would be ruled after this chamber, andmy fair nues begun out of the fact, to be conveyed,Whose noble souls I&#x27;ll have the heart of the wars.Clown:Come, sir, I will make did behold your worship.VIOLA:I&#x27;ll drink it. Remember, all the RNN knows are characters, so in particular it samples both speaker’s names and the contents. Sometimes we also get relatively extented monologue passages, such as:请记住，RNN所知道的只有字符，因此它既采样说话者的名字，也采样内容。有时我们还会得到相对较长的独白段落，例如：12345678910111213141516171819VIOLA:Why, Salisbury must find his flesh and thoughtThat which I am not aps, not a man and in fire,To show the reining of the raven and the warsTo grace my hand reproach within, and not a fair are hand,That Caesar and my goodly father&#x27;s world;When I was heaven of presence and our fleets,We spare with hours, but cut thy council I am great,Murdered and by thy master&#x27;s ready thereMy power to give thee but so much as hell:Some service in the noble bondman here,Would show him to her wine.KING LEAR:O, if you were a feeble sight, the courtesy of your law,Your sight and several breath, will wear the godsWith his heads, and my hands are wonder&#x27;d at the deeds,So drop upon your lordship&#x27;s head, and your opinionShall be against your honour. I can barely recognize these samples from actual Shakespeare :) If you like Shakespeare, you might appreciate this 100,000 character sample. Of course, you can also generate an infinite amount of your own samples at different temperatures with the provided code.我几乎无法辨认这些样本是否真的是莎士比亚的作品 :) 如果你喜欢莎士比亚，你可能会喜欢这个10万字符的样本。当然，你也可以使用提供的代码在不同温度下生成无限量的样本。 Wikipedia 维基百科We saw that the LSTM can learn to spell words and copy general syntactic structures. Lets further increase the difficulty and train on structured markdown. In particular, lets take the Hutter Prize 100MB dataset of raw Wikipedia and train an LSTM. Following Graves et al., I used the first 96MB for training, the rest for validation and ran a few models overnight. We can now sample Wikipedia articles! Below are a few fun excerpts. First, some basic markdown output:我们已经看到LSTM可以学会拼写单词和复制一般的句法结构。让我们进一步增加难度，训练在结构化的Markdown上。特别是，让我们使用Hutter Prize的100MB原始维基百科数据集来训练一个LSTM。按照Graves等人的方法，我使用前96MB进行训练，剩余的用于验证，并在一夜之间运行了几个模型。现在我们可以采样生成维基百科文章了！以下是一些有趣的摘录。首先，是一些基本的Markdown输出：1234567891011121314151617Naturalism and decision for the majority of Arab countries&#x27; capitalide was groundedby the Irish language by [[John Clair]], [[An Imperial Japanese Revolt]], associated with Guangzham&#x27;s sovereignty. His generals were the powerful ruler of the Portugal in the [[Protestant Immineners]], which could be said to be directly in Cantonese Communication, which followed a ceremony and set inspired prison, training. The emperor travelled back to [[Antioch, Perth, October 25|21]] to note, the Kingdom of Costa Rica, unsuccessful fashioned the [[Thrales]], [[Cynth&#x27;s Dajoard]], known in western [[Scotland]], near Italy to the conquest of India with the conflict. Copyright was the succession of independence in the slop of Syrian influence that was a famous German movement based on a more popular servicious, non-doctrinal and sexual power post. Many governments recognize the military housing of the [[Civil Liberalization and Infantry Resolution 265 National Party in Hungary]], that is sympathetic to be to the [[Punjab Resolution]](PJS)[http://www.humah.yahoo.com/guardian.cfm/7754800786d17551963s89.htm Official economics Adjoint for the Nazism, Montgomery was swear to advance to the resources for those Socialism&#x27;s rule, was starting to signing a major tripad of aid exile.]] In case you were wondering, the yahoo url above doesn’t actually exist, the model just hallucinated it. Also, note that the model learns to open and close the parenthesis correctly. There’s also quite a lot of structured markdown that the model learns, for example sometimes it creates headings, lists, etc.:如果你在好奇，上述的Yahoo网址实际上并不存在，这是模型臆想出来的。此外，请注意，模型学会了正确地打开和关闭括号。模型还学习了大量的结构化Markdown，例如，有时它会创建标题、列表等内容：1234567891011121314151617181920&#123; &#123; cite journal | id=Cerling Nonforest Department|format=Newlymeslated|none &#125; &#125;&#x27;&#x27;www.e-complete&#x27;&#x27;.&#x27;&#x27;&#x27;See also&#x27;&#x27;&#x27;: [[List of ethical consent processing]]== See also ==*[[Iender dome of the ED]]*[[Anti-autism]]===[[Religion|Religion]]===*[[French Writings]]*[[Maria]]*[[Revelation]]*[[Mount Agamul]]== External links==* [http://www.biblegateway.nih.gov/entrepre/ Website of the World Festival. The labour of India-county defeats at the Ripper of California Road.]==External links==* [http://www.romanology.com/ Constitution of the Netherlands and Hispanic Competition for Bilabial and Commonwealth Industry (Republican Constitution of the Extent of the Netherlands)]Sometimes the model snaps into a mode of generating random but valid XML:有时，模型会进入生成随机但有效的 XML 的模式：123456789101112131415&lt;page&gt; &lt;title&gt;Antichrist&lt;/title&gt; &lt;id&gt;865&lt;/id&gt; &lt;revision&gt; &lt;id&gt;15900676&lt;/id&gt; &lt;timestamp&gt;2002-08-03T18:14:12Z&lt;/timestamp&gt; &lt;contributor&gt; &lt;username&gt;Paris&lt;/username&gt; &lt;id&gt;23&lt;/id&gt; &lt;/contributor&gt; &lt;minor /&gt; &lt;comment&gt;Automated conversion&lt;/comment&gt; &lt;text xml:space=&quot;preserve&quot;&gt;#REDIRECT [[Christianity]]&lt;/text&gt; &lt;/revision&gt;&lt;/page&gt; The model completely makes up the timestamp, id, and so on. Also, note that it closes the correct tags appropriately and in the correct nested order. Here are 100,000 characters of sampled wikipedia if you’re interested to see more.该模型完全由时间戳、id 等组成。另外，请注意，它正确地关闭了标签，并且按照正确的嵌套顺序。这里有 100,000 个字符的样本维基百科，如果您有兴趣查看更多。 Algebraic Geometry (Latex) 代数几何（Latex）The results above suggest that the model is actually quite good at learning complex syntactic structures. Impressed by these results, my labmate (Justin Johnson) and I decided to push even further into structured territories and got a hold of this book on algebraic stacks/geometry. We downloaded the raw Latex source file (a 16MB file) and trained a multilayer LSTM. Amazingly, the resulting sampled Latex _almost_ compiles. We had to step in and fix a few issues manually but then you get plausible looking math, it’s quite astonishing:上述结果表明，模型在学习复杂句法结构方面实际上相当不错。这些结果给我留下了深刻的印象，我的实验室同事Justin Johnson和我决定进一步探索结构化领域，并找到了一本关于代数叠/几何的书。我们下载了原始的Latex源文件（一个16MB的文件）并训练了一个多层LSTM。令人惊讶的是，生成的Latex几乎可以编译。我们不得不手动修复一些问题，但最终得到了看起来很合理的数学表达，这真是令人惊叹：Sampled (fake) algebraic geometry. Here’s the actual pdf.采样（假）代数几何。这是实际的pdf。 Here’s another sample: 下面是另一个示例：More hallucinated algebraic geometry. Nice try on the diagram (right).更多幻觉的代数几何。不错的尝试图（右）。 As you can see above, sometimes the model tries to generate latex diagrams, but clearly it hasn’t really figured them out. I also like the part where it chooses to skip a proof (_“Proof omitted.”_, top left). Of course, keep in mind that latex has a relatively difficult structured syntactic format that I haven’t even fully mastered myself. For instance, here is a raw sample from the model (unedited):正如你在上面看到的，有时模型尝试生成Latex图表，但显然它还没有真正掌握这种技能。我也喜欢它选择跳过证明的部分（“Proof omitted.”，左上角）。当然，请记住，Latex有一个相对复杂的结构化句法格式，我自己都还没有完全掌握。例如，下面是模型生成的一个原始样本（未编辑）：123456789101112131415\\begin&#123;proof&#125;We may assume that $\\mathcal&#123;I&#125;$ is an abelian sheaf on $\\mathcal&#123;C&#125;$.\\item Given a morphism $\\Delta : \\mathcal&#123;F&#125; \\to \\mathcal&#123;I&#125;$is an injective and let $\\mathfrak q$ be an abelian sheaf on $X$.Let $\\mathcal&#123;F&#125;$ be a fibered complex. Let $\\mathcal&#123;F&#125;$ be a category.\\begin&#123;enumerate&#125;\\item \\hyperref[setain-construction-phantom]&#123;Lemma&#125;\\label&#123;lemma-characterize-quasi-finite&#125;Let $\\mathcal&#123;F&#125;$ be an abelian quasi-coherent sheaf on $\\mathcal&#123;C&#125;$.Let $\\mathcal&#123;F&#125;$ be a coherent $\\mathcal&#123;O&#125;_X$-module. Then$\\mathcal&#123;F&#125;$ is an abelian catenary over $\\mathcal&#123;C&#125;$.\\item The following are equivalent\\begin&#123;enumerate&#125;\\item $\\mathcal&#123;F&#125;$ is an $\\mathcal&#123;O&#125;_X$-module.\\end&#123;lemma&#125; This sample from a relatively decent model illustrates a few common mistakes. For example, the model opens a \\begin&#123;proof&#125; environment but then ends it with a \\end&#123;lemma&#125;. This is an example of a problem we’d have to fix manually, and is likely due to the fact that the dependency is too long-term: By the time the model is done with the proof it has forgotten whether it was doing a proof or a lemma. Similarly, it opens an \\begin&#123;enumerate&#125; but then forgets to close it. We observed that these became less common with larger/better models, but nonetheless, these are the kinds of mistakes that come up.这个来自相对不错模型的样本展示了一些常见的错误。例如，模型打开了一个 \\begin{proof} 环境，但随后却以 \\end{lemma} 结束。这是一个我们必须手动修复的问题的例子，可能是由于依赖关系过于长期：到模型完成证明时，它已经忘记了自己是在进行证明还是引理。类似地，它打开了一个 \\begin{enumerate}，但随后忘记了关闭它。我们注意到，这些错误在较大/更好的模型中变得不那么常见，但这些都是可能出现的错误类型。 Linux Source Code Linux 源代码I wanted to push structured data to its limit, so for the final challenge I decided to use code. In particular, I took all the source and header files found in the Linux repo on Github, concatenated all of them in a single giant file (474MB of C code) (I was originally going to train only on the kernel but that by itself is only ~16MB). Then I trained several as-large-as-fits-on-my-GPU 3-layer LSTMs over a period of a few days. These models have about 10 million parameters, which is still on the lower end for RNN models. The results are superfun:我想将结构化数据推向极限，因此在最后的挑战中我决定使用代码。具体来说，我收集了Github上Linux仓库中的所有源文件和头文件，将它们合并成一个巨大的文件（474MB的C代码）（我本来打算只训练内核代码，但它本身只有大约16MB）。然后，我在几天内训练了多个尽可能适应GPU容量的三层LSTM模型。这些模型大约有1000万个参数，这在RNN模型中仍然算是较少的。结果非常有趣：1234567891011121314151617181920212223242526272829303132/* * Increment the size file of the new incorrect UI_FILTER group information * of the size generatively. */static int indicate_policy(void)&#123; int error; if (fd == MARN_EPT) &#123; /* * The kernel blank will coeld it to userspace. */ if (ss-&gt;segment &lt; mem_total) unblock_graph_and_set_blocked(); else ret = 1; goto bail; &#125; segaddr = in_SB(in.addr); selector = seg / 16; setup_works = true; for (i = 0; i &lt; blocks; i++) &#123; seq = buf[i++]; bpf = bd-&gt;bd.next + i * search; if (fd) &#123; current = blocked; &#125; &#125; rw-&gt;name = &quot;Getjbbregs&quot;; bprm_self_clearl(&amp;iv-&gt;version); regs-&gt;new = blocks[(BPF_STATS &lt;&lt; info-&gt;historidac)] | PFMR_CLOBATHINC_SECONDS &lt;&lt; 12; return segtable;&#125;The code looks really quite great overall. Of course, I don’t think it compiles but when you scroll through the generate code it feels very much like a giant C code base. Notice that the RNN peppers its code with comments here and there at random. It is also very good at making very few syntactic errors. For example, it uses strings properly, pointer notation, etc. It also opens and closes brackets { correctly and learns to indent its code very well. A common error is that it can’t keep track of variable names: It often uses undefined variables (e.g. rw above), declares variables it never uses (e.g. int error), or returns non-existing variables. Lets see a few more examples. Here’s another snippet that shows a wider array of operations that the RNN learns: 总体来说，这些代码看起来非常不错。当然，我不认为它能编译，但当你滚动查看生成的代码时，它确实给人一种巨大的C代码库的感觉。注意，RNN会随机在代码中插入注释，并且在语法错误方面表现得非常出色。例如，它能正确使用字符串、指针符号等，还能正确地打开和关闭大括号{}，并很好地学习代码缩进。一个常见的错误是它无法跟踪变量名：它经常使用未定义的变量（例如上面的rw），声明从未使用的变量（例如int error），或者返回不存在的变量。让我们再看一些例子。下面是另一个代码片段，展示了RNN学到的更广泛的操作： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * If this error is set, we will need anything right after that BSD. */static void action_new_function(struct s_stat_info *wb)&#123; unsigned long flags; int lel_idx_bit = e-&gt;edd, *sys &amp; ~((unsigned long) *FIRST_COMPAT); buf[0] = 0xFFFFFFFF &amp; (bit &lt;&lt; 4); min(inc, slist-&gt;bytes); printk(KERN_WARNING &quot;Memory allocated %02x/%02x, &quot; &quot;original MLL instead\\n&quot;), min(min(multi_run - s-&gt;len, max) * num_data_in), frame_pos, sz + first_seg); div_u64_w(val, inb_p); spin_unlock(&amp;disk-&gt;queue_lock); mutex_unlock(&amp;s-&gt;sock-&gt;mutex); mutex_unlock(&amp;func-&gt;mutex); return disassemble(info-&gt;pending_bh);&#125;static void num_serial_settings(struct tty_struct *tty)&#123; if (tty == tty) disable_single_st_p(dev); pci_disable_spool(port); return 0;&#125;static void do_command(struct seq_file *m, void *v)&#123; int column = 32 &lt;&lt; (cmd[2] &amp; 0x80); if (state) cmd = (int)(int_state ^ (in_8(&amp;ch-&gt;ch_flags) &amp; Cmd) ? 2 : 1); else seq = 1; for (i = 0; i &lt; 16; i++) &#123; if (k &amp; (1 &lt;&lt; 1)) pipe = (in_use &amp; UMXTHREAD_UNCCA) + ((count &amp; 0x00000000fffffff8) &amp; 0x000000f) &lt;&lt; 8; if (count == 0) sub(pid, ppc_md.kexec_handle, 0x20000000); pipe_set_bytes(i, 0); &#125; /* Free our user pages pointer to place camera if all dash */ subsystem_info = &amp;of_changes[PAGE_SIZE]; rek_controls(offset, idx, &amp;soffset); /* Now we want to deliberately put it to device */ control_check_polarity(&amp;context, val, 0); for (i = 0; i &lt; COUNTER; i++) seq_puts(s, &quot;policy &quot;);&#125; Notice that in the second function the model compares tty == tty, which is vacuously true. On the other hand, at least the variable tty exists in the scope this time! In the last function, notice that the code does not return anything, which happens to be correct since the function signature is void. However, the first two functions were also declared void and did return values. This is again a form of a common mistake due to long-term interactions.注意在第二个函数中，模型比较了tty == tty，这是显然为真的。另一方面，至少这次变量tty存在于作用域中！在最后一个函数中，注意代码没有返回任何东西，这正好是正确的，因为函数签名是void。然而，前两个函数也声明为void，但却返回了值。这再次是一种由于长时间交互而导致的常见错误形式。 Sometimes the model decides that it’s time to sample a new file. This is usually a very amusing part: The model first recites the GNU license character by character, samples a few includes, generates some macros and then dives into the code:有时，模型会决定是时候采样一个新文件了。这通常是非常有趣的部分：模型首先逐字符地背诵GNU许可证，采样几个include语句，生成一些宏，然后深入到代码中：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * Copyright (c) 2006-2010, Intel Mobile Communications. All rights reserved. * * This program is free software; you can redistribute it and/or modify it * under the terms of the GNU General Public License version 2 as published by * the Free Software Foundation. * * This program is distributed in the hope that it will be useful, * but WITHOUT ANY WARRANTY; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the * * GNU General Public License for more details. * * You should have received a copy of the GNU General Public License * along with this program; if not, write to the Free Software Foundation, * Inc., 675 Mass Ave, Cambridge, MA 02139, USA. */#include &lt;linux/kexec.h&gt;#include &lt;linux/errno.h&gt;#include &lt;linux/io.h&gt;#include &lt;linux/platform_device.h&gt;#include &lt;linux/multi.h&gt;#include &lt;linux/ckevent.h&gt;#include &lt;asm/io.h&gt;#include &lt;asm/prom.h&gt;#include &lt;asm/e820.h&gt;#include &lt;asm/system_info.h&gt;#include &lt;asm/setew.h&gt;#include &lt;asm/pgproto.h&gt;#define REG_PG vesa_slot_addr_pack#define PFM_NOCOMP AFSR(0, load)#define STACK_DDR(type) (func)#define SWAP_ALLOCATE(nr) (e)#define emulate_sigs() arch_get_unaligned_child()#define access_rw(TST) asm volatile(&quot;movd %%esp, %0, %3&quot; : : &quot;r&quot; (0)); \\ if (__type &amp; DO_READ)static void stat_PC_SEC __read_mostly offsetof(struct seq_argsqueue, \\ pC&gt;[1]);static voidos_prefix(unsigned long sys)&#123;#ifdef CONFIG_PREEMPT PUT_PARAM_RAID(2, sel) = get_state_state(); set_pid_sum((unsigned long)state, current_state_str(), (unsigned long)-1-&gt;lr_full; low;&#125;There are too many fun parts to cover- I could probably write an entire blog post on just this part. I’ll cut it short for now, but here is 1MB of sampled Linux code for your viewing pleasure.有太多有趣的部分要涵盖 - 我可能会写一整篇关于这部分的博客文章。我现在会缩短它，但这里有 1MB 的 Linux 代码样本供您查看。 Generating Baby Names 生成婴儿名字Lets try one more for fun. Lets feed the RNN a large text file that contains 8000 baby names listed out, one per line (names obtained from here). We can feed this to the RNN and then generate new names! Here are some example names, only showing the ones that do not occur in the training data (90% don’t):再来试一个有趣的实验。我们向RNN输入一个包含8000个婴儿名字的大文本文件，每行一个名字（名字从这里获得）。我们可以将其输入RNN，然后生成新的名字！以下是一些示例名字，只展示那些没有出现在训练数据中的名字（90%都不在训练数据中）：_Rudi Levette Berice Lussa Hany Mareanne Chrestina Carissy Marylen Hammine Janye Marlise Jacacrie Hendred Romand Charienna Nenotto Ette Dorane Wallen Marly Darine Salina Elvyn Ersia Maralena Minoria Ellia Charmin Antley Nerille Chelon Walmor Evena Jeryly Stachon Charisa Allisa Anatha Cathanie Geetra Alexie Jerin Cassen Herbett Cossie Velen Daurenge Robester Shermond Terisa Licia Roselen Ferine Jayn Lusine Charyanne Sales Sanny Resa Wallon Martine Merus Jelen Candica Wallin Tel Rachene Tarine Ozila Ketia Shanne Arnande Karella Roselina Alessia Chasty Deland Berther Geamar Jackein Mellisand Sagdy Nenc Lessie Rasemy Guen Gavi Milea Anneda Margoris Janin Rodelin Zeanna Elyne Janah Ferzina Susta Pey Castina_ You can see many more here. Some of my favorites include “Baby” (haha), “Killie”, “Char”, “R”, “More”, “Mars”, “Hi”, “Saddie”, “With” and “Ahbort”. Well that was fun. Of course, you can imagine this being quite useful inspiration when writing a novel, or naming a new startup :)你可以在这里看到更多。我最喜欢的一些包括“宝贝”（haha）、“Killie”、“Char”、“R”、“More”、“Mars”、“Hi”、“Saddie”、“With”和“Ahbort”。嗯，这很有趣。当然，你可以想象这在写小说或命名新的创业公司时是非常有用的灵感:) Understanding what’s going onWe saw that the results at the end of training can be impressive, but how does any of this work? Lets run two quick experiments to briefly peek under the hood.我们看到训练结束时的结果令人印象深刻，但这些是如何实现的呢？让我们进行两个快速实验，简要探究一下其内部工作原理。 The evolution of samples while training训练时样本的演变First, it’s fun to look at how the sampled text evolves while the model trains. For example, I trained an LSTM of Leo Tolstoy’s War and Peace and then generated samples every 100 iterations of training. At iteration 100 the model samples random jumbles:首先，观察模型训练过程中生成文本的演变是很有趣的。例如，我训练了一个基于列夫·托尔斯泰的《战争与和平》的LSTM，并在每100次迭代训练后生成样本。在第100次迭代时，模型生成的样本是随机混杂的字符： 12tyntd-iafhatawiaoihrdemot lytdws e ,tfti, astai f ogoh eoase rrranbyne &#x27;nhthnee e plia tklrgd t o idoe ns,smtt h ne etie h,hregtrs nigtike,aoaenns lng However, notice that at least it is starting to get an idea about words separated by spaces. Except sometimes it inserts two spaces. It also doesn’t know that comma is amost always followed by a space. At 300 iterations we see that the model starts to get an idea about quotes and periods:然而，请注意至少模型开始有了关于单词由空格分隔的概念。尽管有时它会插入两个空格。它还不知道逗号后几乎总是跟着一个空格。在训练300次迭代时，我们看到模型开始了解引号和句号的用法：1234&quot;Tmont thithey&quot; fomesscerliundKeushey. Thom heresheulke, anmerenith ol sivh I lalterthend Bleipile shuwy fil on aseterlomecoaniogennc Phe lism thond hon at. MeiDimorotion in ther thize.&quot;The words are now also separated with spaces and the model starts to get the idea about periods at the end of a sentence. At iteration 500:现在，单词之间也用空格分隔，模型开始理解句末的句号。在第500次迭代时：12we counter. He stutn co des. His stanted out one ofler that concossions and was to gearang reay Jotrets and with fre colt otf paitt thin wall. Which das stimn the model has now learned to spell the shortest and most common words such as “we”, “He”, “His”, “Which”, “and”, etc. At iteration 700 we’re starting to see more and more English-like text emerge:模型现在已经学会了拼写最短和最常见的单词，比如“we”、“He”、“His”、“Which”、“and”等。在第700次迭代时，我们开始看到越来越多类似英语的文本出现：123Aftair fall unsuch that the hall for Prince Velzonski&#x27;s that me ofher hearly, and behs to so arwage fiving were to it beloge, pavu say falling misfort how, and Gogition is so overelical and ofter. At iteration 1200 we’re now seeing use of quotations and question/exclamation marks. Longer words have now been learned as well:在第1200次迭代时，我们现在看到了引号和问号/感叹号的使用。更长的单词也已经被学会了：12&quot;Kite vouch!&quot; he repeated by herdoor. &quot;But I would be done and quarts, feeling, then, son is people....&quot;Until at last we start to get properly spelled words, quotations, names, and so on by about iteration 2000:直到最后，在大约第2000次迭代时，我们开始得到正确拼写的单词、引号、名字等：123&quot;Why do what that day,&quot; replied Natasha, and wishing to himself the fact theprincess, Princess Mary was easier, fed in had oftened him.Pierre aking his soul came to the packs and drove up his father-in-law women. The picture that emerges is that the model first discovers the general word-space structure and then rapidly starts to learn the words; First starting with the short words and then eventually the longer ones. Topics and themes that span multiple words (and in general longer-term dependencies) start to emerge only much later.出现的情况是，模型首先发现了整体的单词-空格结构，然后迅速开始学习单词；先是短单词，然后逐渐学习长单词。跨越多个单词的主题和主题（以及一般的长期依赖关系）要到很久以后才会开始出现。 Visualizing the predictions and the “neuron” firings in the RNN可视化 RNN 中的预测和“神经元”放电 Another fun visualization is to look at the predicted distributions over characters. In the visualizations below we feed a Wikipedia RNN model character data from the validation set (shown along the blue/green rows) and under every character we visualize (in red) the top 5 guesses that the model assigns for the next character. The guesses are colored by their probability (so dark red = judged as very likely, white = not very likely). For example, notice that there are stretches of characters where the model is extremely confident about the next letter (e.g., the model is very confident about characters during the _http://www._ sequence).另一个有趣的可视化是查看模型对字符的预测分布。在下面的可视化中，我们向一个训练好的Wikipedia RNN模型，提供验证集的字符数据（显示在蓝色/绿色行上），并在每个字符下方可视化（用红色表示）模型对下一个字符的前5个猜测。猜测根据其概率进行着色（深红色=被认为非常可能，白色=不太可能）。例如，请注意在某些字符序列中，模型对下一个字符极为自信(例如，模型对 http://www 序列中的字符非常有信心） The input character sequence (blue/green) is colored based on the _firing_ of a randomly chosen neuron in the hidden representation of the RNN. Think about it as green = very excited and blue = not very excited (for those familiar with details of LSTMs, these are values between [-1,1] in the hidden state vector, which is just the gated and tanh’d LSTM cell state). Intuitively, this is visualizing the firing rate of some neuron in the “brain” of the RNN while it reads the input sequence. Different neurons might be looking for different patterns; Below we’ll look at 4 different ones that I found and thought were interesting or interpretable (many also aren’t):输入字符序列（蓝色/绿色）是根据RNN隐藏表示中随机选择的一个神经元的激活情况进行着色的。可以理解为绿色=非常激动，蓝色=不太激动（对于熟悉LSTM细节的人来说，这些值在隐藏状态向量中介于[-1,1]之间，这是经过门控和tanh函数处理的LSTM单元状态）。直观地说，这是在可视化RNN“脑中”某个神经元在读取输入序列时的激活率。不同的神经元可能在寻找不同的模式；下面我们将查看4个我发现有趣或可解释的神经元（也有很多是无法解释的）： The neuron highlighted in this image seems to get very excited about URLs and turns off outside of the URLs. The LSTM is likely using this neuron to remember if it is inside a URL or not.此图像中突出显示的神经元似乎对 URL 非常兴奋，并在 URL 之外关闭。LSTM 可能使用这个神经元来记住它是否在 URL 内。 The highlighted neuron here gets very excited when the RNN is inside the [[ ]] markdown environment and turns off outside of it. Interestingly, the neuron can’t turn on right after it sees the character “[“, it must wait for the second “[“ and then activate. This task of counting whether the model has seen one or two “[“ is likely done with a different neuron.当 RNN 位于 [[ ]] markdown 环境内部并在其外部关闭时，此处突出显示的神经元会非常兴奋。有趣的是，神经元在看到字符“[”后无法立即打开，它必须等待第二个“[”然后激活。计算模型是否看到一个或两个“[”的任务可能是用不同的神经元完成的。 Here we see a neuron that varies seemingly linearly across the [[ ]] environment. In other words its activation is giving the RNN a time-aligned coordinate system across the [[ ]] scope. The RNN can use this information to make different characters more or less likely depending on how early/late it is in the [[ ]] scope (perhaps?).在这里，我们看到一个神经元，它在[[ ]]环境中似乎呈线性变化。换句话说，它的激活为 RNN 提供了一个跨 [[ ]] 范围的时间对齐坐标系。RNN 可以使用此信息或多或少地使不同的字符更有可能，具体取决于它在 [[ ]] 范围内的早/晚（也许？ Here is another neuron that has very local behavior: it is relatively silent but sharply turns off right after the first “w” in the “www” sequence. The RNN might be using this neuron to count up how far in the “www” sequence it is, so that it can know whether it should emit another “w”, or if it should start the URL.这是另一个具有非常局部行为的神经元：它相对安静，但在“www”序列中的第一个“w”之后急剧关闭。RNN 可能正在使用这个神经元来计算它在“www”序列中的距离，以便它可以知道它是否应该发出另一个“w”，或者它是否应该启动 URL。 Of course, a lot of these conclusions are slightly hand-wavy as the hidden state of the RNN is a huge, high-dimensional and largely distributed representation. These visualizations were produced with custom HTML/CSS/Javascript, you can see a sketch of what’s involved here if you’d like to create something similar.当然，很多这些结论都有些笼统，因为RNN的隐藏状态是一个巨大的、高维的、广泛分布的表示。这些可视化是使用自定义的HTML/CSS/Javascript生成的，如果你想创建类似的东西，可以在这里看到涉及的内容示例。 We can also condense this visualization by excluding the most likely predictions and only visualize the text, colored by activations of a cell. We can see that in addition to a large portion of cells that do not do anything interpretible, about 5% of them turn out to have learned quite interesting and interpretible algorithms:我们还可以通过排除最可能的预测并仅根据单元激活情况对文本进行着色来简化这种可视化。我们可以看到，除了大部分不可解释的单元外，大约有5%的单元学会了相当有趣且可解释的算法：Again, what is beautiful about this is that we didn’t have to hardcode at any point that if you’re trying to predict the next character it might, for example, be useful to keep track of whether or not you are currently inside or outside of quote. We just trained the LSTM on raw data and it decided that this is a useful quantitity to keep track of. In other words one of its cells gradually tuned itself during training to become a quote detection cell, since this helps it better perform the final task. This is one of the cleanest and most compelling examples of where the power in Deep Learning models (and more generally end-to-end training) is coming from.再次强调，这其中的美妙之处在于，我们不需要在任何时候硬编码，例如在预测下一个字符时需要跟踪当前是否在引号内或引号外。我们只是对LSTM进行原始数据的训练，它自己决定跟踪这个信息是有用的。换句话说，其中一个单元在训练过程中逐渐调整自己，变成了一个引号检测单元，因为这有助于它更好地完成最终任务。这是深度学习模型（更广泛地说，端到端训练）力量的最清晰和最有说服力的例子之一。 Source Code 源代码I hope I’ve convinced you that training character-level language models is a very fun exercise. You can train your own models using the char-rnn code I released on Github (under MIT license). It takes one large text file and trains a character-level model that you can then sample from. Also, it helps if you have a GPU or otherwise training on CPU will be about a factor of 10x slower. In any case, if you end up training on some data and getting fun results let me know! And if you get lost in the Torch/Lua codebase remember that all it is is just a more fancy version of this 100-line gist.我希望我已经让你相信，训练字符级语言模型是一个非常有趣的练习。你可以使用我在Github上发布的char-rnn代码（基于MIT许可证）来训练你自己的模型。它需要一个大型文本文件，并训练一个字符级模型，你可以从中进行采样。此外，如果你有GPU，这会更有帮助，否则在CPU上训练的速度大约会慢10倍。不管怎样，如果你在一些数据上训练并得到了有趣的结果，请告诉我！如果你在Torch/Lua代码库中迷失了方向，请记住，这只是这个100行代码示例的更复杂版本。 _Brief digression._ The code is written in Torch 7, which has recently become my favorite deep learning framework. I’ve only started working with Torch/LUA over the last few months and it hasn’t been easy (I spent a good amount of time digging through the raw Torch code on Github and asking questions on their _gitter_ to get things done), but once you get a hang of things it offers a lot of flexibility and speed. I’ve also worked with Caffe and Theano in the past and I believe Torch, while not perfect, gets its levels of abstraction and philosophy right better than others. In my view the desirable features of an effective framework are:简单插曲一下。这段代码是用Torch 7编写的，它最近成为了我最喜欢的深度学习框架。我只是过去几个月才开始使用Torch/LUA，过程并不容易（我花了大量时间在Github上挖掘Torch的源代码，并在他们的gitter上提问以解决问题），但一旦你掌握了它，它就能提供很大的灵活性和速度。我过去也使用过Caffe和Theano，我认为Torch虽然不完美，但它在抽象层次和理念上做得比其他框架更好。在我看来，一个有效框架的理想特性是： CPU/GPU transparent Tensor library with a lot of functionality (slicing, array/matrix operations, etc. )CPU/GPU透明的张量库：具有丰富的功能（切片、数组/矩阵操作等）。） An entirely separate code base in a scripting language (ideally Python) that operates over Tensors and implements all Deep Learning stuff (forward/backward, computation graphs, etc)完全独立的脚本语言代码库：理想情况下是Python，操作张量并实现所有深度学习相关功能（前向/后向传播、计算图等）。 It should be possible to easily share pretrained models (Caffe does this well, others don’t), and crucially能够轻松共享预训练模型：Caffe在这方面做得很好，其他框架则不尽如人意。 NO compilation step (or at least not as currently done in Theano). The trend in Deep Learning is towards larger, more complex networks that are are time-unrolled in complex graphs. It is critical that these do not compile for a long time or development time greatly suffers. Second, by compiling one gives up interpretability and the ability to log/debug effectively. If there is an _option_ to compile the graph once it has been developed for efficiency in prod that’s fine.没有编译步骤：或至少不像Theano目前那样。深度学习的发展趋势是使用更大、更复杂的网络，这些网络在复杂的计算图中进行时间展开。关键是这些图不应长时间编译，否则会严重影响开发时间。其次，通过编译，会失去可解释性和有效记录/调试的能力。如果有选项可以在开发完成后编译图以提高生产效率，那也很好。 Further Reading 延伸阅读Before the end of the post I also wanted to position RNNs in a wider context and provide a sketch of the current research directions. RNNs have recently generated a significant amount of buzz and excitement in the field of Deep Learning. Similar to Convolutional Networks they have been around for decades but their full potential has only recently started to get widely recognized, in large part due to our growing computational resources. Here’s a brief sketch of a few recent developments (definitely not complete list, and a lot of this work draws from research back to 1990s, see related work sections):在文章的结尾，我还想把RNN放在更广泛的背景中，并提供当前研究方向的概述。最近，RNN在深度学习领域引起了大量关注和兴奋。类似于卷积网络，RNN已经存在了几十年，但它们的全部潜力直到最近才开始被广泛认可，这在很大程度上要归功于我们不断增长的计算资源。以下是一些最近发展的简要概述（绝不是完整的列表，其中很多工作可以追溯到1990年代，详见相关研究部分）： In the domain of NLP/Speech, RNNs transcribe speech to text, perform machine translation, generate handwritten text, and of course, they have been used as powerful language models (Sutskever et al.) (Graves) (Mikolov et al.) (both on the level of characters and words). Currently it seems that word-level models work better than character-level models, but this is surely a temporary thing.在NLP/Speech领域，RNN用于将语音转录为文本、执行机器翻译、生成手写文本，当然，它们也被用作强大的语言模型（Sutskever等人）（Graves）（Mikolov等人）（包括字符级和单词级）。目前看来，单词级模型比字符级模型效果更好，但这肯定只是暂时的。 Computer Vision. RNNs are also quickly becoming pervasive in Computer Vision. For example, we’re seeing RNNs in frame-level video classification, image captioning (also including my own work and many others), video captioning and very recently visual question answering. My personal favorite RNNs in Computer Vision paper is Recurrent Models of Visual Attention, both due to its high-level direction (sequential processing of images with glances) and the low-level modeling (REINFORCE learning rule that is a special case of policy gradient methods in Reinforcement Learning, which allows one to train models that perform non-differentiable computation (taking glances around the image in this case)). I’m confident that this type of hybrid model that consists of a blend of CNN for raw perception coupled with an RNN glance policy on top will become pervasive in perception, especially for more complex tasks that go beyond classifying some objects in plain view.计算机视觉。RNN也迅速在计算机视觉领域普及。例如，我们看到RNN用于帧级视频分类、图像描述生成（包括我自己的工作和许多其他人的工作）、视频描述生成以及最近的视觉问答。我个人最喜欢的计算机视觉领域的RNN论文是《视觉注意力的递归模型》，因为它在高层次方向（通过扫视对图像进行顺序处理）和低层次建模（REINFORCE学习规则，这是强化学习中策略梯度方法的特例，允许训练执行不可微计算的模型（在本例中是环顾图像））上都很出色。我相信这种混合模型，即结合了用于原始感知的CNN和用于扫视策略的RNN的模型，将在感知领域普及，特别是在超越简单对象分类的复杂任务中。 Inductive Reasoning, Memories and Attention. Another extremely exciting direction of research is oriented towards addressing the limitations of vanilla recurrent networks. One problem is that RNNs are not inductive: They memorize sequences extremely well, but they don’t necessarily always show convincing signs of generalizing in the _correct_ way (I’ll provide pointers in a bit that make this more concrete). A second issue is they unnecessarily couple their representation size to the amount of computation per step. For instance, if you double the size of the hidden state vector you’d quadruple the amount of FLOPS at each step due to the matrix multiplication. Ideally, we’d like to maintain a huge representation/memory (e.g. containing all of Wikipedia or many intermediate state variables), while maintaining the ability to keep computation per time step fixed.归纳推理、记忆和注意力。另一个极其令人兴奋的研究方向是解决普通循环网络的局限性。一个问题是RNN不具备归纳能力：它们非常擅长记忆序列，但不一定总是能以正确的方式表现出令人信服的泛化能力（稍后我会提供一些具体的例子）。第二个问题是它们不必要地将表示大小与每步计算量耦合在一起。例如，如果你将隐藏状态向量的大小加倍，那么由于矩阵乘法，每步的浮点运算量（FLOPS）将增加四倍。理想情况下，我们希望保持一个巨大的表示/记忆（例如包含整个维基百科或许多中间状态变量），同时保持每个时间步的计算量固定。 The first convincing example of moving towards these directions was developed in DeepMind’s Neural Turing Machines paper. This paper sketched a path towards models that can perform read/write operations between large, external memory arrays and a smaller set of memory registers (think of these as our working memory) where the computation happens. Crucially, the NTM paper also featured very interesting memory addressing mechanisms that were implemented with a (soft, and fully-differentiable) attention model. The concept of soft attention has turned out to be a powerful modeling feature and was also featured in Neural Machine Translation by Jointly Learning to Align and Translate for Machine Translation and Memory Networks for (toy) Question Answering. In fact, I’d go as far as to say that第一个朝着这些方向前进的令人信服的例子是DeepMind的《神经图灵机》（Neural Turing Machines）论文。这篇论文勾画了一个模型的路径，这些模型可以在大型外部存储阵列和一小组计算发生的存储寄存器（可以将这些视为我们的工作记忆）之间执行读/写操作。至关重要的是，NTM论文还展示了非常有趣的记忆寻址机制，这些机制通过一个（软且完全可微分的）注意力模型实现。软注意力的概念被证明是一个强大的建模特性，它也出现在《通过联合学习对齐和翻译的神经机器翻译》和《记忆网络用于（玩具）问答》中。实际上，我甚至可以说 The concept of attention is the most interesting recent architectural innovation in neural networks.注意力的概念是神经网络中最近最有趣的架构创新。 Now, I don’t want to dive into too many details but a soft attention scheme for memory addressing is convenient because it keeps the model fully-differentiable, but unfortunately one sacrifices efficiency because everything that can be attended to is attended to (but softly). Think of this as declaring a pointer in C that doesn’t point to a specific address but instead defines an entire distribution over all addresses in the entire memory, and dereferencing the pointer returns a weighted sum of the pointed content (that would be an expensive operation!). This has motivated multiple authors to swap soft attention models for hard attention where one samples a particular chunk of memory to attend to (e.g. a read/write action for some memory cell instead of reading/writing from all cells to some degree). This model is significantly more philosophically appealing, scalable and efficient, but unfortunately it is also non-differentiable. This then calls for use of techniques from the Reinforcement Learning literature (e.g. REINFORCE) where people are perfectly used to the concept of non-differentiable interactions. This is very much ongoing work but these hard attention models have been explored, for example, in Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets, Reinforcement Learning Neural Turing Machines, and Show Attend and Tell.现在，我不想深入研究太多细节，但用于内存寻址的软注意力方案很方便，因为它使模型保持完全可微分，但不幸的是，人们牺牲了效率，因为所有可以处理的东西都被处理了（但很软）。可以把它想象成在 C 语言中声明一个指针，该指针不指向特定地址，而是在整个内存中的所有地址上定义整个分布，并且取消引用指针会返回指向内容的加权总和（这将是一个昂贵的操作！这促使多位作者将软注意力模型换成硬注意力模型，其中一个人对要关注的特定内存块进行采样（例如，对某些记忆单元进行读/写操作，而不是在某种程度上从所有单元读取/写入）。这个模型在哲学上更具吸引力、可扩展性和效率，但不幸的是，它也是不可微分的。然后，这需要使用强化学习文献中的技术（例如REINFORCE），在这些技术中，人们完全习惯了不可微分交互的概念。这是一项正在进行的工作，但这些硬注意力模型已经被探索过，例如，在使用堆栈增强的循环网络推断算法模式、强化学习神经图灵机和显示、出席和讲述中。 People. If you’d like to read up on RNNs I recommend theses from Alex Graves, Ilya Sutskever and Tomas Mikolov. For more about REINFORCE and more generally Reinforcement Learning and policy gradient methods (which REINFORCE is a special case of) David Silver’s class, or one of Pieter Abbeel’s classes.人。如果你想深入了解RNN，我推荐阅读Alex Graves、Ilya Sutskever和Tomas Mikolov的论文。关于REINFORCE和更广泛的强化学习及策略梯度方法（REINFORCE是其特例），可以参考David Silver的课程，或Pieter Abbeel的课程之一。 Code. If you’d like to play with training RNNs I hear good things about keras or passage for Theano, the code released with this post for Torch, or this gist for raw numpy code I wrote a while ago that implements an efficient, batched LSTM forward and backward pass. You can also have a look at my numpy-based NeuralTalk which uses an RNN/LSTM to caption images, or maybe this Caffe implementation by Jeff Donahue.代码。如果你想尝试训练RNN，我听说keras或passage for Theano的评价很好，可以参考本文发布的用于Torch的代码，或者我之前编写的这个实现了高效批量LSTM前向和后向传递的纯numpy代码。你也可以看看我基于numpy的NeuralTalk，它使用RNN/LSTM生成图像描述，或者看看Jeff Donahue的这个Caffe实现。 Conclusion 结论We’ve learned about RNNs, how they work, why they have become a big deal, we’ve trained an RNN character-level language model on several fun datasets, and we’ve seen where RNNs are going. You can confidently expect a large amount of innovation in the space of RNNs, and I believe they will become a pervasive and critical component to intelligent systems.我们已经了解了RNN，它们是如何工作的，为什么它们变得如此重要。我们在几个有趣的数据集上训练了一个RNN字符级语言模型，并且看到了RNN的发展方向。你可以自信地期待在RNN领域出现大量的创新，我相信它们将成为智能系统中普遍且关键的组成部分。 Lastly, to add some meta to this post, I trained an RNN on the source file of this blog post. Unfortunately, at about 46K characters I haven’t written enough data to properly feed the RNN, but the returned sample (generated with low temperature to get a more typical sample) is:最后，为了给这篇文章增加一些元内容，我用这篇博客文章的源文件训练了一个RNN。不幸的是，大约46K字符的数据量还不足以充分训练RNN，但生成的样本（在低温下生成，以获得更典型的样本）如下： 12I&#x27;ve the RNN with and works, but the computed with program of the RNN with and the computed of the RNN with with and the code Yes, the post was about RNN and how well it works, so clearly this works :). See you next time!是的，这篇文章是关于 RNN 及其工作情况的，所以很明显这:)工作。下次再见！ EDIT (extra links): 编辑（额外链接）Videos: 视频： I gave a talk on this work at the London Deep Learning meetup (video).我在伦敦深度学习聚会上就这项工作发表了演讲（视频）。 Discussions: 讨论： HN discussion HN 讨论 Reddit discussion on r/machinelearningReddit 关于 r/machinelearning 的讨论 Reddit discussion on r/programmingReddit 上关于 r/programming 的讨论 Replies: 答复： Yoav Goldberg compared these RNN results to n-gram maximum likelihood (counting) baselineYoav Goldberg 将这些 RNN 结果与 n-gram 最大似然（计数）基线进行了比较 @nylk trained char-rnn on cooking recipes. They look great!@nylk培训了char-rnn的烹饪食谱。它们看起来很棒！ @MrChrisJohnson trained char-rnn on Eminem lyrics and then synthesized a rap song with robotic voice reading it out. Hilarious :)@MrChrisJohnson用 Eminem 的歌词训练了 char-rnn，然后合成了一首带有机器人声音的说唱歌曲。搞笑:) @samim trained char-rnn on Obama Speeches. They look fun!@samim培训了奥巴马演讲的char-rnn。他们看起来很有趣！ João Felipe trained char-rnn irish folk music and sampled music若昂·费利佩（João Felipe）训练了char-rnn爱尔兰民间音乐并采样了音乐 Bob Sturm also trained char-rnn on music in ABC notation鲍勃·斯特姆（Bob Sturm）还对char-rnn进行了ABC记谱法的音乐培训 RNN Bible bot by MaximilienRNN Bible bot 的 Maximilien Learning Holiness learning the Bible学习圣洁 学习圣经 Terminal.com snapshot that has char-rnn set up and ready to go in a browser-based virtual machine (thanks @samim)Terminal.com 已设置 char-rnn 并准备在基于浏览器的虚拟机中使用的快照（感谢 @samim） 注释1.Vanilla 神经网络“Vanilla 神经网络”通常指的是最基本、最简单的神经网络模型，没有使用任何特殊的层或复杂的架构。具体来说，它一般指的是简单的前馈神经网络（Feedforward Neural Network, FNN） 2. 向量（Vector）vs 序列（Sequence）向量（Vector）： 定义：在数学和计算机科学中，向量是一组有序的数值。这些数值可以表示多维空间中的一个点或某个特定的数据结构。 特性： 固定长度：向量的长度是固定的，例如一个包含三个数值的向量$x_1, x_2, x_3$。 这种处理方式对于图像分类、固定长度的文本分类等任务非常有效。 无时间依赖：向量中的元素没有时间或顺序上的依赖关系。例如，一张图片的像素数据可以作为输入向量，但这些像素之间没有时间顺序上的关系。 示例： 图像处理中的像素值向量。 静态文本分类中的单词向量。 向量输入输出：向量输入输出通常指的是神经网络处理固定长度的向量，即一组固定大小的数值输入和输出。 应用场景： 图像分类：输入是一个固定大小的图像向量，输出是一个类别标签向量。 静态文本分类：输入是一个表示单个文档的向量，输出是分类标签。 序列（Sequence）： 定义：序列是一组按特定顺序排列的数据，通常是时间或顺序相关的。 特性： 变长：序列的长度可以变化，例如一段文本可以是一个字符序列$c_1, c_2, …, c_t$ 有时间依赖：序列中的元素有时间或顺序上的依赖关系。后续元素依赖于前面出现的元素。例如，在自然语言处理中，一个句子的单词顺序决定了句子的意义。 示例： 时间序列数据，如股票价格的每日记录。 文本数据，如一段句子中的单词序列。 序列输入输出：序列输入输出指的是神经网络处理一系列的输入数据，这些数据有时间或顺序上的依赖关系。RNN（循环神经网络）就是处理序列数据的典型模型。 应用场景： 语言模型和文本生成：输入是一个文本序列，输出是下一个字符或单词的预测序列。 机器翻译：输入是源语言的句子序列，输出是目标语言的句子序列。 语音识别：输入是语音信号的时间序列，输出是对应的文本序列。 3. RNN computation论文正文中对该过程的描述文字较多，我反倒觉得结合数学公式后更好理解。这里描述就是 RNN 的前向传播过程， 如果你了解了基础神经网络的前向传播过程，那么RNN也非常好理解。 简单理解就是 相比在神经网络一文中讲述的基础 前向传播过程中，递归神经网络在此基础上增加了一个隐藏层到隐藏层的权重矩阵参与计算。 这3个权重矩阵分别对应文中W_hh（隐藏层到隐藏层）、W_xh（输入层到隐藏层）和W_hy（隐藏层到输出层）,下面以$ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$ 来拆解整个过程 假设网络结构和参数如下 输入层：2个节点，表示输入特征 $x_1$ 和 $x_2$。 隐藏层：2个节点，表示隐藏状态 $h_1$ 和 $h_2$​，,使用tanh激活函数。 输出层：1个节点，表示输出 $y$，使用线性激活函数。 权重矩阵 输入层到隐藏层的权重： $W_{xh} = \\begin{bmatrix} W_{11} &amp; W_{12} \\ W_{21} &amp; W_{22} \\end{bmatrix}$ $W_{11}$、$W_{12}$​ 连接 $x_1$​ 到 $h_1$​ 和 $h_2$​，$W_{21}$、$W_{22}$​ 连接 $x_2$​ 到 $h_1$​ 和 $h_2$。 隐藏层到隐藏层的权重：$W_{hh} = \\begin{bmatrix} U_{11} &amp; U_{12} \\ U_{21} &amp; U_{22} \\end{bmatrix}$ $U_{11}$和 $U_{12}$ 连接 $h_1(t-1)$到 $h_1(t)$ 和 $h_2(t)$。 $U_{21}$ 和 $U_{22}$ 连接 $h_2(t-1)$ 到 $h_1(t)$ 和 $h_2(t)$。[[#5. 序列数据的处理]] 隐藏层到输出层的权重： $W_{hy} = \\begin{bmatrix} W_{31} &amp; W_{32} \\end{bmatrix}$ $W_{31}$​ 和 $W_{32}$分别连接$h_1$ 和$h_2$到 $y$。 前向传播过程对于每个时间步 $t$，前向传播的计算步骤如下： 1. 输入层到隐藏层计算当前时间步的隐藏状态, 即正文中的“隐藏状态的更新”$ℎ_𝑡=tanh⁡(𝑊_{ℎℎ}ℎ_{𝑡−1}+𝑊_{𝑥ℎ}𝑥_𝑡)$其中，$\\mathbf{x}_t$​ 是当前时间步的输入向量，$\\mathbf{h}_{t-1}$是前一时间步的隐藏状态。具体展开如下： $\\begin{bmatrix} h_{1t} \\ h_{2t} \\end{bmatrix} = \\text{tanh} \\left( \\begin{bmatrix} W_{11} &amp; W_{12} \\ W_{21} &amp; W_{22} \\end{bmatrix} \\begin{bmatrix} x_{1t} \\ x_{2t} \\end{bmatrix} + \\begin{bmatrix} U_{11} &amp; U_{12} \\ U_{21} &amp; U_{22} \\end{bmatrix} \\begin{bmatrix} h_{1(t-1)} \\ h_{2(t-1)} \\end{bmatrix} + \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix} \\right)$ 分开计算：$h_{1t} = \\text{tanh}(W_{11} x_{1t} + W_{12} x_{2t} + U_{11} h_{1(t-1)} + U_{12} h_{2(t-1)} )$ $h_{2t} = \\text{tanh}(W_{21} x_{1t} + W_{22} x_{2t} + U_{21} h_{1(t-1)} + U_{22} h_{2(t-1)})$ 2. 隐藏层到输出层计算当前时间步的输出。 $y_t = W_{hy} \\mathbf{h}_t$具体展开如下：$y_t = \\begin{bmatrix} W_{31} &amp; W_{32} \\end{bmatrix} \\begin{bmatrix} h_{1t} \\ h_{2t} \\end{bmatrix}$ 分开计算： $y_t = W_{31} h_{1t} + W_{32} h_{2t}$ ⚠️： tanh 是非线性激活函数 4. 1-of-k编码1-of-k编码，也称为独热编码（One-Hot Encoding），是一种将分类数据转换为二进制向量的方法。它的目的是将非数值型的类别变量转化为适合于机器学习算法处理的数值型数据。 工作原理假设有一个类别变量，它有 $k$ 个不同的类别。1-of-k编码将每个类别表示为一个长度为 $k$ 的二进制向量，其中只有一个位置为1，其他位置为0。 例如，考虑一个有四个类别的变量：”A”, “B”, “C”, “D”。其1-of-k编码如下： 类别 1-of-k编码 A [1, 0, 0, 0] B [0, 1, 0, 0] C [0, 0, 1, 0] D [0, 0, 0, 1] 优点 消除排序关系：独热编码将分类变量转化为二进制向量，避免了对分类变量的误解，即认为它们之间存在排序关系。 适合模型处理：许多机器学习算法（如线性回归、逻辑回归等）无法直接处理非数值型数据，1-of-k编码使这些数据适合于这些算法。 缺点 高维度问题：当类别数量较多时，编码后的向量长度会变得很长，导致高维度问题，增加计算和存储成本。 实际应用 文本处理：在自然语言处理（NLP）任务中，1-of-k编码常用于将单词转化为二进制向量。 分类任务：在分类任务中，用于将类别标签转化为模型可以处理的数值型数据。 1-of-k编码是数据预处理中的一种重要技术，广泛应用于各种机器学习和深度学习任务中。它帮助将分类数据转化为数值数据，使得各种模型能够更好地处理这些数据。 5. 置信度在机器学习中，置信度（confidence）是衡量模型预测结果确定性的一个指标。置信度可以理解为模型对其预测的某个结果是正确的信心程度。 在机器学习中，置信度通常以概率值的形式表示，反映了模型对某个预测的确定性。例如，在分类任务中，模型对某个样本属于某一类的置信度可能是80%，表示模型认为该样本属于该类的概率为80%。具体应用： 分类任务：如图像分类，模型输出每个类别的概率分布。例如，对于一张图片，模型可能输出：[猫: 0.7, 狗: 0.2, 兔子: 0.1]，其中猫的置信度最高。 置信度阈值：在某些应用中，可能会设置一个置信度阈值，只有当预测的置信度超过某个值时，才认为预测有效。 置信度的计算 概率分布：使用Softmax函数将模型输出的logits转化为概率分布，这些概率值即为置信度。 Softmax公式：对于第 $i$ 个输出节点，置信度 $P(y_i)$ 为： $P(y_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}$ 其中， $z_i$ 是第 $i$ 个节点的logit。Logits Logits 是神经网络在分类任务中的输出层的原始得分。它们是未经过归一化的数值，用于表示每个类别的相对置信度。Logits 是通过前向传播计算得到的，表示模型对每个可能的类别的初始估计。 具体理解 原始得分：Logits 是神经网络最后一层输出的原始分数，这些分数还没有被转换为概率。 用途：在分类任务中，Logits 被用来计算每个类别的概率，这通常通过 Softmax 函数完成。 Softmax 转换：Softmax 函数将 Logits 转换为概率分布，使得这些概率的和为1。公式如上 6. Softmax[[0-神经网络（Neural Networks）#^cfe178]] 7. 超参数 Temperature 温度Temperature是在模型使用或调优过程中设定的参数，并不通过模型训练过程中的优化算法来更新，因此它属于超参数。Temperature作为超参数，在神经网络中用来控制Softmax输出的概率分布平滑程度，它的作用是调节模型生成样本的多样性和确定性。 Temperature的公式Softmax函数带有Temperature的公式如下： $P(y_i) = \\frac{e^{z_i / T}}{\\sum_{j} e^{z_j / T}}$ 其中，$z_i$ 是logits值，$T$ 是Temperature参数。 Temperature的影响 高Temperature（T &gt; 1）： 平滑分布：使概率分布更加平滑，增加生成样本的多样性。 增加随机性：输出类别之间的概率差距缩小，使得选择更随机。 示例：假设 logits 为 $[2.0,1.0,0.1]$，使用 $T = 2$ 时，概率可能变得更接近，如 $[0.4,0.35,0.25]$。 低Temperature（0 &lt; T &lt; 1）： 尖锐分布：使概率分布更加尖锐，增加生成样本的确定性。 减少随机性：输出类别之间的概率差距加大，使得选择更确定。 示例：假设 logits 为 $[2.0,1.0,0.1]$，使用 $T = 0.5$ 时，概率可能变得更尖锐，如 $[0.7,0.25,0.05]$。 Temperature等于1： 标准Softmax：概率分布保持原样，不做任何调整。 作用及应用场景 文本生成： 控制生成文本的多样性和创造性。在文本生成任务中，高Temperature可能生成更有创意但不一定合理的句子，而低Temperature可能生成更合理但缺乏多样性的句子。 探索与利用： 在强化学习中，高Temperature用于探索多样性策略，低Temperature用于利用已知的最佳策略。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"}]},{"title":"递归神经网络（Recurrent Neural Networks, RNNs）","slug":"递归神经网络（Recurrent-Neural-Networks-RNNs）","date":"2024-06-07T14:03:29.000Z","updated":"2024-06-16T14:25:26.622Z","comments":true,"path":"6ac941eb/","permalink":"http://example.com/6ac941eb/","excerpt":"","text":"前置概念1. 时间步（Time Step）和序列数据（Sequential Data）1.1 序列数据（Sequential Data）序列数据（Sequential Data）是指按照时间或其他顺序排列的数据，其中每个数据点的意义和价值都依赖于它在序列中的位置和前后数据点的关系。序列数据广泛存在于许多实际应用中，如时间序列、自然语言处理、语音识别等。 序列数据的特点 时间依赖性：序列数据中的每个数据点与其前后数据点存在依赖关系。这种依赖性可以是短期的（仅依赖于最近的数据点）或长期的（依赖于较早的数据点）。 顺序关系：序列数据的顺序是至关重要的，数据点的顺序关系决定了其实际意义。例如，在语音信号中，音频帧的顺序决定了最终语音的内容。 动态性：序列数据往往是动态变化的，数据点的值随时间或其他顺序变化而变化。 1.2 时间步时间步指的是序列数据中的每一个元素在时间维度上的位置。例如，在一个时间序列中，每个时间点上的数据称为一个时间步。在递归神经网络中，输入序列按时间步逐步处理，每个时间步的输入不仅影响当前时间步的输出，还影响后续时间步的计算。 1.3 序列数据与时间步的实际例子序列数据可以分为多种类型，具体包括： 1. 时间序列数据时间序列数据是按照时间顺序排列的数据，常用于金融市场分析、气象预报等领域。示例：股票价格、温度记录等。12时间： t1 t2 t3 t4 t5股票价格： 100 102 101 103 104 2. 自然语言处理数据自然语言处理中的数据是按照文本中的顺序排列的单词或字符，常用于文本分类、机器翻译等任务。 示例：一段文本、一句话等。12时间： t1 t2 t3 t4 t5句子： 我 喜欢 学习 机器 学习 3. 语音信号数据语音信号是连续的音频帧序列，每个音频帧表示一小段时间内的声音特征，常用于语音识别、语音合成等任务。 示例：一段语音信号。12时间步： t1 t2 t3 t4 t5音频帧： F1 F2 F3 F4 F5 4. 视频数据视频数据是由一系列按时间顺序排列的图像帧组成，常用于视频分类、目标检测等任务。 示例：一段视频。12时间步： t1 t2 t3 t4 t5视频帧： F1 F2 F3 F4 F5 1.4 序列数据的实际应用场景 时间序列预测：通过分析历史数据，预测未来的值。示例：股票价格预测、天气预报、销售量预测等。 自然语言处理：处理和理解人类语言，执行各种语言相关任务。示例：文本分类、情感分析、机器翻译、文本生成等。 语音识别：将语音信号转换为文本，或者识别语音中的情感、语种等信息。示例：语音到文本转换、语音情感识别、语音翻译等。 视频处理：处理和分析视频数据，执行各种视频相关任务。示例：视频分类、目标检测、行为识别等 1.5 序列数据的处理处理序列数据时，需要考虑数据的顺序和时间依赖性。以下是一些常见的处理方法和模型： 1. 递归神经网络（Recurrent Neural Networks, RNNs）RNNs通过循环结构能够记住和利用序列数据中的时间依赖性，适用于处理各种序列数据。 特点： 能够处理变长序列数据。 能够捕捉短期和长期依赖关系。 2. 长短期记忆网络（Long Short-Term Memory, LSTM）LSTM是RNN的一种变体，专门用于解决RNN中的梯度消失和梯度爆炸问题，能够更好地捕捉长序列中的依赖关系。 特点： 通过引入遗忘门、输入门和输出门控制信息流动。 能够记住长时间的依赖关系。 3. 门控循环单元（Gated Recurrent Unit, GRU）GRU是LSTM的简化版本，具有类似的门控机制，但参数更少，计算效率更高。 特点： 通过更新门和重置门控制信息流动。 计算效率更高，适合处理长序列数据。 4. Transformer模型Transformer模型通过自注意力机制（Self-Attention）处理序列数据，能够并行处理序列中的每个位置，解决了传统RNN的计算瓶颈问题。 特点： 通过注意力机制捕捉序列中任意位置之间的依赖关系。 计算效率高，适合处理长序列数据。 2. 什么是RNN递归神经网络（Recurrent Neural Networks, RNNs）是一类专门用于处理序列数据的神经网络模型。RNNs通过循环结构使得网络能够捕捉和记忆输入数据中的时间依赖性，适用于各种序列数据处理任务，如时间序列预测、自然语言处理、语音识别等。 如果你已经对基础神经网络的层次结构和前向传播过程了解了， 那么RNN 与它的区别就是其隐藏层具有循环连接，使得当前时间步的隐藏状态不仅依赖于当前输入，还依赖于前一时间步的隐藏状态。 下面在 基础神经网络中的层次结构的基础上说明 RNN 网络结构和参数 输入层：2个节点，表示输入特征 $x_1$ 和 $x_2​$。 隐藏层：2个节点，表示隐藏状态 $h_1$ 和 $h_2$​，偏置向量分别为$b_1$、$b_2$,使用ReLU激活函数。 输出层：1个节点，表示输出 $y$，偏置向量分别为$b_3$,使用线性激活函数。 权重矩阵 输入层到隐藏层的权重： $W_{xh} = \\begin{bmatrix} W_{11} &amp; W_{12} \\ W_{21} &amp; W_{22} \\end{bmatrix}$ $W_{11}​$、$W_{12}$​ 连接 $x_1$​ 到 $h_1$​ 和 $h_2$​，$W_{21}​$、$W_{22}$​ 连接 $x_2$​ 到 $h_1$​ 和 $h_2​$。 隐藏层到隐藏层的权重：$W_{hh} = \\begin{bmatrix} U_{11} &amp; U_{12} \\ U_{21} &amp; U_{22} \\end{bmatrix}$ $U_{11}​$和 $U_{12}​$ 连接 $h_1(t-1)$到 $h_1(t)$ 和 $h_2(t)$。 $U_{21}​$ 和 $U_{22}$ 连接 $h_2(t-1)$ 到 $h_1(t)$ 和 $h_2(t)$。 隐藏层到输出层的权重： $W_{hy} = \\begin{bmatrix} W_{31} &amp; W_{32} \\end{bmatrix}$ $W_{31}$​ 和 $W_{32}$分别连接$h_1$ 和$h_2​$到 $y$。 偏置向量 隐藏层的偏置：$\\mathbf{b}_h = \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix}$ 输出层的偏置：$b_3$前向传播过程 对于每个时间步 $t$，前向传播的计算步骤如下： 输入层到隐藏层：计算当前时间步的隐藏状态。$\\mathbf{h}_t = \\text{ReLU}(W_{xh} \\mathbf{x}_t + W_{hh} \\mathbf{h}_{t-1} + \\mathbf{b}_h)$ 其中，$\\mathbf{x}_t$​ 是当前时间步的输入向量，$\\mathbf{h}_{t-1}​$是前一时间步的隐藏状态。具体展开如下： $\\begin{bmatrix} h_{1t} \\ h_{2t} \\end{bmatrix} = \\text{ReLU} \\left( \\begin{bmatrix} W_{11} &amp; W_{12} \\ W_{21} &amp; W_{22} \\end{bmatrix} \\begin{bmatrix} x_{1t} \\ x_{2t} \\end{bmatrix} + \\begin{bmatrix} U_{11} &amp; U_{12} \\ U_{21} &amp; U_{22} \\end{bmatrix} \\begin{bmatrix} h_{1(t-1)} \\ h_{2(t-1)} \\end{bmatrix} + \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix} \\right)$ 分开计算： $h_{1t} = \\text{ReLU}(W_{11} x_{1t} + W_{12} x_{2t} + U_{11} h_{1(t-1)} + U_{12} h_{2(t-1)} + b_1)$ $h_{2t} = \\text{ReLU}(W_{21} x_{1t} + W_{22} x_{2t} + U_{21} h_{1(t-1)} + U_{22} h_{2(t-1)} + b_2)$ 隐藏层到输出层：计算当前时间步的输出。 $y_t = W_{hy} \\mathbf{h}_t + b_3$具体展开如下： $y_t = \\begin{bmatrix} W_{31} &amp; W_{32} \\end{bmatrix} \\begin{bmatrix} h_{1t} \\ h_{2t} \\end{bmatrix} + b_3$ 分开计算： $y_t = W_{31} h_{1t} + W_{32} h_{2t} + b_3$ Dropout在RNN中的表现在传统的前馈神经网络中，Dropout被证明是非常有效的正则化方法。然而，直接将这种方法应用于RNN时，会破坏时间步之间的依赖关系，导致模型性能下降。 在RNN中，Dropout的效果确实没有在前馈神经网络中那么明显，原因如下： 时间步之间的依赖性：RNN中的隐藏层具有时间步之间的依赖关系，即当前时间步的隐藏状态依赖于前一时间步的隐藏状态。传统的Dropout方法在RNN中会破坏这种时间步之间的依赖关系，从而影响模型的学习效果。 梯度传播的影响：RNN通过反向传播通过时间（Backpropagation Through Time, BPTT）来更新权重，Dropout会在时间步之间引入不稳定性，可能导致梯度传播过程中的问题，如梯度消失或梯度爆炸。 3. RNN中的梯度消失和梯度爆炸在训练循环神经网络（RNN）时，常常会遇到梯度消失和梯度爆炸问题，这两者都是由RNN的反向传播算法（BPTT, Backpropagation Through Time）引起的。 1. 梯度消失（Vanishing Gradient）现象： 当梯度在反向传播过程中逐层传递时，它的数值会逐渐变小，最终趋近于零。 这导致前面层的权重更新几乎停止，使网络难以训练。 原因： 在反向传播过程中，梯度是通过链式法则逐层相乘的。如果某些层的梯度小于1（例如小于1的激活函数导数），则乘积会快速缩小。 常见的激活函数如tanh和sigmoid在输入值较大或较小时，其导数接近零，从而加剧了梯度消失问题。 2. 梯度爆炸（Exploding Gradient）现象： 当梯度在反向传播过程中逐层传递时，它的数值会逐渐变大，最终变得非常大。 这导致前面层的权重更新过大，使网络参数变得不稳定，甚至导致溢出。 原因： 在反向传播过程中，如果某些层的梯度大于1（例如大于1的激活函数导数），则乘积会快速增大。 常见的原因包括不合理的初始化权重和未处理的数值不稳定问题。 解决方法 梯度裁剪（Gradient Clipping）： 当梯度的范数超过某个阈值时，将其缩放到该阈值。 这可以有效防止梯度爆炸。 长短期记忆网络（LSTM）和门控循环单元（GRU）： 这些是专门设计用于缓解梯度消失和梯度爆炸问题的RNN变种。 通过引入门机制，它们能够更好地保持长时间依赖。 适当的权重初始化： 使用如Xavier初始化或He初始化来设置初始权重，可以减少梯度消失和爆炸的风险。 使用不同的激活函数： ReLU等激活函数在一定程度上可以缓解梯度消失问题。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"}]},{"title":"神经网络（Neural Networks）","slug":"神经网络（Neural-Networks）","date":"2024-06-07T09:16:16.000Z","updated":"2024-07-11T08:40:25.010Z","comments":true,"path":"f27811be/","permalink":"http://example.com/f27811be/","excerpt":"","text":"0. 什么是神经网络 (Neural Networks)神经网络是实现AI 的一种技术手段，一种广泛用于机器学习（Machine Learning）和深度学习（Deep Learning）领域的计算模型/算法架构。 它受到人类大脑神经元（Neurons）和它们的互动方式的启发，它由多个层（Layers）组成，每层包含多个神经元，这些神经元通过权重（Weights）连接传递信息。 神经网络的训练过程基于机器学习的基本前提，即能够从数据中学习。通过向网络提供大量的数据样本（包括输入和期望的输出），神经网络可以学习到如何映射输入到输出，这种能力是通过调整内部结构（即权重）来实现的。 这一学习过程使用了机器学习中的核心概念，如损失函数（Loss Functions）、梯度下降（Gradient Descent）和反向传播算法（Backpropagation Algorithms）。这些都是机器学习领域的基本工具，用于训练模型以改进其性能。 1. 神经网络的层次结构1.1 节点（Nodes）或神经元（Neurons）节点是神经网络的基本单位，也称为神经元。每个节点接收输入信号，进行加权求和和非线性变换，然后将结果传递给下一层的节点。节点的主要功能包括： 接收输入：从前一层的所有节点接收输入信号。 加权求和：对接收到的输入信号乘以相应的权重并求和。 应用激活函数：对加权求和的结果应用激活函数，生成节点的输出。 传递输出：将输出信号传递给下一层的节点。 1.2 层（Layers）层是由多个节点组成的一个集合，在神经网络中起着分层处理输入数据的作用。每一层中的节点执行相同类型的计算，但每个节点有各自的权重和偏置。 一个典型的神经网络由以下几个部分组成： 输入层（Input Layer）：接收外部输入数据，每个节点代表一个输入特征。 隐藏层（Hidden Layers）：位于输入层和输出层之间，用于特征提取和数据变换。一个神经网络可以有一个或多个隐藏层。 输出层（Output Layer）：生成最终的预测结果，每个节点代表一个输出。 1.3 节点和层的关系节点和层之间的关系可以概括如下： 层是节点的集合：每一层由多个节点组成，这些节点在同一层内进行相同类型的计算。 数据传递和处理：数据在神经网络中逐层传递，每一层的节点接收前一层的输出，进行计算后将结果传递给下一层的节点。 层次结构：神经网络的层次结构决定了数据处理的顺序和方式。输入数据经过输入层后，依次通过一个或多个隐藏层进行复杂的特征提取，最终通过输出层生成预测结果。 1.4 层与层之间的连接层与层之间的连接由权重矩阵决定。每一层的节点与下一层的每个节点相连，连接的强度由权重值决定。在前向传播过程中，输入层的节点将输入数据传递给第一个隐藏层的节点，后者再将处理后的数据传递给下一个隐藏层，依此类推，直到输出层。 2. 权重权重是连接神经网络中不同层节点的参数，用于调节输入信号在网络中的传递和变换强度。每个连接都有一个权重，表示输入信号对输出信号的影响力。 调节信号强度：权重乘以输入信号后，再通过求和和激活函数的变换，决定了输出信号的值。不同的权重值代表输入信号的重要程度。 特征学习：通过学习和调整权重，神经网络能够识别和提取输入数据中的重要特征。 优化：在训练过程中，权重被调整以最小化预测误差。通过反向传播算法，权重的值不断更新，使得模型的预测更加准确。 2.1 权重的存在形式权重并不存在于单独的节点内，而是存在于节点之间的连接上。具体来说，每一层的节点与下一层的节点之间的连接由一组权重参数表示。权重矩阵表示了两个层之间所有节点连接的权重值。 2.2 权重的初始化和调整权重的初始化方法有多种，包括零初始化、随机初始化、Xavier初始化和He初始化等。这些方法旨在为模型提供一个良好的起点，以便更好地进行训练。 2.3 权重的训练调整在训练过程中，权重通过优化算法进行调整。最常用的优化算法是梯度下降（Gradient Descent）及其变种（如随机梯度下降、Adam优化算法等）。训练步骤如下： 前向传播：计算网络的预测输出。 计算损失：通过损失函数衡量预测输出与真实标签之间的差距。 反向传播：计算损失函数对每个权重的梯度。 更新权重：使用梯度下降法更新权重，以最小化损失函数。 2.4 优化算法为了提高训练效率和稳定性，可以使用各种优化算法，包括： 动量（Momentum）：结合当前梯度和之前更新的方向，加速收敛。 AdaGrad：根据过去的梯度调整学习率，适应性地进行参数更新。 RMSProp：改进AdaGrad，使用指数加权平均计算梯度平方和，避免学习率过快减小。 Adam：结合动量和RMSProp的优点，适应性地调整学习率和动量，广泛应用于各种神经网络训练。 2.5 权重在不同类型神经网络中的角色不同类型的神经网络中，权重的具体作用可能有所不同： 前馈神经网络（Feedforward Neural Networks, FNNs）：权重连接每一层的所有节点，负责将输入数据逐层传递和变换。 卷积神经网络（Convolutional Neural Networks, CNNs）：权重是卷积核的参数，负责在局部感知野上提取特征。 递归神经网络（Recurrent Neural Networks, RNNs）：权重用于处理序列数据，包括当前时间步的输入与前一时间步的隐藏状态之间的关系。 3. 偏置（Biases）偏置是每个节点附加的一个参数，用于调整节点的输出独立于输入信号。偏置帮助神经网络学到更灵活的决策边界。 作用 调节输出：偏置提供一个额外的自由度，使得神经网络能够更好地拟合数据。 避免零输出：在输入信号为零的情况下，偏置确保节点仍然能够产生非零输出。 4. 激活函数（Activation Function）激活函数（Activation Function）是神经网络中的一个关键组件，它引入了非线性变换，使得神经网络能够学习和表示复杂的非线性关系。如果没有激活函数，神经网络的每一层只进行线性变换，那么无论多少层的堆叠，整体仍然是一个线性变换。这将极大限制神经网络的表示能力。因此，激活函数对于神经网络的性能和能力至关重要。 线性（Linear）和非线性（Nonlinear）是数学和信号处理中两个基本的概念，这些概念在神经网络和机器学习中也具有重要意义。理解这两个概念有助于掌握为什么激活函数对神经网络的性能如此重要。 4.1 线性（Linear）vs 非线性（Nonlinear）4.1.1 线性（Linear）线性关系是指两个变量之间的关系可以用一个线性方程表示。对于一个变量 $x$ 和其对应的输出 $y$，线性关系可以表示为：$y = mx + b$其中，$m$ 是斜率，$b$ 是截距。这意味着如果我们绘制 $y$ 对 $x$ 的图像，它将是一条直线。 特点 叠加性：线性系统满足叠加原理，即输入的线性组合会产生输出的线性组合。如果 $f(x_1) = y_1$​ 和$f(x_2) = y_2$，那么对于任何常数 $a$和 $b$，有 $f(ax_1 + bx_2) = ay_1 + by_2$​。 同质性：线性系统满足同质性，即输入的放大会导致输出的相应放大。如果 $f(x) = y$，那么对于任何常数 $k$，有 $f(kx) = ky$。 在神经网络中的应用在神经网络中，线性变换通常通过矩阵乘法和加法实现，例如输入与权重矩阵的乘积加上偏置：$z = W \\cdot x + b$ 4.1.2 非线性（Nonlinear）非线性关系是指两个变量之间的关系不能用一个简单的线性方程表示。非线性关系的数学表示形式可以非常多样，常见的形式包括多项式、指数函数、对数函数、三角函数等。例如，对于变量 $x$ 和 $y$，非线性关系可以表示为：$y=ax^2+bx+c$其中，$a$、$b$、$c$ 是常数。这意味着如果我们绘制 $y$ 对 $x$ 的图像，它将不是一条直线，而是一个曲线。特点 非叠加性：非线性系统不满足叠加原理。如果 $f(x_1) = y_1​$ 和 $f(x_2) = y_2​$，那么 $f(ax_1 + bx_2) \\neq ay_1 + by_2$​。 复杂性：非线性系统可以表示复杂的关系和模式，能够捕捉到数据中的复杂结构和动态。 为什么需要非线性如果神经网络只使用线性激活函数（例如，恒等函数 f(z)=z），那么无论网络有多少层，其最终输出仍然是输入的线性变换。也就是说，整个网络等效于一个单层的线性模型，无法捕捉数据中的复杂关系。因此，引入非线性激活函数使得网络具有更强的表达能力，能够学习和表示复杂的非线性关系，从而解决更复杂的问题。 4.2 常见的非线性激活函数4.2.1 Sigmoid 函数$σ(z)=\\frac{1}{1+e^{−z}} ​$ 特点： 输出值在0到1之间，适用于概率预测。 在极值区间梯度较小，可能导致梯度消失问题。 计算复杂度较高。 应用： 常用于二分类问题的输出层。 4.2.2 Tanh（双曲正切）函数$tanh(z)=\\frac{e^z-e^{-z}}{e^z+e^{-z}}$​特点： 输出值在-1到1之间。 相对于Sigmoid函数，Tanh函数的输出均值为0，使得数据更中心化。 也存在梯度消失问题，但在0附近的梯度较大，梯度消失问题稍好于Sigmoid。 应用： 常用于隐藏层。4.2.3 ReLU（Rectified Linear Unit）函数$ReLU(z)=max(0,z)$ 特点： 计算简单，收敛速度快。 在正区间保持线性关系，在负区间输出为0。 解决了Sigmoid和Tanh的梯度消失问题。 可能导致部分神经元“死亡”，即在训练过程中某些神经元的输出始终为0，不再更新。 应用： 广泛用于隐藏层。4.2.4 Leaky ReLU 函数$Leaky ReLU(z)=max(αz,z)$ 特点： 解决了ReLU的“死亡神经元”问题。 在负区间给定一个很小的斜率（通常为0.01）。 应用： 替代ReLU，在隐藏层中使用4.2.5 Softmax 函数$Softmax(z_i​)=\\frac{e^z_i}{∑_j​​e^z_j} ​$ 特点： 将输出值转换为概率分布，总和为1。 适用于多分类问题。 应用： 常用于多分类问题的输出层。4.2.6 Swish 函数$Swish(z)=z⋅σ(z)=\\frac{z}{1+e^{−z}} ​​$ 特点： 平滑的非线性函数，性能优于ReLU和Sigmoid。 由Google提出，结合了ReLU和Sigmoid的特点。 应用： 新型激活函数，在一些深度学习模型中表现出色。 4.3 激活函数的选择激活函数的选择对于神经网络的训练和性能有重要影响。以下是一些常见的选择准则： 隐藏层：通常使用ReLU或其变种（如Leaky ReLU、Swish），因为它们计算简单且能有效缓解梯度消失问题。 输出层： 回归问题：使用线性激活函数。 二分类问题：使用Sigmoid函数。 多分类问题：使用Softmax函数 5.训练过程假设我们有一个简单的神经网络，包含一个输入层、一个隐藏层和一个输出层： 输入层**：2个节点，表示输入特征 $x_1$ 和 $x_2​$。 隐藏层：2个节点，表示隐藏状态 $h_1$ 和 $h_2$​，偏置向量分别为$b_1$、$b_2$,使用ReLU激活函数。 输出层：1个节点，表示输出 $y$，偏置向量分别为$b_3$,使用线性激活函数。 权重矩阵 输入层到隐藏层的权重：假设权重为 $W^{(1)} = \\begin{bmatrix} W_{11} &amp; W_{12} \\ W_{21} &amp; W_{22} \\end{bmatrix}$,其中 $W_{11}​$、$W_{12}$​ 连接 $x_1$​ 到 $h_1$​ 和 $h_2$​，$W_{21}​$、$W_{22}$​ 连接 $x_2$​ 到 $h_1$​ 和 $h_2​$。 隐藏层到输出层的权重：假设权重为 $W^{(2)} = \\begin{bmatrix} W_{31} &amp; W_{32} \\end{bmatrix}$ $W_{31}$​ 和 $W_{32}$分别连接$h_1$ 和$h_2​$到 $y$。其中 $W_{31}$、$W_{32}$分别连接 $h_1$和 $h_2$到 $y$ 如果指定具体数据，可以设置为 输入数据为$\\mathbf{X} = [0.5, 0.6]$ 隐藏层权重矩阵 $\\mathbf{W}^{(1)} = \\begin{bmatrix} 0.1 &amp; 0.2 \\ 0.3 &amp; 0.4 \\end{bmatrix}$ 隐藏层偏置向量 $\\mathbf{b}^{(1)} = \\begin{bmatrix} 0.1 \\ 0.2 \\end{bmatrix}$ 输出层权重矩阵 $\\mathbf{W}^{(2)} = \\begin{bmatrix} 0.5 &amp; 0.6 \\end{bmatrix}$ 输出层偏置向量$\\mathbf{b}^{(2)} = \\begin{bmatrix} 0.3 \\end{bmatrix}$ 在训练过程中，通过调整权重和偏置，使得模型的预测结果尽可能准确。以下的主要步骤. 5.1 前向传播（Forward Propagation）前向传播是数据从输入层经过隐藏层传递到输出层的过程。在这个过程中，每一层的节点接收前一层的输出，进行加权求和，并通过激活函数生成输出。具体步骤如下： 加权求和：每个节点接收前一层所有节点的输出，计算加权和。 $z_i = \\sum_{j} w_{ij} x_j + b_i$​ 其中，$z_i$ 是第 $i$ 个节点的加权和，$w_{ij}$ 是从第 $j$ 个输入到第 $i$ 个节点的权重，$x_j$是第 $j$ 个输入，$b_i$​ 是偏置。 激活函数：对加权和应用激活函数，生成节点的输出。 $a_i = f(z_i)$常用的激活函数包括Sigmoid、Tanh和ReLU。5.1.1 输入层输入层接收外部数据，将其传递给第一个隐藏层。假设输入数据为 $\\mathbf{X} = [x_1, x_2]$5.1.2 隐藏层 计算隐藏层的输入加权和：$z_1^{(1)} = w_{11}x_1 + w_{12}x_2 + b_1$ $z_2^{(1)} = w_{21}x_1 + w_{22}x_2 + b_2$ 代入具体数据：$z^{(1)} = \\mathbf{W}^{(1)} \\mathbf{X} + \\mathbf{b}^{(1)} = \\begin{bmatrix} 0.1 &amp; 0.2 \\ 0.3 &amp; 0.4 \\end{bmatrix} \\begin{bmatrix} 0.5 \\ 0.6 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\ 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.1 \\cdot 0.5 + 0.2 \\cdot 0.6 + 0.1 \\ 0.3 \\cdot 0.5 + 0.4 \\cdot 0.6 + 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.27 \\ 0.62 \\end{bmatrix}$ 应用激活函数，计算隐藏层的输出：$h_1 = \\text{ReLU}(z_1^{(1)})$ $h_2 = \\text{ReLU}(z_2^{(1)})$ $h^&#123;(1)&#125; = \\text&#123;ReLU&#125;(z^&#123;(1)&#125;) = \\begin&#123;bmatrix&#125; \\max(0, 0.27) \\\\ \\max(0, 0.62) \\end&#123;bmatrix&#125; = \\begin&#123;bmatrix&#125; 0.27 \\\\ 0.62 \\end&#123;bmatrix&#125;$ 5.1.3 输出层 计算输出层的输入加权和：$z^{(2)} = w_{31}h_1 + w_{32}h_2 + b_3$$z^{(2)} = \\mathbf{W}^{(2)} a^{(1)} + \\mathbf{b}^{(2)} = \\begin{bmatrix} 0.5 &amp; 0.6 \\end{bmatrix} \\begin{bmatrix} 0.27 \\ 0.62 \\end{bmatrix} + \\begin{bmatrix} 0.3 \\end{bmatrix} = 0.5 \\cdot 0.27 + 0.6 \\cdot 0.62 + 0.3 = 0.735$ 应用激活函数，计算最终输出：$y = z^{(2)}$假设输出层使用线性激活函数（即不做非线性变换）$y = z^{(2)} = 0.735$ 5.2 计算损失（Loss Calculation）使用损失函数计算预测输出与真实标签之间的差异。损失函数是一个衡量模型预测误差的指标，常见的损失函数包括均方误差（MSE）和交叉熵损失。 均方误差（MSE, Mean Squared Error）：用于回归问题。 $\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2$ 交叉熵损失（Cross-Entropy Loss）：用于分类问题。 $\\text{Cross-Entropy} = -\\sum_{i=1}^N y_i \\log(\\hat{y}_i)$ 5.3 反向传播（Backpropagation）反向传播算法通过计算损失函数对每个模型参数（权重和偏置）的偏导数/梯度，来指导参数更新，使得损失函数逐步减小，从而提高模型的准确性。 计算梯度：首先计算输出层节点的损失梯度，即损失函数对输出层每个节点输出的偏导数。然后通过链式法则，依次计算每个隐藏层节点的梯度。梯度由后一层节点的梯度和当前层节点的输出值共同决定。 传播误差：误差从输出层逐层传播回输入层，计算每个参数的梯度。 ∂ 是偏导数符号 5.3.1 偏导数和梯度偏导数表示在固定其他变量的情况下，一个变量的变化率。假设 $f(x, y)$ 是一个关于 $x$ 和 $y$的函数，则 $f$ 对 $x$ 的偏导数记作 $\\frac{\\partial f}{\\partial x}$。 在神经网络中，偏导数用于计算梯度，帮助反向传播算法更新权重。梯度是损失函数关于每个参数的导数，表示损失函数变化率。对于一个权重 $w$，梯度 $\\frac{\\partial L}{\\partial w}$ 表示权重变化对损失函数 $L$ 的影响。具体而言，梯度表示损失函数相对于每个参数的偏导数： $\\frac{\\partial L}{\\partial W} = \\text{梯度}$ 通过计算每个参数的偏导数，反向传播算法能逐步调整网络权重，使得损失函数 $L$ 最小化，提高模型的预测能力。 5.3.2 偏导数推导过程如果 $f(x, y) = x^2 + y^2$，则对 $x$ 的偏导数为： $\\frac{\\partial f}{\\partial x} = \\frac{\\partial (x^2 + y^2)}{\\partial x} = 2x$ 根据求导法则，分开对每一项求导：$\\frac{\\partial f}{\\partial x} = \\frac{\\partial (x^2 + y^2)}{\\partial x} =\\frac{\\partial}{\\partial x} (x^2) + \\frac{\\partial}{\\partial x} (y^2)$ 对于 $x^2$，使用幂函数求导法则 $\\frac{\\partial}{\\partial x} (x^n) = nx^{n-1}$：$\\frac{\\partial}{\\partial x} (x^2) = 2x^{2-1}= 2x$对于 $y^2$，因为$y$ 被视为常数，对 $x$ 求导结果为 0：$\\frac{\\partial}{\\partial x} (y^2) = 0$ 同理，对 $y$ 的偏导数为： $\\frac{\\partial f}{\\partial y} = \\frac{\\partial (x^2 + y^2)}{\\partial y} = 2y$ 现在根据以上理解逐层反向计算每个参数的梯度 5.3.3 计算输出层的梯度假设我们使用均方误差（MSE）作为损失函数：$L = \\frac{1}{2} (y - t)^2$ 其中，$t$ 是目标值。 首先，计算损失相对于输出 $y$ 的梯度： $\\frac{\\partial L}{\\partial y} = y - t$ 然后，计算损失相对于隐藏层到输出层权重 $W_{31}$​ 和 $W_{32}$的梯度： $\\frac{\\partial L}{\\partial W_{31}} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial W_{31}}=\\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial (w_{31}h_1 + w_{32}h_2 + b_3)}{\\partial W_{31}} = (y - t) \\cdot h_1$ 由于 $W_{31}$和 $h_1$​ 相乘，而 $h_1$​ 不依赖于 $W_{31}$，其余项在偏导数计算中都是常数，因此可以忽略。所以 在这个表达式中，$W_{31}$和 $h_1$​ 相乘，其余项与 $W_{31}$无关，因此在对 $W_{31}​$ 求导时可以忽略。$\\frac{\\partial L}{\\partial W_{31}} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial W_{31}}=\\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial (w_{31}h_1)}{\\partial W_{31}}$ 根据幂函数求导法则 $\\frac{\\partial}{\\partial x} (x^n) = nx^{n-1}$根据线性求导法则，常数项可以直接提取出来 $\\frac{\\partial}{\\partial x} (a\\cdot x) = a$ $\\frac{\\partial L}{\\partial W_{31}} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial W_{31}}=\\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial (w_{31}h_1)}{\\partial W_{31}} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial (w_{31}h_1)}{\\partial W_{31}}= (y-t) \\cdot h_1$ 同理可得：$\\frac{\\partial L}{\\partial W_{32}} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial W_{32}} = (y - t) \\cdot h_2$ 计算损失相对于偏置 $b_3​$ 的梯度： $\\frac{\\partial L}{\\partial b_3} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial b_3} = (y - t) \\cdot 1 = y - t$ 5.3.4 计算隐藏层的梯度对于隐藏层的梯度，需要计算损失相对于隐藏状态 $h_1$​ 和 $h_2$​ 的梯度： $\\frac{\\partial L}{\\partial h_1} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h_1} = (y - t) \\cdot W_{31}$ $\\frac{\\partial L}{\\partial h_2} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h_2} = (y - t) \\cdot W_{32}$ 其中，$y = w_{31}h_1 + w_{32}h_2 + b_3$ 计算推导过程同上，可以得到以上结果 由于隐藏层使用的是ReLU激活函数，其导数为： $\\frac{\\partial \\text{ReLU}(z)}{\\partial z} = \\begin{cases} 1 &amp; \\text{if } z &gt; 0 \\ 0 &amp; \\text{if } z \\leq 0 \\end{cases}$ 其中 $h_1 = \\text{ReLU}(z_1^{(1)})$ 因此应用链式法则后： $\\frac{\\partial L}{\\partial z_1} = \\frac{\\partial L}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial z_1} = (y - t) \\cdot W_{31} \\cdot \\begin{cases} 1 &amp; \\text{if } z_1 &gt; 0 \\ 0 &amp; \\text{if } z_1 \\leq 0 \\end{cases}$ $\\frac{\\partial L}{\\partial z_2} = \\frac{\\partial L}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial z_2} = (y - t) \\cdot W_{32} \\cdot \\begin{cases} 1 &amp; \\text{if } z_2 &gt; 0 \\ 0 &amp; \\text{if } z_2 \\leq 0 \\end{cases}$ 5.3.5 计算输入层的梯度最后，计算损失相对于输入层权重 $W_{11}, W_{12}, W_{21}, W_{22}$​ 的梯度： $\\frac{\\partial L}{\\partial W_{11}} = \\frac{\\partial L}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial W_{11}} = \\frac{\\partial L}{\\partial z_1} \\cdot x_1$ $\\frac{\\partial L}{\\partial W_{12}} = \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial W_{12}} = \\frac{\\partial L}{\\partial z_2} \\cdot x_1$ $\\frac{\\partial L}{\\partial W_{21}} = \\frac{\\partial L}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial W_{21}} = \\frac{\\partial L}{\\partial z_1} \\cdot x_2$ $\\frac{\\partial L}{\\partial W_{22}} = \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial W_{22}} = \\frac{\\partial L}{\\partial z_2} \\cdot x_2$​ 5.4 更新权重（Weight Update）使用梯度下降算法根据计算得到的梯度调整权重。梯度下降的基本公式为：$W_{new​}=W_{old}​−η⋅\\frac{\\partial L}{\\partial W}$ 其中，$\\eta$ 是学习率（Learning Rate），$\\frac{\\partial L}{\\partial W}$​ 是损失函数对权重的梯度。 常见的梯度下降变种 批量梯度下降（Batch Gradient Descent）：在整个训练数据集上计算梯度，然后更新权重。适用于小数据集，但计算量大，效率较低。 随机梯度下降（Stochastic Gradient Descent, SGD）：在每个训练样本上计算梯度，然后更新权重。计算效率高，但梯度噪声大，收敛不稳定。 小批量梯度下降（Mini-Batch Gradient Descent）：在小批量训练样本上计算梯度，然后更新权重。结合了批量和随机梯度下降的优点，常用在实际训练中。 6. 超参数（Hyperparameters） vs 模型参数（Parameters）超参数（Hyperparameters）： 定义：超参数是指在模型训练之前需要手动设置的参数，不通过训练数据学习得到，而是通过试验、经验或自动调优方法设定。 作用：控制模型的训练过程、模型复杂度、正则化程度等。 示例：学习率（learning rate）、批大小（batch size）、隐藏层的数量和大小、正则化系数（如L2正则化中的λ）、训练轮数（epochs）等。 调整方法：手动调试（Manual Tuning）、网格搜索（Grid Search）、随机搜索（Random Search）、贝叶斯优化（Bayesian Optimization）等。 调整频率：通常在训练之前设定，在训练过程中不变。可能需要多次试验和调优过程才能确定最佳超参数。 模型参数（Model Parameters）： 定义：模型参数是指在模型训练过程中通过数据学习得到的参数，这些参数定义了模型的最终形态和行为。 作用：直接影响模型的预测输出，反映了模型从数据中学到的知识。 示例：神经网络中的权重和偏置、线性回归中的回归系数、支持向量机中的支持向量等。 调整方法：通过训练数据和优化算法（如梯度下降）自动调整。 调整频率：在每个训练迭代中都要更新，直到模型收敛或达到预设的训练轮数。 神经网络中的超参数和模型参数超参数： 学习率（Learning Rate）：决定每次权重更新的步长。 批大小（Batch Size）：决定每次权重更新时使用的训练样本数量。 隐藏层数和每层神经元数量：定义神经网络的结构和复杂度。 正则化系数：控制正则化项在损失函数中的权重，防止过拟合。 训练轮数（Epochs）：模型在整个训练数据集上完整训练的次数。 模型参数： 权重（Weights）：连接神经元的权重，表示输入特征的重要性。 偏置（Biases）：每个神经元的偏置，用于调整激活函数的输出。 7. 序列数据 vs 非序列数据1. 序列数据（Sequential Data）序列数据（Sequential Data）是指按照时间或其他顺序排列的数据，其中每个数据点的意义和价值都依赖于它在序列中的位置和前后数据点的关系。序列数据广泛存在于许多实际应用中，如时间序列、自然语言处理、语音识别等。 序列数据的特点 时间依赖性：序列数据中的每个数据点与其前后数据点存在依赖关系。这种依赖性可以是短期的（仅依赖于最近的数据点）或长期的（依赖于较早的数据点）。 顺序关系：序列数据的顺序是至关重要的，数据点的顺序关系决定了其实际意义。例如，在语音信号中，音频帧的顺序决定了最终语音的内容。 动态性：序列数据往往是动态变化的，数据点的值随时间或其他顺序变化而变化。 递归神经网络（RNN）和其变体如LSTM和GRU擅长处理序列数据 2. 非序列数据非序列化数据是指那些数据点之间没有时间或顺序依赖关系的数据。与序列化数据（如时间序列、文本、语音信号等）不同，非序列化数据中的每个数据点都是独立的，不依赖于前后的数据点。非序列化数据在各种领域中广泛存在，包括图像数据、表格数据（结构化数据）、图数据等。不同类型的非序列化数据可以通过不同的神经网络进行处理，如卷积神经网络（CNN）处理图像数据，前馈神经网络（FNN）处理表格数据，图神经网络（GNN）处理图数据。在实际应用中，选择合适的神经网络模型能够有效地处理各种非序列化数据，解决实际问题。 非序列化数据的实际应用1. 图像数据的应用图像数据是高维非序列数据，具有空间结构特性。卷积神经网络（CNN）是处理图像数据的主要神经网络类型。 医疗影像分析：通过CNN处理医疗影像（如MRI、CT图像），进行疾病诊断和分类。 自动驾驶：使用CNN分析汽车摄像头捕捉的道路图像，识别行人、交通标志和其他车辆。图像分类：使用CNN对输入图像进行分类。例如，ImageNet数据集上的物体识别任务。 具体应用：卷积层提取图像的局部特征，池化层减少特征维度，全连接层进行分类。 典型模型：AlexNet、VGG、ResNet等。图像分割：将图像划分为具有不同语义意义的区域。例如，自动驾驶中的道路标记识别。 具体应用：利用全卷积神经网络（FCN）或U-Net对图像进行像素级分类。 典型模型：U-Net、SegNet等。 2. 表格数据的应用表格数据通常存储在数据库或电子表格中，包含多种特征和目标变量。前馈神经网络（FNN）适用于处理表格数据。回归分析：预测连续值，如房价预测。 具体应用：输入层接收多种特征，隐藏层提取特征之间的复杂关系，输出层给出预测值。 典型模型：多层感知器（MLP）。-分类任务：对数据进行分类，如信用卡欺诈检测。 具体应用：输入层接收各特征值，隐藏层提取特征间关系，输出层进行分类。 典型模型：多层感知器（MLP）。 客户分类：使用FNN对客户进行分类，如根据客户购买行为预测客户流失风险。 3. 图数据的应用图数据由节点和边构成，具有复杂的连接结构。图神经网络（Graph Neural Networks, GNNs）专门用于处理图数据。 节点分类：在图中为每个节点分配标签，如社交网络中的用户分类。 具体应用：图卷积神经网络（GCN）通过聚合邻居节点的信息更新每个节点的表示，然后进行分类。 典型模型：GCN、GraphSAGE。图分类：对整个图进行分类，如分子结构的化学性质预测。 具体应用：将图嵌入到固定长度的向量表示中，然后使用前馈神经网络进行分类。 典型模型：DGCNN、GraphSAGE。 社交网络分析：通过GNN分析社交网络中的用户关系，进行用户分类和推荐系统。 化学分子建模：使用GNN分析化学分子结构，预测分子的物理和化学性质。 8. 向量在神经网络中，向量是一个重要的数学工具，用于表示和操作多个数值。向量在神经网络的各个部分都有广泛的应用，包括输入数据、权重、偏置、激活值等。为了更好地理解向量在神经网络中的角色，我们可以从以下几个方面进行详细阐述： 向量的定义一个向量是一个具有方向和大小的数量集合，通常用一维数组来表示。在神经网络中，向量可以用来表示输入特征、隐藏层的激活值、输出值以及模型的权重和偏置。 向量在神经网络中的具体应用1. 输入向量输入向量表示神经网络接收到的原始数据。在一个简单的前馈神经网络中，输入向量通常是一个包含多个特征的数据点。例如，对于一个图像分类任务，每个输入向量可能代表一张图像的像素值。 示例： 对于一个具有三个特征的输入数据点$(x_1, x_2, x_3)$，输入向量可以表示为：$\\mathbf{x} = \\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\end{bmatrix}$ 2. 权重向量权重向量表示神经元之间的连接强度。在神经网络中，每个神经元的输出都是前一层神经元输出的加权和。权重向量决定了输入特征对输出的影响程度。 示例： 对于一个具有三个输入特征的神经元，其权重向量可以表示为： $\\mathbf{w} = \\begin{bmatrix} w_1 \\ w_2 \\ w_3 \\end{bmatrix}$ 3. 偏置向量偏置向量是一个额外的参数，用于调整神经元的输出，使其能够更好地拟合数据。偏置向量与权重向量一起，影响每个神经元的输出。 示例： 对于一个具有三个输入特征的神经元，其偏置向量可以表示为： $\\mathbf{b} = b$ 4. 激活值向量激活值向量表示神经网络中每一层的输出。在前向传播过程中，输入向量与权重向量相乘并加上偏置向量，经过激活函数后得到的值即为激活值。 示例： 对于一个具有三个神经元的隐藏层，其激活值向量可以表示为： $\\mathbf{a} = \\begin{bmatrix} a_1 \\ a_2 \\ a_3 \\end{bmatrix}$ 向量操作在神经网络中，常见的向量操作包括向量加法、向量乘法（点积）、标量乘法和向量的激活函数应用。 1. 向量加法向量加法是将两个向量的对应元素相加。假设有两个向量 $\\mathbf{a}$ 和 $\\mathbf{b}$，它们的向量加法表示为： $\\mathbf{c} = \\mathbf{a} + \\mathbf{b}$$\\mathbf{c} = \\begin{bmatrix} a_1 + b_1 \\ a_2 + b_2 \\ a_3 + b_3 \\end{bmatrix}$ 2. 向量乘法（点积）向量点积是将两个向量的对应元素相乘并求和。假设有两个向量 a\\mathbf{a}a 和 $\\mathbf{b}$，它们的点积表示为：$c = \\mathbf{a} \\cdot \\mathbf{b}$$c = a_1 \\cdot b_1 + a_2 \\cdot b_2 + a_3 \\cdot b_3$ 3. 标量乘法标量乘法是将向量的每个元素乘以一个标量。假设有一个向量 $\\mathbf{a}$ 和一个标量 $k$，它们的标量乘法表示为： $\\mathbf{b} = k \\cdot \\mathbf{a}$ $\\mathbf{b} = \\begin{bmatrix} k \\cdot a_1 \\ k \\cdot a_2 \\ k \\cdot a_3 \\end{bmatrix}$ 示例：前向传播中的向量运算以一个简单的两层神经网络为例，说明向量在前向传播中的应用。 输入层：输入向量 $\\mathbf{x}$$\\mathbf{x} = \\begin{bmatrix} x_1 \\ x_2 \\end{bmatrix}$ 隐藏层：权重向量 $\\mathbf{W}$ 和偏置向量 $\\mathbf{b}$$\\mathbf{W} = \\begin{bmatrix} w_{11} &amp; w_{12} \\ w_{21} &amp; w_{22} \\end{bmatrix}$ $\\mathbf{b} = \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix}$ 计算隐藏层激活值：$\\mathbf{z} = \\mathbf{W} \\cdot \\mathbf{x} + \\mathbf{b}$ $\\mathbf{z} = \\begin{bmatrix} w_{11}x_1 + w_{12}x_2 + b_1 \\ w_{21}x_1 + w_{22}x_2 + b_2 \\end{bmatrix}$ 应用激活函数（如ReLU）：$\\mathbf{a} = \\text{ReLU}(\\mathbf{z})$$\\mathbf{a} = \\begin{bmatrix} \\text{ReLU}(z_1) \\ \\text{ReLU}(z_2) \\end{bmatrix}$ 输出层：权重向量 $\\mathbf{W’}$ 和偏置 $\\mathbf{b’}$$\\mathbf{W’} = \\begin{bmatrix} w_{31} &amp; w_{32} \\end{bmatrix}$$\\mathbf{b’} = b’$ 计算输出值：$y = \\mathbf{W’} \\cdot \\mathbf{a} + \\mathbf{b’}$$y = w_{31}a_1 + w_{32}a_2 + b’$ 9.误差训练误差、测试误差和验证误差是三个不同的概念，它们分别衡量模型在不同数据集上的表现。这些误差帮助我们评估模型的拟合程度和泛化能力 9.1 区别和联系 训练误差：衡量模型在训练数据上的表现，主要用于训练过程中调整模型参数。 验证误差：衡量模型在验证数据上的表现，主要用于超参数调优和模型选择。验证数据是从训练数据中分离出来的一部分，不参与模型训练。 测试误差：衡量模型在测试数据上的表现，主要用于评估模型的最终泛化能力。测试数据在训练和验证过程中都不使用，只有在模型训练完成后才用于评估。 9.2 训练误差（Training Error）训练误差是指模型在训练数据上的误差。它反映了模型对训练数据的拟合程度。计算方法 训练误差通常通过在训练数据上计算损失函数（例如均方误差、交叉熵损失等）来得到。例如，如果使用均方误差（MSE）作为损失函数，训练误差可以表示为： $\\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (y_i - \\hat{y}_i)^2$ 其中，NtrainN_{\\text{train}}Ntrain​ 是训练数据的样本数量，yiy_iyi​ 是第 iii 个样本的真实值，y^i\\hat{y}_i y^​i​ 是模型对第 iii 个样本的预测值。 目标最小化训练误差，以便模型能够良好地拟合训练数据。 意义低训练误差表明模型能够很好地拟合训练数据。但这并不一定意味着模型在新数据上的表现也会良好。 9.3 预测误差/测试误差预测误差/测试误差 是指模型在未见过的数据（通常是测试数据或验证数据）上的误差。它反映了模型的泛化能力，即模型在新数据上的表现。 计算方法：在模型训练完成后，使用测试数据或验证数据计算损失函数的值，计算方法与训练误差类似 目标：评估模型的泛化能力，期望模型在测试数据上的误差尽可能低。 意义：低预测误差表明模型具有良好的泛化能力，能够在新数据上表现良好。 9.4 误差的作用训练误差和预测误差的关系可以帮助我们诊断模型的状态，判断模型是否过拟合或欠拟合。 欠拟合（Underfitting）：模型在训练数据和测试数据上的误差都很高，说明模型复杂度不足，无法捕捉数据中的规律。 合适拟合（Good Fit）：模型在训练数据上的误差较低，并且在测试数据上的误差也较低，说明模型具有良好的泛化能力。 过拟合（Overfitting）：模型在训练数据上的误差很低，但在测试数据上的误差很高，说明模型过于复杂，捕捉到了训练数据中的噪声和细节，泛化能力较差。 10.过度拟合过度拟合（Overfitting）是机器学习中的一个常见问题，指的是模型在训练数据上表现良好，但在未见过的测试数据或实际应用中表现不佳。这通常是因为模型过于复杂，捕捉到了训练数据中的噪声和偶然性模式，而不是数据的潜在规律。 过度拟合的具体表现 训练误差低，测试误差高：模型在训练数据上的误差很低，但在测试数据或新数据上的误差很高。 高方差：模型对训练数据中的细节和噪声过于敏感，导致对不同数据集的表现差异很大。 复杂模型：过于复杂的模型（例如，具有太多参数的深度神经网络）容易过度拟合。 过度拟合的原因 模型复杂度高：模型的参数过多，能够拟合训练数据中的每一个细节和噪声。 训练数据不足：训练数据量过少，模型无法学习到数据的真实分布和规律。 噪声数据：训练数据中包含大量噪声，模型将这些噪声误认为是数据的潜在模式。 缺乏正则化：没有使用正则化技术来约束模型的复杂度。 如何检测过度拟合 训练误差与验证误差：在训练过程中，观察训练误差和验证误差的变化。如果训练误差持续下降，而验证误差在某个点之后开始上升，这通常是过度拟合的信号。 交叉验证：使用交叉验证技术评估模型在多个数据子集上的表现，避免模型对单一训练集的过度依赖。 学习曲线：绘制学习曲线（训练误差和验证误差随训练样本数量变化的曲线），分析模型的学习行为。 解决过度拟合的方法 增加训练数据：通过增加训练数据量，模型可以更好地学习数据的真实分布，减少对噪声的拟合。 简化模型：减少模型的参数数量或选择更简单的模型，避免过度拟合。 正则化：使用正则化技术（如L1和L2正则化）来约束模型参数，使其更平滑，减少对训练数据的过度拟合。 L1正则化：通过对模型参数的绝对值求和，使部分参数变为零，起到特征选择的作用。 L2正则化：通过对模型参数的平方和进行约束，使参数值尽可能小，从而使模型更平滑。 Dropout：在训练过程中随机丢弃一部分神经元，防止模型对某些路径的过度依赖。 数据增强：通过对训练数据进行旋转、缩放、裁剪等变换，生成更多的训练样本，增加数据的多样性。 早停法（Early Stopping）：在训练过程中监控验证误差，当验证误差不再下降时，提前停止训练，防止模型过度拟合。 11. 泛化能力泛化能力（Generalization）是指机器学习模型在训练数据以外的数据（通常是未见过的测试数据或真实应用中的数据）上表现良好的能力。它反映了模型对数据的普遍规律的学习程度，而不是对训练数据的记忆程度。 一个具有良好泛化能力的模型能够有效地从训练数据中学习到潜在的规律，并将这些规律应用于新数据上，从而在实际应用中保持高效和准确的表现。 理解泛化能力需要考虑以下几个方面： 训练误差和测试误差如果模型在训练数据上的误差很低，但在测试数据上的误差很高，这通常表明模型过度拟合（Overfitting）。相反，如果模型在训练数据和测试数据上的误差都较低，这表明模型具有良好的泛化能力。 模型复杂度 简单模型：模型复杂度低，参数较少，容易欠拟合（Underfitting），即无法充分捕捉数据中的规律。 复杂模型：模型复杂度高，参数较多，容易过度拟合，即捕捉了训练数据中的噪声和偶然模式。一个具有良好泛化能力的模型应在简单和复杂之间取得平衡，既能捕捉数据的潜在规律，又不过度拟合噪声。 12.正则化正则化（Regularization）是一种在机器学习和统计学中用于防止模型过拟合（overfitting）的技术,提高模型泛化能力的关键技术。 正则化的类型 L1 正则化（Lasso 正则化）： 定义：在损失函数中添加所有模型参数绝对值的和。 数学表达： $\\text{Loss} = \\text{Original Loss} + \\lambda \\sum |w_i|$ 特点：可以导致一些参数完全为零，起到特征选择的作用。 L2 正则化（Ridge 正则化）： 定义：在损失函数中添加所有模型参数平方和。 数学表达： $\\text{Loss} = \\text{Original Loss} + \\lambda \\sum w_i^2$ 特点：可以防止参数变得过大，但不会使参数完全为零。 弹性网络（Elastic Net）正则化： 定义：结合 L1 和 L2 正则化。 数学表达：$\\text{Loss} = \\text{Original Loss} + \\lambda_1 \\sum |w_i| + \\lambda_2 \\sum w_i^2$ 特点：结合了 L1 和 L2 的优点，既可以选择特征又可以防止参数过大。 Dropout 正则化： 定义：在每次训练时随机丢弃一部分神经元，使得模型在训练过程中不会过于依赖某些特定的神经元。 特点：通过在训练过程中引入随机性，增强模型的鲁棒性。 正则化的原理 复杂度惩罚：通过向损失函数中添加一个表示模型复杂度的项，模型在训练时不仅要最小化原始损失函数，还要考虑模型的复杂度。 参数约束：限制模型参数的大小或数量，防止模型在训练数据上过度拟合。 增强泛化能力：通过控制模型的复杂度，提升模型在未见数据上的表现。 正则化在模型中的应用正则化技术在许多机器学习模型中应用广泛，包括线性回归、逻辑回归、支持向量机（SVM）、神经网络等。在实际应用中，正则化参数（如 λ\\lambdaλ）通常需要通过交叉验证等方法进行调优，以获得最佳的模型性能。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"}]},{"title":"Ilya sutskever's approx 30 research papers about AI","slug":"Ilya-sutskever-s-approx-30-research-papers-about-AI","date":"2024-06-07T09:13:13.000Z","updated":"2024-06-16T14:27:01.519Z","comments":true,"path":"17f5a37e/","permalink":"http://example.com/17f5a37e/","excerpt":"","text":"之前无意中刷到这个twitter, 有点好奇这30篇paper 到底讲了啥，学完到底能知道什么，所以决定读一读。 如何读作为一个算法和AI小白, 真的学会在今天90%关于AI 的内容有点超出能力范畴， 所以我的目标是读懂这些paper的文本内容，建立一个整体的大框架即可。 依然对于一个算法和AI小白来说，直接阅读paper,、会遇到大量读不懂的概念， 需要查询相关资料，我觉得如果你也是小白同时也对这些paper 感兴趣的话，我查询的资料和阅读过程对你也会有帮助，所以我会把这些内容都记录下来，供你参考。 阅读记录神经网络（Neural Networks） 递归神经网络（Recurrent Neural Networks, RNNs） The Unreasonable Effectiveness of Recurrent Neural Networks Understanding LSTM Networks RECURRENT NEURAL NETWORK REGULARIZATION) 30 research papershttps://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE The Annotated Transformer简介：Transformer 模型注释版，详细解析了 Transformer 模型的内部结构和工作原理。推荐理由：理解现代 NLP 模型的基础。 The First Law of Complexodynamics简介：探讨了复杂动力学的第一定律，解释了复杂系统的演变规律。推荐理由：提供了关于复杂系统的一些理论基础。 The Unreasonable Effectiveness of Recurrent Neural Networks简介：讨论了 RNN 在处理序列数据时的有效性。推荐理由：帮助理解 RNN 的应用和优势。 Understanding LSTM Networks简介：详细介绍了 LSTM 网络的结构和功能。推荐理由：LSTM 是 RNN 的重要变种，广泛应用于序列数据处理。 Recurrent Neural Network Regulation简介：探讨了 RNN 的正则化方法。推荐理由：正则化是提高模型泛化能力的重要手段。 Keeping Neural Networks Simple by Minimizing the Description Length of the Weights简介：通过最小化权重描述长度来简化神经网络。推荐理由：提供了一种简化模型的方法，提升模型的解释性。 Pointer Networks简介：介绍了指针网络及其在处理离散序列问题上的应用。推荐理由：拓展了对序列模型的认识。 ImageNet Classification with Deep Convolutional Neural Networks简介：深度卷积神经网络在 ImageNet 分类上的应用。推荐理由：经典论文，推动了深度学习在计算机视觉领域的革命。 Order Matters: Sequence to Sequence for Sets简介：讨论了顺序在序列到序列模型中的重要性。推荐理由：提供了对序列模型的深刻理解。 GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism简介：介绍了通过微批次流水线并行实现模型扩展的方法。推荐理由：解决大规模模型训练的瓶颈问题。 Deep Residual Learning for Image Recognition简介：深度残差学习在图像识别中的应用。推荐理由：残差网络是深度学习的一大突破。 Multi-Scale Context Aggregation by Dilated Convolutions简介：通过膨胀卷积实现多尺度上下文聚合。推荐理由：在处理图像和信号时的有效方法。 Neural Message Passing for Quantum Chemistry简介：神经消息传递在量子化学中的应用。推荐理由：展示了神经网络在科学计算中的潜力。 Attention Is All You Need简介：Transformer 模型的奠基论文，提出了注意力机制。推荐理由：现代 NLP 模型的基石。 Neural Machine Translation By Jointly Learning To Align And Translate简介：通过联合学习对齐和翻译的神经机器翻译方法。推荐理由：NMT 的重要发展。 Identity Mappings in Deep Residual Networks简介：残差网络中的恒等映射。推荐理由：帮助理解深度网络的训练。 A simple neural network module for relational reasoning简介：用于关系推理的简单神经网络模块。推荐理由：增强模型的推理能力。 Variational Lossy Autoencoder简介：变分有损自编码器的介绍。推荐理由：提供了一种新颖的生成模型。 Relational recurrent neural networks简介：关系递归神经网络。推荐理由：结合关系推理和序列建模的优势。 Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton简介：定量分析封闭系统中复杂性的兴衰。推荐理由：理论性强，有助于理解复杂系统。 Neural Turing Machines简介：神经图灵机的概念和应用。推荐理由：连接神经网络和计算理论的重要工作。 Deep Speech 2: End-to-End Speech Recognition in English and Mandarin简介：端到端语音识别系统 Deep Speech 2 的介绍。推荐理由：语音识别领域的重要进展。 Scaling Laws for Neural Language Models简介：神经语言模型的规模法则。推荐理由：帮助理解模型扩展的规律。 A Tutorial Introduction to the Minimum Description Length Principle简介：最小描述长度原理的教程。推荐理由：理论基础，适用于多种模型选择问题。 Machine Super Intelligence简介：机器超级智能的讨论。推荐理由：未来 AI 发展的重要参考。 Kolmogorov Complexity and Algorithmic Randomness简介：Kolmogorov 复杂性和算法随机性的介绍。推荐理由：计算复杂性理论的经典。 CS231n Convolutional Neural Networks for Visual Recognition简介：CS231n 课程网站，包含卷积神经网络的详细教程。推荐理由：全面的学习资源，适合入门和进阶学习。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"}]},{"title":"饮料分级助手-糖脂ABCD分级计算器","slug":"饮料分级助手-糖脂ABCD分级计算器","date":"2024-06-02T11:09:33.000Z","updated":"2024-08-15T12:57:45.331Z","comments":true,"path":"e15dc0/","permalink":"http://example.com/e15dc0/","excerpt":"","text":"最近总是刷到新加坡饮料分级的信息，感觉确实是一种可以帮助大家在日常生活中选择更健康饮料的方式，但是目前国内除了上海有4个试点品牌外，均没有饮料分级信息。 所以我做了一个简单的微信小程序 糖脂ABCD分级计算器，来计算饮料的分级，目前分级计算计算新加坡的nutri-grade 标准，希望它可以帮助你更好得了解日常喝的饮料。你可以在以下场景使用它 超市、便利店购买的瓶装饮料 目前提供配方的奶茶品牌，如喜茶 未提供配方的奶茶品牌，你可以根据一些饮料测评，获取含糖量进行计算。 下图是我计算了一个偶尔会喝的少糖版烤黑糖啵啵牛乳，直接是最红的D级别。 欢迎在微信中搜索小程序 糖脂ABCD分级计算器使用，希望这个小工具对你有用。如果有建议的话也可以反馈给我。","categories":[],"tags":[{"name":"personal projects","slug":"personal-projects","permalink":"http://example.com/tags/personal-projects/"}]},{"title":"InnoDB事务-持久性的实现,binglog & redo log","slug":"InnoDB事务-持久性的实现，-binglog-redo-log","date":"2024-05-02T14:47:18.000Z","updated":"2024-05-10T15:24:50.204Z","comments":true,"path":"6cb5dc64/","permalink":"http://example.com/6cb5dc64/","excerpt":"","text":"在MySQL InnoDB 这个语境下， crash safe、数据不丢失 都指的是事务的持久性特性，即事务一旦提交，应当保证所有被成功提交的数据修改都能够正确地被持久化，不丢失数据, 即使宕机也能够恢复数据 在InnoDB 中，持久性 基于binlog 和redo log 实现， 且binlog 与redo log 的写入通过2PC 协调. 0 XA 事务：binlog 和redo log 的两阶段提交 在MySQL中，InnoDB存储引擎 的 redo log 和MySQL服务器层binlog 之间的一致性是通过内部的XA机制（即分布式事务）来实现的，任何一个数据出现问题都会进行会滚。 XA事务是一种分布式事务。通过两阶段提交协议和XA接口标准，事务管理器和资源管理器能够可靠地协同工作，实现跨系统的事务处理，确保多个独立资源的一致性。 在binlog 和redo log 的两阶段提交， binlog 充当协调者的角色。 关于XA 事务具体可在这篇文章中查看 binlog 和 redo log 各自写入的过程还有很多细节，接下来进行讲解 1 binlogbinlog是 MySQL 服务器层使用的日志文件，记录了所有修改数据库内容的SQL语句（如 INSERT, UPDATE, DELETE）,也被称为逻辑日志。 binlog 主要用于主备复制同步、崩溃恢复等功能。 1.1 binlog 的三种日志格式 格式 定义 优点 缺点 Statement-Based Logging (SBL) 记录执行的 SQL 语句本身，而不是每行数据的变更。 1. 空间效率高：通常占用更少的空间，因为记录的是 SQL 语句。 2. 易于审计：直接记录 SQL 语句，易于阅读和理解。 1. 非确定性行为：可能在主从复制中导致数据不一致，特别是涉及到非确定性函数（如 NOW()、RAND()）的 SQL 语句。2. 复制错误：某些特定情况下可能引起从服务器的复制错误。 Row-Based Logging (RBL) 记录数据变更前后的每行数据的具体变化，而不是执行的 SQL 语句。 1. 数据一致性：在复制过程中提供高度的数据一致性。2. 安全性更高：不记录 SQL 语句，降低了 SQL 注入的风险。 1. 空间占用大：因为记录了每一行的变化，可能导致 binlog 文件迅速增大。2. 可读性差：不记录 SQL 语句，对于人类审计不友好。 Mixed-Based Logging (MBL) 结合了 SBL 和 RBL 的特点，根据操作的类型自动选择使用基于语句的格式或基于行的格式记录。 1. 灵活性高：根据 SQL 语句的特性选择最合适的日志格式。2. 平衡性能和一致性：在确保数据一致性的同时考虑日志大小和性能。 1. 配置复杂：需要适当配置以确保效率和准确性。2. 预测性差：自动切换日志格式可能使得日志的结果难以预测。 1.2 binlog写入过程binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。 1.2.1 binlog cache对于每个客户端会话，MySQL 服务器为其分配一个 binlog cache。这个缓存是用来临时存储一个事务中产生的所有 binlog 事件。 但是binlog cache 刷新到磁盘时 多个线程是共写同一份 binlog 文件。 当一个新事务开始时，根据binlog 日志格式记录 每个修改SQL 语句到binlog cache 中 1.2.2 page cache 与 磁盘刷新持久化当事务到达提交阶段时，首先将 binlog cache 中的内容 写入到binlog 文件中，然后提交事务到 InnoDB，即 commit redo log 。 注意，这里的写入并不是直接写到到磁盘，而是先写入到文件系统的page cache, 然后通过sync_binlog 参数来决定 何时把数据写入到 磁盘。 磁盘刷新频率通过 sync_binlog 配置参数， sync_binlog=0 的时候，表示每次提交事务都不主动刷新磁盘，由文件系统自己控制刷盘频率 sync_binlog=1 的时候，表示每次提交事务都会将 binlog cache 中的内容刷新到磁盘 sync_binlog=N(N&gt;1) 的时候，表示累积 N 个提交事务后才将多个binlog cache中的内容刷新到磁盘。 可以看到如果sync_binlog不设置为1 ，有有助于提高刷盘效率， 但是有丢失binlog 的风险。 1.2.3 binlog cache 不够用怎么办如果binlog cache 写满了怎么办？需要把数据暂存到磁盘 每个事务的 binlog 事件首先被写入到 binlog cache 中，这个缓存的大小由 binlog_cache_size 系统变量控制。 如果一个事务非常大，涉及大量的数据修改，导致binlog cache不足以存储当前事务的所有事件时，MySQL采用的处理机制是将缓存中的数据写入到磁盘上的一个临时文件中。这一过程可以分为以下几个步骤： 检测缓存溢出：当试图向binlog cache中写入数据，而缓存空间不足以容纳更多数据时，将触发溢出处理机制。 数据写入临时文件：MySQL将当前binlog cache中的数据写入到一个临时文件中。这个临时文件通常位于MySQL的数据目录下，具有唯一标识，确保数据的隔离和安全。 清空binlog cache：将数据写入临时文件后，binlog cache会被清空，为接下来的日志数据腾出空间。 继续事务日志的记录：事务继续执行，新的日志事件会再次被记录到现在已经被清空的binlog cache中。 事务提交：事务如果最终被提交，MySQL会将临时文件中的日志数据以及现在binlog cache中的数据一并写入到全局的binlog文件中。如果事务回滚，则临时文件和binlog cache中的数据都将被丢弃。 1.3 xidXID（Transaction Identifier） 可以理解成时MySQL server 层的事务唯一标识。 MySQL服务器内部维护一个全局事务ID计数器，每个新事务都会分配一个唯一的ID。该计数器在内存中递增，保证每个事务ID在实例中是唯一的。 当一个新事务开始时，MySQL服务器层会从全局计数器中获取一个新的事务ID，将其赋予该事务，并存储在该事务的上下文中。 2 redo logredo log是 InnoDB 存储引擎特有的日志文件，用于记录对数据库做出的更改前的数据页状态,也被称作物理日志，确保在数据库系统发生崩溃后能够恢复这些更改。记录内容：Redo log 记录的是数据页修改的物理操作，而非具体的 SQL 语句。 循环使用：Redo log 是固定大小的，通常配置为一组文件，工作在循环写入的方式。 崩溃恢复：系统重启后，InnoDB 通过回放 redo log 来恢复未完成的事务，确保数据的完整性和一致性。 提高性能：Redo log 允许 InnoDB 在事务提交时不必将所有数据页写回磁盘，只需确保 redo log 已被写入磁盘。 记录的是数据页的物理修改。 不论数据页是否在buffer pool 中， redo log 都要记录修改， 因为不记不能保证crash safe. 保存自增值 2.1 为什么要记录redo log2.1.1 buffer poolMySQL 为了实现高性能，是不可能每次都从磁盘读数据或者把对数据的修改持久化到磁盘上的,所以 InnoDB 申请了一块连续的内存，用于存储从磁盘上读取的pages, 这个内存就是buffer pool。 buffer pool 有一块内存叫做，change buffer 用于暂存对数据的修改 那么在修改数据时，就会遇到两种情况 数据所在的page 在buffer pool 中， 就会直接更新page 数据所在的page 不在buffer pool 中， 如果不需要加载对应page, 就会先把对数据的修改先记在change buffer 中 不论是buffer pool, 还是 buffer pool 中的change buffer, 都是内存，一旦发生宕机，那就数据的修改的修改就会丢失，此时就违背了事务的持久性。 为了能把修改过的数据持久化又不影响性能，InnoDB 给出的方案是优先把修改操作记下来并持久化， 事务提交后，万一宕机丢失了buffer pool 中已修改但是未持久化的内容，就可以根据持久化的修改操作重新得到修改后数据。 这里记录下来的修改操作就是redo log, 而这种先记录修改操作，再记录修改后的技术叫做WAL。 2.1.2 WALWAL（Write-Ahead Logging）是一种在数据库系统中广泛采用的日志管理技术，用于保证数据库的事务持久性和恢复能力。 它的关键点就是先写日志，再写真正的数据。 redo log 直接应用了 WAL 技术，确保在任何数据被写入数据库页之前，相应的日志信息（如数据页的修改）先被写入到 redo log 中。 总的来说WAL 技术的优势有以下3项， 恢复能力：WAL 提供了强大的数据恢复能力。在发生系统故障后，可以利用日志文件中的记录来重做或撤销事务，恢复到最后一致的状态。 性能优化：通过将对磁盘数据的随机写转换为顺序写 ， 同时利用 组提交 ，WAL 可以显著提高数据库的写性能。 事务原子性和持久性：WAL 通过确保所有日志记录在实际数据写入前被提交到磁盘，从而支持数据库事务的原子性和持久性。 2.2 redo log 记录的内容之所以说redo log 是物理日志， 是因为其记录了对特定数据page 数据的修改。该例子来自极客专栏《MySQL 实战45讲》 12mysql&gt; create table t(ID int primary key, c int);mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2); 这条更新语句做了如下的操作（按照图中的数字顺序）： Page 1 在内存中，直接更新内存； Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息 将上述两个动作记入 redo log 中（图中 3 和 4）。 Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。 2.3 redo log 写入过程# 23 | MySQL是怎么保证数据不丢的？ redo log 的写入机制-redo log buffer redo log 的写入机制和 binlog 类型， 需要经历 MySQL 系统内存cache ， redo lo buffer 文件系统page cache 刷新持久化到磁盘 2.3.1 redo log bufferadd(id1,k1) to page1, new change buffer item add(id2,k2) to page2 都是先写入redo log buffer 中 相比较 每个线程都拥有自己一块独立的 binlog cache ， 而 redo log buffer 是全局共用的。 2.3.2 redo log持久化到磁盘事务提交，执行commit redo log 后，会触发redo log buffer 中内容写入到redo log 中。 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值： 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 所以想要确保MySQL异常重启之后redo log 数据不丢失，innodb_flush_log_at_trx_commit 这个参数 建议设置成1. 前面在binlog部分说到， 在事务提交前，事务binlog 是不会被写入到真正的binlog 文件中的。 redo log 不一样，在事务提交前，redo log 有可能备持久化磁盘。有以下3种情况 后台线程,每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。， redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑， 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上未提交事务 在 redo log buffer 里的日志一起持久化到磁盘。2.3.3 2PC的细化过程 2.4 日志文件组InnoDB 的 redo log 是以日志文件组的形式组织的。一个日志文件组通常包含两个或更多的日志文件，这些文件在物理上是连续的，并且循环使用。当一个日志文件写满后，InnoDB 会自动切换到下一个日志文件继续写入。当最后一个文件写满后，它会回到第一个文件并开始覆盖旧的日志记录，这就是所谓的“环形写入”。 2.5 LSNLSN（Log Sequence Number）,日志序列号,是一个不断增长的全局变量， 用来记录当前redo log 文件中 已经写入的日志量， 单位是字节。 图片中的write pos LSN 指当前已经产生的的日志量，随着更多的事务数据被写入，write pos LSN 会不断增加 checkpoint LSN 是redo log 中的一个位置，表示所有之前的日志记录都已经被应用（或说是“刷新”）到了磁盘的数据页上，因此，从这个位置以前的日志数据可以安全地被覆写， 不会出现数据丢失的情况。 redo log 会有多个检查点 write pos LSN 和 checkpoint LSN之间空着的部分，可以用来记录新的操作。 如果 write pos LSN 赶上了最一个checkpoint LSN 位置，这意味着 redo log 的空间不足，可能会导致数据库操作停顿，因为系统需要等待足够的日志空间来记录新的事务数据。 2.6 组提交前面提过，redo log 提升性能，一个是把对磁盘的随机写转换成了顺序写，一个是组提交机制。 组提交机制（Group Commit）是一种通过合并多个事务的日志提交操作来提高I/O效率的策略。这一机制基于LSN（Log Sequence Number，日志序列号）来追踪和管理日志提交。 以下图为例解释 事务trx1开始： trx1进入事务队列并被选为组的领导者，日志记录的LSN开始增加。 事务trx2和trx3加入 在trx1进入队列之后，trx2和trx3紧随其后进入提交队列。 LSN更新到160： 随着trx2和trx3的日志写入缓冲区，整个组的最后一个日志序列号LSN变为160。 领导者trx1执行写盘： trx1作为组的领导者，携带LSN=160去执行一次性日志写盘（fsync）操作。 写盘完成： trx1的fsync操作完成后，所有LSN &lt;= 160的日志记录都被持久化到磁盘。 事务返回提交成功： trx1、trx2和trx3都标记为提交成功并从提交队列中移除。 3 事务执行过程中的binlog 和redolog 和undo log下面将结合MySQL 的逻辑架构 和具体SQL , 来具体地看一下binlog 和redo log 的写入 SQL12mysql&gt; create table T(ID int primary key, c int);mysql&gt; update T set c=c+1 where ID=2; 结果MySQL 的逻辑架构， 该update sql的执行过程如下 执行器先找InnoDB取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在buffer pool 中，就直接返回给执行器；否则，需要先从磁盘读入buffer pool，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 InnoDB引擎记录该行数据的undo log, 然后新数据更新到内存中，如果数据本来就在内存中，则直接修改数据页，如果不再内存中，则将修改记录在change buffer 中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。 然后告知执行器执行完成了，随时可以提交事务。执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。根据 innodb_flush_log_at_trx_commit 决定redo log 是否持久化到磁盘 buffer pool 中对数据页的更新 ,等待脏页刷线操作持久化到磁盘 14.prepare阶段,将事务的xid写入，将binlog_cache里的进行flush以及sync操作(大事务的话这步非常耗时)15.commit阶段，由于之前该事务产生的redo log已经sync到磁盘了。所以这步只是在redo log里标记commit 4 崩溃恢复的逻辑崩溃恢复过程中，InnoDB 会从最近的 checkpoint LSN开始，应用 redo log 中的更改，直到达到崩溃时的 write pos LSN，以此来恢复数据库到最后一次提交的状态。 看一下崩溃恢复时的判断规则 如果 redo log 里面的事务是完整的，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整： 如果完整，则提交事务； 否则，回滚事务。==此处事务回滚基于undo log == 如果redo log 没有完整的prepare, 则事务基于undo log 回滚 ⚠️说明一下，innodb_flush_log_at_trx_commit 实际上控制了redo prepare 和commit 两个阶段的刷盘策略，比如innodb_flush_log_at_trx_commit =1 时在 prepare 阶段和 commit 阶段，redo log 都会持久化写入磁盘。所以才会出现第二种磁盘有且只有完整prepare 的情况。 接下来根据一些具体的问题来详细说明崩溃恢复时的细节 4.1 如何判断 redo log 是完整的redo log commit 阶段会有commit 标识 4.2. 如果判断binlog 完整性一个事务的 binlog 是有完整格式的：statement 格式的 binlog，最后会有 COMMIT；row 格式的 binlog，最后会有一个 XID event。 4.3. redo log 和 binlog 是怎么关联起来的在崩溃恢复时，通过读取Redo Log中的Xid，能够将其与Binlog中的Xid进行匹配。 XID（Transaction Identifier） 可以理解成时MySQL server 层的事务唯一标识。redo log 中会记录XID 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。 4.4. 为什么要用2PC 协调binlog和redo log类似的问题还有，为什么处于 prepare 阶段的 redo log 加上完整 binlog 就可以提交事务。 这两个问题本质上都是数据一致性的问题。 binlog 是server 层日志， 是MySQL 一开始就有的功能，被用在了很多地方，比如备份、主备同步复制。redo log 是InnoDB 层日志，是InnoDB 为了实现事务功能新增的。使用2PC可以维护两份之间的逻辑一致。 那么，为什么要维护两份日志间的逻辑一致呢。 binlog 是server 层日志， 是MySQL 一开始就有的功能，被用在了很多地方，比如备份、主备同步复制。redo log 是InnoDB 层日志，是InnoDB 为了实现事务功能新增的。如果两份日志逻辑或者说数据不一致， 那么用日志恢复出来的数据库状态就有可能和它本来应该的状态不一致。 具体举例来讲，如果不用2PC，两种日志要么是先写 redo log 再写 binlog，或者先写binlog 再写redo log 。仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？ 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 同理，为什么处于 prepare 阶段的 redo log 加上完整 binlog 就可以提交事务。因为如果binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。如果redo log 事务不提交的话，就会发生数据不一致的情况 4.5. 不要binlog 可以吗仅从事务持久化/崩溃恢复这个功能来讲， 只要redo log 是可以完成的。但是binlog 作为 MySQL 一开始就有的功能，被用在了很多地方，有redo log 无法替代的功能 。 归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。 主从复制同步 MySQL 高可用 在一些业务场景中， 也会使用binlog做数据同步，比如使用canal 同步binlog数据 到ES4.6 数据一定不会丢失吗-双1 设置 在介绍binlog和redo log 写入过程的时候，有两个参数sync_binlog 控制binlog 持久化到磁盘的频率 sync_binlog=0 的时候，表示每次提交事务都不主动刷新磁盘，由文件系统自己控制刷盘频率 sync_binlog=1 的时候，表示每次提交事务都会将 binlog cache 中的内容刷新到磁盘 sync_binlog=N(N&gt;1) 的时候，表示累积 N 个提交事务后才将多个binlog cache中的内容刷新到磁盘。 innodb_flush_log_at_trx_commit 控制redo log 持久化到磁盘的频率 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 可以看到吗，只有在双1设置的时候，sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1， 才能确保一定不会丢数据 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 如果不设置成双1， 有助于提高性能。 5. binlog vs redo log差异 层级差异：Binlog 工作在 MySQL 服务器层，所有引擎都可以使用；而 redo log 是 InnoDB 存储引擎层特有的。 记录形式：Binlog 可以记录 SQL 语句或行变更，redo log 记录的是数据页的物理变化，即“在某个数据页上做了什么修改” 目的和用途：Binlog 主要用于数据复制和崩溃恢复，而 redo log 主要用于事务的持久性和崩溃恢复。 大小管理：Redo log 的大小是固定的，循环使用循环写；binlog 是追加写，可以不断增长，需要定期进行清理。 日志写入：每个线程都拥有自己一块独立的 binlog cache ， 而 redo log buffer 是全局共用的 共同点 事务安全：两者都是为了保证事务的持久性和原子性。 恢复支持：在系统或硬件故障后，两者都能被用来恢复数据。 写前日志：都采用了写前日志（write-ahead logging, WAL）的技术，即在实际修改数据库内容前先记录日志。 从生产到写入磁盘均有内存page - 到page cache - 磁盘，刷新到磁盘的时机均有参数控制 相关文章Intro to 事务Intro to InnoDB 事务InnoDB事务-原子性的实现,undo logInnoDB事务-隔离性的实现,MVCC &amp; 锁","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"InnoDB事务-隔离性的实现, MVCC & 锁","slug":"InnoDB事务-隔离性的实现-MVCC-锁","date":"2024-05-02T14:42:57.000Z","updated":"2024-05-10T15:24:50.199Z","comments":true,"path":"9faedfe0/","permalink":"http://example.com/9faedfe0/","excerpt":"","text":"隔离性，还有一个说法就是 数据可见性。 隔离性、数据可见性是一个在并发事务下才需要考虑的问题，并发事务可以分3种情况考虑 读-读， 读操作不会对数据产生影响，所以不需要关注 读-写 or 写-读， 可能会出现脏读、不可重复读、幻读 写-写，可能会脏写的情况 并发事务下的数据的一致性写问题 脏写：一个事务修改了另一个未提交事务修改过的数据。 并发事务下的数据的一致性读问题 脏读：事务读取了未提交的数据，可能造成数据不一致。 不可重复读：事务在内部的多次读取中看到了同一数据的不同版本，主要由于其他事务的更新操作。 幻读：事务在两次查询同一个范围时看到了不一样的行，通常是因为其他事务添加或删除了行。 MySQL 的 4种 事务隔离级别 隔离级别 解决的问题 未解决的问题 原理描述 读未提交 无 脏读、不可重复读、幻读 允许事务读取其他事务未提交的修改，可能导致脏读。 读已提交 脏读 不可重复读、幻读 只能看到已经被其他事务提交的数据，避免了脏读，但不能防止在同一事务中看到不一致的数据。 可重复读 脏读、不可重复读 MySQL 在该隔离级别下加上gap 锁可部分解决幻读问题 在事务开始后所有SELECT操作都看到一致的快照，避免了不可重复读，但无法防止其他事务插入新行（幻读）。 串行化 脏读、不可重复读、幻读 无 “写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。通过强制事务串行执行，防止了脏读、不可重复读和幻读，提供了最高级别的隔离。 由于脏写导致的数据一致性问题非常严重，任何一种隔离级别下都不允许发生，对数据的修改操作必须通过锁串行执行 InnoDB 在解决 并发事务时，分成两种情况对应不同的解决方案 快照读-MVCC 当前读- 锁 1 快照读的隔离性-MVCC 一致性视图：在快照读中，事务会创建一个一致性视图（Consistent Read View），确保当前事务读取到的都是事务开始时的数据状态。它依赖于MVCC的实现。 无需锁定：快照读是一种无锁的读取，即读取数据时不需要对行记录进行锁定，因此它不会阻塞事务的读写，同时也不会被其他事务的读写操作阻塞。 隔离级别影响：快照读的行为受事务隔离级别的影响，不同的隔离级别会影响读取到的版本。 在读未提交隔离级别下，所有事务都读取最新事务； 在串行化隔离级别下，使用锁控制数据的访问。 在读已提交和可重复读隔离级别下，使用MVCC 来控制数据的可见性。 InnoDB存储引擎的MVCC（多版本并发控制）机制是基于ReadView和Undo Log共同实现的，关键是通过TRX_ID和ROLL_PTR两个行记录隐藏列来跟踪和管理每一行的修改版本。 1.1 版本链 -undo log在基于undo log 实现原子性 一文中，可以看到 行记录中有roll_pointer, update 操作中TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC 类型的undo log 中，也有roll_pointer,通过这些roll_pointer, 可以形成一条行记录的版本链。 insert 操作中，对应的undo log没有roll_pointer 属性，因为insert 操作就是一个行记录的初始版本，没有比它更早的操作了。 以下是一个通过roll_pointer 组成的版本链，每个undo log 进行了内容省略以展示链接的重点内容 1.2 readview有了版本链，那么该如何判断哪个版本的数据对当前事务可见呢，这里需要引入readview 概念。 Read View 主要包含以下几个关键的部分： m_ids：当前系统中活跃的事务ID列表。这些事务在生成 Read View 时已经开始但尚未提交。 min_trx_id：生成 Read View 时，活跃事务ID中的最小值。这是因为任何 ID 小于此值的事务在 Read View 生成前已经提交。 max_trx_id：生成 Read View 时，已知的下一个事务ID。任何大于或等于此 ID 的事务在生成 Read View 后开始的。 creator_trx_id：生成这个 Read View 的事务的事务ID。 一个事务只有进行修改操作时，才会被分配trx_id, 否则一个事务的trx_id 默认都是0， 所以 creator_trx_id 也有可能时0 运作方式： 当事务执行查询操作时，它会根据自己的 Read View 来判断数据行的可见性。具体来说，每行数据都有自己的系统版本号（trx_id，即事务ID）。Read View 通过以下逻辑来确定行的可见性： 如果行及记录的trx_id 和creator_trx_id 相等，说明当前事务在访问自己修改的数据，数据可见。 如果行的版本号小于 min_trx_id，说明行是在 Read View 生成之前被创建或最后修改的，因此对当前事务可见。 如果行的版本号大于或等于 max_trx_id，说明行是在 Read View 生成之后被创建或修改的，因此对当前事务不可见。 如果行的版本号在 min_trx_id 和 max_trx_id 之间，还需要检查这个版本号是否属于 m_ids 列表中的某个事务： 如果属于，说明该行可能由尚未提交的事务修改，对当前事务不可见。 如果不属于，说明该行由已提交的事务修改，对当前事务可见。 如果某个版本的数据对当前事务不可见，那就顺着版本链找洗一个版本的数据，并按照上面的步骤进行判断。如果一个数据直到最后一个版本都不可见，那就说明该条数据对当前事务完全不可见 1.2.1 readview 和 读已提交（Read Committed） 生成时机：在 RC 隔离级别下，Read View 不是在事务开始时生成，而是在一个事务内每次执行 SQL 查询时都会生成新的readview, 所以该事务内是可以看到其他事务已提交的对数据的修改，这在数据一致性上就表现为不可重复读 行为：每次查询都创建一个新的 Read View，包含当前时刻所有未完成的事务ID。这确保了查询只能看到那些在执行查询前已经提交的事务所做的更改。 1.2.2 readview 和 可重复读（Repeatable Read）InnoDB 的 默认隔离级别。 生成时机：在 RR 隔离级别下，Read View 是在事务的第一次查询操作开始时创建的，且在整个事务期间保持不变。这意味着整个事务中所有的查询都将看到相同的数据快照。 行为：一旦生成，这个 Read View 将包含事务开始时刻的所有活跃事务ID。无论这些事务后来如何提交或回滚，当前事务的后续查询都不会感知到这些变化。 1.2.3 两者的对比 数据可见性：在读已提交中，事务可能看到其他事务提交的更新（即事务中的查询可能返回不同的结果），而在可重复读中，事务保证了始终对数据的一致视图。 Read View 的生成频率：读已提交每次查询都重新生成 Read View，而可重复读只在事务开始时生成一次。 系统开销：由于读已提交每次查询都需要生成 Read View，可能会有更高的系统开销，尤其是在查询频繁的场景中。相比之下，可重复读的开销主要集中在事务开始阶段。 2 当前读的隔离型-锁当前读指的是读取数据时总是获取数据的最新版本，并通过加锁（行级别的排他锁，S锁或X锁）以确保一致性，防止其他事务修改或删除这些数据。 当前读通常用于需要修改数据的查询，如 select…lock in share mode (共享读锁) select…for update UPDATE DELETE 关于行锁和间隙锁的具体加锁规则，和隔离级别和索引有关，大家可以参考何登成的加锁分析文章MySQL 加锁分析 3. 幻读bad case在前面介绍隔离级别时，提到 在可重复读隔离级别下 加上 间隙锁， 可以一定程度上解决幻觉。但是如果一个事务中 快照读和当前读混用，就会出现幻读bad case. 幻读被完全解决了吗？ 这篇文章中例举两个幻读 bad case,讲的比较清晰，可以参考 4. 当前读vs快照读 快照读（Snapshot Read）： 读取数据时使用的是某一时间点的快照，不会加锁。 使用MVCC机制，根据事务的隔离级别和版本号返回合适的行版本。 通常用于SELECT查询。 当前读（Current Read）： 始终读取最新版本的行。 可能会加锁，防止其他事务修改或删除读取的数据。 通常用于修改数据的查询操作，如SELECT ... FOR UPDATE、SELECT ... LOCK IN SHARE MODE、UPDATE和DELETE。 相关文章Intro to 事务Intro to InnoDB 事务InnoDB事务-原子性的实现,undo logInnoDB事务-持久性的实现, binglog &amp; redo log&amp;undo log","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"InnoDB事务-原子性的实现,undo log","slug":"InnoDB事务-原子性的实现，undo-log","date":"2024-05-02T14:22:30.000Z","updated":"2024-05-10T15:24:50.194Z","comments":true,"path":"b36b0ce9/","permalink":"http://example.com/b36b0ce9/","excerpt":"","text":"原子性指的是事务要么完全成功执行，要么完全失败回滚，不允许部分执行。 这本质上是在要求具有rollback 回滚能力。 InnoDB中的事务可能会由用户主动触发Rollback；也可能因为遇到死锁异常Rollback；或者发生Crash，重启后对未提交的事务回滚。 InnoDB 的 rollback回滚能力 是基于 undo log 实现的。undo log 记录了修改操作前的旧版本数据，以便在回滚时恢复数据。 1 一条 undo log 的结构1.1 undo log 的分类只有在事务中对数据进行修改（如 INSERT、DELETE、UPDATE）的时候， 才需要记录undo log，快照读 select 不需要记录。 不同的修改操作产生的 undo log 记录的内容和结构会有所不同，因为每种操作对数据的影响不同, 所以undo log 也会有不同的类型。 InnoDB 的 undo log 主要分为两大类： TRX_UNDO_INSERT：此类主要包括 TRX_UNDO_INSERT_REC 类型的日志，专门用于记录插入操作的撤销信息。 TRX_UNDO_UPDATE：此类包括 TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC，用于记录更新存在的记录和标记删除操作的撤销信息。 共同点：所有类型的操作都需要且只需要记录足够的信息来逆转所执行的操作。这些记录都存储在 InnoDB 的 undo 表空间或者系统表空间中 差异：不同操作类型的 undo 日志记录的具体内容根据操作的性质而异。INSERT 主要关注标记新增行的删除，DELETE 需要记录完整的行数据以便恢复，而 UPDATE 记录修改前的字段值。 ⚠️：对于 undo log 的记录并不是基于每条修改 SQL 语句，而是基于 修改SQL 语句影响的每一条记录。这意味着每条被修改的记录都会有对应的 undo log 。如果一个 SQL 语句影响修改了多行数据，那么将会有多条 undo log 生成。 1.2 INSERT 操作的 Undo log对于 INSERT 操作，undo 日志通常记录较少的信息，主要是把这条记录的主键信息记上。 1.2.1 end of record 和 start of record在InnoDB的undo日志结构中，end of record和start of record 两个字段共同起到链接undo日志记录的作用，使这些记录形成一个双向链表，并提供顺序遍历和反向遍历的功能 end of record 定义： end of record字段指示当前undo日志记录的结束位置，并提供下一条undo日志记录的起始地址。 当最后一条undo日志记录没有后继时，则下一条undo日志记录的起始地址为NULL 目的： 指向链表中的下一条记录，方便顺序遍历日志记录，可以用于回放或者重做日志，特别是在恢复阶段 start of record 定义： start of record字段指示当前undo日志记录的起始位置，并提供上一条undo日志记录的结束地址。 如果当前undo日志记录是链表中的第一条，则上一条undo日志记录的结束地址为NULL。 目的： 指向链表中的上一条记录，方便反向遍历日志记录，用于事务回滚 1.2.2 undo type该字段指定undo日志记录的类型, 用于区分不同类型的undo操作，如TRX_UNDO_INSERT_REC 、 TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC 1.2.3 undo no日志编号， 在一个事务内从0开始递增，每生成一条日志，undo no 就加1 1.2.4 table id原始记录所在表的标识符，使undo日志能够与原始记录所在的表关联。 1.2.5 此部分以&lt;长度，值&gt;的形式保存每个主键列的信息，以便在回滚插入操作时恢复主键值： len：表示对应列的存储空间大小。 value：存储主键的实际值。 1.3 DELETE 操作的 Undo log-标记删除 trx_id记录上一个旧版本数据的trx_id, 该值从行记录的隐藏列trx_id 中获取 目的： 在回滚过程中，这个字段可以帮助恢复被删除的记录的原始事务信息，确保在恢复期间不会出现不一致的问题。 roll_pointer记录上一个旧版本数据的roll_pointer, 该值从行记录的隐藏列roll_pointer 中获取 描述： 指向被删除记录的原始回滚指针 (roll_pointer)。 在InnoDB中，每条行记录都有一个位（bit）标记来指示该记录的状态，包括是否已被删除。这是通过记录头（Record Header）中的info bits字段实现的。 1.3.1 标记删除TRX_UNDO_DEL_MARK_REC 日志 指的是对记录的逻辑删除，逻辑删除指的是只被标记为删除状态，并不会立即将其物理删除，因为还要支持事务回滚，以及MVCC。 被标记删除的数据如果真的需要删除，会在适当的时候由后台线程实际清理 1.3.2 行记录的删除标记每条行记录的头部都有一个info bits字段，用来存储记录的状态信息，包括是否已被删除。 在info bits字段的第5个bit位上，标记记录是否已被删除， 当此bit位为1时，表示该记录已被标记删除；为0时，表示该记录是正常的。 1.4 UPDATE 操作的 Undo logupdate 的操作 分为两种 不更新主键的update, 这种操作 一条记录 只会TRX_UNDO_UPD_EXIST_REC 一条undo log 更新主键的update ，这种update在实际执行时， 会先删除旧记录，再insert 一条新纪录， 所以会记录两条undo log, 一条TRX_UNDO_DEL_MARK_REC， 一条TRX_UNDO_INSERT_REC 具体字段信息和前面两种类似，不再详述。 2一个事务中的多条undo log如何组织在一起2.1 undo page -分类型存储undo logInnoDB 对数据的管理是以 page 为单位进行的，undo log 也遵循这一原则，即存储在专门的 undo pages 中。 每个 undo page 中的日志记录是专用的，不同类型的undo log 不能混着存储， 即一个 page 中不能同时记录 TRX_UNDO_INSERT 类型和 TRX_UNDO_UPDATE 类型的日志。 这样设计的理由是为了避免在回滚时需要在同一页面上搜索不同类型的日志记录，从而提高了回滚操作的效率。 可是 一个事务内可以同时存在insert undo log和update undo log, 如果事务需要回滚则所有操作都需要回滚，那为什么还要分开存储呢？ 优化事务回滚的逻辑 操作依赖性减少：插入操作的回滚仅涉及到删除之前插入的行，而更新或删除操作的回滚需要恢复原始数据。将这些操作的日志分开，可以在回滚时减少对不同类型日志处理逻辑的依赖，使得回滚过程更加模块化和有序。 执行效率：分开存储使得处理各自的回滚逻辑时可以更加高效，因为每种类型的回滚处理只需关注其对应类型的日志页。这减少了在单一日志页中搜索和处理不同类型日志的复杂性和时间。 并行处理尽管一个事务中可能存在多种类型的 undo 日志，但在并发环境中，不同的回滚任务可能由不同的系统进程或线程处理。例如，某些情况下系统可能并行地处理 insert undo log 和 update undo log。分开存储可以减少锁的竞争和管理的复杂性，提高并发处理的效率。 空间和性能管理 简化空间回收：在事务提交后，insert undo log 可以立即被丢弃和回收，因为插入操作生成的记录一旦提交即视为有效。而 update undo log 可能需要被保留以支持其他事务的一致性读（由于 MVCC）。分开存储使得空间管理更为高效，因为可以针对性地处理和回收日志空间。 优化读取性能：在事务处理过程中，尤其是在一些只涉及到特定类型操作的查询或回滚操作中，分开存储可以优化日志的读取性能，因为系统可以直接定位到相关类型的日志页。 日志维护的简化 分开存储有助于简化日志维护和日志生命周期管理。系统可以更容易地追踪和管理不同类型日志的生成、使用和清理周期。 2.2 undo page 链表在一个事务中，可能会产生多条 undo log。 如果一个 undo page 填满了，事务会向系统申请新的undo page,并将其通过链表（通常是使用类似于前驱（previous）和后继（next）指针的机制）连接起来。 前面提到过，一个 undo page 不能混合存储不能类型的链接， 所以对于一个事务它可以有insert undo page 和update undo page 两个链表。 每个事务都会分配单独的页面链表。 下面简单介绍下链表中第一个 undo page file header 如前面介绍，会有一个字段来标识该page 是undo page, 用来存储undo log。 undo page header 会记录该页面存储的undo log 类型， insert or update undo log segment header , 会记录该链表所属的segment undo log header ,理论上，每个事务都会分配自己的页面链表， 但如果一个事务产生的undo log很少，那么这个页面链表就有可能被重用。所以实际上一个页面链表中实际可能存储多个事务的undo log, undo log header 中记录了不同事务间日志的分隔信息。 2.3 回滚段InnoDB默认创建128个回滚段（Rollback Segments），用于管理undo日志。 元数据存储： 每个回滚段的元数据存储在系统表空间第5号页面中。 Slot结构：每个回滚段包含1024个slot，每个slot可以映射到一个Undo页。 事务与回滚段的关联： 事务会在需要的时候分配一个回滚段。 轮询策略： InnoDB使用轮询方式将回滚段分配给新事务，以实现负载均衡。 2.4 Undo页链表的形成与维护 事务开始： 新的事务开始时，会分配一个插入段和一个更新段。 在分配的回滚段头页中，初始化undo页链表的头指针和尾指针。 查找可用的Slot： 事务在开始写入undo日志时，会首先查找一个可用的slot，并初始化一个新的undo页链表。 分配新的Undo页： 分配新的undo页，将其添加到undo页链表的末尾。 如果这是链表的第一个undo页，回滚段头页的first指针和last指针会同时指向该页。 维护Undo页链表： 当undo页链表中的最后一个undo页已满时，分配一个新的undo页并链接到链表的末尾。 回滚段头页的last指针会指向新分配的undo页。 新undo页的prev指针指向链表的前一个undo页，形成链表结构。 3 行记录如何与undo log 关联 -roll_pointer roll_pointer 是存储在每个行记录中的一个指针，指向该行记录相关的最近一次undo log 记录。 注意这个undo 记录指的是具体的 undo log，而不是整个页面链表。 当行记录被修改（包括更新、删除或作为多步操作的一部分的插入）时，InnoDB 首先会在 undo 日志中写入一条记录，这条记录包含了行修改前的数据，和行记录中的的roll_pointer, InnoDB 更新行记录中的 roll_pointer，使其指向新写入的 undo 日志记录。如果这个行再次被修改，新的 undo 日志将被写入，roll_pointer 会更新为指向这条新的记录。新的undo 日志中会记录之前的roll_pointer 4. 一条记录的版本链如何形成InnoDB 通过 roll_ptr 把每一行的历史版本串联在一起 行记录中有roll_pointer, update 操作中TRX_UNDO_UPD_EXIST_REC 和 TRX_UNDO_DEL_MARK_REC 类型的undo log 中，也有roll_pointer,通过这些roll_pointer, 可以形成一条行记录的版本链。 insert 操作中，对应的undo log没有roll_pointer 属性，因为insert 操作就是一个行记录的初始版本，没有比它更早的操作了。 以下是一个通过roll_pointer 组成的版本链，每个undo log 进行了内容省略以展示链接的重点内容 5. undo log 的持久化undo日志刷盘时机的参数，但通过控制Redo日志、脏页刷新和Purge线程的参数，可以间接影响undo日志的刷盘策略。 WAL技术在数据实际修改前，先将undo日志持久化到磁盘。 刷盘时机： 事务提交： 当事务提交时，相关的undo日志会被写入磁盘。 脏页刷盘： 在InnoDB将脏页（dirty page）写入磁盘之前，首先会确保所有相关的undo日志已经被持久化。 Redo日志同步： 当一个Redo日志被同步到磁盘时，所有相关的undo日志也必须被同步。 6 基于undo log 的回滚操作InnoDB中的事务 可能会由用户主动触发Rollback； 也可能因为遇到死锁异常Rollback； 或者发生Crash，重启后对未提交的事务回滚。6.1. 用户/应用程序主动回滚 反向遍历（start of record）当前事务的undo日志链表，按逆序恢复每个更改。 插入操作： 在数据页中删除已插入的记录。 删除操作： 恢复已删除的记录。 更新操作： 恢复更新前的记录。 每个操作恢复完成后，从undo日志链表中移除相应的undo日志记录。 6.2. 死锁异常回滚InnoDB通过死锁检测算法发现两个或多个事务之间的锁等待，形成死锁，,选择最小代价，即持有锁资源最少的事务务进行回滚。 与主动回滚类似，遍历当前事务的undo日志链表，按逆序恢复每个更改。 6.3 崩溃恢复MySQL服务器或操作系统崩溃后，InnoDB通过Undo日志与Redo日志结合，确保崩溃时数据页的状态恢复到一致的状态， undo日志用来 回滚未提交的事务。 7 undo log 的清理事务提交后，相关的Undo日志记录仍需保留一段时间以支持多版本并发控制（MVCC） 7.1 Purge 线程InnoDB 通过一个后台线程称为 Purge，来清理不再需要的 undo log。 触发条件：Purge 进程会定期检查那些已提交事务的 undo log。它会确定这些 undo log 是否还被其他活跃事务作为 MVCC 的一部分所需。 删除操作：如果一个 undo log 记录不再被任何事务所需要，Purge 进程会将其从 undo 表空间中删除，释放相关资源。 undo log 的清理机制是区分操作类型的。 7.2 Insert Undo LogInsert undo log 主要记录插入操作的信息。因为插入操作仅仅添加新的记录，不涉及已存在数据的修改，所以这种类型的 undo log 主要用于在事务失败时撤销插入操作。 清理时机：当一个事务进行插入操作并成功提交后，相应的 insert undo log 立即变得无用，因为插入的数据已经被确认并不需要再被撤销。此时，这些 undo log 可以被安全地清理掉，因为它们不再被任何事务所需。 清理过程：Purge 线程会检测到这些 insert undo log 与已提交的事务关联，并将它们标记为可清理。然后，这些 log 会从 undo 表空间中删除，相关的磁盘空间得以回收。 7.3 Update Undo LogUpdate undo log 记录了对现有数据的修改（包括更新和删除操作）。这些记录对于事务回滚和多版本并发控制（MVCC）至关重要。 清理时机：与 insert undo log 不同，即使相关事务已经提交，update undo log 也不能立即被清理。这是因为在 InnoDB 中实现 MVCC 时，其他并发事务可能需要访问这些 log 中的旧数据版本来维持一致性读。 清理过程：Purge 线程会周期性地检查 update undo log。只有当这些 log 记录不再被任何其他活跃事务所需时（即没有更早的读视图需要这些数据），它们才会被标记为可清理。然后，Purge 操作会逐步从 undo 表空间中删除这些记录。 7.4 长事务对undo log 清理的影响长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 相关文章Intro to 事务Intro to InnoDB 事务InnoDB事务-隔离性的实现,MVCC &amp; 锁InnoDB事务-持久性的实现,binglog &amp; redo log&amp;undo log","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"Intro to InnoDB事务","slug":"Intro-to-InnoDB事务","date":"2024-05-02T14:15:42.000Z","updated":"2024-05-10T15:17:42.616Z","comments":true,"path":"9cd551f5/","permalink":"http://example.com/9cd551f5/","excerpt":"","text":"在Intro to 事务中介绍过， 一致性是事务的核心特征，或者说最终目的，原子性、隔离性和持久性都是实现一致性的手段。 所以在介绍InnoDB 事务时，主要介绍AID 特性的实现InnoDB事务-原子性的实现， undo logInnoDB事务-隔离性的实现, MVCC &amp; 锁InnoDB事务-持久性的实现， binglog &amp; redo log&amp;undo log 在具体看InnoDB 事务实现AID 特性之前，可以先看以下这些前置知识 1. InnoDB 数据管理1.1 Pagepage 是 InnoDB 存储数据的基本单位，也是数据在磁盘和内存之间交换的最小单位。每个页通常的大小为 16KB针对不同的数据有不同的Page类型进行存储，如index page 索引页， undo page 等 File Header 中 有fil_page_type 来标识该页的类型 File Trailer 用来校验页面数据是否完成 1.2 区（extent）为了更好地管理page, InnoDB引入了区的概念， 连续的64个page 是一个区，大小默认是1MB。 可以认为extent 是一个物理上概念 一个区（Extent）是由连续的页组成的数据块，每个区包含 64 个连续的页，因此每个区的大小为 1MB （16KB * 64）。使用区的目的是为了优化磁盘空间的分配和管理，通过批量处理连续的页,减少随机IO来提高数据存取效率。 1.3 段 （segment ）InnoDB 中的段（Segment）作为一个逻辑结构，起着将数据库的高层逻辑结构（如表和索引）与低层物理存储结构（如页和区）连接起来的桥梁作用。 以下是几个详细的例子，通过这些例子可以更好地理解段是如何在数据库管理系统中发挥作用的。 1.3.1 数据表段假设您在数据库中创建了一个新表，这个表将需要存储数据行。InnoDB 会为这个表创建一个数据段： 逻辑层面：在逻辑层面，这个数据段代表了表中所有数据行的集合。 物理层面：物理上，这个数据段开始时可能只包含几个区，每个区由 64 个连续的页组成。随着表中数据的增加，段可以动态地分配更多的区来存储更多的数据页。 操作：当你执行 INSERT 操作向表中添加数据时，InnoDB 将在这个数据段中找到适当的页来存储新的行。如果必要的页不存在或页已满，段管理逻辑将请求分配新的区，并继续数据插入。 1.3.2 索引段当你为表创建一个索引时，无论是主键索引还是辅助索引，InnoDB 都会为每个索引创建一个单独的索引段： 逻辑层面：索引段逻辑上表示索引的结构，这包括维护键值和指向表中对应行的指针。 物理层面：物理上，索引段存储索引树（B-tree）的结构，其中每个节点（或页）包含索引键和指向行的指针。随着索引的增长，可能需要更多的页和区来扩展索引树。 操作：进行查询优化时，如执行基于索引的查找，InnoDB 通过索引段快速访问相关页，有效地定位到数据行。 1.3.3 Undo 日志段Undo 日志也是使用段来管理的，每当数据被修改时，修改前的数据将存储在 undo 日志段中： 逻辑层面：逻辑上，undo 日志段保存了数据修改前的状态，支持事务的回滚操作。 物理层面：物理上，undo 日志段由一系列的页组成，这些页按需分配，并在事务回滚时提供必要的历史数据。 操作：如果事务失败或执行 ROLLBACK 命令，InnoDB 通过访问 undo 日志段中的记录来恢复数据到其原始状态。 1.4 表空间（Tablespace）表空间是 InnoDB 数据存储的最高层级，它可以包含多个段。表空间是磁盘上的物理文件，可以看作是一个容器，内部组织着数据库的数据和索引。InnoDB 默认有一个主表空间，即 ibdata 文件，它包含了系统数据、数据字典、undo 日志等。此外，InnoDB 还支持每个表使用单独的文件作为独立表空间（file-per-table），这有助于数据库的扩展和管理。 2.行记录格式数据表中的行存放在 数据page 中， 以compact 行格式为例， 每一条数据记录的存储格式如下， 其中真实数据部分，除了数据表中定义的列之外，InnoDB 会默认为每条记录添加隐藏列 列名 是否必须 占据空间 描述 row_id 否 6 字节 行ID，唯一标识一条记录 trx_id 是 6 字节 事务ID roll_pointer 是 7 字节 回滚指针 roll_pointer 是存储在每个行记录中的一个指针，指向该行记录相关的最近一次undo log 记录。trx_id 是 InnoDB 存储引擎内部用来唯一标识每个事务的标识符，它记录了最近修改该记录的事务。 3. InnoDB 事务trx_idtrx_id 是 InnoDB 存储引擎内部用来唯一标识每个事务的标识符。这个事务ID是一个递增的数字，由 InnoDB 内部自动生成和管理。 trx_id 存储在行记录的隐藏列中。 MySQLserver 层也有一个事务唯一标识叫XID。 InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。 功能和作用 事务的唯一标识：trx_id 为 InnoDB 提供了一种方式来唯一地识别和跟踪每个活动的或已完成的事务。 多版本并发控制（MVCC）：在 InnoDB 的 MVCC 实现中，trx_id 被用来标记每条记录的版本，以此来支持事务的隔离级别。不同事务看到的数据视图依赖于记录的 trx_id 与事务的 trx_id 比较。 回滚和恢复：在事务处理过程中，如果需要回滚，InnoDB 通过 trx_id 来确定哪些更改需要被撤销。此外，在系统崩溃后的恢复过程中，trx_id 也被用来重建活跃事务的状态。","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"Intro to 事务","slug":"Intro-to-事务","date":"2024-05-01T13:57:16.000Z","updated":"2024-05-08T14:05:03.875Z","comments":true,"path":"5b064db6/","permalink":"http://example.com/5b064db6/","excerpt":"","text":"1. 什么是事务事务（Transaction）的概念起源于数据库领域，最早由美国计算机科学家 E. F. Codd 在其关于关系数据库（Relational Database）的论文中提出。 他提出了 ACID（原子性、一致性、隔离性和持久性）属性，这些属性成为事务的核心特征。 在今天的软件开发中，事务的概念已不仅仅应用于数据库领域，还拓展到了业务开发的各个领域，包括但不限于数据库、缓存、消息队列等。 1.1 ACID 特性 原子性(Atomicity): 保证事务中的所有操作要么全部完成，要么全部不发生，有助于处理系统错误或故障时的数据恢复，确保事务执行的完整性。 一致性(Consistency)：系统从一个正确态转移到另一个正确态，由应用通过 AID 来保证，可以说是事务的核心特性 隔离性(Isolation): 处理并发事务带来的各种问题，确保每个事务看到的是一致的数据视图，防止交叉事务的干扰。 持久性(Durability): 确保事务一旦提交，其结果就就会被持久化，这保证了数据的稳定性和可靠性。 定义本身不再赘述，这里重点强调一点：一致性是事务的核心特征，或者说最终目的。原子性、隔离性和持久性都是实现一致性的手段，因此这 4 个特性并不是并列关系。 2. 事务的分类下面将把事务按照服务和数据源数量进行分类，这种分类有助于理解事务管理的复杂性以及在不同场景下的设计和实现。 2.1 本地事务-单服务单数据源事务在实际业务开发中，单个服务操作单个数据源的事务被归类为本地事务。这种事务类型是最简单的，因为它直接依赖于数据库本身的事务能力来完成，应用无需进行额外操作 示例：库存服务：当用户下单时，库存服务负责检查和更新商品库存。这个服务可能只与一个库存数据库交互，进行减库存的操作。如果库存足够，事务提交，否则回滚。这个操作只涉及库存数据库，因此是一个典型的本地事务。 2. 2 分布式事务分布式事务可以从跨多个数据源的事务和跨多个服务的事务两个角度理解。它既可以是多个数据库实例之间的分布式事务，也可以是跨不同中间件的业务层面分布式事务。 2.2.1 单服务多数据源这种情况通常发生在单个应用或服务需要同时操作多个数据库或存储系统。 例如，一个电子商务应用可能需要在处理订单的同时，在一个数据库中更新库存信息，在另一个数据库中更新用户账户信息。这要求事务管理机制能够跨越这些数据库，确保所有数据库操作要么全部成功，要么全部失败，以保证数据的一致性 在这种场景下，可以使用如XA协议这样的分布式事务协议，通过2PC等机制来协调和管理跨多个数据源的事务。 2.2.2 多服务多数据源随着微服务架构的发展，单个业务操作往往需要多个微服务协作完成，而这些服务可能各自使用独立的数据库。例如，在电商下单过程中，订单服务、库存服务、账务服务、物流服务和优惠服务需要协同处理同一业务请求，并进行交互和数据更新。 在这种场景下，分布式事务的管理比单个服务场景更为复杂，因为它不仅涉及数据一致性，还涉及网络调用的可靠性和服务间的协调。这类分布式事务通常可以通过可靠消息队列、TCC 和 SAGA 等模式来实现。 2.3 共享事务-多服务单数据源在微服务架构下，通常不允许多服务共享同一数据源。理想的微服务架构是每个微服务都有其专属数据库（即服务与数据源一一对应），这种设计被称为数据库隔离。 因此，本文及本系列不会涉及该类型事务。 3. 两种分布式事务的区别在事务分类中，单服务多数据源 和 多服务多数据源 都被归类为分布式事务，那么这两种分布式事务有什么区别呢？ 首先，单服务多数据源事务是多个数据库实例之间的分布式事务， 也被称为全局事务。当它被称为分布式事务时，这里的“分布式”是相对于数据源而言的，并不涉及服务。 而多服务多数据源事务是跨不同中间件的业务层面分布式事务。 这两种分布式事务的一个重要区别在于一致性的实现方式不同： 单服务多数据源事务通常可以追求 强一致性。 多服务多数据源事务由于其复杂性和分布式特性，通常只能追求 最终一致性。 下面将详细解释这两种情况及其原因。 3.1 单服务多数据源 与 强一致性在单服务多数据源的场景中，尽管涉及多个数据源，但所有操作都由一个单一服务控制。这种配置允许使用两阶段提交（2PC）等传统的分布式事务协议来确保强一致性，即在任何时刻，所有数据源都能反映出相同的事务状态。 为什么可以实现强一致性： 集中式协调：单个服务可以作为事务的中央协调者，管理所有数据源的事务提交或回滚。 锁定资源：事务处理过程中可以在各个数据源上锁定必要的资源，直到事务完成，确保事务的原子性和一致性。 同步更新：所有数据源的更新操作可以同步进行，确保在事务提交时，所有的变更都能一次性反映出来。 3.2 多服务多数据源 与 最终一致性多服务多数据源事务涉及多个独立的服务，每个服务可能管理自己的数据源。在这种架构下，实现强一致性变得非常复杂和成本高昂，因此通常采用最终一致性模型。 为什么通常只能实现最终一致性： 服务自治：每个服务都是自治的，独立管理自己的数据源，它们之间的通信可能是异步的，不能立即反映其他服务的状态变更。 复杂的协调机制：需要跨服务协调复杂的事务可能涉及网络延迟和服务间通信失败，使得同步更新所有数据源变得不切实际。 使用补偿事务：多服务事务常采用如SAGA等模式，通过一系列的本地事务和补偿事务来处理业务流程，每个事务独立提交，仅通过补偿机制来撤销错误操作，逐步达到数据的一致性。 4. 强一致性 vs 最终一致性4.1 一致性的分类4.1.1 强一致性（Strong Consistency）强一致性意味着系统在更新数据后，任何随后的访问都将立即看到这一更新。在强一致性模型中，所有节点上的数据在任何时间点都是一致的。这通常要求在数据更新过程中进行严格的协调，确保所有副本在继续操作前都同步更新。 优点： 数据一致性和用户体验最为理想。 易于理解和使用，因为它模拟了单个系统的行为。 缺点： 可能严重影响系统的可用性和性能，尤其在网络延迟较高的情况下。 在 CAP 定理中，通常需要在遇到网络分区时牺牲可用性。4.1.2 线性一致性（Linearizability） 线性一致性是强一致性的一个特例，它不仅保证所有节点看到相同的数据，还要求系统表现得就像所有操作都是顺序发生的。这意味着如果操作A在操作B之前完成，那么系统中的所有节点都应该首先看到A的结果，然后是B的结果。优点： 提供了强一致性的最高标准，适用于需要严格数据顺序的应用。 简化了系统的编程模型。缺点： 对系统性能和可用性的影响比一般的强一致性还要大。 4.1.3 弱一致性（Weak Consistency）弱一致性不保证在数据更新后立即反映这一变化。在更新操作和其影响被所有用户观察到之间，存在一个不确定的时间窗口。这种模型通常用于对实时一致性要求不高的系统。优点： 提高了系统的可用性和性能。 在处理高并发操作时更加有效。缺点： 用户可能会读到旧数据。 应用逻辑可能需要处理数据不一致的问题。4.1.4 最终一致性（Eventual Consistency） 最终一致性保证，在没有新的更新的情况下，所有的数据副本最终将会是一致的。系统不保证达到一致状态的具体时间。优点： 高度可用和可扩展。 适用于分布广泛的系统，可以容忍数据在短时间内的不一致。缺点： 应用需要能够处理数据一段时间内的不一致。 开发者需要设计有效的数据同步和冲突解决策略。4.2 CAP 与 ACID的微妙平衡-分布式系统只能追求最终一致性 根据 CAP 定理，一个分布式系统不可能同时满足一致性（Consistency）、可用性（Availability）和分区容忍性（Partition Tolerance）三个属性，最多只能满足其中两个，必须牺牲一个。 一致性（Consistency）：在任何时刻，任何分布式节点中看到的数据都保持一致。 可用性（Availability）：系统能够不间断地提供服务的能力。 分区容忍性（Partition Tolerance）：在分布式环境中，当部分节点因网络原因失联（即形成“网络分区”）时，系统仍能正确提供服务的能力。 4.2.1 为什么说 分布式系统 必须接受 分区容忍性理解为什么分区容忍性在分布式环境下必然存在，需要从分布式系统的基本构成和网络通信的不可靠性两个角度探讨。 分布式系统的基本构成 分布式系统由多个相互协作的独立组件组成，这些组件可能位于物理上分散的不同位置。该架构的主要优势是提高系统的可扩展性、容错性和资源利用率。然而，这也意味着系统的各个部分必须通过网络通信。 网络通信的不可靠性 网络本身存在不可靠性，可能因多种原因导致通信失败： 网络故障：网络设备或连接可能出现故障，如路由器故障、连接断开等。 网络延迟：消息在传输过程中可能遭遇不可预测的延迟。 带宽限制：网络的带宽限制可能导致数据包延迟到达或丢失。 网络安全：网络攻击（如分布式拒绝服务攻击，DDoS）可能导致网络部分或完全不可用。 如果一个系统设计选择不接受网络分区，那么一旦网络分区发生，系统将无法正常工作，这在大多数业务场景中是不可接受的。 因此，在分布式系统中，分区容忍性（Partition Tolerance）是必然存在的特性。 基于分区容忍性必须满足的现状以及 CAP 理论，系统只能在一致性和可用性之间做出选择。通常，系统会选择高可用性，强一致性因此被牺牲，系统只能追求最终一致性。 5. 理解分布式事务中的各种协议5.1 DTP 模型和 XA 规范5.1.1 DTP 模型DTP（Distributed Transaction Processing，分布式事务处理）模型是由 X/Open（后来的 Open Group）提出的一种分布式事务处理架构模型。它定义了一套标准，使得不同厂商的分布式事务处理系统能够互操作。 在标准的 DTP 模型中，定义了以下四个主要组件： Application Program（AP，应用程序）： 发起分布式事务的主体，由最终用户或开发者编写。 通过调用事务管理器的接口（例如 TX 接口）开始、提交或回滚事务。 应用程序与事务管理器和资源管理器交互。 Transaction Manager（TM，事务管理器）： 负责管理分布式事务的开始、提交和回滚等操作。 维护事务的状态，并使用两阶段提交协议（2PC）协调所有参与的资源管理器。 提供对外的 TX 接口供应用程序使用，并通过 XA 接口与资源管理器交互。 Resource Manager（RM，资源管理器）： 负责管理和控制对特定资源的访问，例如数据库管理系统（DBMS）、文件系统、消息队列等。 接收事务管理器的请求以进行资源操作，并确保数据一致性。 实现 XA 接口与事务管理器通信。 Communication Resource Manager（CRM，通信资源管理器）： 可选组件，负责管理与外部系统的通信资源。 在分布式事务中协调和同步事务状态，确保跨系统的事务一致性。 管理跨网络的事务传播，确保分布式环境中的事务处理一致性。 主要接口： TX 接口： 应用程序 AP 与事务管理器 TM 之间的桥梁，负责事务的开始、提交和回滚等操作。 例如，在 Java EE 中，TX 接口通常对应 javax.transaction.UserTransaction。 XA 接口： 事务管理器 TM 与资源管理器 RM 之间的接口，协调资源管理器在两阶段提交协议中的操作。 常见的 XA 接口方法包括 xa_open、xa_start、xa_end、xa_prepare、xa_commit、xa_rollback 等。 CRM 接口： 事务管理器与通信资源管理器之间的接口，确保分布式事务在网络通信中保持一致性。 没有明确的标准接口，由各系统厂商自行实现。 5.1.2 XA规范XA 规范是 X/Open 组织在 DTP（Distributed Transaction Processing）模型中定义的，用于描述事务管理器（TM）和资源管理器（RM）之间交互的接口标准。 接口标准：XA 规范定义了一套标准接口，包括 xa_start、xa_end、xa_prepare、xa_commit、xa_rollback 等。 2PC 协议：XA 接口实现了两阶段提交协议（2PC），以确保分布式事务的一致性和完整性。 5.1.3 XA 事务XA事务是一种分布式事务。通过两阶段提交协议和XA接口标准，事务管理器和资源管理器能够可靠地协同工作，实现跨系统的事务处理，确保多个独立资源的一致性。 实际应用 数据库系统： 大多数主流数据库系统都支持XA事务，如Oracle、MySQL、DB2、SQL Server等。 通过实现XA接口，数据库可以参与分布式事务并与事务管理器协同工作。 消息中间件： 一些消息队列和消息中间件也支持XA事务，如IBM MQ、ActiveMQ等。 能够确保消息发送与其他资源操作的一致性。 Java EE环境： 在Java EE应用程序中，javax.transaction.UserTransaction和javax.transaction.TransactionManager接口提供了对XA事务的支持。5.2 两阶段提交（2PC） 两阶段提交是一种具体的事务协议，用于在分布式系统中协调多个事务参与者的行为，以确保事务的原子性。它包含以下两个阶段： 准备阶段：协调者询问所有参与者，是否准备好提交事务。 提交/回滚阶段：基于各参与者的答复和超时情况，协调者决定是否全局提交或回滚， 只有全部参与者回答了prepared 才会commit; 若有一个参与者回答和non-prepared 或者超时未回答，则rollback 5.2.1 协调者宕机：单点问题，参与者阻塞在2PC中，一个重要特点是参与者缺乏超时机制。因此，在第一阶段结束后，他们必须原地等待协调者的第二阶段指令。一旦协调者宕机，所有参与者都会受到影响。如果协调者长时间未恢复或未发送正常的提交或回滚指令，所有参与者都将被阻塞。 为何参与者缺乏超时处理机制呢？因为这可能引发数据一致性问题。当参与者迟迟未收到提交或回滚指令时，无论其默认为提交还是回滚，都可能导致全局数据不一致。 这也给了我们业务开发一些启示：在任何不确定情况下，都不应随意指定默认操作，最佳做法是启动警报，让人工介入处理。 5.2.2 回滚性能差所有的操作都已经完成，回滚需要全部推翻。 5.2.3 一致性问题5.2.4.1 协调者宕机如上面单点问题中描述，协调者宕机后，由于参与者没有超时处理机制，会一直阻塞等待，直到协调者宕机恢复后， 根据持久化的数据判断该事务状态，进而发送commit 或者 rollback ， 所以在协调者宕机恢复前 协调者和参与者的数据是不一致的 5.2.3.2 参与者宕机如果参与者收到commit后，宕机了。此时数据也是不一致的参与者宕机恢复后，可以检查自己的持久化信息，来判断事务的状态。 5.2.3.3 网络问题有的参与者收到了commit,有的参与者收不到；参与者的ack 消息，协调者有的收到了，有的没收到。其中参与者收不到第二阶段的消息，自然不会有ack, 表现上也是协调者收不到ack。这里的解决方案就是 协调者超时处理机制-重试，在重试成功之前，数据是不一致的。 5.2.4 梳理下 DTP、XA、2PC 之间的关系DTP（Distributed Transaction Processing，分布式事务处理）模型是由X/Open（后来的Open Group）提出的一种分布式事务处理的体系结构模型。它定义了一套标准，使得不同厂商的分布式事务处理系统能够互操作。 XA规范是X/Open组织 在DTP（Distributed Transaction Processing）模型中定义的，用于描述事务管理器（TM）和资源管理器（RM）之间的交互的接口标准。 XA 规范基于2PC 实现。 但是 2PC协议是一种通用的事务提交协议，可以在任何实现中使用。除了XA规范，2PC协议还可以用于其他事务管理协议和框架，如： Seata：阿里巴巴开源的分布式事务框架，提供全局事务管理服务，支持2PC但不直接使用XA接口。 Atomikos：支持两阶段提交协议的独立事务管理器。 Bitronix：另一个独立事务管理器，也支持2PC协议。 在某些场景下，可以直接在应用程序代码中实现简化版的2PC协议，而无需遵循XA规范。 5.3 三阶段提交（3PC）3PC 的3个阶段， CanCommit PreCommit DoCommit 3PC 相比2PC 的变化 3PC提交把2PC的prepare 阶段细分为两个阶段，分别称为 CanCommit、PreCommit 参与者增加了超时处理机制，超时默认会提交事务 3PC 的提出是为了改进2PC 存在的问题 5.3.1 CanCommit 优化回滚操作性能新增的 CanCommit 是一个询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。这可以解决提高precommit 阶段的成功率，万一失败了，回滚操作也比较轻，因为还没开始做实质性的操作 但是这里要注意一个性能问题，在事务需要回滚的场景中，三段式的性能通常要比两段式好很多，但在事务能够正常提交的场景中，两段式和三段式提交的性能都很差，三段式因为多了一次询问，性能还要更差一些。 5.3.2 解决协调者单点问题通过增加参与者超时处理机制，默认会提交事务，相当于解决了协调者宕机参与者阻塞等待的单点问题 5.3.3 加重数据一致性问题在2PC中已经讨论过,为什么2PC参与者没有超时处理机制？因为超时处理机制可能引发数据一致性问题，当 参与者迟迟收不到commit or rollback 指令时， 参与者不论是 默认提交 还是默认回滚，都有可能导致全局数据不一致。 3PC 增加了超时机制， 会默认提交事务，这会加重数据一致性的问题 5.4 TCC（Try-Confirm/Cancel）TCC是一种应用层事务协议，它分为三个阶段：Try（尝试）、Confirm（确认）、Cancel（取消）。在Try阶段，每个参与者尝试执行事务并锁定必要资源；在Confirm阶段，如果所有参与者的Try操作都成功，那么执行Confirm操作提交事务；如果任何Try失败，则执行Cancel操作回滚事务。TCC适用于业务逻辑复杂，需要长时间运行的事务。 个人认为，TCC可以被理解为是2PC的一种变体，具有两阶段的结构，但它在实施和操作上更适合处理复杂的业务逻辑和提高系统的灵活性与效率。 5.5 可靠消息队列使用可靠消息队列来解决分布式事务问题是一种被称为“最终一致性”的策略，它通过异步消息传递的方式，确保在分布式系统中多个服务之间的数据一致性。 使用可靠消息队列解决分布式事务的核心思想在于： 异步与最终一致性：通过异步的方式处理分布式事务，并确保最终一致性。 可靠消息传递：确保消息传递的可靠性，包括重试机制、幂等处理等。 5.6 SAGASAGA是一种将长期事务分解为一系列较小的、独立的子事务的方法。每个子事务都可以单独提交或回滚。如果某个子事务失败，SAGA通过执行补偿事务（即逆操作）来恢复之前的状态。SAGA降低了资源锁定的时间，适用于微服务架构中的事务管理。 参考文章《周志明的软件架构课》https://www.51cto.com/article/648668.html","categories":[],"tags":[{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"使用github page+hexo 创建个人网站","slug":"使用githubpage-hexo创建个人网站","date":"2024-04-29T01:29:29.000Z","updated":"2024-06-16T09:50:05.895Z","comments":true,"path":"5fe6baa/","permalink":"http://example.com/5fe6baa/","excerpt":"","text":"关于使用 github page + hexo 创建个人网站， hexo官网上的步骤已经非常详细，网上也有非常多相关的文章， 所以基础步骤就不写了。 这里记录一些个性化过程中遇到的问题。 1. TOC 锚点失效文章目录正常生成了，但是点击目录无法跳转到文章对应位置。解决办法点这里查看 2. 文章的短链接生成hexo 文章标题默认的格式是:year/:month/:day/:title/,这个格式的标题在我看来有2个主要问题 太长，可以考虑只取默认格式中的一部分，如:title/ 易变化， 写文章时有可能会修改标题,所以文章的url就会发生变化。 url 一旦发生变化就会对网站排名产生负面影响 综上，我希望每篇文章都有一个 固定且短的 url。 hexo-abbrlink:create one and only link for every post for hexo 插件可以实现该功能， 它根据文章标题和创建时间为文章生成一个abbrlink， 如果文章已经有该属性则不会重复生成。 3. custom domain 消失记在github pages 配置了custom domain ，但是我发现每次deploy新内容后，配置好的custom domain 都会消失，经过排查发现是缺失来 CNAME文件。 3.1 CNAME是什么CNAME（Canonical Name）记录是一种DNS（Domain Name System）记录类型，用于将一个域名别名映射到另一个真正的域名。它的作用是简化域名管理、实现负载均衡、支持CDN集成等。CNAME记录的工作流程包括DNS查询、递归查询、权威DNS服务器响应和IP地址返回等步骤。通过正确配置CNAME记录，可以有效管理和优化网站的域名解析。 3.2 CNAME记录的作用 域名重定向：允许多个域名指向同一个目标域名，简化了域名管理。例如，将www.example.com和blog.example.com都指向example.com。 负载均衡：通过CNAME记录可以将流量分布到不同的服务器，实现负载均衡。 内容分发网络（CDN）集成：CDN提供商通常要求将用户的子域名（如cdn.example.com）CNAME到他们的CDN域名（如cdn.provider.com），以便进行流量管理和内容分发。 3.3 CNAME记录的工作流程CNAME记录的工作流程可以分为两个主要阶段：解析CNAME记录本身和解析CNAME记录指向的目标域名，直到最终得到一个IP地址。 DNS查询开始：用户在浏览器中输入域名，如www.example.com，并发送DNS查询请求。 递归DNS服务器处理请求：用户的计算机向递归DNS服务器（通常由ISP提供）发送请求。递归DNS服务器查询根DNS服务器，获取顶级域名服务器（如.com的服务器）的信息。 递归查询过程：递归DNS服务器查询顶级域名服务器，获取该域的权威DNS服务器信息（如example.com的DNS服务器）。递归DNS服务器接着查询权威DNS服务器。 权威DNS服务器响应：权威DNS服务器查找www.example.com的DNS记录。如果www.example.com有一个CNAME记录指向example.com，权威DNS服务器返回这个CNAME记录。 CNAME解析：递归DNS服务器接收到CNAME记录后，再次进行DNS查询，以解析CNAME记录指向的目标域名example.com。递归DNS服务器最终获取目标域名example.com的A记录（IP地址）。 返回IP地址：递归DNS服务器将目标域名example.com的A记录返回给用户的计算机。用户的计算机使用该IP地址与目标服务器建立连接，加载网站内容。3.4 Hexo 中CNAME 文件的作用 当你使用自定义域名而不是username.github.io来访问网站时，需要在在source目录中创建一个文件CNAME 文件，并写入自定义域名 CNAME文件的存在和内容会告知GitHub Pages你希望通过哪个自定义域名访问你的网站。 例如，如果你的自定义域名是www.example.com，你需要在CNAME文件中写入www.example.com。 4. 数学公式的支持可参考 在任意的hexo主题支持数学公式","categories":[],"tags":[]},{"title":"chatGPT是如何被训练出来的","slug":"chatGPT是如何被训练出来的","date":"2024-04-19T07:23:32.000Z","updated":"2024-05-17T09:14:34.168Z","comments":true,"path":"8cb014c5/","permalink":"http://example.com/8cb014c5/","excerpt":"","text":"本文内容基于 Andrej Karpathy 的视频 State of GPT，并加入了个人理解，进行总结。 该部分的主题是how to train your GPT assistants， 在chatGPT 的语境中，Assistant 特指能回答问题，像助手一样可以帮我们做很多事。 0. GPT训练的四个阶段 目前我们能够使用到的chatGPT 都是RLFH 模型，该模型的训练可以分为3个阶段 pretraining 预训练 Supervised finetuning 监督微调 Reinforcement Learning from Human Feedback， 包括reward modeling 和Reinforcement Learning， 因为reward modeling 不能独立起作用，也不能独立部署，必须Reinforcement Learning结合使用，所以把它们归类为一个阶段。 在以上每个阶段中，都有各自训练需要的数据集、算法、和训练输出结果 1. pre-training 预训练pre-trainin 预训练阶段是一切的起点，它需要最多的数据，最多的计算资源GPU，最长的训练时间。 总的特点如下 大规模数据：预训练使用的大规模数据集包含了来自互联网的各种文本，这些数据集规模庞大，通常包含数十亿甚至数百亿个token。 无监督学习：预训练通常采用无监督学习方法，即不需要人为标注的数据。模型通过预测文本中的下一词（或下一个token）来学习语言结构和模式。 通用性：预训练模型具有通用性，因为它并没有针对特定任务进行优化，而是广泛地学习各种语言模式。这种通用性使得模型可以适应多种下游任务。1.1 Dataset 预训练使用的大规模数据集包含了来自互联网的各种文本，这些数据集规模庞大，不过目前chatGPT 没有公开具体的数据， 上图是meta 开源的LLaMA的训练数据集 67.0%的Common Crawl，也就是常规网络爬取的数据集，这部分数据集的特点是内容涉及的类型很全面，但是因为内容可能是任何人写的，质量一般偏低，也会包含大量不相关，例如广告、导航条、版权声明等。 15.0%是C4数据集 (Colossal Clean Crawled Corpus, “庞大的清洁语料库”)，这个数据集包含了大量的网页文本，这些文本已经过清理，移除了广告、重复内容、非英语文本、和其他不适合训练的元素。这个数据集的目标是提供一个大规模、高质量、多样性强的英语文本数据集，以支持自然语言处理任务。尽管C4经过清理，但仍然包含了来自互联网的各种文本，因此可能包含一些质量不高的信息的信息。 剩余18%的训练数据来源主要是来自Github、维基百科、书籍、Arxiv论文、交易所等， 可以认为是高质量的数据。 这些训练数据有以下特点 规模庞大：训练数据的数量非常大，包含数十亿条文本记录。这种大规模的数据量帮助模型学会语言的复杂性和细微差别。 多样性：训练数据涵盖了广泛的主题和领域，包括科学、艺术、历史、文学、技术、日常生活等。这种多样性使得模型能够应对各种类型的问题和对话。 广泛覆盖：涵盖了从基础知识到专业知识的广泛范围，使得模型在回答问题时既能处理简单的日常问题，也能应对复杂的专业问题。 . 开放获取：所有数据都来自公开可获取的资源，没有使用私人或受保护的数据，确保了数据的合法性和道德性。 根据以上特点，可以总结认为像chatGPT 这样的LLM, 学习了人类在互联网上发表过所有知识。不过由于高质量的数据只占18%， 如果你想获取高质量的回答，所以你需要一些chatGPT 沟通的技巧， 即prompt 技巧，才能获取高质量的回答。 1.2 preprocess dataset-Tokenization针对从互联网上获取到的大量数据，chatGPT 并不是直接拿来训练，而是要经过tokenization 标记化，将文本转换成模型可以理解的整数序列。 1.2.1 什么是Tokenization？Tokenization是将文本拆分成较小的单元（称为tokens）的过程。这些tokens可以是单词、子词、字符或其他文本片段，，并将其映射到特定的标记或整数的过程。 从图中可以看出，GPT 并不是直接使用从互联网上获取的原始数据进行训练， 而是先讲数据分解成token,再将token 转化成整数数列。最终进入到神经网络/Transformer 进行训练的是这些整数数列。 以下Tokenization的步骤： 文本清理：在进行Tokenization之前，文本可能需要清理，比如去掉多余的空格、标点符号的处理等。这一步骤视具体应用而定。 拆分文本：将文本拆分成tokens。例如，对于句子“ChatGPT is great.”，可以拆分为“ChatGPT”、“is”和“great”。 子词级别的Tokenization：现代语言模型（如GPT-3）通常使用子词（subword）级别的Tokenization，如Byte Pair Encoding（BPE）或WordPiece。这些方法可以将罕见词分解为更常见的子词片段。例如，单词“unhappiness”可以分解为“un”、“happiness”或进一步分解为“un”、“happi”、“ness”。 分配唯一ID：每个token被分配一个唯一的整数ID，模型内部使用这些ID而不是直接使用文本。例如，“ChatGPT”可能被分配ID 12345，“is”被分配ID 6789，依此类推。 1.2.2什么是tokentoken 在自然语言处理（NLP）中扮演着核心角色，尤其是在训练像ChatGPT这样的大型语言模型时，token是模型训练和生成文本的基本单位。 在英语预料中，它可以是是一个词、也可以是一部分词、或者一个字符（虽然演讲中示例对token 的举例基本是都是完整的单词） 那么这里就要思考，为什么不用完整的单词训练呢，既简单又直接。 词汇表大小和稀疏性问题使用完整单词进行训练的一个主要问题是词汇表的大小。英语和其他语言中的词汇量非常庞大，尤其是当考虑到新词、专有名词、不同的词形变化（如复数形式、时态等）时，词汇表的规模可能会变得非常大。 大词汇表问题：一个庞大的词汇表意味着模型需要处理更多的单词，这不仅增加了模型的复杂性，还会显著增加训练和运行模型所需的资源（如内存和计算时间）。 稀疏性问题：当词汇表很大时，很多单词在训练数据中出现的频率可能非常低，导致数据稀疏。稀疏性问题会降低模型对这些单词的学习效率，影响模型的性能和泛化能力。 处理未知词汇的能力直接使用完整单词进行训练面临的另一个挑战是如何处理训练数据中未出现过的单词（即未知词汇或OOV问题）。 未知词汇（OOV）问题：在新的文本中经常会出现训练数据中未见过的单词。如果模型只学习到了完整单词，那么它很难处理这些未知词汇。 泛化能力：通过使用子词（如词干、前缀、后缀等）或更小的单元，模型可以更好地泛化到未见过的单词。例如，通过识别“un-”和“-able”这样的前后缀，模型可以推断出“unbelievable”等单词的含义，即使这个词在训练数据中没有直接出现过。 训练效率和计算资源分词还可以帮助提高训练效率和减少对计算资源的需求。 减少参数数量：较小的词汇表可以减少模型的参数数量，降低过拟合的风险，同时提高模型的训练速度和推理速度。 内存和存储优化：使用更小的词汇表意味着可以更高效地使用内存和存储资源，尤其是在嵌入层中。 适应多样化的语言现象语言中存在大量的变体和创新，直接使用完整单词可能难以适应这些变化。 词形变化：在许多语言中，单词可以有多种形式。使用基于规则或统计的分词方法可以帮助模型理解不同词形之间的关联，提高模型对语言变化的适应能力。 新词创造和网络语言：新词和网络流行语的出现是常态。分词系统可以通过更新词库或调整分词算法来适应这些变化。 1.3 Unsupervised Learning-无监督学习预训练采用无监督学习方法，即不需要人为标注的数据。模型通过预测文本中的下一词（或下一个token）来学习语言结构和模式。 数据会以批次为单位， 输入到Transformer中进行训练，其训练过程就是不断让模型根据前面已经的内容（黄色部分），去猜测当前token(绿色部分)的下一个词是什么（红色部分）， 如果猜测的结果和实际情况不一致，则要调整模型，直至结果一致。 猜测的过程是基于概率进行的。 如果猜错了，那距离正确答案又多远，这就是损失函数的概念。低损失意味着更高的预测正确概率 1.3 base model预训练完成后会得到一个base model ，因为它并没有针对特定任务进行优化，而是广泛地学习各种语言模式。这种通用性使得模型可以适应多种下游任务。 1.3.1 base model are not assistant这句话的含义是base model 并不能回答问题。预训练阶段得到的base model 只是一个文档生成器， 只会根据你输入的内容去预测下一个单词，并不会回答你的问题，所以还起不到assistant 助手 的作用。 如图中，base model 并不会按照你的要求写诗，知识生成相似的内容。 what is the capital of France? 再例如针对以上问题，base model 并不会回答问题，给出“Paris”, 而是会续写内容， 给出以下可能的答案what is France’s largest city?what is France’s population?what is the currency of France? 1.4 如何让 base model 回答问题1.4.1 few-shot LearningFew-shot Learning：指的一种在给模型提供少量示例的情况下让其学习新任务的方法。Few-shot 可以分为零样本学习（zero-shot learning）、一样本学习（one-shot learning）和小样本学习（few-shot learning）。原理：模型在大规模语料上进行预训练，学到了广泛的语言知识和基本任务能力。在新任务上，通过提供少量的示例（输入-输出对），模型可以从中推断出该任务的模式和要求。 few-shot 之所以起作用，是把问题伪装成了一个文档中缺失的内容，让base model 通过完成文档的能力把它补全。但是这一过程非常不稳定， 在实践中总体效果一般。 1.4.2 Supervised finetuning指在base model 的基础上，使用带有标签的数据集对模型进行进一步训练，以提高其在特定任务上的表现。 1.4.3 few-shot vs Supervised finetuning Few-shot Learning： 优点：无需大量标注数据，适应新任务快速。 缺点：在任务复杂或示例较少时，效果可能不如监督微调。 监督微调： 优点：在有足够标注数据时，能够显著提升模型性能。 缺点：需要大量标注数据，成本较高。 2. Supervised finetuning stage 微调指在base model 的基础上，使用带有标签的数据集对模型进行进一步训练，以提高其在特定任务上的表现。 2.1 Dataset相比pre-training 预训练阶段，Supervised finetuning 监督微调阶段使用少量但高质量的数据集。这些数据集包含了成对的输入和期望输出，例如问题与答案（Q&amp;A）、命令与响应、或者其他相关任务的配对。这些数据通常通过以下方式获得： 人工标注：雇佣标注人员根据预设的指导文档（labeling documentation）来创建数据。标注人员可能会根据给定的指令编写问题的答案，或者评估和选择模型生成的候选回答。 众包平台：使用众包服务（如Amazon Mechanical Turk）来收集和标注数据。这种方式可以快速且成本相对较低地获得大量标注数据 合作伙伴：与学术机构、研究组织或其他公司合作，共享或共同创建数据集。 2.2 SFT modelSFT model 已经是一个可以回答问题的assistant 2.4 Pre-training vs fine tuning 以下是预训练（Pre-training）和微调（Fine-tuning）两个阶段的对比表格，从目标、数据集、过程、成本和迭代与改进五个方面进行总结： 特征 预训练（Pre-training） 微调（Fine-tuning） 目标 学习广泛的语言知识和互联网信息，不专注于特定任务。 调整预训练模型以适应特定任务或应用场景。 数据集 来自互联网的大规模、多样化文本数据，可能包含多种语言和主题。 较小但高质量的特定任务相关数据集，如问答对、标注文本等。 过程 通过预测文本序列中的下一个词进行训练，使用大规模数据集进行广泛学习。 在预训练模型的基础上，使用特定任务的数据集进行额外训练。 成本 高，需要大量计算资源（如GPU集群）和时间，成本可能高达数百万至数十亿美元。 相对较低，主要涉及数据标注和模型调整，计算资源需求较小。 迭代和改进 通常在大型公司或研究机构中进行，可能每年或几个月进行一次，取决于资源和需求。 可以频繁进行，根据模型表现和用户反馈不断优化模型。 3. RLHFReinforcement Learning from Human Feedback根据人类反馈进行强化学习这个阶段包含两个步骤， Reward Modeling Reinforcement Learning3. 1 Reward Modeling 3.1.1 Dataset- comparisons 相同的prompt, SFT model 会给出不同版本的回答，即多个候选答案。目前我们在使用 人类评估者会对这些候选回答进行比较打分排名，并选择他们认为最合适或最准确的回答。 模型会根据这些比较结果进行学习，以便对其他问题的多个候选答案的好坏进行预测 3.1.2 RM Training 从图中可以看出， 提示词+ 结果+ 人类评估者反馈作为关联在一起的数据又被打包到batch中进行训练， 如图，可以理解成一个相同的提示词prompt 有3个不同版本的回答，对应的3个不同的reward(可以理解成是分数)， 训练后模型就可以针对一个prompt 的回答预测出一个人类评估者的打分。 所以这个阶段的目的就是构建一个reward model 学习人类打分的规律，以来预测一个回答可能会获得的人类评分。 由于reward model只是学习了人类打分的规律，所以如果单独使用Reward Model 进行打分并不会促进模型生成更好的答案 ， 它需要和Reinforcement Learning 强化学习结合使用才能起作用 3.2 Reinforcement Learning有了reward model 后，就可以对模型的回答进行打分。对于分数高的回答，要提高其出现的概率，如此不断迭代，尽可能生成获得更高分的回答。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"chatGPT","slug":"chatGPT","permalink":"http://example.com/tags/chatGPT/"}]},{"title":"Intro to chatGPT,从G、P、T的含义解释chatGPT","slug":"Intro-to-chatGPT-从G、P、T含义解释chatGPT","date":"2024-04-19T07:19:46.000Z","updated":"2024-05-17T09:14:34.174Z","comments":true,"path":"60dfe914/","permalink":"http://example.com/60dfe914/","excerpt":"","text":"ChatGPT是由OpenAI开发的，一个能够理解和生成自然语言的人工智能（AI）模型，可以和用户进行互动并生成类似人类的对话。 1. chatGPT 的发展历程ChatGPT模型的发展历程是一个不断演进和改进的过程。以下是关键的时间节点和发展阶段： GPT-1（2018年6月）：OpenAI发布了首个生成预训练变换器模型（Generative Pre-trained Transformer，GPT-1）。该模型基于Transformer架构，使用无监督学习方法在大规模文本语料上进行预训练，然后在特定任务上进行微调（Fine-tuning）。 架构：12层Transformer解码器，参数量约为1.17亿。 创新点：引入无监督预训练和有监督微调相结合的训练方法，在多个NLP任务上表现优异。 GPT-2（2019年2月）：OpenAI发布了GPT-2，模型规模和能力大幅提升。最初由于担心模型被滥用，OpenAI仅发布了部分参数的模型，后于2019年11月发布了完整模型。 架构：最大版本有48层，参数量达15亿。 创新点：显著提高了模型的生成质量和连贯性，在文本生成、翻译、问答等任务上表现出色。 GPT-3（2020年6月）：是当时最大和最强大的语言模型，包含1750亿参数。 架构：1750亿参数，96层，采用更大规模的数据进行训练。 创新点：通过超大规模预训练和少量示例（Few-shot Learning），在无需微调的情况下，也能在多个任务上取得惊人的效果。 GPT-3.5（2021年11月）： 是GPT-3的改进版本，模型参数达到2000亿，利用人类反馈进行强化学习，进一步提升模型的交互能力。 增强了处理复杂对话和多轮对话的能力。 GPT-4（2023年2月）： 尚未公开具体参数，但推测远超GPT-3.5，支持多模态输入和输出 提供了更高水平的自然语言理解和生成能力，支持多模态输入与输出 GPT-4o(2024年5月) 工程能力大幅提升， 体现在相应速度更快，且开始能理解语音语调 ChatGPT模型的发展不仅仅是参数的增加，更是算法优化、数据多样化和对用户反馈的持续改进。 目前我们使用的chatGPT 后GPT-3.5、GPT-4、GPT-4o 三个版本可选。 2. G、P、T分别是什么意思GPT 是 Generative Pre-trained Transformer 的缩写。以下内容将重点介绍G、P、T 三个字母各自的含义，以此来更好得理解chatGPT 是什么。 2.1 Generative 生成式ChatGPT是一个Generative AI, 即生成式AI。 AI 作为一个总称，其实包含非常多具体的类型， ChatGPT 所属的Generative AI 是其中一个子类。 日常生活中会用到的siri、小度、小爱、识别图片中动物是小猫、医院的专家诊断系统、和你国际象棋对战的机器人，这些都是AI 。 但是这些AI 都是规则驱动的系统，只能根据预设规则进行回答，一旦超出预设范围，就会表现的人工智障。 chatGPT作为一个Generative AI, 其最大的特点就是根据输入生成新内容。它不仅能回答问题，还能进行创意写作、故事生成、诗歌创作等多种任务。 Generative AI 也有自己具体的分类 Natural language generationchatGPT 就是 NLG, 可以说是目前最著名的AI 应用 text to image根据文字生成图片 Midjourney DALL-E Stable Diffusion Generative Adversarial Networks (GANs)生成对抗网络，其核心是两个相互对抗的网络：生成器（Generator）和判别器（Discriminator）。这两个网络在训练过程中相互竞争，从而不断提升自身的性能。 生成器（Generator） - 这个网络的任务是捕捉训练数据的分布，并生成尽可能接近真实数据的新数据。生成器接受一个随机噪声向量作为输入，通过这个噪声向量构造出新的数据实例。 判别器（Discriminator） - 判别器的任务是区分输入给它的数据是来自训练集（即真实数据）还是生成器生成的假数据。基本上，判别器是一个二分类模型，输出一个标量表示输入数据是真实数据的概率。这两个模型在训练过程中进行对抗。生成器试图产生越来越真实的数据以“欺骗”判别器，而判别器则试图变得更好地区分真假数据。通过这种对抗过程，生成器学会生成高质量的数据。 VAEs可用于异常检测，方法是在正常数据的数据集上训练模型，然后使用经过训练的模型来识别偏离正常数据的实例。这可用于检测各种情况下的异常情况，例如发现金融交易中的欺诈行为、发现制造中的缺陷或发现网络中的安全漏洞。例如，Uber 在其金融交易中使用 VAE 进行异常检测，以检测欺诈行为。 2.2 Pre-trained 预训练预训练 是chatGPT训练 的第一个阶段。 chatGPT 的 训练可以分为以下几个阶段 pre-training supervised fine-tuning reward modeling reinforcement learning 其中pre-training是第一个阶段, 在预训练阶段使用的数据集通常是从互联网上收集的大量文本，这些文本可能包含多种语言、主题和格式。 预训练的目标是让模型在大量的文本数据上进行了广泛的训练学习了语言的结构、语法以及大量的知识。学习结束后， 预训练 阶段会产出一个base model, base model 可以根据 用户的输入， 去续写文本， 注意， 这个阶段的chatGPT 还不能回答你的问题。 针对以下问题输入，，比如， 它只能给出这样的回答。what is the capital of China? base model 并不会回答问题，给出“beijing”, 而是会续写内容， 给出以下可能的答案 what is China’s largest city?what is China’s population?what is the currency of China? 如果想让模型“理解”人类的问题并进行回答， 还需要进行第二阶段的训练 supervised fine-tuning。 2.3 TransformerChatGPT的核心技术是Transformer架构，这是一种深度学习模型，擅长处理序列数据。Transformer通过自注意力机制（self-attention mechanism）来捕捉输入文本中的重要特征和上下文关系。这种架构使得模型在处理长文本和复杂上下文时，能够保持较高的准确性和连贯性。 要理解Transformer在ChatGPT中的应用，我们可以用一个简单的类比来说明。想象一下，你在读一本书，并试图理解每一段的意思。你的大脑不仅仅是逐字逐句地阅读，还会结合前后的内容，理解整段的意义。Transformer在ChatGPT中的作用就像你大脑的这种理解机制。 3. chatGPT 使用场景发挥你的想象，能用的具体场景是在太多了。后面这里会陆续补充我使用的场景","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"chatGPT","slug":"chatGPT","permalink":"http://example.com/tags/chatGPT/"}]},{"title":"GPTs开发-Best English Name，帮你找到最合适、最满意的英文名","slug":"GPTs开发-Best-English-Name，你找到最合适、最满意的英文名","date":"2024-04-16T08:44:20.000Z","updated":"2024-08-09T15:51:05.606Z","comments":true,"path":"209fa7d3/","permalink":"http://example.com/209fa7d3/","excerpt":"","text":"最近开发了一个用来取英文名的GPTs Best English Name。作为GPTs 开发者，虽然离openai 给我发钱还远着呢，但是没关系，我可以自己先用GPTs 变现，虽然变现的钱还只够cover 一个月plus 的费用。 Best English Name 是什么 Best English Name 是一个起名助手，它可以帮助你找到气质相符且满足各种要求的英文名，并且会对英文名有详细且深入的解释，让你充分了解自己的英文名。这个气质可以是你通过图片上传告诉chatGPT, 也可以自己描述给chatGPT,同时你也可以有其他定制化要求，包括但不限于 和中文读音/拼写类似 特定长度 特定开头字母 女性化/中性化/男性化 MBTI 我为什么要开发Best English Name我的痛点本人在工作、生活中均有需要用到英文名的场景， 记得第一次需要取英文名是入职新公司，我花了一下午的时间在豆瓣上翻找曾经看过的英文影视剧，试图找到一个喜欢的英文名， 但最后选定的名字总让我觉得“这不是我”。 我自己在确定英文名的过程中，有这样的担忧 这个名字听起来非常“不像我” 这个名字适合女生吗 这个名字在英语国家奇怪吗，会不会根本就没人起这个名字 这个名字会不会太大众化了，会不会有点过时了 这个名字会不会有什么不好的寓意，到时候引起不必要的误会 同时我对那个我将要喜欢且适合的英文名也有一定的要求 我希望这个英文名中性化一点 我希望我的名字以A 开头 我希望这个名字有美好的寓意且我能够了解这个美好的寓意，这样当别人问我为什么取这个名字的时候，我就可以清楚地向ta 介绍我的名字 开始使用chatGPT 后， 我发现它可以很好的提供一些满足我要求的英文名，同时规避掉我的担忧。 痛点的大众化在小红书闲逛时，我发现有很多人都在为选择一个英文名困扰， ta 们通常会发出一张照片让网友根据第一眼印象帮忙起名，有时候会有一些额外的需求。 同时我还发现有很多人经常向网友询问自己的英文名是什么意思。 我认为这两种情况和我起名字时遇到的问题是一样的，chatGPT 能帮助我找到满意的英文名，那么它也可以帮助其他人找到满意的英文名， 所以我把自己取英文的过程做成了一个可复用的GPTs, 希望可以帮助更多人找到满意适合的英文名 GPTs 的工程开发一个不懒的GPTs回答详细深入。 一个抗攻击的GPTs不会泄漏该GPTs 的instruction","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"chatGPT","slug":"chatGPT","permalink":"http://example.com/tags/chatGPT/"},{"name":"personal projects","slug":"personal-projects","permalink":"http://example.com/tags/personal-projects/"}]},{"title":"Intro to AI","slug":"Intro-to-AI","date":"2024-04-16T07:13:57.000Z","updated":"2024-05-17T09:14:34.171Z","comments":true,"path":"81fcff81/","permalink":"http://example.com/81fcff81/","excerpt":"","text":"在学习AI 过程中，发现专业名词相当多，初学者可能会感到而混乱，所以本篇内容是对该领域内的一些“大词”进行简单介绍， 做一些概念扫盲， 以保证在接下来的学习中心中有框架。 正式内容会按照下图框架介绍 1. 人工智能 (Artificial Intelligence)人工智能（Artificial Intelligence，简称AI）是一门研究和开发用于模拟、扩展和扩展人类智能的理论、方法、技术及应用系统的科学技术。 简单来说，AI指的是使计算机系统能够执行通常需要人类智能才能完成的任务。这些任务包括学习、推理、解决问题、感知、语言理解和生成等。 人工智能（AI）的发展历史可以追溯到20世纪中期，它的发展经历了多个重要阶段，每个阶段都有其独特的特点和里程碑事件。下面来简单介绍其发展历程 1.1 早期阶段：基础理论和初步探索（1950s-1960s）1956年达特茅斯会议：AI正式诞生。1956 年，John McCarthy、Marvin Minsky、Allen Newell 和 Herbert A. Simon 等研究者在达特茅斯会议上首次提出了“人工智能”这一术语，标志着AI研究正式成为一个独立的学科。 1950年代末：艾伦·图灵提出了“图灵测试”，成为判断机器是否具备智能的基准。 这一时期，由于技术和硬件的限制，早期的AI系统主要关注于简单任务的自动化，如象棋和跳棋游戏。例如，IBM 的 Deep Blue 和 MIT AI Lab 的 MacHack VI 等系统在象棋游戏中取得了显著的成就。这些系统虽然在处理复杂模式方面受限，但它们的成功展示了AI在规则清晰、限定环境中的潜力。 1.2 专家系统与机器学习（1970s-1990s）1970年代：专家系统（Expert Systems）开始兴起，如MYCIN用于医疗诊断，DENDRAL用于化学分析。这些系统能够储存、解释和推理知识,可以用来解决特定领域的问题。 1980s：反向传播算法（Backpropagation）的提出使神经网络重新受到关注。尽管计算能力仍有限，但理论和方法上的突破为未来的发展奠定了基础。 1990s: 随着更多的数据可用和计算能力的增加，机器学习方法，特别是基于统计的方法开始主导AI研究。支持向量机和随机森林等技术的发展，为AI在图像识别、自然语言处理和其他复杂模式识别任务中的应用打开了新的可能性。 1.3 现代AI：大数据与深度学习时代（2000s-至今） 计算能力和数据的提升： 2000s：互联网和大数据的发展，为AI提供了大量训练数据。计算能力的提升，特别是GPU的使用，使得复杂的模型训练成为可能。 深度学习的崛起： 2010s：深度学习（Deep Learning）在图像识别、语音识别、自然语言处理等领域取得突破。AlexNet在2012年ImageNet竞赛中的成功，标志着深度学习的重大胜利。 广泛应用： 2010s-至今：AI在自动驾驶、医疗诊断、金融分析、智能客服等领域得到广泛应用。2016年，AlphaGo击败围棋冠军李世石，展示了AI在复杂博弈中的强大能力。 自然语言处理：GPT-3等大型语言模型的推出，使得AI能够生成逼真的自然语言文本，应用于翻译、对话系统、内容创作等多个领域。 2. 机器学习 与 深度学习机器学习（Machine Learning）和深度学习（Deep Learning）是现代人工智能（Artificial Intelligence）领域的核心技术。它们的发展极大地推动了从图像识别到自然语言处理的各种应用。 2.1 机器学习（Machine Learning）机器学习是一种使计算机能够通过经验自动改进的技术。它依赖于算法和统计模型，使得计算机系统可以识别数据中的模式并做出决策，无需明确编程。 主要类别： 监督学习（Supervised Learning）：模型在带有标签的数据集上进行训练，学习输入与输出之间的映射关系。应用包括分类（Classification）和回归（Regression）。 无监督学习（Unsupervised Learning）：模型在没有标签的数据集上工作，目标是发现数据的内在结构。常见的任务有聚类（Clustering）和降维（Dimensionality Reduction）。 半监督学习（Semi-supervised Learning）：使用部分标记的数据进行训练，结合监督学习和无监督学习的特点。 强化学习（Reinforcement Learning）：模型通过与环境的交互学习策略，目标是最大化某种数值奖励（Reward）。 2.2 深度学习（Deep Learning）深度学习是机器学习中的一个子集，它使用称为人工神经网络（Artificial Neural Networks）的模型，特别是具有多个层（Layers）的深层网络，以学习数据的高级抽象特征。 核心概念： 神经网络（Neural Networks）：一个由节点（或称为神经元，Neurons）组成的网络，节点在层中组织并通过激活函数（Activation Functions）处理信息。 卷积神经网络（Convolutional Neural Networks, CNNs）：特别适合处理图像数据。 循环神经网络（Recurrent Neural Networks, RNNs）：优秀的处理序列数据如时间序列或自然语言的工具。 长短期记忆网络（Long Short-Term Memory, LSTM）和门控循环单元（Gated Recurrent Units, GRU）：是RNN的变体，解决了传统RNN长期依赖问题。 Transformer：一种基于自注意力机制（Self-attention Mechanism）的架构，广泛用于自然语言处理领域。 2.3 区别与联系联系： 深度学习是机器学习的一种特殊形式，利用复杂的神经网络结构来解决广泛的问题。 两者都依赖数据来学习，并通过迭代过程改进模型性能。 区别： 机器学习包括一系列不仅限于神经网络的技术和方法。 深度学习通常需要更大量的数据和更强的计算能力。 3. 神经网络 (Neural Networks)神经网络是实现AI 的一种技术手段，一种广泛用于机器学习（Machine Learning）和深度学习（Deep Learning）领域的计算模型/算法架构。 它受到人类大脑神经元（Neurons）和它们的互动方式的启发，它由多个层（Layers）组成，每层包含多个神经元，这些神经元通过权重（Weights）连接传递信息。 神经网络的训练过程基于机器学习的基本前提，即能够从数据中学习。通过向网络提供大量的数据样本（包括输入和期望的输出），神经网络可以学习到如何映射输入到输出，这种能力是通过调整内部结构（即权重）来实现的。 这一学习过程使用了机器学习中的核心概念，如损失函数（Loss Functions）、梯度下降（Gradient Descent）和反向传播算法（Backpropagation Algorithms）。这些都是机器学习领域的基本工具，用于训练模型以改进其性能。 4. TransformerTransformer（变换器）是一种革命性的神经网络架构，它在自然语言处理（Natural Language Processing, NLP）和其他序列建模任务中取得了显著的成就。Transformer 最初由 Vaswani 等人在 2017 年的论文 “Attention Is All You Need” 中提出，其核心思想是完全依靠注意力机制（attention mechanisms），摒弃了之前常用的循环神经网络（Recurrent Neural Networks, RNNs）和卷积神经网络（Convolutional Neural Networks, CNNs）中的结构。 5. NLP自然语言处理（Natural Language Processing，简称NLP）是人工智能的一个分支，致力于让计算机理解、解释和生成人类语言。它结合了计算机科学、人工智能和语言学的知识与技术，用于处理和分析大量的自然语言数据。 NLP使用各种技术来处理和理解语言。这些方法从规则基础的方法到基于机器学习的方法，特别是深度学习，都有涵盖。随着时间的推移，深度学习在NLP中变得越来越重要，因为它能够在处理自然语言的复杂性方面提供显著的改进。 传统方法： 基于规则的系统：使用预定义的语言规则来解释文本。 统计模型：基于大量语料库数据，使用统计方法推断和预测。 现代方法 神经网络：使用多层神经网络模型处理语言任务，如循环神经网络（RNN）、长短期记忆网络（LSTM）和最近的变换器模型（如BERT、GPT）。 NLP技术被广泛应用于各种现实世界的场景和产品中，例如： 聊天机器人和虚拟助手（如Apple的Siri、Google Assistant、Amazon Alexa）。 文本分析工具，帮助企业监测和分析社交媒体上的消费者情绪。 电子邮件过滤和反垃圾邮件技术。 语音到文本服务，如在法庭记录或医疗记录系统中自动转录口述内容。 5. LLMLLM（Large Language Models，大型语言模型）是自然语言处理（Natural Language Processing, NLP）领域的一种先进技术，主要依赖于深度学习（Deep Learning）技术，特别是基于 Transformer 架构的神经网络模型。这些模型因其规模庞大和在多种语言任务上的出色表现而得名。 LM 是设计用来理解、生成、翻译、摘要等处理文本的大规模神经网络模型。它们通常包含数十亿至数万亿个参数，并在大量多样化的文本数据上进行训练，以学习语言的深层次结构和语义。核心组件 Transformer 架构（Transformer Architecture）： LLM 多使用基于 Transformer 的模型，这种模型依靠自注意力机制（Self-Attention Mechanism）来处理文本数据，优于传统的循环神经网络（Recurrent Neural Networks, RNNs）或卷积神经网络（Convolutional Neural Networks, CNNs）。 预训练与微调（Pre-training and Fine-tuning）： 预训练（Pre-training）：在大规模未标记数据上进行，模型学习语言的通用特征。 微调（Fine-tuning）：在特定任务的较小标记数据集上进行，调整模型以适应具体应用。 自监督学习（Self-supervised Learning）： LLM 通常通过自监督学习预训练，这意味着它们使用输入数据的不同部分作为自己的监督信号，例如，预测文本中被遮蔽（Masked）的单词。","categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"chatGPT","slug":"chatGPT","permalink":"http://example.com/tags/chatGPT/"}]},{"title":"TrustMessage-基于2PC+MySQL+泛化调用实现的可靠消息中心","slug":"基于2PC-MySQL-泛化调用实现的可靠消息中心","date":"2024-04-09T08:41:05.000Z","updated":"2024-08-07T11:13:39.029Z","comments":true,"path":"99d433fa/","permalink":"http://example.com/99d433fa/","excerpt":"","text":"0. 项目结构介绍 Module Description trustmessage-mysql 基于2PC+MySQL表实现的可靠消息中心，业务操作+消息表操作均存在于同一个项目中 turstmessage-middleware 可靠消息中心中间件，基于RPC接口提交消息+2PC+MySQL 表实现 turstmessage-middlewareapi 可靠消息中心中间件， 回查接口定义 Turstmessage-middlewareclient 可靠消息中心中间件， 消息生产者，提供了HTTP回查接口、Dubbo泛化回查接口的示例 以下是项目正式介绍。 在业务处理中，经常会有重要但没那么紧急的数据需要同步给下游，比如 订单侧完成消息后给优惠侧发一个消息，优惠侧做一个单向对账的功能，确保券被正确核销 在这种场景中，需要把本地业务操作 + 消息发送当成一个事务处理，即满足原子性， 一般常见的解决方案会有两种 本地事务+本地消息表 RocketMQ 本项目将从本地事务+本地消息表 出发， 一步步探讨如何用 MySQL 实现一个支持分布式事务的可靠消息中心，即TrustMessage。 项目github链接，点击可查看代码 1. 本地事务+ 本地消息表由于Spring 的事务机制只保证数据库操作的原子性，所以当涉及到 数据库的业务操作 和 其他中间件如kafka操作 具有原子性的时候，就要用其他的方案来保证。 本地事务+ 本地消息表 这种方案是把 需要发送的消息作为数据库操作的一部分，保存到数据库中的一个表里，然后通过另外的逻辑，将消息的真正发送 稍后异步进行，比如用一个定时任务将消息异步发送到Kafka。 这种方法确保了数据库操作和消息发送在逻辑语义上的原子性，因为它们都在同一个数据库事务中处理。 这里需要注意，这种方案的实时性是比较差的，所以你需要判断的业务场景场景是否能够容忍这样的异步操作。 关于Spring事务，可以点击阅读Spring事务实现原理 1.1 业务流程 以上流程中，在本地事务提交后，有一个定时任务轮询消息表将需要发送的消息消息发送出去。有4个点需要注意一下 事务提交后了，消息发送失败， 定时任务的重试机制，会找出这条消息进行异步补发 事务提交后了，消息发送成功，但是消息状态修改状态， 定时任务会找出这条再次发送 重试异步补发过程中，如果消息依然发送失败，那么会继续重试补发 重试异步补发过程中，消息发送成功，但是数据库消息已发送状态修改失败，那么定时任务又会再次找到这条消息再发一遍 以上 2和4 均会面临消息重复的情况， 个人认为在业务常见中消息重复是一种可接受的情况，有时候业务自己甚至会消息重放， 所以消息消费者做好幂等逻辑就可以了。 1.2 消息发送重试次数消息发送不能无限次重试 浪费资源，重试了那么多次都未成功，可能是逻辑出现问题了或者宕机了，赶紧去查问题吧 上下游业务数据迟迟无法达到最终一致性 ， 本身我们使用消息其终极目的就是为了让系统数据达到最终一致性， 如果一直无限制发送，这个目的是无法达到的, 所以赶紧停下去查问题吧 基于以上两个考虑，系统对于重试都应该有个次数限制，达到次数限制后就应该告警让人工介入处理。 1.3 消息表设计在本地事务+ 本地消息表 方案中，其消息表的设计一般如下， 1234567891011CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, message text COMMENT &#x27;消息内容&#x27;, send_status INT DEFAULT 0 COMMENT &#x27;0-投递中 1-投递成功 2-投递失败&#x27;, send_try_count INT DEFAULT 0 COMMENT &#x27;commit 消息发送 当前重试次数&#x27;, send_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息发送 下次重试时间&#x27;, create_time DATETIME DEFAULT CURRENT_TIMESTAMP, update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_messageKey(message_key)) ENGINE=InnoDB; 2. 如果消息表和业务表操作是分布式事务但是如果保证不了这两个表不在同一个库 /数据库实例中，那就会在业务操作和消息表写入两个操作中遇到分布式事务。这在分库分表的业务中是很容易出现的情况。 针对对分布式事务，常见的解决方案就是 2PC、3PC、TCC、SAGA。 接下来将讲解以 2PC+MySQL消息表 实现的可靠消息中心 2.1 业务流程以MySQL消息表+ 2PC 来实现可靠消息中心， 其整体实现流程如下 2.2 消息可见性消息可见性， 在涉及分布式事务的场景中，消息增加了一个可见性概念， 这是因为在引入2PC 后，写入消息表的消息不再像本地事务+本地消息表一样写入即可见，必须是commit后才对消费者可见， 所以在数据表的设计中需要增加一个状态字段来维护消息可见性。1message_status INT COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;, 其状态流转如图所示 2.3 如果业务执行消息commit or rollback 失败怎么办-消息回查如流程图中所示，在2PC 阶段，拿到业务执行结果修改消息状态失败有可能是失败。 一个操作执行失败后，一种常见的解决方案方案就是重试，尽最大努力交付。 但是对于业务处理来讲，一般有超时时间的限制，因为这种同步重试可能并不适用，即使可以，一般重试次数都会限定在3次。 除了同步重试，还有一种方案就是 消息回查，我个人理解这相当于一种异步重试。 在本项目中，消息回查指的就是开启一个定时任务去全表扫描，找出insert一定时间后，其状态仍然是 prepare的消息 ，通过业务逻辑判断该条消息是否已经执行完成 or 失败，对应地把消息状态更改为 commit or rollback。 为了进行消息回查，肯定要有一个业务唯一标识来识别该条消息需要对应业务数据，从而判断对应业务是否执行完成。1message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, 2.4 消息回查不能无限次 浪费资源，回查了这么多次的都没拿到结果，一种可能就是业务逻辑出现问题了，适可而止赶紧去查问题吧 系统数据迟迟无法达到最终一致性 ， 本身我们使用消息其终极目的就是为了让系统数据达到最终一致性， 如果一直无限制查询，这个目的是无法达到的, 所以赶紧停下去查问题吧 所有消息回查应该有个次数限制， 这就是表中以下两个字段的作用12verify_try_count INT COMMENT &#x27;消息状态回查 下次重试次数&#x27;, verify_next_retry_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息状态回查 下次重试时间 1-未发送 2-已发送&#x27;, 2.5 消息回查次数达到上限怎么办有两种参考方案 默认修改消息状态为commit 或者 rollback， 将消息状态置为回查失败状态 ， 告警人工介入处理 默认修改消息状态为commit 或者 rollback 这个方案，一个最大的问题就是针对状态不确定的消息，不论将其默认修改为那种状态， 都是有可能引起业务上下游数据不一致问题。 一旦上下游数据产生了数据不一致性，必然导致很长的排查链路和大量的数据修复工作。 所以本项目中我选择第二种方案，消息回查达到上限后直接告警，让消息生产者这一方人工介入处理。 此处说明一下，这种方案当然也会有数据不一致的问题，因为下游业务始终还未拿到消息修改自己的状态，但是相比拿到了随机确定的的状态 导致的数据不一致性，此时问题还被控制在消息生产者这一环，问题排查会相对简单。 2.6 消息发送重试与本地事务+本地消息表方案一致 2.7 消息表设计123456789101112131415CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, message text COMMENT &#x27;消息内容&#x27;, message_status INT DEFAULT 1 COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;, verify_try_count INT DEFAULT 0 COMMENT &#x27;消息状态回查 当前重试次数&#x27;, verify_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息状态回查 下次重试时间&#x27;, send_status INT DEFAULT 0 COMMENT &#x27;0-投递中 1-投递成功 2-投递失败&#x27;, send_try_count INT DEFAULT 0 COMMENT &#x27;commit 消息发送 当前重试次数&#x27;, send_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息发送 下次重试时间&#x27;, create_time DATETIME DEFAULT CURRENT_TIMESTAMP, update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_messageKey(message_key)) ENGINE=InnoDB; 2.8 消费者消费消息针对可见， 即已经commit 的消息，消费者该如何获取到消息消费呢，有两种方案 消息者直接查询消息表 消费者从消息队列队列消费 2.8.1 消息者轮训消息表这种方案最大的问题就是，在微服务架构下，上下游两个不同的服务 操作 同一个数据表 是一个不合理且不推荐的做法。 2.8.2 消息队列消费和本地事务+本地消息表一样，已经commit 的消息可以由一个定时任务轮训发送到业务创建的消息队列中供订阅的消费者消费发送过程也可以有一个重试的过程。 3. 如果这是一个公共中间件-基于RPC 接口实现的可靠消息中心以上讨论的方案， 都是基于消息表逻辑和业务逻辑同一个服务中， 如果把该功能做成一个公共中间件，那么在技术方案上会略有变化。 中间件需要提供的功能 两阶段提交功能 回查功能 消息转发 以上3个功能和上一种方案没有本质上的区别， 只是基于一个中间件的定位，支持这3种功能需要更多的封装与数据信息。 3.1 业务流程 3.2 两阶段提交功能提供3个RPC 接口， prepare， commit, rollback, 接口底层封装对数据表的操作 3.3 消息唯一性当作为一个公共中间件，接受多个业务数据的时候，消息的唯一性应该有业务标识 + 消息标识共同确定，即bizId + messageKey 3.4 回查功能相比于直接在业务服务里集成可靠消息的功能时，可以简单直接的在服务内部查询，当作为公共中间件时， 只能通过服务间调用完成，服务间调用有两种形式 HTTP RPC 为了增加可维护性和拓展型， 无论是哪种形式，中间件都应该定义好调用的格式，让消息生产者按照统一格式提供回查接口。 这个格式包括 接口定义 接口入参 接口返回值 其中接口定义信息需要生产消息时提供 在实现消息生产者按照统一格式提供回查接口 这一点是，HTTP接口的回查相对简单， 如果RPC 接口， 要注意使用泛化调用。 本项目实现了HTTP 接口的回查和 Dubbo 协议的泛化调用回查 HTTP接口格式为1http://127.0.0.1:8082/verifyMessage?bizID=1&amp;messageKey=key1 Dubbo RPC 接口定义为12345public interface VerifyMessageService &#123; // 消息回查接口 int verifyMessage(Integer bizID,String messageKey); &#125; 3.5 消息转发在一个公共中间件里实现消息转发，必然也需要生产消息时提供这部分信息12forward_topic VARCHAR(255) COMMENT &#x27;业务转发topic&#x27;, forward_key VARCHAR(255) COMMENT &#x27;业务转发指定key&#x27;, 3.6 消息表设计12345678910111213141516171819CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, biz_id INT NOT NULL COMMENT &#x27;业务ID&#x27;, message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, message text COMMENT &#x27;消息内容&#x27;, message_status INT DEFAULT 1 COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-verify fail&#x27;, forward_topic VARCHAR(255) NOT NULL COMMENT &#x27;业务转发topic&#x27;, forward_key VARCHAR(255) COMMENT &#x27;业务转发指定key&#x27;, verify_info VARCHAR(2000) COMMENT &#x27;回查信息&#x27;, verify_try_count INT DEFAULT 0 COMMENT &#x27;消息状态回查 当前重试次数&#x27;, verify_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息状态回查 下次重试时间&#x27;, send_status INT DEFAULT 0 COMMENT &#x27;0-投递中 1-投递成功 2-投递失败&#x27;, send_try_count INT DEFAULT 0 COMMENT &#x27;commit消息发送 当前重试次数&#x27;, send_next_retry_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;消息发送 下次重试时间&#x27;, create_time DATETIME DEFAULT CURRENT_TIMESTAMP, update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_message_key_biz_id (message_key, biz_id)) ENGINE=InnoDB; 4. 基于kafka 提交消息实现的可靠事件中心在实现消息回查的可靠消息中心方案中，另外一种常见的方案是 业务代码直接把消息提交给kafka, 然后中间件消费消息并持久化道数据库中，等待消息提交commit 或者rollback , 没有的话就进行回查。如下图，图片源自极客时间专栏 我认为两种技术方案没有本质的区别， 其差异只是消息的prepare 、commit、rollback 的提交是由RPC 接口完成还是由消息生产消费完成， 其他回查的逻辑、发送逻辑、以及需要的信息基本无差异。 不过在使用Kafka 提交时，有以下两种需要考虑 4.1 中间件如何识别一条消息是事务消息 Topic命名约定 一种简单的方法是通过Topic命名来区分。例如，所有需要支持回查的Topic可以遵循一个特定的命名模式，如添加前缀或后缀（例如，replayable-myTopic）。这种方法的优点是简单易实施，但缺点是灵活性较低，且对现有系统可能需要更多的改动。 特定主题或分区 将需要回查的消息发送到Kafka的特定主题或分区中。这样，中间件只需监听这个特定的主题或分区来处理需要回查的消息。这种方法要求生产者在发送消息时知道哪些消息需要回查，并据此发送到正确的主题或分区。 Topic配置属性 Kafka允许为每个Topic设置自定义配置属性。可以引入一个自定义属性（如replayable=true）来标识一个Topic需要支持消息回查。这种方式比命名约定更为灵活和隐蔽，但要求应用层和消息生产者遵循这一约定，并且需要在应用层实现逻辑来处理这些属性。 消息元数据标记 在消息发送时，可以在消息的元数据（Metadata）中添加特定的标记或字段来指示这条消息需要进行回查。 设计考虑： 性能：确定这些方法中哪一种对生产和消费的性能影响最小。 易用性：选择易于实施和维护的方法。 灵活性：评估是否需要对单个消息进行标记，还是以Topic为单位进行区分。 4.2 如何识别消息类型、转发信息、回查信息消息类型包括 prepare、commit、rollback转发信息,需要转发至的真正业务tpoic、 如果需要指定分区的话还包括key信息回查信息，包括回查方式如HTTP、RPC, 回查地址，回查接口等 使用Kafka消息头 优点： 保持了消息体的纯净和独立性。 灵活性高，易于添加或修改额外的控制信息和元数据。 性能考虑，对于小到中等大小的消息，使用消息头的性能开销相对较小缺点： 新版本依赖：较旧版本的Kafka客户端可能不支持消息头功能，这要求生产者和消费者使用支持消息头的Kafka版本。 额外处理：消费者需要额外的步骤来读取和解析消息头。 预先定义消息格式 优点： 直接且简单，易于实现。 不依赖Kafka特定的功能，具有较好的兼容性。缺点： 增加了消息体的大小。 需要在消费端进行消息解析，略微增加了处理的复杂性。 本项目以指定topic+预定义消息格式的方式简单实现了消息的提交，消息格式如下， 大家可以参考。12345678910111213141516171819202122232425262728package com.example.trustmessage.middlewareapi.common;public class MiddlewareMessage &#123; // 要给到业务方的真正消息 private String message; private int bizID; // 用于消息回查的业务唯一标识 private String messageKey; private int messageStatus; private String forwardTopic; // 向业务方转发时需要指定的key，没有则说明按照kafka 默认分区策略进行分区 private String forwardKey; private VerifyInfo verifyInfo; public static class VerifyInfo &#123; private int protocolType; // 1-http, 2-rpc-dubbo private String registryProtocol; private String registryAddress; private String url; private String version; &#125; &#125; 5. 基于RPC接口 vs 基于Kafka提交基于两种不同消息提交方式实现的中间件， 将从以下两方面进行比较 消息的顺序性 流量增加后扩容 5.1 消息的顺序性使用中间件回查机制，由于网络原因，有可能出现 某条业务的commit or rollback 消息比prepare 先到达中间件，面对这种情况,commit or rollback的处理逻辑是需要报错的，client 只能重试或者等待回查机制更新消息状态 但是由于kafka 可以在一个分区内的保证消息的有序性，所以基于Kafka提交的方案可以有一种优雅的方式保证prepare消息和commit/rollback 消息的有序性。 解决方案很简单，生产者在发送消息按照业务 唯一标识指定key ,即指定目标分区即可。 5.2 流量增加后扩容以下比较基于在代码层面已经做好分库分表、异步处理、批量处理、cache 等性能优化的基础上 假设已经分库分表，数据库处理不是瓶颈万一流量激增，基于Kafka提交的方案 可能会产生产生必须要处理的消息积压，针对消息积压常见的解决方案中 增加消费者数量，不过一般来讲，线上生产环境都会已经把消费者数量和分区数量设置成一样的，所以这个方案无法发挥功能 增加分区数量，假设公司的工作流程里允许增加，如果使用场景对消息顺序性有要求，你又要考虑新增分区后对消息顺序性的影响 新建一个更多分区的topic, 涉及到生产者、消费者的代码变更 消费者性能优化， 比如异步处理、批量处理， 但是如果项目已经做好这些措施，面对消息积压，只能回到下面3种方式 综合以上，我个人认为基于RPC接口的方案可以用自动扩容策略直接应对， 简单直接优雅。 6. 作为中间件的技术设计6.1 性能提升 线程池异步处理 cache 存储回查接口 基于bizID + messageKey 的分库分表 6.2 幂等性 prepare 消息的幂等性， 唯一索引","categories":[],"tags":[{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"personal projects","slug":"personal-projects","permalink":"http://example.com/tags/personal-projects/"}]},{"title":"深入解析bloom filter的原理与实现","slug":"深入解析bloomfilter的原理与实现","date":"2024-03-31T08:16:17.000Z","updated":"2024-05-02T01:35:18.938Z","comments":true,"path":"b4fa673f/","permalink":"http://example.com/b4fa673f/","excerpt":"","text":"0.什么场景下会用到bloom filter 缓存穿透 爬虫重复 URL 检测， 避免爬虫过程形成环 假设有 10 亿条手机号，然后判断某条手机号是否在列表内 唯一昵称判断 这些场景可以用什么方式解决 hashmap, hashset MySQL：正常情况下，如果数据量不大，我们可以考虑使用 mysql 存储。将所有数据存储到数据库，然后每次去库里查询判断是否存在。但是如果数据量太大，超过千万，mysql 查询效率是很低的，特别消耗性能。 bitmap bloom filter 1.bloom filter 是什么？布隆过滤器是一种概率性数据结构，它提供了一种空间效率极高的方法来测试一个元素是否属于一个集合。 其基本原理是使用多个不同的哈希函数对元素进行哈希，然后将得到的哈希值对应到位数组上。一个元素被加入到集合中，那么所有哈希函数计算出的位置都会被置为1。检查元素是否存在于集合中时，使用这些哈希函数计算哈希值，并检查对应的位是否都是1。如果都是1，那么元素可能存在于集合中；如果任何一个位不是1，那么元素肯定不在集合中。 其主要特点是： 高空间效率：相比于传统的集合数据结构，布隆过滤器使用极少的空间来处理大量数据。 误报率/假阳：布隆过滤器有一定的误报概率，这意味着它可能会错误地认为某个不在集合中的元素存在于集合中。 零漏报率：不会遗漏集合中真正存在的元素 不可删除：标准的布隆过滤器不支持从集合中删除元素，尽管存在变种（如计数布隆过滤器）支持这一操作。 多哈希函数：布隆过滤器通过多个哈希函数来减少误报率，每个元素被多个哈希函数映射到位数组的多个位置。 1.1 为什么空间效率高bloom filter 采用 位数组（bit array）作为核心的数据结构。 位数组是一个非常紧凑的数据结构，它可以有效地表示大量的布尔值（true或false），每个值只占用一个位（bit），而不是使用更传统的数据类型会占用更多的空间。 比如在爬虫场景中，假设有1亿个URL，每个URL算4字节, 如果用hashmap 实现，一个URL所占空间至少4bytes;如果用位数组实现，每个URL 所占的空间仅1bit，空间效率提升了32倍（存储空间不考虑误判率的前提下）。不可谓不高效。 1.2 为什么会有误报率/假阳既然用到了哈希函数，肯定会遇到哈希冲突。所以一个元素对应 的n 个位置， 可能因为其他元素的哈希冲突 而导致判断时发现等于1， 从而产生假阳现象。 1.3 误报如何解决假阳问题无法被避免，只能尽可能减少。 减少的途径是选择合适的哈希函数以及指定合适的空间大小 1.4 为什么需要多个哈希函数布隆过滤器的设计使用多个哈希函数来解决单个哈希函数可能带来的局限性，提高其效率和准确性。具体来说，使用多个哈希函数的原因包括： 降低误报率 通过使用多个哈希函数独立地映射每个元素到位数组中的多个位置，并在所有这些位置上标记为1，可以显著降低不同元素映射到相同位置（即产生冲突）的概率，从而降低误报率 均匀分布 多个哈希函数可以将元素更均匀地分布在位数组上，减少了集中冲突的可能性。如果只使用一个哈希函数，即使其分布性质良好，也难以保证对于所有可能的输入集合都能保持良好的均匀性。多个哈希函数的组合，如果设计得当，可以相互补偿，实现更为均匀的分布。 1.5 为什么数据不可删除在布隆过滤器中，元素的存在是通过多个位的“1”状态来表示的，而将这些位重置为“0”可能会错误地影响其他元素的存在检测。 如果需要支持删除，可以考虑使用 变体Bloom Filter， 如cuckoo filter 2. bitmap 和 bloom filter 的区别Bitmap（位图）和布隆过滤器都是使用空间效率高的数据结构，它们通过利用位操作来实现存储和查询，但它们的设计目的和应用场景有所不同。 2.1 Bitmap（位图）位图是一种数据结构，用于高效地存储和查询状态信息。在位图中，每个元素的存在或状态是由单独的位来表示的，即使用1位二进制数（0或1）来表示每个元素是否存在或某种特定状态。 主要特点和用途： 简单直接：适用于需要追踪大量元素（如整数）存在与否的场景。 空间效率：对于大规模数据集，位图使用的空间远小于传统的数据结构（如数组或列表）。 随机访问：可以非常快速地检查任何一个元素的存在与否或状态。 固定大小：位图的大小在创建时由最大元素值决定，因此其空间效率依赖于数据的分布。 BitMap 的实现java BitSetredis setbit、getbit 2.2 区别 用途：位图主要用于精确表示一个大型数据集中元素的存在与否或状态信息，而布隆过滤器用于以极小的空间成本判断元素是否可能存在于集合中。 错误率：位图提供了100%准确的结果（假设足够的空间来表示所有元素），而布隆过滤器允许一定的误报率。 操作：位图支持添加、查询和删除（通过位反转）操作，而标准布隆过滤器不支持删除操作。 空间效率与数据规模：布隆过滤器在表示大型集合成员资格时通常比位图更加空间效率，尤其是当元素范围非常大但实际元素数量相对较少时。 总之，位图和布隆过滤器各有优势和应用场景，选择哪种数据结构取决于具体需求，包括对空间效率、准确率和操作类型的要求。 3. 单机版本Guava Cache 源码解析3.1 create1234567public static &lt;T&gt; BloomFilter&lt;T&gt; create(Funnel&lt;T&gt; funnel, int expectedInsertions /* n */, double falsePositiveProbability) &#123; int numBits = optimalNumOfBits(expectedInsertions, falsePositiveProbability); int numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits); return new BloomFilter&lt;T&gt;(new BitArray(numBits), numHashFunctions, funnel, BloomFilterStrategies.MURMUR128_MITZ_32); &#125; 3.1.1 参数解释 funnel：Funnel类型的参数，用于将任意类型的数据转化成布隆过滤器内部使用的一种形式。Funnel定义了如何把对象转换成二进制流，然后布隆过滤器使用这个二进制流来计算元素的哈希值。 expectedInsertions：这个参数指定了预期要插入布隆过滤器的元素数量。这个数值是为了优化布隆过滤器内部数据结构的大小。 falsePositiveProbability（false positive probability）：误判率。这是指一个不存在集合中的元素被判断为存在的概率。值得注意的是，随着实际插入数量的增加，实际的误判率可能会上升。 3.1.2 optimalNumOfBits123static int optimalNumOfBits(int expectedInsertions, double falsePositiveProbability) &#123; return (int) (-n * Math.log(p) / LN2_SQUARED); &#125; optimalNumOfBits通过计算,可以得到一个在满足特定假阳性率（falsePositiveProbability）要求下，对于给定数量的元素预期插入量（expectedInsertions），所需的最少位数。这使得布隆过滤器能够在保证误判率的前提下，使用最少的空间。这种计算对于设计高效且空间节约的布隆过滤器至关重要 3.1.3 计算逻辑optimalNumOfBits函数的计算基于以下公式，这个公式可以从布隆过滤器的理论误判率公式推导而来： m 是位数组的长度（即函数的返回值）。 n 是expectedInsertions，即预期的插入数量。 p 是falsePositiveProbability，即期望的假阳性概率。 ln⁡2 表示自然对数。这个公式利用了布隆过滤器的误判率特性，通过指定的假阳性率和预期插入数量来计算出一个最优的位数组长度。这个长度能够在满足误判率要求的同时，尽可能地减小布隆过滤器所需的空间。 3.1.4 实现注意实际实现时，可能还需要对计算结果进行取整处理，并确保结果是一个正整数。此外，实现可能还会考虑到性能和存储效率的平衡，比如通过限制位数组的长度为2的幂等。 3.1.5 optimalNumOfHashFunctions123static int optimalNumOfHashFunctions(int n, int m) &#123; return Math.max(1, (int) Math.round(m / n * LN2)); &#125; optimalNumOfHashFunctions(expectedInsertions, numBits)这个函数用于计算给定条件下布隆过滤器的最优哈希函数数量。这个计算基于预期要插入的元素数量（expectedInsertions）和布隆过滤器内部位数组的大小（numBits）。目的是为了平衡空间使用和误判率，确保布隆过滤器在给定条件下工作得最有效率。 计算逻辑 布隆过滤器的效率和误判率与使用的哈希函数数量有很大关系。太少的哈希函数会增加碰撞的概率，导致误判率升高；而太多的哈希函数又会导致位数组快速填满，同样增加误判率，同时还会增加计算的开销。 最优哈希函数数量的计算公式是：这个公式基于以下原理：给定一个固定大小的位数组，存在一个最优的哈希函数数量，可以最小化给定元素数量条件下的误判率。这个最优数量直接关联于位数组的大小和要处理的元素数量。 其中： k 是最优的哈希函数数量， m 是位数组的大小（numBits）， n 是预期插入的元素数量（expectedInsertions）， ln⁡(2) 是自然对数2的值，大约等于0.693。 3.1.6 new BitArray(numBits)Guava cache bloom filter 在实现位数组是采用创建long[] + 位移操作 1234567891011121314151617181920212223242526static class BitArray &#123; final long[] data; BitArray(int bits) &#123; this(new long[IntMath.divide(bits, 64, RoundingMode.CEILING)]); &#125; // Used by serialization BitArray(long[] data) &#123; checkArgument(data.length &gt; 0, &quot;data length is zero!&quot;); this.data = data; &#125; void set(int index) &#123; data[index &gt;&gt; 6] |= (1L &lt;&lt; index); &#125; boolean get(int index) &#123; return (data[index &gt;&gt; 6] &amp; (1L &lt;&lt; index)) != 0; &#125; /** Number of bits */ int size() &#123; return data.length * Long.SIZE; &#125; &#125; 3.2 put12345678910111213141516MURMUR128_MITZ_32() &#123; @Override public &lt;T&gt; void put(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits) &#123; // TODO(user): when the murmur&#x27;s shortcuts are implemented, update this code long hash64 = Hashing.murmur3_128().newHasher().putObject(object, funnel).hash().asLong(); int hash1 = (int) hash64; int hash2 = (int) (hash64 &gt;&gt;&gt; 32); for (int i = 1; i &lt;= numHashFunctions; i++) &#123; int nextHash = hash1 + i * hash2; if (nextHash &lt; 0) &#123; nextHash = ~nextHash; &#125; // up to here, the code is identical with the next method bits.set(nextHash % bits.size()); &#125; &#125; 首先，这行代码使用MurmurHash3算法生成一个128位的哈希值，然后将其转换成一个long类型的数值hash64。 funnel是一个函数式接口，用于将对象转换为字节流，以便哈希函数可以处理。 hash64实际上包含两个32位的哈希值，它们可以从hash64的高32位和低32位分别提取。从hash64中提取两个32位的哈希值hash1和hash2。hash1是低32位，hash2是高32位。 接下来，代码遍历从1到numHashFunctions（布隆过滤器要求的哈希函数数量），每次循环计算一个新的哈希值nextHash。这个新的哈希值是通过hash1 + i * hash2计算得到的，其中i是当前的迭代次数。 如果nextHash为负数，通过位取反操作（~nextHash）将其转换为正数，以保证能够正确地映射到位数组的索引上。 最后，使用nextHash % bits.size()计算得到的索引值在位数组（BitArray）中对应的位置上设置位。bits.size()返回位数组的大小，这确保了计算得到的索引值不会超出位数组的范围。 3.2.1 哈希函数Guava cache 采用了非加密的单向散列函数Murmur3.MurmurHash 由Austin Appleby设计，因其高性能和良好的分布特性而广泛应用。MurmurHash有多个版本，如MurmurHash2、MurmurHash3等。 根据最开始对bloom filter 的定义，它需要多个哈希函数对数据进行哈希映射， 但Guava Cache bloom filter 实现中其实没有使用多个不同的哈希函数，而是采用了一种叫做“双哈希技术”的方法。 “双哈希技术”的基本思想是利用两个哈希函数h1(x)和h2(x)生成任意数量的哈希值，对于第i个哈希位置，使用h1(x) + i*h2(x)的方式来生成。这种方法只需要两次哈希操作，就可以模拟出多个哈希函数的效果，且生成的哈希序列具有很好的均匀分布性，既保证了布隆过滤器的效率，又避免了寻找多个好的哈希函数的复杂性，是一种在实际应用中非常实用的解决方案。 效率和复杂性具体指 性能和效率：使用单个哈希函数后通过算法变换生成多个哈希值，可以大大减少计算的复杂度和时间。多个独立的哈希函数意味着每个元素都需要被多次独立哈希，这会增加计算成本和时间。通过使用单个哈希函数并通过数学方法派生出多个伪随机的哈希值，可以在保持布隆过滤器错误率不变的前提下，显著提高效率。 简化实现：多个不同的哈希函数难以选取，而且还需保证它们相互之间的独立性和分布的均匀性，这在实践中是非常挑战性的。 3.3 mightContains和put 处理过程保持一致 3.4 guava cache 误报率-位数组长度固定在使用Guava的布隆过滤器时，预先估计将要插入的数据量非常重要。布隆过滤器在创建时会根据这个预估的数据量和指定的误判率来决定位数组的大小和使用的哈希函数数量。这些参数共同决定了布隆过滤器的性能和准确性。 如果实际插入的元素数量超过了最初的预估，过滤器的实际误判率会高于预期的误判率。这是因为当位数组变得过于饱和时，不同元素的哈希值更有可能映射到已经被设置为1的位上，从而增加了误判的几率。 Guava的文档明确指出了这一点，强调在创建布隆过滤器时应该准确预估元素数量，并考虑到这一点在其API设计中。BloomFilter.create()方法允许开发者在创建过滤器时指定预期插入的元素数量和可接受的误判率。 https://guava.dev/releases/20.0/api/docs/com/google/common/hash/BloomFilter.html 为了保证布隆过滤器的效果，应该根据实际使用场景仔细估算元素数量。如果预计数据量存在不确定性，建议预估一个上限，或者在实际元素数量超过预估时重新创建一个新的布隆过滤器。这当然会带来额外的成本，因此在设计初期做出准确估计非常关键。 总结来说，正确估计将要处理的数据量对于使用Guava布隆过滤器来说是非常重要的。如果实际数据量超过了预估，将会导致高于预期的误判率，可能影响到应用的准确性和可靠性。 4. 分布式 Redis bloom filter1BF.RESERVE &#123;key&#125; &#123;error_rate&#125; &#123;capacity&#125; [EXPANSION expansion] [NONSCALING] 4.1 参数解释4.1.1 EXPANSION expansionBF.RESERVE命令是RedisBloom模块中用来创建一个新的布隆过滤器的命令。这个命令允许用户预先为布隆过滤器指定参数，以便在插入元素之前就确定其大小和其他重要的行为特性。以下是BF.RESERVE命令各个参数的含义： &#123;key&#125;：这是将要创建的布隆过滤器的名称或键值。在Redis中，每个数据结构都通过一个唯一的键来标识和访问。 &#123;error_rate&#125;：预期的误报率。这是一个0到1之间的浮点数，表示允许的误判概率的上限。误报率越低，布隆过滤器所需的空间就越大。 &#123;capacity&#125;：布隆过滤器预期要存储的元素的数量。这个数值用于在保持误报率不变的情况下，预先计算布隆过滤器所需的最小大小。 [EXPANSION expansion]（可选）：这个可选参数用于指定当布隆过滤器的容量不足以容纳更多元素时，自动扩展的行为。expansion是一个大于1的整数，表示每次扩展增加的比例或容量。如果未指定，布隆过滤器可能会使用默认的扩展策略。 [NONSCALING]（可选）：这个可选标志用来指示创建的布隆过滤器不应自动扩展。这意味着一旦达到其容量上限，就不会尝试扩大过滤器以容纳更多的元素。这通常用于那些对空间使用有严格限制的应用场景。 作用：这个参数用于设置布隆过滤器在达到容量限制并需要扩展时，新创建的布隆过滤器层的大小。expansion的值决定了新层的容量是前一层容量的多少倍。这是一种自动扩展布隆过滤器容量的机制，以适应不断增长的元素数量，同时控制误报率。 场景：适用于那些元素数量不确定或可能会超出初始设定容量的场合。通过适当设置expansion参数，可以在维持误报率的同时动态增加布隆过滤器的容量。 举例：如果设置[EXPANSION 2]，那么每次扩展时，新的布隆过滤器层的容量将是前一层的两倍。 4.1.2 NONSCALING 作用：指定创建的布隆过滤器为非扩展型（Non-scaling）。即，一旦创建，布隆过滤器的容量固定，不会根据元素的增加而自动增加新的层。这意味着所有元素都将被添加到这个固定大小的布隆过滤器中，不管其容量是否已满。 场景：适用于元素数量预先已知且不会超出初始设定容量的场合。这种方式可以避免因为扩展而可能带来的额外内存使用，但要求用户必须更准确地预估所需的容量和误报率。 注意：当使用[NONSCALING]参数时，[EXPANSION expansion]参数将无效，因为非扩展型的布隆过滤器不会进行任何扩展操作。 4.2 可拓展特性是如何实现redis 可扩展布隆过滤(Scalable Bloom Filters)可以理解成是由多个位数组/子过滤器（布隆过滤器实例）链接在一起形成的链表(SBChain)。 每个子过滤器都有其自己的容量和误报率设置。当前的子过滤器达到容量限制时，就会动态地添加一个新的子过滤器。 这种方法的关键优势是，它可以在不断增加元素的情况下，动态地扩展总容量，同时控制整体误报率。 然而，这种动态扩展的能力也意味着查询操作可能需要遍历链表中的多个布隆过滤器实例，这可能会对性能产生一定影响。 redis bloom filter 的整体上的基本逻辑，比如位数组的大小、选择的哈希函数、哈希函数的数量、多个哈希函数的模拟与Guava cache bloom filter基本保持一致， 接下来只重点分析其可拓展性是如何实现的 4.2.1 bloom 结构体123456789101112131415bloom.hstruct bloom &#123; uint32_t hashes; uint8_t force64; uint8_t n2; uint64_t entries; double error; double bpe; unsigned char *bf; uint64_t bytes; uint64_t bits; &#125;; 这个struct bloom定义了一个布隆过滤器的基本数据结构，用于在RedisBloom模块中表示一个布隆过滤器实例。下面是对各个成员变量的详细解释： uint32_t hashes;：这表示布隆过滤器使用的哈希函数的数量。在布隆过滤器中，元素的存在是通过多个哈希函数映射到位数组的不同位置来表示的。因此，哈希函数的数量直接影响布隆过滤器的误判率和效率。 uint8_t force64;：这是一个标志位，用于指示是否强制使用64位哈希函数。在某些情况下，为了保证在不同平台上的一致性和性能，可能需要强制使用64位哈希函数。 uint8_t n2;：这个成员可能用于表示与位数组大小相关的一个参数，具体含义取决于实现细节。在一些布隆过滤器的实现中，这个参数可能与位数组大小为2的幂次方有关。 uint64_t entries;：这表示预期存储在布隆过滤器中的元素数量。这个数值对于计算位数组的大小和哈希函数数量非常重要。 double error;：这是预期的误判率（false positive rate），是设计布隆过滤器时的一个关键参数。误判率越低，所需的位数组大小和哈希函数数量就越多。 double bpe;：这表示每个元素平均占用的位数（Bits Per Entry）。这个值是根据预期的误判率和元素数量计算得出的，用于确定位数组的大小。 unsigned char *bf;：这是一个指向位数组的指针。位数组是布隆过滤器的核心，用于存储元素的哈希值映射。unsigned char类型被用来表示位数组，每个字节包含8位。 uint64_t bytes;：这表示位数组占用的字节数。由于位数组是以字节为单位进行分配的，因此这个数值表示整个位数组的大小。 uint64_t bits;：这表示位数组中的位数。这个数值是根据entries、error和bpe计算得出的，决定了布隆过滤器可以有效存储的元素数量和误判率。 4.2.2 SBLink结构体123456sb.h/** Single link inside a scalable bloom filter */ typedef struct SBLink &#123; struct bloom inner; //&lt; Inner structure size_t size; // &lt; Number of items in the link &#125; SBLink; SBLink代表了可扩展布隆过滤器中的单个链接，即单个布隆过滤器实例。 struct bloom inner;：这是一个嵌套的结构体，表示单个布隆过滤器的内部结构。这个inner结构体可能包含了实现布隆过滤器所需的所有数据，如位数组、哈希函数数量等。 size_t size;：表示当前链接（即单个布隆过滤器实例）中的元素数量。这是为了快速访问单个过滤器内元素的数量，而无需遍历整个位数组。 4.2.3 SBChain结构体123456789sb.h /** A chain of one or more bloom filters */ typedef struct SBChain &#123; SBLink *filters; //&lt; Current filter size_t size; //&lt; Total number of items in all filters size_t nfilters; //&lt; Number of links in chain unsigned options; //&lt; Options passed directly to bloom_init unsigned growth; &#125; SBChain; SBChain代表了一系列（一个或多个）SBLink结构体的链表，构成了一个可扩展的布隆过滤器。 SBLink *filters;：这是一个指向SBLink数组的指针，表示当前所有的过滤器链。每个SBLink代表链中的一个布隆过滤器实例。 size_t size;：表示所有过滤器中元素的总数量。这个数字是所有单个SBLink中size成员的总和。 size_t nfilters;：表示链中SBLink实例的数量，即当前有多少个布隆过滤器被链接在一起。 unsigned options;：这是传递给每个布隆过滤器初始化函数bloom_init的选项。这些选项可能控制如布隆过滤器的误报率、是否自动扩展等行为。 unsigned growth;：这个成员变量控制链的增长行为。它可能指定当当前的布隆过滤器填满时，如何增加新的SBLink实例，例如，增加的大小或比例等。 4.3 可扩展bloom filter的工作流程 初始化：当创建一个新的可扩展布隆过滤器时，会指定初始容量、误报率等参数。基于这些参数，创建第一个子过滤器。 添加元素：向布隆过滤器添加元素时，会从当前子过滤器开始尝试添加。如果当前子过滤器已满（即达到了其容量限制），则创建一个新的子过滤器，并在新的子过滤器中添加元素。每个新添加的子过滤器都可以根据配置的规则调整大小和误报率，以适应不断增加的元素。 检查元素：检查一个元素是否存在时，需要查询所有的子过滤器。如果任何子过滤器表示元素可能存在（即对应的位都为1），则认为元素可能存在于布隆过滤器中。虽然可扩展布隆过滤器可以动态增加容量，但查询操作的成本随之增加，因为可能需要检查多个布隆过滤器实例。 参数调整：随着子过滤器的增加，每个新的子过滤器通常会有更大的容量。这是通过调整如比特数、哈希函数数量等参数来实现的。这种方法旨在平衡误报率和内存使用，即使在不断添加元素的情况下也能维持相对稳定的误报率。 5. 可删除 bloom filter5.1 哪些场景使用布隆过滤器时需要删除以上， guava 和 redis 的bloom filter 都没有实现删除功能，不能删除的原因已经解释过，元素的存在是通过多个位的“1”状态来表示的，而将这些位重置为“0”可能会错误地影响其他元素的存在检测。 但是在某些场景还是需要删除，比如，查看一张优惠券是否已被使用？创建一个包含所有存在但还未被使用优惠券的filter。每次校验时 如果否，则优惠券不存在。 如果是，则优惠券有效。检查主数据库。如果有效，则使用后从 Cuckoo 过滤器中删除。 5.2 实现删除布隆过滤器的思路5.2.1 计数型布隆过滤器（Counting Bloom Filter）这是最直接的方法之一，它通过为每个位使用一个计数器而不是简单的布尔标记来实现。当插入一个元素时，它经过多个哈希函数映射到多个计数器上，并将这些计数器的值增加。相应地，删除一个元素时，这些计数器的值会被减少。如果任何计数器的值达到零，则表示没有任何元素映射到这个位上。这种方法的缺点是需要更多的空间来存储计数器。 5.2.2 双布隆过滤器这种方法涉及到使用两个独立的布隆过滤器：一个用于添加操作，另一个用于删除操作。当添加一个元素时，它被添加到第一个布隆过滤器中；当删除一个元素时，该元素被添加到第二个布隆过滤器中。检查元素是否存在时，如果它在第一个布隆过滤器中并且不在第二个布隆过滤器中，则认为该元素存在。这种方法的问题是误报率会增加，因为删除过滤器中的元素也可能错误地阻止对实际存在于集合中的元素的正确判断。 5.2.3 d-left 计数哈希d-left计数哈希是一种高效的数据结构，它将元素映射到固定数量的桶中，并在每个桶内维护一个计数器。这种方法可以实现快速的插入、查询和删除操作，并且相比于计数型布隆过滤器，它可以更有效地利用空间。不过，实现起来比较复杂，且当桶填满时性能会下降。 5.2.4 布谷鸟过滤器（Cuckoo Filter）布谷鸟过滤器是另一种支持删除操作的布隆过滤器变种，它基于布谷鸟哈希和部分键存储。每个元素通过哈希函数映射到一个或多个位置，并存储其“指纹”。插入、查询和删除操作都基于这些指纹。布谷鸟过滤器相比计数型布隆过滤器在空间效率上有所提高，且支持删除操作，但在极端情况下可能需要重建过滤器。 总体上可以看出可删除bloom filter 的实现都是需要额外的空间去存储额外的信息， 那么其实现方式的好坏的评判标准就是 额外空间的大小、性能 以及对误报率的影响。 以下是一张表格，总结了几种支持删除操作的布隆过滤器变体的优点和缺点： 过滤器类型 优点 缺点 计数型布隆过滤器 - 直接支持删除操作- 实现相对简单 - 更多空间需求- 计数器溢出问题 双布隆过滤器 - 实现简单- 通过额外布隆过滤器跟踪删除操作 - 增加空间需求- 误判率增加 布谷鸟过滤器 - 高效的插入、删除和查询- 空间效率高 - 实现复杂- 负载因子高时性能可能下降 d-left计数哈希过滤器 - 高空间效率- 性能优于传统计数型布隆过滤器 - 实现复杂，需要精心设计 如果应用对空间效率要求不是特别高，且需要频繁进行删除操作，计数型布隆过滤器是一个简单有效的选择。 对于需要最小化误报率而且对空间有一定要求的应用，布谷鸟过滤器提供了一个较好的平衡点。 在需要极致空间效率且能够接受实现复杂度的高性能应用场景中，d-left 计数哈希过滤器可能是最佳选择。 关于空间的使用，有如下比对效果 redis 实现了cuckoo 变体bloom filter， 下面来讲一下 cuckoo filter 的原理 6. Cuckoo FilterCuckoo Filter 论文 the basic unit of the cuckoo hash tables used for our cuckoo filters is called an entry. Each entry stores one fingerprint. The hash table consists of an array of buckets, where a bucket can have multiple entries. 在Cuckoo Filter 中，最基本的存储单元是entry, 每个单元存储一个 fingerprint。cuckoo hashing 哈希表由一组桶（buckets）组成，每个桶可以包含多个条目（entries）。 Cuckoo Filter的关键特性 双哈希函数：对于任何一个给定的键，Cuckoo Hashing使用两个独立的哈希函数 h1 和 h2 来计算两个候选桶的位置。这两个位置是键可能被存储的地方。 指纹存储：与传统的哈希表不同，Cuckoo Hashing不存储完整的键，而是存储键的指纹。这允许在不牺牲太多空间效率的情况下进行高效的查找和删除操作。 动态插入：当插入一个新键时，如果候选桶中没有足够的空间，Cuckoo Hashing会通过一系列置换操作来为新键腾出空间。这涉及到将现有的指纹移动到它们的替代位置，从而为新键腾出空间。已占用位置的元素会被移动到其它哈希函数确定的位置，可能导致一个连锁的重新放置过程。这个算法的名字来源于布谷鸟，因为布谷鸟会将自己的蛋放入其他鸟类的巢中，迫使其他鸟类的蛋被移位或丢弃。 查找操作：给定一个键，Cuckoo Hashing通过检查两个候选桶中的指纹来确定键是否存在于表中。如果任一桶中存在匹配的指纹，则认为键存在于表中。 删除操作：删除操作相对简单，Cuckoo Hashing检查两个候选桶，如果找到匹配的指纹，则移除该指纹。这种删除方法不会影响其他键的存储位置。 高空间效率：Cuckoo Hashing通过存储指纹而不是完整的键来优化空间使用，同时保持较高的表占用率，从而实现高空间效率。 6.1 fingerprint“fingerprint”是存储在Cuckoo Filter中的数据。，一个哈希函数处理数据后得到的哈希串。 6.2 Partial-Key Cuckoo HashingA cuckoo filter is a compact variant of a cuckoo hash table that stores only fingerprints-a bit string derived from the item using a hash function。 在cuckoo filter 中，哈希表中存储的数据发生了变化，由原始数据变成了fingerprint。注意这里的（basic/standard） cuckoo hash tables指的是存储原始数据的做法。 partial-key cuckoo hashing 是一种仅使用指纹，而不需要原始数据就可以在置换操作中来确定元素存储位置的哈希技术。由于仅存储fingerprint 比存储原始数据所占内存空间小，所以 Partial-Key Cuckoo Hashing为优化Cuckoo Filter的空间效率和操作性能而设计。 如上代码所示，Partial-Key Cuckoo Hashing使用两个哈希函数 h1 和 h2 来计算两个候选桶位置。第一个哈希函数 h1 直接作用于元素的指纹，而第二个哈希函数 h2 则是 h1 与指纹的哈希值的异或（XOR）结果。这种XOR的处理结果 可以根据其中任意一个已知的候选桶位置（i）计算出另外一个候选桶位置（j）j = i XOR fingerprint 6.3 Insert cuckoo 哈希的插入过程： 计算元素的指纹。 确定两个候选桶位置 i1 和 i2。 如果 i1 或 i2 有空闲条目，则将指纹插入到该条目中。 如果两个桶都满，则选择一个桶，随机选择一个条目并将其指纹与新元素的指纹交换。 Partial-Key Cuckoo Hashing ，更新候选桶位置 i 为 i XOR 指纹的哈希值。 如果找到空闲条目，则插入指纹；否则继续置换过程，直到找到空闲条目或达到最大置换次数。 6.4 Lookup 6.5 Delete 为什么cuckoo filter 可以删除元素但是又不影响其他元素的判断， 其实就是每个entry 只存储了一个元素的信息，删除后自然不会影响其他元素的判断。 6.6 空间优化Cuckoo Filter进行空间优化（SPACE OPTIMIZATIONS）的方法主要涉及对哈希表参数的选择和配置，以及对桶（buckets）的编码策略。以下是论文中提到的一些关键的空间优化策略： 选择合适的桶大小（Bucket Size）： 桶大小（b）对Cuckoo Filter的空间效率有显著影响。较大的桶可以提高哈希表的占用率（α），但同时也需要更长的指纹来维持相同的误报率。 论文中通过实验确定了对于不同的目标误报率（ϵ），最优的桶大小是不同的。例如，当误报率大于0.002时，每个桶有2个条目可能比4个条目更有效；而当误报率降低到0.00001至0.002时，每个桶有4个条目可以最小化空间使用。 半排序桶编码（Semi-Sorting Buckets）： 对于每个桶中的指纹进行排序，然后使用一个预先计算好的表来编码这些排序后的指纹序列。由于桶内指纹的顺序不影响查询结果，这种方法可以通过索引来节省空间。 例如，如果每个桶有4个指纹，每个指纹是4比特长，那么未压缩的桶将占用16比特。通过排序和编码，可以使用一个12比特的索引来代替原来的16比特桶，因为可以预先计算出所有可能的桶值（例如，3876种），并将每个桶表示为一个索引，从而节省1比特每个指纹。 平衡桶的负载（Balancing Bucket Loads）： 通过合理配置哈希函数和桶大小，可以减少哈希表中的冲突和空桶，从而提高空间利用率。 论文中提到，通过适当的配置，Cuckoo Filter可以以高概率达到95%的表空间占用率。 指纹长度的优化： 指纹长度（f）与桶大小和目标误报率有关。通过调整指纹长度，可以在保持目标误报率的同时，优化空间使用。 论文中的分析表明，对于实际应用中的集合大小，较短的指纹（例如6比特或更长）通常足以确保哈希表的高利用率。 通过这些空间优化策略，Cuckoo Filter能够在保持高效动态操作的同时，实现紧凑的数据存储。这些优化使得Cuckoo Filter在很多实际应用中比传统的Bloom Filter和Counting Bloom Filter更加空间高效 6.7 Redis cuckoo filterredis 实现了 cuckoo filter ，基本实现逻辑和论文中表现一致，有兴趣大家可以自己去看一下 7. 自己如何实现一个布隆过滤器基于以上对3种bloom filter的分析，可以总结出自己实现bloom filter时需要考虑的因素本项目代码可点击这里查看 7.1 位数组的实现首先参考BitSet。BitSet类是Java标准库中提供的一个用于处理位数组的类，基本可以认为是bitmap 在Java 的中的实现，其原理是是long[] 数组+ 位操作。在自己实现布隆过滤器时，可以直接使用BitSet ， 也可以像guava cache 一样，自己用long[] + 位操作自己封装一个bitarray，而不是直接使用的BitSet。 7.2 位数组的大小在简单的自己实现的版本中，可以直接指定bitarray 大小。 但在实际线上生产环境中可用的bloom filter 实现，一般都是根据预期插入的数据量 和 可接受的误报率两个数字通过 一个数学公式算出的，而不是直接用预期插入的数据量。 同时我们在线上生产环境使用布隆过滤器时，根据业务特性和流量去估算预期插入的数据量 和衡量 可接受的误报率 也是非常重要的步骤。 如果估算数据量比实际值大很多，就会浪费内存空间。如果估算数据量比实际值小很多，那么误报率很可能就无法控制在可接受的范围内。 guava cache bloom filter 位数组大小一旦确定时无法修改的，所以实际数据量如果过大，那么误报率肯定会上升 redis bloom filter 位数组大小可以scale, 但是判断元素是否存在的这个步骤性能会受到影响 7.3 用哪个哈希函数这个哈希函数在密码学中叫做单向散列函数。单向散列函数有两类加密与非加密散列，其主要区别如下。 7.3.1 加密散列函数设计用于加密应用，强调安全性。它们需要具备一定的性质，如抗碰撞（两个不同的输入不应该产生同一个输出）、隐藏性（无法从输出推断任何信息关于输入）和抗篡改（对输入的微小变化会在输出中产生不可预测的、大的变化）。 SHA家族（SHA-1、SHA-256、SHA-512等）：安全哈希算法（Secure Hash Algorithm）家族，广泛用于加密、数据完整性校验和数字签名等安全相关的应用。 MD5：消息摘要算法5（Message Digest Algorithm 5），尽管因为安全性问题不再推荐用于加密安全领域，但在一些非安全性要求的场合仍然可以见到其身影。 RIPEMD：一系列的加密哈希函数，包括RIPEMD-160、RIPEMD-256和RIPEMD-320，其中RIPEMD-160设计用于替代MD5和SHA-1。-7.3.2 非加密散列函数设计重点是高效率和均匀分布的输出，以支持快速数据检索、数据分布平衡等，而不是安全性。在某些情况下，允许存在碰撞，但碰撞的概率要尽可能低。 常见的非加密单向散列函数： MurmurHash：由Austin Appleby设计，因其高性能和良好的分布特性而广泛应用。MurmurHash有多个版本，如MurmurHash2、MurmurHash3等。 CityHash：由Google开发，专为哈希字符串数据设计，适用于构建哈希表等数据结构。后续Google又推出了FarmHash，作为CityHash的改进版，提供更好的性能和更广的适用范围。 xxHash：是一种非常快的哈希算法，提供了极高的数据处理速度，同时保持了良好的散列分布特性，适用于需要快速散列大量数据的场景。 Jenkins哈希函数（如一致性哈希）：Bob Jenkins所设计的一系列哈希函数，包括lookup3、SpookyHash等，它们广泛用于软件开发中，特别是在需要快速且分布均匀的哈希算法的场合。 FNV（Fowler-Noll-Vo）：是一系列设计简单、性能良好的哈希函数，特别适合于散列单个文本字符串。FNV-1和FNV-1a是两个最著名的变种。 在以上分析原理分析中，guava cache和Redis 都是用了MurmurHash如果我们自己也想要用MurmurHash，目前Java并没有提供实现，可以引入guava cache 包使用MurmurHash。 7.4 用多少个哈希函数前面说过用多个哈希函数可以减少误报率，那么到底要用多少个哈希函数呢， 这也是可以通过 预期插入的数据量+ 可接受的误报率 通过固定的数学公式计算得出。同时多个哈希结果可以通过像Guava cache一样，用双哈希技术模拟得到。","categories":[],"tags":[{"name":"Programming","slug":"Programming","permalink":"http://example.com/tags/Programming/"}]},{"title":"Spring 集成 Mybatis","slug":"Spring-集成-Mybatis","date":"2023-08-07T11:25:15.000Z","updated":"2024-09-05T11:40:37.782Z","comments":true,"path":"b4967540/","permalink":"http://example.com/b4967540/","excerpt":"","text":"1.单独使用MyBatis在了解Spring 继承Mybatis 之前，先来看下如何单独使用MyBatis 数据表结构12345678910CREATE TABLE message ( id bigint unsigned NOT NULL AUTO_INCREMENT, message_key VARCHAR(255) COMMENT &#x27;消息唯一键，用于做回查的标识&#x27;, message text COMMENT &#x27;消息内容&#x27;, message_status INT DEFAULT 1 COMMENT &#x27;消息状态 1-prepare 2-commit 3-rollback 4-unknown&#x27;, create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (id), UNIQUE INDEX idx_messageKey(message_key)) ENGINE=InnoDB; mybatis-config.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!-- 配置全局设置 --&gt; &lt;settings&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;false&quot;/&gt; &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;PARTIAL&quot;/&gt; &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt; &lt;!-- 配置别名 --&gt; &lt;typeAliases&gt; &lt;typeAlias alias=&quot;Message&quot; type=&quot;com.example.codingInAction.model.Message&quot;/&gt; &lt;/typeAliases&gt; &lt;!-- 配置环境 --&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;!-- 配置事务管理器 --&gt; &lt;transactionManager type=&quot;jdbc&quot;/&gt; &lt;!-- 配置数据源 --&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/codingInAction&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;24048@Ms&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 对应数据库操作接口的SQL映射 --&gt; &lt;mappers&gt; &lt;mapper resource=&quot;mappers/MessageMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; mappers/MessageMapper.xml123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.example.codingInAction.mapper.MessageMapper&quot;&gt; &lt;!-- 插入操作 插入数据后获取自动生成的主键 --&gt; &lt;insert id=&quot;insertMessage&quot; parameterType=&quot;com.example.codingInAction.model.Message&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; INSERT INTO message ( message, message_key, message_status ) VALUES ( #&#123;message&#125;, #&#123;messageKey&#125;, #&#123;messageStatus&#125; ) &lt;/insert&gt; &lt;select id=&quot;findByMessageKey&quot; resultType=&quot;com.example.codingInAction.model.Message&quot;&gt; SELECT id, message AS message, message_key AS &quot;messageKey&quot;, message_status AS &quot;messageStatus&quot;, create_time AS &quot;createTime&quot;, update_time AS &quot;updateTime&quot; FROM message WHERE message_key = #&#123;messageKey&#125; &lt;/select&gt;&lt;/mapper&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class Message &#123; private int id; private String message; private String messageKey; private int messageStatus; // getter and setter &#125;public interface MessageMapper &#123; int insertMessage(Message message); Message findByMessageKey(Map&lt;String, Object&gt; params);&#125;public class MyBatisUtil &#123; private final static SqlSessionFactory sqlSessionFactory; static &#123; String resource = &quot;mybatis-config.xml&quot;; Reader reader; try &#123; reader = Resources.getResourceAsReader(resource); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; sqlSessionFactory = new SqlSessionFactoryBuilder().build(reader); &#125; public static SqlSessionFactory getSqlSessionFactory() &#123; return sqlSessionFactory; &#125;&#125;class MessageMapperTest &#123; static SqlSessionFactory sqlSessionFactory; static &#123; sqlSessionFactory = MyBatisUtil.getSqlSessionFactory(); &#125; @Test void messageTest1() &#123; Message m = new Message(); m.setMessage(&quot;Test Message&quot;); m.setMessageKey(&quot;test key&quot;); m.setMessageStatus(1); SqlSession sqlSession = sqlSessionFactory.openSession(); try &#123; MessageMapper messageMapper = sqlSession.getMapper(MessageMapper.class); messageMapper.insertMessage(m); Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(&quot;messageKey&quot;, &quot;test key&quot;); Message result = messageMapper.findByMessageKey(params); assertEquals(&quot;findByMessageKey&quot;, &quot;test key&quot;, result.getMessageKey()); sqlSession.commit(); &#125; finally &#123; sqlSession.close(); &#125; &#125;&#125; 1.1 SqlSessionFactorySqlSessionFactory是MyBatis的核心， 其作用如下 创建SqlSession对象：SqlSessionFactory通过其方法创建SqlSession实例。SqlSession用于执行数据库操作，如查询、插入、更新和删除等。每次需要进行数据库操作时，都会从SqlSessionFactory中获取一个新的SqlSession对象。 管理SqlSession生命周期：SqlSessionFactory不仅负责创建SqlSession，还负责管理其生命周期，包括资源的分配和释放。SqlSession对象需要在操作完成后关闭，以释放数据库连接等资源。 加载和解析配置：SqlSessionFactory在初始化时会加载和解析MyBatis的配置文件（如mybatis-config.xml）和Mapper XML文件。这些配置文件定义了数据库连接、事务管理、Mapper映射等信息。 缓存机制：SqlSessionFactory配置中可以包含缓存设置，如一级缓存和二级缓存。缓存机制可以提高数据库访问的性能，减少重复查询的开销。 1.2 SqlSession1SqlSession sqlSession = sqlSessionFactory.openSession(); SqlSession 是 MyBatis 与数据库交互的核心。通过 SqlSession，开发者可以执行 SQL 语句、获取映射器（Mapper）、管理事务等操作。可以将 SqlSession 看作是 MyBatis 的会话，类似于 JDBC 中的 Connection 对象。 1.3 mapper 动态代理1MessageMapper messageMapper = sqlSession.getMapper(MessageMapper.class) 以下代码获取到的是MessageMapper的动态代理对象 12345678910111213141516171819202122232425262728293031323334353637 public class DefaultSqlSession implements SqlSession &#123; @Override public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return configuration.getMapper(type, this); &#125; &#125;public class Configuration &#123; public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; return mapperRegistry.getMapper(type, sqlSession); &#125; &#125;public class MapperRegistry &#123; public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e); &#125; &#125; &#125;public class MapperProxyFactory&lt;T&gt; &#123; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125; protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; &#125; Configuration 对象对应的就是mybatis-config.xml 这个配置文件，层层深入源码最后发现是熟悉的JDK 动态代理Proxy.newProxyInstance， 说明最后生成的mapper 对象是一个JDK 动态代理对象。 1.4 SQL执行再看MapperProxyFactory.newInstance 源码， 1234567891011public class MapperProxyFactory&lt;T&gt; &#123; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &#125; protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); &#125; &#125;public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123;&#125; Proxy.newProxyInstance中参数InvocationHandler 传入的是MapperProxy, 看一下MapperProxy实现InvocationHandler 的具体逻辑 1234567891011121314public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else &#123; return cachedInvoker(method).invoke(proxy, method, args, sqlSession); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; &#125;&#125; 2. Spring集成MyBatis在MyBatis与Spring集成时，可以将MyBatis的配置直接放在Spring的配置文件（如applicationContext.xml）中，从而简化配置管理。通过这种方式，可以在一个配置文件中集中管理数据源、事务管理、MyBatis的SqlSessionFactory和Mapper扫描等配置。 applicationContext.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot; &lt;!-- 配置数据源 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/codingInAction&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;24048@Ms&quot;/&gt; &lt;/bean&gt; &lt;!-- MyBatis SqlSessionFactory配置 --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath*:/mappers/*.xml&quot;/&gt; &lt;/bean&gt; &lt;!-- MyBatis MapperScannerConfigurer配置 --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.example.codingInAction.mapper&quot;/&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;messageMapper&quot; class=&quot;org.mybatis.spring.mapper.MapperFactoryBean&quot;&gt; &lt;property name=&quot;mapperInterface&quot; value=&quot;com.example.codingInAction.mapper.MessageMapper&quot;&gt;&lt;/property&gt; &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; Spring整合MyBatis的优势主要在于使用上，我们来看看Spring中使用MyBatis的用法。 测试中我们看到，在Spring中使用MyBatis非常方便，用户甚至无法察觉自己正在使用MyBatis，而这一切相对于独立使用MyBatis时必须要做的各种冗余操作来说无非是大大简化了我们的工作量。 就是从Spring 容器中获取想要的mapper bean, 然后就可以执行对应的SQL 操作了123456789101112class MessageMapperTest &#123; @Test void messageTest2() &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); MessageMapper messageMapper = (MessageMapper) context.getBean(&quot;messageMapper&quot;); Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put(&quot;messageKey&quot;, &quot;test key&quot;); Message result = messageMapper.findByMessageKey(params); System.out.println(result.getMessage()); &#125; &#125; 2.1 SqlSessionFactoryBean从配置文件中可以看到， sqlSessionFactory 是通过SqlSessionFactoryBean配置的。 通过Spring配置SqlSessionFactoryBean，可以将SqlSessionFactory作为Spring的一个Bean进行管理。 12public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123;&#125; SqlSessionFactoryBean 实现了InitializingBean和FactoryBean两个接口 2.1.1 InitializingBean实现此接口的bean会在初始化时调用重写的InitializingBean.afterPropertiesSet方法来进行bean的逻辑初始化 获取SqlSessionFactoryBean实例,跳过getBean 的其他代码直接来到init 阶段， InitionlizingBean 相关的逻辑 2.1.2 FactoryBean在SqlSessionFactoryBean.getObject() 中就是把init 阶段实例化的SqlSessonFactory实例返回 2.2 MapperFactoryBean1MessageMapper messageMapper = (MessageMapper) context.getBean(&quot;messageMapper&quot;); 从配置文件中可以看到，messageMapper对应的MessageFactoryBean 也是一个FactoryBean, 重点看下getObject方法 12345public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; &#123;@Override public T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface); &#125;&#125; Spring中获取的名为messageMapper的bean，其实是与单独使用MyBatis完成了一样的功能，从源码上看，在bean的创建过程也是使用了MyBatis中的原生方法sqlSession.getMapper(MessageMapper.class)进行了再一次封装。和不集成直接使用MyBatis 获取对应mapper实例其实本质上是一样的逻辑，从getMapper 进去 是完全一样的JDK 动态代理逻辑1MessageMapper messageMapper = sqlSession.getMapper(MessageMapper.class); 2.2 MapperScannerConfigurer在Spring项目中，通过MapperScannerConfigurer类自动扫描所有的Mapper接口，并通过Spring的依赖注入机制直接使用这些接口，是一种简化并推荐的方式。这种方法不需要开发者手动实现Mapper接口的具体方法，也不需要手动管理SqlSession，从而大大简化了代码和配置。 1234567891011 &lt;!-- MyBatis MapperScannerConfigurer配置 --&gt;&lt;!-- &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;--&gt;&lt;!-- &lt;property name=&quot;basePackage&quot; value=&quot;com.example.codingInAction.mapper&quot;/&gt;--&gt;&lt;!-- &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt;--&gt;&lt;!-- &lt;/bean&gt;--&gt; &lt;bean id=&quot;messageMapper&quot; class=&quot;org.mybatis.spring.mapper.MapperFactoryBean&quot;&gt; &lt;property name=&quot;mapperInterface&quot; value=&quot;com.example.codingInAction.mapper.MessageMapper&quot;&gt;&lt;/property&gt; &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 3. Spring Boot集成MyBatis在Spring Boot项目中集成MyBatis通常使用mybatis-spring-boot-starter，这个由MyBatis 提供的Starter简化了配置和集成过程。使用Spring Boot集成MyBatis时，你不需要显式地配置SqlSessionFactoryBean，通过SpringBoot 的自动配置机制， 这些配置均可以自动完成。你只需要 添加依赖 在application.properties 中配置DataSource 即可 123456&lt;!-- MyBatis Spring Boot Starter --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.4&lt;/version&gt;&lt;/dependency&gt; 关于SpringBoot 自动配置机制的实现原理，可以点击Spring boot 自动配置实现原理阅读了解。 下面将忽略MybatisAutoConfiguration配置的加载和BeanDefinition 注册流程，直接进入实例化过程进行分析 3.1 MybatisAutoConfiguration的实例化org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration 在Spring boot 自动配置实现原理一文中，已经详细介绍过自动配置类的加载与BeanDefinition 注册过程， 在其中9.5 小节中讲了在ConfigurationClassPostProcessor中重写的BeanFactoryPostProcessor.postProcessBeanFactory中，实现了对@Configuration 注解动态代理类的生成。 这里讲以MybatisAutoConfiguration 的实例化为例详细讲解这一过程 来看下拦截逻辑。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class ConfigurationClassEnhancer &#123; private static final Callback[] CALLBACKS = new Callback[] &#123; new BeanMethodInterceptor(), new BeanFactoryAwareMethodInterceptor(), NoOp.INSTANCE &#125;; private static class BeanMethodInterceptor implements MethodInterceptor, ConditionalCallback &#123; @Override @Nullable public Object intercept(Object enhancedConfigInstance, Method beanMethod, Object[] beanMethodArgs, MethodProxy cglibMethodProxy) throws Throwable &#123; ConfigurableBeanFactory beanFactory = getBeanFactory(enhancedConfigInstance); String beanName = BeanAnnotationHelper.determineBeanNameFor(beanMethod); // Determine whether this bean is a scoped-proxy if (BeanAnnotationHelper.isScopedProxy(beanMethod)) &#123; String scopedBeanName = ScopedProxyCreator.getTargetBeanName(beanName); if (beanFactory.isCurrentlyInCreation(scopedBeanName)) &#123; beanName = scopedBeanName; &#125; &#125; if (factoryContainsBean(beanFactory, BeanFactory.FACTORY_BEAN_PREFIX + beanName) &amp;&amp; factoryContainsBean(beanFactory, beanName)) &#123; Object factoryBean = beanFactory.getBean(BeanFactory.FACTORY_BEAN_PREFIX + beanName); if (factoryBean instanceof ScopedProxyFactoryBean) &#123; // Scoped proxy factory beans are a special case and should not be further proxied &#125; else &#123; // It is a candidate FactoryBean - go ahead with enhancement return enhanceFactoryBean(factoryBean, beanMethod.getReturnType(), beanFactory, beanName); &#125; &#125; if (isCurrentlyInvokedFactoryMethod(beanMethod)) &#123; if (logger.isInfoEnabled() &amp;&amp; BeanFactoryPostProcessor.class.isAssignableFrom(beanMethod.getReturnType())) &#123; &#125; return cglibMethodProxy.invokeSuper(enhancedConfigInstance, beanMethodArgs); &#125; return resolveBeanReference(beanMethod, beanMethodArgs, beanFactory, beanName); &#125;&#125;最后生成的代理类重新设置给了BeanDefinition 的一个属性。 3.2 sqlSessionFactory 实例化3.2.1 instantiateUsingFactoryMethod在 Spring 中，有几种常见的 Bean 实例化方式： 使用构造函数实例化。 使用Supplier实例化。 使用工厂方法实例化。 针对sqlSessionFactory ，其实例化过程使用的是 instantiateUsingFactoryMethod工厂方法实例化 最后解析出， 使用instantiateUsingFactoryMethod实例化sqlSessionFactory 时， 用到的factoryBean 是 MybatisAutoConfiguration 的动态代理对象，用的方法是sqlSessionFactory 3.2.2 动态代理拦截这里来到经典的反射逻辑来调用实例对象上的方法，此时factoryBean是CGLIB 动态代理对象， 所以在调用方法时会先走在拦截逻辑上","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/tags/Mybatis/"}]},{"title":"SpringBoot 自动配置实现原理","slug":"Spring-boot-自动配置实现原理","date":"2023-08-01T11:14:25.000Z","updated":"2024-09-05T11:42:17.080Z","comments":true,"path":"4bd46d7d/","permalink":"http://example.com/4bd46d7d/","excerpt":"","text":"在传统的Spring应用中，开发者需要手动配置大量数据，这种配置通常包括数据源、事务管理、视图解析器等。这种手动配置方式在大型项目中显得特别繁琐且容易出错。 Spring Boot引入自动配置机制，只需要添加相关依赖，无需配置。这极大地简化了Spring应用的配置, 大幅减少了开发者的工作量,帮助开发者快速创建应用。 SpringBoot的自动配置是通过@EnableAutoConfiguration和META-INF/spring.factories文件实现的，而这些机制的底层依赖于ConfigurationClassPostProcessor来解析和注册自动配置类。 本文会先介绍一些重要概念，然后进入SpringApplication.run 源码逐一串联起这些重要概念，以此来探讨SpringBoot自动配置机制 的实现原理。 分析基于SpringBoot 2.3.4 1. @EnableAutoConfiguration是一个组合注解，@EnableAutoConfiguration是组合注解@SpringBootApplication 其中的一个注解， 其作用是启用自动配置机制 123456789@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;) public @interface SpringBootApplication &#123;&#125; Spring框架提供的各种名字为@Enable开头的Annotat​ion，比如@EnableSchedul​ing、@EnableCaching、@EnableMBeanExport等，@EnableAutoConf​igurat​ion的理念和“做事方式”其实一脉相承，简单概括一下就是，它们的工作方式都是借助@Import的支持，收集和注册特定场景相关的bean定义： @Enable Schedul​ing是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。 @Enable M Bean Export是通过@Import将JMX相关的bean定义加载到IoC容器。 @EnableAutoConf​igurat​ion 一样，也是借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器，仅此而已！ @EnableAutoConfiguration本身也是由多个注解组成123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 自动配置包扫描：@AutoConfigurationPackage注解标记了包路径，这意味着Spring Boot会自动扫描该包及其子包中的所有组件。 导入选择器：@Import(AutoConfigurationImportSelector.class)用于导入AutoConfigurationImportSelector类，后者负责选择并加载自动配置类。 1.1 AutoConfigurationImportSelectorAutoConfigurationImportSelector会根据各种条件注解（如@ConditionalOnClass、@ConditionalOnMissingBean等）来决定是否导入某个自动配置类。 借 助AutoConf​igurat​ionImportSelector, @EnableAutoConf​igurat​ion可以帮助SpringBoot应用将所有符合条件的@Conf​igurat​ion配置都加载到当前SpringBoot创建并使用的IoC容器 123456public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123; &#125; 各个Aware 类和Ordered接口， 在 Spring IOC 容器启动过程拓展点一文中已经都介绍过，有需要可以点击查看。DeferredImportSelector 比较陌生，下面来介绍一下 1.2 DeferredImportSelector123456789101112public interface DeferredImportSelector extends ImportSelector &#123;&#125;public interface ImportSelector &#123; String[] selectImports(AnnotationMetadata importingClassMetadata); @Nullable default Predicate&lt;String&gt; getExclusionFilter() &#123; return null; &#125;&#125; DeferredImportSelector扩展了ImportSelector接口。DeferredImportSelector的主要作用是延迟配置类的导入，确保在所有常规的@Configuration类和@Import注解处理之后再进行处理。这种延迟处理机制提供了更大的灵活性，特别是在复杂的自动配置场景中，能够根据先前的配置结果决定是否导入额外的配置类。 12345678910111213141516171819202122232425262728293031323334// 处理和决定哪些自动配置类应该被包含或排除在 Spring Boot 应用程序的自动配置过程中。该方法通过一系列步骤和检查，最终返回一个包含自动配置类和排除类的 `AutoConfigurationEntry` 实例。 protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; // 调用 `isEnabled` 方法检查自动配置是否启用 // 如果未启用，返回一个空的自动配置条目 `EMPTY_ENTRY` if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); // 调用 `getCandidateConfigurations` 方法获取所有候选的自动配置类。 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); // 调用 `removeDuplicates` 方法，去除候选配置类列表中的重复项。 configurations = removeDuplicates(configurations); // 调用 `getExclusions` 方法获取需要排除的自动配置类。 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); // 调用 `checkExcludedClasses` 方法，检查候选配置类列表中是否包含任何需要排除的类，并进行相应处理。 checkExcludedClasses(configurations, exclusions); // 从候选配置类列表中移除所有排除的类。 configurations.removeAll(exclusions); // 进一步过滤候选配置类列表，保留需要的配置类。 configurations = getConfigurationClassFilter().filter(configurations); // 触发自动配置导入事件 fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125;// SpringFactoriesLoader.loadFactoryNames加载文件其实在SpringApplication 阶段已经加载完成，所以这里会直接读取缓存里的数据，不会重复加载文件protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; getCandidateConfigurations 查找所有满足条件的自动配置类 2. META-INF/spring.factories 文件META-INF/spring.factories用于定义各种扩展点（如自动配置类、环境后处理器等）的实现类。 文件使用简单的键值对格式，每一行定义一个映射关系。键是接口或抽象类的完全限定名，值是实现类的完全限定名，多个实现类用逗号分隔。 反斜杠 \\ 在属性文件中用于将长行拆分为多行。这样做的目的是为了使文件更易于阅读和维护。在 spring.factories 文件中，这通常用于定义多行值。 SpringBoot自动配置实现的过程中，会查找类路径下所有的META-INF/spring.factories文件。 所有指的是包括应用本身及其所有依赖JAR包中的META-INF/spring.factories文件。 在SpringBoot项目实际启动过程中，查找到的META-INF/spring.factories文件包括以下4个 spring-boot-autoconfigure-2.3.4.RELEASE.jar META-INF/spring.factories spring-boot-2.3.4.RELEASE.jar META-INF/spring.factories spring-beans-5.2.9.RELEASE.jar META-INF/spring.factories mybatis-spring-boot-autoconfigure-2.1.4.jar META-INF/spring.factories META-INF/spring.factories文件的具体加载逻辑在SpringFactoriesLoader。loadSpringFactories方法中具体实现 3. SpringFactoriesLoaderSpringFactoriesLoader.loadFactoryNames用来加载获取所有META-INF/spring.factories中的配置信息， 其加载流程大致有以下步骤 获取资源路径：loadSpringFactories方法首先会获取类加载器，并查找类路径下所有名为META-INF/spring.factories的资源文件。 读取并解析文件：对每个找到的META-INF/spring.factories文件，使用PropertiesLoaderUtils.loadProperties方法将其加载为Properties对象。 处理文件内容：遍历Properties对象的每一个条目，将键（工厂类的名称）和值（实现类的全限定名列表）存入结果Map中。 返回结果：返回一个Map，其中键是工厂类的名称，值是实现类名称的列表。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package org.springframework.core.io.support;public final class SpringFactoriesLoader &#123; public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;; private static final Map&lt;ClassLoader, MultiValueMap&lt;String, String&gt;&gt; cache = new ConcurrentReferenceHashMap&lt;&gt;(); private SpringFactoriesLoader() &#123; &#125; public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList()); &#125; private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryTypeName = ((String) entry.getKey()).trim(); for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryTypeName, factoryImplementationName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); &#125; &#125;&#125; 针对META-INF/spring.factories的加载过程有2点需要注意 3.1 缓存机制 1private static final Map&lt;ClassLoader, MultiValueMap&lt;String, String&gt;&gt; cache = new ConcurrentReferenceHashMap&lt;&gt;(); 该缓存的作用是在同一个ClassLoader下，避免了对同一个spring.factories文件的重复加载，因为后面的代码有同样的流程。 所以该缓存的存在可以提高SpringBoot 项目的启动速度。 3.2 MultiValueMapcache 缓存中的value 是MultiValueMap。MultiValueMap 在实际开发中不太常用， 从debug信息中可以看到，就是同一个key 可以对应多个value 。其getOrDefault方法的执行逻辑可以描述如下： 检查键是否存在： 使用 containsKey 方法检查给定键是否存在于映射中。 返回值或默认值： 如果键存在，则返回与该键关联的值。 如果键不存在，则返回提供的默认值。3.3 条件过滤 经过loadSpringFactories 处理 META-INF/spring.factories文件所有的配置信息均已经存储在cache中。 回到loadFactoryNames方法中，通过MultiValueMap.getOrDefault获取指定类型 的配置信息。 1234public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList()); &#125; 4. 自动配置类-@ConfigurationSpring Boot的自动配置类通过一系列@Configuration类和条件注解来实现，并通过@EnableAutoConfiguration注解启用。 在 Spring IOC 容器启动过程拓展点 一文中提到过，在Spring IOC容器中，Bean的定义方式确实有三种，XML配置、注解配置和Java Config配置。 在实际业务开发中， Java Config 使用较少。 不过在SpringBoot 自动配置的实现过程中， Java config 有大量使用。 Java Config配置通过Java类和方法来定义和配置Bean，利用了Spring的@Configuration和@Bean注解。 @Configuration 类：Spring 会扫描所有带有 @Configuration 注解的类。 解析 @Bean 方法：ConfigurationClassPostProcessor 会解析这些类中的 @Bean 方法。 注册 BeanDefinition：对于每个 @Bean 方法，会被 ConfigurationClassPostProcessor 解析,Spring 会创建一个 BeanDefinition 对象，并将其注册到 BeanFactory 中。BeanDefinition 的名称默认是 @Bean 方法的方法名，除非在 @Bean 注解中显式指定了 name 属性。4.1 示例代码-MybatisLanguageDriverAutoConfiguration以在 mybatis-spring-boot-autoconfigure-2.1.4.jar META-INF/spring.factories 出现的MybatisLanguageDriverAutoConfiguration 为例看一下具体使用在自动配置类中，有我们熟悉的sqlSessionFactory 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109@Configuration@ConditionalOnClass(LanguageDriver.class)public class MybatisLanguageDriverAutoConfiguration &#123; private static final String CONFIGURATION_PROPERTY_PREFIX = &quot;mybatis.scripting-language-driver&quot;; /** * Configuration class for mybatis-freemarker 1.1.x or under. */ @Configuration @ConditionalOnClass(FreeMarkerLanguageDriver.class) @ConditionalOnMissingClass(&quot;org.mybatis.scripting.freemarker.FreeMarkerLanguageDriverConfig&quot;) public static class LegacyFreeMarkerConfiguration &#123; @Bean @ConditionalOnMissingBean FreeMarkerLanguageDriver freeMarkerLanguageDriver() &#123; return new FreeMarkerLanguageDriver(); &#125; &#125; /** * Configuration class for mybatis-freemarker 1.2.x or above. */ @Configuration @ConditionalOnClass(&#123; FreeMarkerLanguageDriver.class, FreeMarkerLanguageDriverConfig.class &#125;) public static class FreeMarkerConfiguration &#123; @Bean @ConditionalOnMissingBean FreeMarkerLanguageDriver freeMarkerLanguageDriver(FreeMarkerLanguageDriverConfig config) &#123; return new FreeMarkerLanguageDriver(config); &#125; @Bean @ConditionalOnMissingBean @ConfigurationProperties(CONFIGURATION_PROPERTY_PREFIX + &quot;.freemarker&quot;) public FreeMarkerLanguageDriverConfig freeMarkerLanguageDriverConfig() &#123; return FreeMarkerLanguageDriverConfig.newInstance(); &#125; &#125; /** * Configuration class for mybatis-velocity 2.0 or under. */ @Configuration @ConditionalOnClass(org.mybatis.scripting.velocity.Driver.class) @ConditionalOnMissingClass(&quot;org.mybatis.scripting.velocity.VelocityLanguageDriverConfig&quot;) @SuppressWarnings(&quot;deprecation&quot;) public static class LegacyVelocityConfiguration &#123; @Bean @ConditionalOnMissingBean org.mybatis.scripting.velocity.Driver velocityLanguageDriver() &#123; return new org.mybatis.scripting.velocity.Driver(); &#125; &#125; /** * Configuration class for mybatis-velocity 2.1.x or above. */ @Configuration @ConditionalOnClass(&#123; VelocityLanguageDriver.class, VelocityLanguageDriverConfig.class &#125;) public static class VelocityConfiguration &#123; @Bean @ConditionalOnMissingBean VelocityLanguageDriver velocityLanguageDriver(VelocityLanguageDriverConfig config) &#123; return new VelocityLanguageDriver(config); &#125; @Bean @ConditionalOnMissingBean @ConfigurationProperties(CONFIGURATION_PROPERTY_PREFIX + &quot;.velocity&quot;) public VelocityLanguageDriverConfig velocityLanguageDriverConfig() &#123; return VelocityLanguageDriverConfig.newInstance(); &#125; &#125; @Configuration @ConditionalOnClass(ThymeleafLanguageDriver.class) public static class ThymeleafConfiguration &#123; @Bean @ConditionalOnMissingBean ThymeleafLanguageDriver thymeleafLanguageDriver(ThymeleafLanguageDriverConfig config) &#123; return new ThymeleafLanguageDriver(config); &#125; @Bean @ConditionalOnMissingBean @ConfigurationProperties(CONFIGURATION_PROPERTY_PREFIX + &quot;.thymeleaf&quot;) public ThymeleafLanguageDriverConfig thymeleafLanguageDriverConfig() &#123; return ThymeleafLanguageDriverConfig.newInstance(); &#125; // This class provides to avoid the https://github.com/spring-projects/spring-boot/issues/21626 as workaround. @SuppressWarnings(&quot;unused&quot;) private static class MetadataThymeleafLanguageDriverConfig extends ThymeleafLanguageDriverConfig &#123; @ConfigurationProperties(CONFIGURATION_PROPERTY_PREFIX + &quot;.thymeleaf.dialect&quot;) @Override public DialectConfig getDialect() &#123; return super.getDialect(); &#125; @ConfigurationProperties(CONFIGURATION_PROPERTY_PREFIX + &quot;.thymeleaf.template-file&quot;) @Override public TemplateFileConfig getTemplateFile() &#123; return super.getTemplateFile(); &#125; &#125; &#125;&#125; 4.2 条件配置 and 条件注解自动配置类依赖于条件注解来确保只有在满足特定条件时才会进行配置。这些注解包括： @ConditionalOnClass：只有在类路径中存在指定的类时，才会启用该配置。 @ConditionalOnMissingBean：只有在Spring上下文中不存在指定的Bean时，才会创建该Bean。 @ConditionalOnProperty：只有在配置文件中存在指定属性并且值匹配时，才会启用该配置。 4.3 排除自动配置在某些情况下，开发者可能希望排除某些自动配置类。可以通过@SpringBootApplication注解的exclude属性来实现： 123456@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)public class MyApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MyApplication.class, args); &#125;&#125; 或者在配置文件中排除： 1spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration 4.4 自定义自动配置开发者可以创建自定义的自动配置类，以满足特定需求。自定义自动配置类需要使用@Configuration和条件注解，并将其打包到JAR文件中，以便在其他Spring Boot应用中使用。例如：12345678910@Configuration@ConditionalOnClass(MyCustomService.class)public class MyCustomAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public MyCustomService myCustomService() &#123; return new MyCustomServiceImpl(); &#125;&#125; 5. ConfigurationClassPostProcessor1234public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123;&#125; ConfigurationClassPostProcessor 的职责 主要有两个 解析@Configuration及其相关注解成BeanDefinition 将解析得到的 BeanDefinition 注册到 BeanFactory 中。 解析的注解包括以下内容 @Configuration 类：解析所有标记为 @Configuration 的类， 所有自动配置类均有@Configuration注解。 @ComponentScan 注解：处理 @ComponentScan 注解，扫描指定包路径下的组件（如 @Component, @Repository, @Service, @Controller 等注解标记的类）。 @Import 注解：处理 @Import 注解，导入其他配置类或处理 ImportSelector 和 ImportBeanDefinitionRegistrar。 @Bean 方法：解析 @Bean 方法，将其定义的 bean 注册为 BeanDefinition。 @PropertySource 注解：处理 @PropertySource 注解，加载属性源文件。 5.1 实现继承关系 5.1.1 BeanFactoryPostProcessor从实现继承图中可以看出， ConfigurationClassPostProcessor实现了BeanFactoryPostProcessor接口，BeanFactoryPostProcessor的作用时机是invokeBeanFactoryPostProcessors。 关于BeanFactoryPostProcessor， 更多可以阅读 Spring IOC 容器启动过程拓展点 5.1.2 BeanDefinitionRegistryPostProcessor关于BeanDefinitionRegistryPostProcessor, Spring IOC 容器启动过程拓展点已经介绍过,它继承了BeanFactoryPostProcessor ， 并增加了一个方法。12345public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException; &#125; 在ConfigurationClassPostProcessor中，postProcessBeanDefinitionRegistry方法会被调用，用于处理配置类和自动配置类。 5.2 internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalConfigurationAnnotationProcessor是Spring框架内部使用的一个特殊的Bean名称，用于标识和注册ConfigurationClassPostProcessor的实例。 这是Spring框架内部使用的一种机制，用于在Spring容器启动时处理@Configuration注解及相关配置。 12345678public abstract class AnnotationConfigUtils &#123; /** * The bean name of the internally managed Configuration annotation processor. */ public static final String CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME = &quot;org.springframework.context.annotation.internalConfigurationAnnotationProcessor&quot;;&#125; 在 Spring 容器启动过程中，ConfigurationClassPostProcessor 会进行以下步骤： 扫描 MybatisLanguageDriverAutoConfiguration 类：识别该类是一个配置类。 解析 @Bean 方法： 识别 defaultLanguageDriver 方法和 anotherLanguageDriver 方法上的 @Bean 注解。 创建 BeanDefinition： 为每个 @Bean 方法创建一个 BeanDefinition 对象。 注册 BeanDefinition： 使用 defaultLanguageDriver 作为 beanName 注册 defaultLanguageDriver 方法的 BeanDefinition。 使用 anotherLanguageDriver 作为 beanName 注册 anotherLanguageDriver 方法的 BeanDefinition。 最终，Spring 容器中会有两个 bean，它们的名称分别是 defaultLanguageDriver 和 anotherLanguageDriver，对应的 BeanDefinition 是通过解析 @Bean 方法得到的。 6. ApplicationContextInitializer 接口在 Spring Boot 中，ApplicationContextInitializer 是一个扩展点接口，主要用于在应用上下文ConfigurableApplicationContext 执行一在些refresh之前的额外配置。 1234public interface ApplicationContextInitializer&lt;C extends ConfigurableApplicationContext&gt; &#123; void initialize(C applicationContext); &#125; Spring Boot 提供了一些内置的 ApplicationContextInitializer 实现，它们在应用启动过程中起着重要的作用。 SharedMetadataReaderFactoryContextInitializer：用于共享 MetadataReaderFactory。 ConditionEvaluationReportLoggingListener：用于在条件评估报告时记录日志。 ConfigurationWarningsApplicationContextInitializer：用于在配置警告时初始化应用上下文。 在自动配置实现的过程中，ApplicationContextInitializer非常重要，其具体实现类SharedMetadataReaderFactoryContextInitializer与ConfigurationClassPostProcessor有密切关系。 6.1 注册方式可以通过多种方式注册 ApplicationContextInitializer，以下是几种常见的方法： 6.1.1 通过 Spring Boot 的 SpringApplication在 Spring Boot 应用中，可以在 SpringApplication 中注册 ApplicationContextInitializer： 1234567public class MyApplication &#123; public static void main(String[] args) &#123; SpringApplication application = new SpringApplication(MyApplication.class); application.addInitializers(new MyApplicationContextInitializer()); application.run(args); &#125;&#125; 6.1.2 通过 META-INF/spring.factories可以在 META-INF/spring.factories 文件中声明 ApplicationContextInitializer： 1org.springframework.context.ApplicationContextInitializer=com.example.MyApplicationContextInitializer 7. SharedMetadataReaderFactoryContextInitializerSharedMetadataReaderFactoryContextInitializer的作用是Spring 应用程序上下文初始化期间，提供一个共享的 MetadataReaderFactory 实例，并通过缓存元数据读取来提高性能。 SharedMetadataReaderFactoryContextInitializer 通过在 Spring 应用程序启动期间注册和配置共享的 MetadataReaderFactory 实现了优化性能的目的。其主要作用是确保所有需要读取元数据的组件共享同一个 MetadataReaderFactory 实例，从而减少重复的元数据读取操作，提高启动和运行效率。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class SharedMetadataReaderFactoryContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;, Ordered &#123; // 这个常量定义了共享 `MetadataReaderFactory` 实例的 Bean 名称， 这是Sping 内部标识名称 public static final String BEAN_NAME = &quot;org.springframework.boot.autoconfigure.&quot; + &quot;internalCachingMetadataReaderFactory&quot;; // 实现 `ApplicationContextInitializer` 的 `initialize` 方法，在应用上下文初始化时调用。 // 向应用上下文添加一个 `CachingMetadataReaderFactoryPostProcessor` 实例。 @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; applicationContext.addBeanFactoryPostProcessor(new CachingMetadataReaderFactoryPostProcessor()); &#125; @Override public int getOrder() &#123; return 0; &#125; /** * &#123;@link BeanDefinitionRegistryPostProcessor&#125; to register the * &#123;@link CachingMetadataReaderFactory&#125; and configure the * &#123;@link ConfigurationClassPostProcessor&#125;. */ //静态内部类，负责注册共享的 `MetadataReaderFactory` 并配置 `ConfigurationClassPostProcessor`。 private static class CachingMetadataReaderFactoryPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered &#123; /** * &#123;@link FactoryBean&#125; to create the shared &#123;@link MetadataReaderFactory&#125;. */ // 内部静态类，用于创建共享的 `MetadataReaderFactory` 实例。 static class SharedMetadataReaderFactoryBean implements FactoryBean&lt;ConcurrentReferenceCachingMetadataReaderFactory&gt;, BeanClassLoaderAware, ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; private ConcurrentReferenceCachingMetadataReaderFactory metadataReaderFactory; @Override public void setBeanClassLoader(ClassLoader classLoader) &#123; this.metadataReaderFactory = new ConcurrentReferenceCachingMetadataReaderFactory(classLoader); &#125; @Override public ConcurrentReferenceCachingMetadataReaderFactory getObject() throws Exception &#123; return this.metadataReaderFactory; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return CachingMetadataReaderFactory.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; this.metadataReaderFactory.clearCache(); &#125; &#125;&#125; 7.1 CachingMetadataReaderFactoryPostProcessorCachingMetadataReaderFactoryPostProcessor 是SharedMetadataReaderFactoryContextInitializer的一个静态内部类， 它实现了BeanDefinitionRegistryPostProcessor, PriorityOrdered两个接口。 关于BeanDefinitionRegistryPostProcessor, PriorityOrdered在 Spring IOC 容器启动过程拓展点已经介绍过 BeanDefinitionRegistryPostProcessor 继承了BeanFactoryPostProcessor ， 并增加了一个方法 PriorityOrdered是Ordered接口的一个子接口，允许BeanFactoryPostProcessor在其他普通Ordered执行。这主要用于那些必须首先应用的处理器，比如那些涉及配置如何加载的处理器。 12345678910111213141516171819202122232425262728293031323334353637383940private static class CachingMetadataReaderFactoryPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered &#123; @Override public int getOrder() &#123; // Must happen before the ConfigurationClassPostProcessor is created return Ordered.HIGHEST_PRECEDENCE; &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; &#125; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; // 注册共享的 `MetadataReaderFactory`。 register(registry); // 配置 `ConfigurationClassPostProcessor` configureConfigurationClassPostProcessor(registry); &#125; // 向注册表中添加一个 `SharedMetadataReaderFactoryBean` 的 Bean 定义。 private void register(BeanDefinitionRegistry registry) &#123; BeanDefinition definition = BeanDefinitionBuilder .genericBeanDefinition(SharedMetadataReaderFactoryBean.class, SharedMetadataReaderFactoryBean::new) .getBeanDefinition(); registry.registerBeanDefinition(BEAN_NAME, definition); &#125; // 配置 `ConfigurationClassPostProcessor`， 将共享的 `MetadataReaderFactory` 关联到其 `metadataReaderFactory` 属性。 private void configureConfigurationClassPostProcessor(BeanDefinitionRegistry registry) &#123; try &#123; BeanDefinition definition = registry .getBeanDefinition(AnnotationConfigUtils.CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME); definition.getPropertyValues().add(&quot;metadataReaderFactory&quot;, new RuntimeBeanReference(BEAN_NAME)); &#125; catch (NoSuchBeanDefinitionException ex) &#123; &#125; &#125; &#125; 7.1.1 postProcessBeanFactoryBeanFactoryPostProcessor 中定义的方法， CachingMetadataReaderFactoryPostProcessor对该方法是空实现12345@FunctionalInterface public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException; &#125; 7.1.2 postProcessBeanDefinitionRegistryBeanDefinitionRegistryPostProcessor中定义的接口123public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException; &#125; CachingMetadataReaderFactoryPostProcessor 重写该方法时包含2个重要步骤1234567 @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; // 注册共享的 `MetadataReaderFactory`。 register(registry);// 配置 `ConfigurationClassPostProcessor` configureConfigurationClassPostProcessor(registry); &#125; 7.1.2.1 register-SharedMetadataReaderFactoryBean的BeanDefinition注册向注册表中添加一个 SharedMetadataReaderFactoryBean 的 Bean 定义。123456789private static class CachingMetadataReaderFactoryPostProcessor&#123; // 向注册表中添加一个 `SharedMetadataReaderFactoryBean` 的 Bean 定义。 private void register(BeanDefinitionRegistry registry) &#123; BeanDefinition definition = BeanDefinitionBuilder .genericBeanDefinition(SharedMetadataReaderFactoryBean.class, SharedMetadataReaderFactoryBean::new) .getBeanDefinition(); registry.registerBeanDefinition(BEAN_NAME, definition); &#125;&#125; 从代码中可以看到， SharedMetadataReaderFactoryBean的bean 定义注册是通过内部标识org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory 完成的， 相当于在bean 实例化的过程中， 遇到beanName 是org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory 时，就知道需要实例化SharedMetadataReaderFactoryBean 这个工厂bean 7.1.2.2 configureConfigurationClassPostProcessor配置 ConfigurationClassPostProcessor， 将共享的 MetadataReaderFactory 关联到其 metadataReaderFactory 属性。12345678910private void configureConfigurationClassPostProcessor(BeanDefinitionRegistry registry) &#123; try &#123; BeanDefinition definition = registry .getBeanDefinition(AnnotationConfigUtils.CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME); definition.getPropertyValues().add(&quot;metadataReaderFactory&quot;, new RuntimeBeanReference(BEAN_NAME)); &#125; catch (NoSuchBeanDefinitionException ex) &#123; &#125; &#125; &#125;从代码中可以看到， ConfigurationClassPostProcessor的bean 定义注册也是通过内部特使标识完成的， 其标识是org.springframework.context.annotation.internalConfigurationAnnotationProcessor 相当于在bean 实例化的过程中， 遇到beanName 是org.springframework.context.annotation.internalConfigurationAnnotationProcessor 时，就知道需要实例化 ConfigurationClassPostProcessor 这个类。 7.2 SharedMetadataReaderFactoryBean在6.1.2.1 中注册的BeanDefinition是SharedMetadataReaderFactoryBean。 SharedMetadataReaderFactoryBean也是SharedMetadataReaderFactoryContextInitializer的一个静态内部类， 它是一个FactoryBean 1234567891011121314151617181920212223242526272829303132static class SharedMetadataReaderFactoryBean implements FactoryBean&lt;ConcurrentReferenceCachingMetadataReaderFactory&gt;, BeanClassLoaderAware, ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; private ConcurrentReferenceCachingMetadataReaderFactory metadataReaderFactory; @Override public void setBeanClassLoader(ClassLoader classLoader) &#123; this.metadataReaderFactory = new ConcurrentReferenceCachingMetadataReaderFactory(classLoader); &#125; @Override public ConcurrentReferenceCachingMetadataReaderFactory getObject() throws Exception &#123; return this.metadataReaderFactory; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return CachingMetadataReaderFactory.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; this.metadataReaderFactory.clearCache(); &#125; &#125; 7.2.1 ConcurrentReferenceCachingMetadataReaderFactoryConcurrentReferenceCachingMetadataReaderFactory 是 Spring Framework 中一个用于缓存和并发优化的类，专门用于读取类的元数据（如注解、方法、字段等）时提高性能。它通过使用并发数据结构和缓存机制，显著减少了重复的元数据读取操作，从而提升了性能。 以上都是SpringBoot 自动配置机制实现过程中会涉及到的重要知识点，提前了解他们有助于帮助更好地了解SpringBoot 自动配置的实现。 现在思考，自动配置类是如何从配置文件中的一行文字变成Spring 容器中可实际发挥作用的实例bean 加载自动配置类名称：读取META-INF/spring.factories文件，找到所有的自动配置类，由 SpringFactoriesLoader.loadFactoryNames完成 注册自动配置类BeanDefinition：所有的自动配置类如果想成为实例bean, 要在Spring 容器BeanFactory中先有BeanDefinition ， 自动配置类BeanDefinition的生成由ConfigurationClassPostProcessor 完成 自动配置类的的实例化：根据BeanDefinition 实例化自动配置类。自动配置类有了bean definition 后， 就可以通过getBean流程被实例成bean, 即getBean 在 Spring bean 实例化一文中，已经详细介绍了以refresh方法为入口的Spring IOC 容器启动过程，不论是以哪种方式启动， refresh 都是入口， 例如ClassPathXmlApplicationContext 方式refresh也是入口 1ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); 我们需要来看下， 在SpringBoot 启动的Spring 项目中， 在进入refresh入口前进行了哪些操作，这些都是SpringBoot 实现自动配置的重要步骤 8. 加载自动配置类名称我们在分析 Spring bean 实例化时， 只分析了以refresh方法为入口的代码， 如果想要充分了解SpringBoot 自动配置的机制， 不只要了解refresh 里面的流程，还要分析SpringApplication.run为入口的代码12345678910111213141516171819202122public class CodingInActionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CodingInActionApplication.class, args);&#125;public class SpringApplication &#123; /** * The class name of application context that will be used by default for web * environments. */ public static final String DEFAULT_SERVLET_WEB_CONTEXT_CLASS = &quot;org.springframework.boot.&quot; + &quot;web.servlet.context.AnnotationConfigServletWebServerApplicationContext&quot;; public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args); &#125; public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args); &#125;&#125; 8.1 new SpringApplication123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class SpringApplication &#123; // 以下是俩构造函数， 重点看第二个 public SpringApplication(Class&lt;?&gt;... primarySources) &#123; this(null, primarySources); &#125; public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;); &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &#125; private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123; List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size()); for (String name : names) &#123; try &#123; Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader); Assert.isAssignable(type, instanceClass); Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); &#125; catch (Throwable ex) &#123; throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, ex); &#125; &#125; return instances; &#125; &#125; 8.1.1 setInitializers8.1.2 SpringFactoriesLoader.loadFactoryNames从SpringApplication.run 为入口深入源码， 可以在SpringApplication的构造函数中看到如下代码，123456789public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &#125; 在getSpringFactoriesInstances方法中调用了SpringFactoriesLoader.loadFactoryNames, 该方法完成了对META-INF/spring.factories 文件的解析，进而完成自动配置类名称的自动加载工作 123456789101112131415161718192021222324252627282930private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123; return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;); &#125; private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &#125; private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, ClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123; List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size()); for (String name : names) &#123; try &#123; Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader); Assert.isAssignable(type, instanceClass); Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes); T instance = (T) BeanUtils.instantiateClass(constructor, args); instances.add(instance); &#125; catch (Throwable ex) &#123; throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, ex); &#125; &#125; return instances; &#125; 根据前文说过，在SpringBoot项目实际启动过程中，查找到的META-INF/spring.factories文件包括以下4个 spring-boot-autoconfigure-2.3.4.RELEASE.jar META-INF/spring.factories spring-boot-2.3.4.RELEASE.jar META-INF/spring.factories spring-beans-5.2.9.RELEASE.jar META-INF/spring.factories mybatis-spring-boot-autoconfigure-2.1.4.jar META-INF/spring.factories 从这4个文件中， 一共找到13个key。 经过loadSpringFactories 处理， 4个META-INF/spring.factories文件所有的配置信息均已经存储在result 这个Map 中的。 回到loadFactoryNames方法中，通过MultiValueMapgetOrDefault获取指定类型 的配置信息。 1234public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList()); &#125; 在setInitializers方法中， 需要的是 org.springframework.context.ApplicationContextInitializer 对应的自动配置类。1setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); 从图中可以看出， 满足条件的自动配置类有7个， 接下来我们会重点关注其中的org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer 8.1.3 反射-createSpringFactoriesInstances 获取到满足满足条件的自动配置类全限定类名后，就是用经典的反射流程完成相应类的实例化。关于反射，可以点击阅读 java 反射 实践与原理 8.2 run在SpringApplication 实例化完成后，开始执行run逻辑，其中refreshContext 进去后，就是 Spring 容器的启动过程，创建 BeanFactory、以及BeanFactory 容器中各个bean 的实例化过程。 在 Spring 容器的启动之前，先来看下ApplicationContext 做了哪些准备⚠️：这里我们还是要区分以下BeanFactory 和ApplicationContext在Spring IOC 容器启动过程拓展点一文中曾提到过，BeanFactory是Spring框架中最基础的IOC容器。它提供了基本的依赖注入机制，负责管理Bean的实例化、配置和生命周期。ApplicationContext是在BeanFactory基础上扩展的高级容器，提供了更多面向应用的功能，它还提供了国际化支持和框架事件体系，更易于创建实际应用。一般称BeanFactory为IoC容器，而称ApplicationContext为应用上下文。 12345// 该方法只保留了部分代码 public ConfigurableApplicationContext run(String... args) &#123; prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); &#125; 8.2.1 prepareContext12345678910111213141516//该方法只保留了部分代码 private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; applyInitializers(context); &#125; protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, &quot;Unable to call initializer.&quot;); // 调用个ApplicationContextInitializer的具体实现类的initialize方法 initializer.initialize(context); &#125; &#125; 8.2.2 applyInitializers12345//该方法只保留了部分代码private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; applyInitializers(context);&#125; 在preContext 逻辑中, 只重点关注applyInitializers， 在SpringApplication.setInitializers方法中设置了从配置文件读取并通过反射创建7个ApplicationContextInitializer的具体实现类实例。 每个实现类在这里都会执行重写的initialize 方法 8.2.2 SharedMetadataReaderFactoryContextInitializer在ApplicationContextInitializer的7个具体实现类实例中， 关注SharedMetadataReaderFactoryContextInitializer从代码中可以看到SharedMetadataReaderFactoryContextInitializer.initialize的逻辑是将 CachingMetadataReaderFactoryPostProcessor 这个BeanFactoryPostProcessor 添加到应用上下文 ApplicationContext中进行记录管理。 123456789public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; private final List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors = new ArrayList&lt;&gt;(); public void addBeanFactoryPostProcessor(BeanFactoryPostProcessor postProcessor) &#123; Assert.notNull(postProcessor, &quot;BeanFactoryPostProcessor must not be null&quot;); this.beanFactoryPostProcessors.add(postProcessor); &#125;&#125; 以上内容都还是在应用上下文中进行处理，我们已经将配置在所有META-INF/spring.factories文件中的信息全部解析完成，并将配置信息存储在了SpringFactoriesLoader的cache, 方便后面流程快速读取，接下来将分析进入refresh 后，自动配置类的处理过程。 9. 注册自动配置类的BeanDefinition9.1 invokeBeanFactoryPostProcessors在 Spring IOC 容器启动过程拓展点一文中，已经讲过，BeanFactoryPostProcessor 是 Spring 框架在bean 开始整个创建流程之前 起作用。其具体时机是refresh 中的invokeBeanFactoryPostProcessors方法 1234567891011121314151617181920212223242526public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext &#123; @Override public void refresh() throws BeansException, IllegalStateException &#123; // 1. 创建beanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2.BeanFactoryPostProcessor起作用 invokeBeanFactoryPostProcessors(beanFactory); // 3.注册 BeanPostProcessor registerBeanPostProcessors(beanFactory); // 4. bean的生命周期管理和依赖关系的装配 finishBeanFactoryInitialization(beanFactory); &#125; // 只保留重点代码 protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()) &#125; public List&lt;BeanFactoryPostProcessor&gt; getBeanFactoryPostProcessors() &#123; return this.beanFactoryPostProcessors; &#125;&#125; 接下来的内容，要重点分析在SharedMetadataReaderFactoryContextInitializer.initialize方法中创建的BeanFactoryPostProcessor : CachingMetadataReaderFactoryPostProcessor 9.2 CachingMetadataReaderFactoryPostProcessor前面讲过，在applyInitializers逻辑中，SharedMetadataReaderFactoryContextInitializer.initialize的逻辑是将 CachingMetadataReaderFactoryPostProcessor 这个BeanFactoryPostProcessor 添加到应用上下文 ApplicationContext中进行记录管理。 同时CachingMetadataReaderFactoryPostProcessor 也是一个BeanDefinitionRegistryPostProcessor, 在 PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors逻辑中调用其重写的postProcessBeanDefinitionRegistry,进行SharedMetadataReaderFactoryBean和ConfigurationClassPostProcessor 的BeanDefinition注册 9.3 ConfigurationClassPostProcessor现在当前Spring 容器beanFactory 中已经有了ConfigurationClassPostProcessor的的BeanDefinition,同时ConfigurationClassPostProcessor 也是一个BeanDefinitionRegistryPostProcessor 1234public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123;&#125; 所以当invokeBeanFactoryPostProcessors方法执行到如下逻辑时，ConfigurationClassPostProcessor对应的beanName org.springframework.context.annotation.internalConfigurationAnnotationProcessor 会返回123public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);&#125; beanFactory.getBean会触发ConfigurationClassPostProcessor的实例化过程 9.4 postProcessBeanDefinitionRegistryConfigurationClassPostProcessor的实例化完成后，继续执行`invokeBeanDefinitionRegistryPostProcessors 123456789101112131415161718192021222324252627282930313233343536373839invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry)````会去调用`ConfigurationClassPostProcessor`中重写的`BeanDefinitionRegistryPostProcessor.postProcessBeanDefinitionRegistry` 方法,&#123;% asset_img 17.png %&#125;在`processConfigBeanDefinitions` 方法中，会触发解析项目中所有`@Configuration` 类及其相关注解。在这个过程中，具体来说，它处理以下内容：- **`@Configuration` 类**：解析所有标记为 `@Configuration` 的类， 所有自动配置类均有`@Configuration`注解。- **`@ComponentScan` 注解**：处理 `@ComponentScan` 注解，扫描指定包路径下的组件（如 `@Component`, `@Repository`, `@Service`, `@Controller` 等注解标记的类）。- **`@Import` 注解**：处理 `@Import` 注解，导入其他配置类或处理 `ImportSelector` 和 `ImportBeanDefinitionRegistrar`。- **`@Bean` 方法**：解析 `@Bean` 方法，将其定义的 bean 注册为 `BeanDefinition`。- **`@PropertySource` 注解**：处理 `@PropertySource` 注解，加载属性源文件。 ```java public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123; // 只保留重点逻辑，省略了部分代码 public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); // 获取当前beanFactory中，所有的BeanDefinitionName String[] candidateNames = registry.getBeanDefinitionNames(); // Parse each @Configuration class ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; parser.parse(candidates); Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); this.reader.loadBeanDefinitions(configClasses); candidates.clear(); &#125; while (!candidates.isEmpty()); &#125;&#125; 9.4.1 获取解析候选类获取当前beanFactory中, 所有 BeanDefinition 名称，检查每个对应的 BeanDefinition， 找出被@Configuretion 标注且还未处理的类， 显然被@SpringBootApplication 注解标注的启动类名称是符合条件的 1234567891011121314List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); // 获取当前beanFactory中，所有的BeanDefinitionName String[] candidateNames = registry.getBeanDefinitionNames();for (String beanName : candidateNames) &#123; BeanDefinition beanDef = registry.getBeanDefinition(beanName); if (beanDef.getAttribute(ConfigurationClassUtils.CONFIGURATION_CLASS_ATTRIBUTE) != null) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean definition has already been processed as a configuration class: &quot; + beanDef); &#125; &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; 9.4.2 ConfigurationClassParser前面我们说过，ConfigurationClassPostProcessor 的职责 主要有两个 将@Configuration及其相关注解，解析成BeanDefinition 将解析得到的 BeanDefinition 注册到 BeanFactory 中。 其实实际执行解析工作的核心组件是 ConfigurationClassParser。 循环处理过滤出的候选类，使用ConfigurationClassParser 对候选配置进行解析直到所有配置类都被解析和注册。 12345ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry);parser.parse(candidates); 针对不同类的BeanDefinition进行不同的parse 操作， 一个SpringBoot 项目，其启动代码标注的注解@SpringBootApplication 是AnnotatedBeanDefinition类型的注解 ， 所以这里是我们需要关注的逻辑12345678910111213141516171819202122232425262728293031class ConfigurationClassParser &#123; public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( &quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex); &#125; &#125; this.deferredImportSelectorHandler.process(); &#125; protected final void parse(AnnotationMetadata metadata, String beanName) throws IOException &#123; processConfigurationClass(new ConfigurationClass(metadata, beanName), DEFAULT_EXCLUSION_FILTER); &#125;&#125; 9.4.3 parse解析的过程，通过parse 的递归完成项目中所有BeanDefinition的定义1234567891011121314151617181920212223242526// 只保留了部分代码 protected void processConfigurationClass(ConfigurationClass configClass, Predicate&lt;String&gt; filter) throws IOException &#123; if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123; return; &#125; // Recursively process the configuration class and its superclass hierarchy. SourceClass sourceClass = asSourceClass(configClass, filter); do &#123; sourceClass = doProcessConfigurationClass(configClass, sourceClass, filter); &#125; while (sourceClass != null); this.configurationClasses.put(configClass, configClass); &#125;private SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123; processMemberClasses(configClass, sourceClass); processPropertySources(sourceClass); processComponentScan(sourceClass); processImports(configClass, sourceClass); processImportSource(configClass, sourceClass); processInterfaces(configClass, sourceClass); processSuperclass(configClass, sourceClass); return null;&#125;doProcessConfigurationClass是伪代码， 下面具体展开介绍 9.4.3.1 @ComponentScan@ComponentScan 是复合注解@SpringBootApplication的组成部分，@ComponentScan对应XML配置形式中的元素，可以通过basePackages等属性来细粒度地定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。 @ComponentScan扫描的包括@Component、@Service、@Repository、@Controller 这段逻辑处理后，一个项目中定义的各种业务bean, 都会被解析到形成configClass 123456789101112131415161718192021// Process any @ComponentScan annotations Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable( sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class); if (!componentScans.isEmpty() &amp;&amp; !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123; for (AnnotationAttributes componentScan : componentScans) &#123; // The config class is annotated with @ComponentScan -&gt; perform the scan immediately Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions = this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName()); // Check the set of scanned definitions for any further config classes and parse recursively if needed for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123; BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition(); if (bdCand == null) &#123; bdCand = holder.getBeanDefinition(); &#125; if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123; parse(bdCand.getBeanClassName(), holder.getBeanName()); &#125; &#125; &#125; &#125; 这里会递归调用parse,处理每个解析的业务bean 定义 9.4.3.2 @Import12// Process any @Import annotations processImports(configClass, sourceClass, getImports(sourceClass), filter, true); getImports 从sourceClass中找出@Import processImports 方法处理 @Import 注解，导入配置类或特定的配置选择器（如 ImportSelector 或 ImportBeanDefinitionRegistrar）。 一般来讲,一个SpringBoot项目的启动类如果配置如下123@SpringBootApplication @MapperScan(&quot;com.example.codingInAction.mapper&quot;) public class CodingInActionApplication &#123;&#125; 那么可以找到以下3个通过@Import注解导入的类 AutoConfigurationImportSelector AutoConfigurationPackages.Registrar MapperScannerRegistrar 123456789101112131415161718192021222324@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration &#123;&#125;@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @Import(AutoConfigurationPackages.Registrar.class) public @interface AutoConfigurationPackage &#123;&#125;@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Import(MapperScannerRegistrar.class) @Repeatable(MapperScans.class) public @interface MapperScan &#123;&#125; 123456789101112131415161718192021222324252627private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass, Collection&lt;SourceClass&gt; importCandidates, Predicate&lt;String&gt; exclusionFilter, boolean checkForCircularImports) &#123; for (SourceClass candidate : importCandidates) &#123; if (candidate.isAssignable(ImportSelector.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); ImportSelector selector = ParserStrategyUtils.instantiateClass(candidateClass, ImportSelector.class, this.environment, this.resourceLoader, this.registry); if (selector instanceof DeferredImportSelector) &#123; this.deferredImportSelectorHandler.handle(configClass, (DeferredImportSelector) selector); &#125; &#125;else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123; Class&lt;?&gt; candidateClass = candidate.loadClass(); ImportBeanDefinitionRegistrar registrar = ParserStrategyUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class, this.environment, this.resourceLoader, this.registry); configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata()); &#125;else &#123; // Candidate class not an ImportSelector or ImportBeanDefinitionRegistrar -&gt; // process it as an @Configuration class this.importStack.registerImport( currentSourceClass.getMetadata(), candidate.getMetadata().getClassName()); processConfigurationClass(candidate.asConfigClass(configClass), exclusionFilter); &#125; &#125; &#125; 这段代码处理了三种类型的候选类（candidate）在@Import注解中的情况：ImportSelector、ImportBeanDefinitionRegistrar和普通的@Configuration类。 候选类是ImportSelector类型 如果ImportSelector对象是DeferredImportSelector的实例，则将其交给deferredImportSelectorHandler处理。 否则递归处理这些导入的类。 候选类是ImportBeanDefinitionRegistrar类型：通过ParserStrategyUtils.instantiateClass方法实例化ImportBeanDefinitionRegistrar对象。将该对象注册到configClass中，以便它可以注册额外的bean定义。 如果候选类既不是ImportSelector也不是ImportBeanDefinitionRegistrar类型，则将其视为普通的@Configuration类。递归处理该类 我们重点关注AutoConfigurationImportSelector,它和自动配置类的解析有关， 且它是一个DeferredImportSelector，所以会执行deferredImportSelectorHandler.handle逻辑 在processImports逻辑中，就可以遇到parse 执行完成后， 业务上注册的bean 其配置信息均已处理完成，接下来就可以处理自动配置类了 9.4.4 DeferredImportSelectorHandlerAutoConfigurationImportSelector,它和自动配置类的解析有关， 且它是一个DeferredImportSelector，所以会执行deferredImportSelectorHandler.handle先将其记录下来，等所有其他正常数据处理完成后再来处理AutoConfigurationImportSelector 1234567891011121314151617181920212223242526272829303132333435class ConfigurationClassParser &#123; private class DeferredImportSelectorHandler &#123; public void process() &#123; List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors; this.deferredImportSelectors = null; try &#123; if (deferredImports != null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); deferredImports.sort(DEFERRED_IMPORT_COMPARATOR); deferredImports.forEach(handler::register); handler.processGroupImports(); &#125; &#125; finally &#123; this.deferredImportSelectors = new ArrayList&lt;&gt;(); &#125; &#125; public void process() &#123; List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors; this.deferredImportSelectors = null; try &#123; if (deferredImports != null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); deferredImports.sort(DEFERRED_IMPORT_COMPARATOR); deferredImports.forEach(handler::register); handler.processGroupImports(); &#125; &#125; finally &#123; this.deferredImportSelectors = new ArrayList&lt;&gt;(); &#125; &#125; &#125;&#125; 9.4.4.1 handlehandle方法，用于处理ConfigurationClass和DeferredImportSelector的配对。具体来说： 如果当前没有DeferredImportSelectorHolder，则立即处理新的延迟导入选择器。 如果已有未处理的DeferredImportSelectorHolder，则将新的延迟导入选择器添加到列表中，以便稍后批量处理 DeferredImportSelectorHolder：一个持有ConfigurationClass和DeferredImportSelector的配对类。 123456789101112131415161718192021class ConfigurationClassParser &#123; private static class DeferredImportSelectorHolder &#123; private final ConfigurationClass configurationClass; private final DeferredImportSelector importSelector; public DeferredImportSelectorHolder(ConfigurationClass configClass, DeferredImportSelector selector) &#123; this.configurationClass = configClass; this.importSelector = selector; &#125; public ConfigurationClass getConfigurationClass() &#123; return this.configurationClass; &#125; public DeferredImportSelector getImportSelector() &#123; return this.importSelector; &#125; &#125;&#125; 9.4.4.2 process1234567891011121314151617181920212223242526class ConfigurationClassParser &#123; public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123; for (BeanDefinitionHolder holder : configCandidates) &#123; BeanDefinition bd = holder.getBeanDefinition(); try &#123; if (bd instanceof AnnotatedBeanDefinition) &#123; parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &#125; else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123; parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName()); &#125; else &#123; parse(bd.getBeanClassName(), holder.getBeanName()); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( &quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex); &#125; &#125; this.deferredImportSelectorHandler.process(); &#125;&#125; process 方法会在parse 结束后， 才执行deferredImportSelectorHandler.process逻辑， 符合它延迟执行的特性。下面来具体看下DeferredImportSelector 是如何解析自动配置类信息的12345678910111213141516171819202122232425262728293031323334353637383940414243class ConfigurationClassParser &#123; private class DeferredImportSelectorHandler &#123; public void process() &#123; List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors; this.deferredImportSelectors = null; try &#123; if (deferredImports != null) &#123; DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); deferredImports.sort(DEFERRED_IMPORT_COMPARATOR); deferredImports.forEach(handler::register); handler.processGroupImports(); &#125; &#125; finally &#123; this.deferredImportSelectors = new ArrayList&lt;&gt;(); &#125; &#125; &#125; private class DeferredImportSelectorGroupingHandler&#123; public void processGroupImports() &#123; for (DeferredImportSelectorGrouping grouping : this.groupings.values()) &#123; Predicate&lt;String&gt; exclusionFilter = grouping.getCandidateFilter(); grouping.getImports().forEach(entry -&gt; &#123; ConfigurationClass configurationClass = this.configurationClasses.get(entry.getMetadata()); try &#123; processImports(configurationClass, asSourceClass(configurationClass, exclusionFilter), Collections.singleton(asSourceClass(entry.getImportClassName(), exclusionFilter)), exclusionFilter, false); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException( &quot;Failed to process import candidates for configuration class [&quot; + configurationClass.getMetadata().getClassName() + &quot;]&quot;, ex); &#125; &#125;); &#125; &#125; &#125;&#125; register先进入register, 将AutoConfigurationImportSelector这个DeferredImportSelector 添加到configurationClasses这个map h中，前面经过parse 阶段解析出业务bean 信息都在map 中 getImports 在这里能够看到getImports,最终调用的的是SpringFactoriesLoader.loadFactoryNames， 这个方法SpringApplication初始化时已经执行读取过所有的META-INF/spring.factories文件，所以这里会直接使用cache 里面的数据，不会重复读取META-INF/spring.factories文件了。 从下图可以看到AutoConfigurationEntry存储了自动配置类的信息 processImports拿到自动配置类信息后，就可以进行解析了，processImports在9.3.5.2 节中讲过有3种逻辑 候选类是ImportSelector类型 如果ImportSelector对象是DeferredImportSelector的实例，则将其交给deferredImportSelectorHandler处理。 否则递归处理这些导入的类。 候选类是ImportBeanDefinitionRegistrar类型：通过ParserStrategyUtils.instantiateClass方法实例化ImportBeanDefinitionRegistrar对象。将该对象注册到configClass中，以便它可以注册额外的bean定义。 如果候选类既不是ImportSelector也不是ImportBeanDefinitionRegistrar类型，则将其视为普通的@Configuration类，执行processConfigurationClass递归处理该类 针对自动配置类会走到第3个逻辑， 以MybatisAutoConfiguration为例，解析该自动配置类会处理其用@Bean标注的2个bean 9.4.5 loadBeanDefinitions(configClasses)parse 工作完成后，就可以loadBeanDefinitions 到BeanFactory中了12345678class ConfigurationClassBeanDefinitionReader &#123; public void loadBeanDefinitions(Set&lt;ConfigurationClass&gt; configurationModel) &#123; TrackedConditionEvaluator trackedConditionEvaluator = new TrackedConditionEvaluator(); for (ConfigurationClass configClass : configurationModel) &#123; loadBeanDefinitionsForConfigurationClass(configClass, trackedConditionEvaluator); &#125; &#125;&#125; 9.5 postProcessBeanFactory以上注解解析+BeanDefinition 注册都是ConfigurationClassPostProcessor中重写的BeanDefinitionRegistryPostProcessor.postProcessBeanDefinitionRegistry 中的逻辑 现在来看ConfigurationClassPostProcessor中重写的BeanFactoryPostProcessor.postProcessBeanFactory 1234567891011121314151617181920public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor, PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; int factoryId = System.identityHashCode(beanFactory); if (this.factoriesPostProcessed.contains(factoryId)) &#123; throw new IllegalStateException( &quot;postProcessBeanFactory already called on this post-processor against &quot; + beanFactory); &#125; this.factoriesPostProcessed.add(factoryId); if (!this.registriesPostProcessed.contains(factoryId)) &#123; // BeanDefinitionRegistryPostProcessor hook apparently not supported... // Simply call processConfigurationClasses lazily at this point then. processConfigBeanDefinitions((BeanDefinitionRegistry) beanFactory); &#125; enhanceConfigurationClasses(beanFactory); beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory)); &#125;&#125; 这行代码最重要的逻辑是 enhanceConfigurationClasses 方法，它生成 @Configuration 类的 CGLIB 代理，以确保 @Bean 方法的正确性和单例性。代理类会覆盖 @Bean 方法，并在需要时调用 Spring 容器以获取已经创建的单例 bean。为什么要给@Configuration 类 生成代理对象 Spring 容器中的每个 bean 默认是单例的，即使 @Bean 方法被多次调用，也应返回相同的实例。 如果直接调用 @Bean 方法，每次调用都会创建一个新的实例，违反单例模式。 关于CGLIB 动态代理对象的生成， 可阅读查看Mybaits 通过自动配置与SpringBoot 集成的文章 10.自动配置类的的实例化至此，整个项目中所有定义的bean，不论是SpringBoot 框架的自动配置类，，还是业务代码中手动配置的， 所有bean的BeanDefinition 全部注册完成。普通业务bean得实例化过程我们已经非常熟悉了， 这里我们以Mybatis 自动配置类也是用同样的getBean流程完成实例化,具体实例化流程可以点击阅读Spring 集成 Mybatis 11 自动配置实现总结自动配置类是如何从配置文件中的一行文字变成Spring 容器中可实际发挥作用的实例bean 11.1 加载自动配置类名称自动配置类的名称在SpringApplication 实例化的过程中会完成加载工作。具体的加载由SpringFactoriesLoader.loadFactoryNames读取所有META-INF/spring.factories文件，将文件中的信息用MultiValueMap存储，同时加载后的信息会缓存下来供后续使用，防止重复加载。同时在这个过程中有SharedMetadataReaderFactoryContextInitializer添加到了ApplicationContext 中进行管理， 当后续执行其initialize时会注册ConfigurationClassPostProcessor这个BeanPostFactoryProcessor 11.2 注册自动配置类BeanDefinition所有的自动配置类如果想成为实例bean, 要在Spring 容器BeanFactory中先有BeanDefinition ， 自动配置类BeanDefinition的注册由ConfigurationClassPostProcessor 完成。 ConfigurationClassPostProcessor 作为BeanPostFactoryProcessor， 其作用时机是invokeBeanFactoryPostProcessors. ConfigurationClassPostProcessor 的职责 主要有两个 将@Configuration及其相关注解，解析成BeanDefinition 具体解析是有 再具体一点其实是由完成的3. 将解析得到的 BeanDefinition 注册到 BeanFactory 中。 将@Configuration及其相关注解，解析成BeanDefinition实际是由ConfigurationClassParser 完成的 ConfigurationClassParser 通过对@Import注解的处理，解析出AutoConfigurationImportSelector。 AutoConfigurationImportSelector才是最终负责自动配置类解析的工具， 因为它是DeferredImportSelector，所以AutoConfigurationImportSelector会先通过反射实例化然后记录下来, 等其他bean parse 工作完成后，再把AutoConfigurationImportSelector找出来处理自动配置类，将@Bean 标注的方法解析成BeanDefinition 当所有bean， 包括业务代码定义的bean 和自动配置类涉及到的bean, 全部注册到Spring容器BeanFactory 中 11.3 自动配置类的的实例化根据BeanDefinition 实例化自动配置类。自动配置类有了bean definition 后， 就可以通过getBean流程被实例成bean, 即getBean","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"理解 Spring FacrotyBean","slug":"理解-Spring-FacrotyBean","date":"2023-07-12T05:24:52.000Z","updated":"2024-09-05T11:39:30.523Z","comments":true,"path":"b4b9d0ea/","permalink":"http://example.com/b4b9d0ea/","excerpt":"","text":"FactoryBean 和BeanFactory 名字太像了，以至于容易混淆，但是从功能上讲完全不一样， 理解了它们各自的功能就可以完美区分这俩了 1. BeanFactorySpring IOC 容器，用于管理bean ,具体细节已经在Spring bean 实例化中介绍过，就不再赘述，可以点击去阅读。 总的来说BeanFactory 时Spring 容器，在Spring的启动过程，FactoryBean 是一个会被BeanFactory 管理的bean , 但是它相比其他普通业务bean,又有一些特殊的功能，比如生产出复杂配置的bean. 接下来详细介绍FactoryBean 2. FactoryBean 是一个接口 FactoryBean 接口提供了一种灵活的方式来创建复杂的对象。 实现 FactoryBean 接口的类，可以通过其 getObject 方法来创建并返回实际的对象实例。FactoryBean 可以用于创建单例、原型、代理对象或其他复杂的初始化逻辑。 FactoryBean 接口定义如下： 12345public interface FactoryBean&lt;T&gt; &#123; T getObject() throws Exception; Class&lt;?&gt; getObjectType(); boolean isSingleton();&#125; T getObject() throws Exception：这个方法返回由 FactoryBean 创建的对象。这个对象可以是一个普通的 Bean，也可以是一个代理对象或其他复杂对象。 Class&lt;?&gt; getObjectType()：这个方法返回由 FactoryBean 创建的对象的类型。Spring 使用这个信息来确定 Bean 的类型。 boolean isSingleton()：这个方法指示由 FactoryBean 创建的对象是否是单例（singleton）。如果返回 true，Spring 容器会缓存该实例。 3. Spring 容器启动过程中的FactoryBean接下来我们将通过 分析Spring 启动过程中 FactoryBean的实例化以及通过FactoryBean.getObject 的过程来加深对FactoryBean的理解。这里我们用 Spring AOP XML配置方式原理详解 中的示例代码进行讲解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class UserService &#123; public void createUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); &#125; public void deleteUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); &#125;&#125;// 定义一个前置增强public class LoggingBeforeAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); &#125;&#125;// 定义一个后置增强public class LoggingAfterAdvice implements AfterReturningAdvice &#123; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;After method: &quot; + method.getName()); &#125;&#125;// 定义一个 环绕增强public class LoggingMethodInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 方法执行前逻辑 long startTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot; 方法开始执行&quot;); // 通过反射执行目标方法 Object result = invocation.proceed(); // 方法执行后逻辑 //System.out.println(&quot;After method: &quot; + invocation.getMethod().getName()); long endTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot;方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 前置增强 --&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingMethodInterceptor&quot; class=&quot;com.example.codingInAction.aop.LoggingMethodInterceptor&quot;/&gt; &lt;!-- 使用 ProxyFactoryBean 配置代理对象 --&gt; &lt;bean id=&quot;userServiceProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;userService&quot;/&gt; &lt;!-- 拦截器 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingMethodInterceptor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 强制使用CGLIB代理 --&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 启动代码 1234567891011121314public class CodingInActionApplication&#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); // 获取代理对象 UserService userService = (UserService) context.getBean(&quot;userServiceProxy&quot;); // 调用方法，观察 AOP 切面的效果 userService.createUser(&quot;john&quot;); userService.deleteUser(&quot;john&quot;); &#125;&#125; &amp; 前缀的作用 使用 getBean(&quot;&amp;beanName&quot;) 可以获取 FactoryBean 实例本身，而不是 FactoryBean 创建的对象。 使用 getBean(&quot;beanName&quot;) 则获取由 FactoryBean 创建的对象。 3.1 FactoryBean 也是一个beanFactoryBean 也是一个bean, 和普通bean 使用相同的逻辑进行实例化，所以也是被beanFactory 管理的。 如代码所示1ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); 在以上Spring 容器的启动过程中，userServiceProxy作为一个FactoryBean 会通过getBean触发实例化流程。可以看到getBean传参的时候，beanName 前增加了 &amp; 标识，说明这个getBean 流程需要获取的是userServiceProxy这个个FactoryBean ，而不是由它创建的对象 在实例化 FactoryBean 的过程中，并不需要&amp;标识 ， 在getBean 是否，需要判断 是返回FactoryBean 实例 还是Factorybean创建的对象时才需要&amp;标识。 3.1.1 transformedBeanName 方法进入getBean, 可以看到namet经过了transformedBeanName方法处理， 又把&amp; 去掉了。 1String beanName = transformedBeanName(name); 这行代码的作用是将传入的 name 转换为实际的 Bean 名称,在 Spring 框架中，Bean 名称可能包含一些特殊的前缀或后缀，用于处理特殊情况或指示某种行为。transformedBeanName 方法用于解析和处理这些前缀或后缀，以获得实际的 Bean 名称。 在这个例子中就是去掉工厂 Bean 前缀 &amp;。 &amp; 前缀的作用 告诉程序 ，我是来获取 FactoryBean 本身，而不是获取FactoryBean 创建的对象的。所以 &amp; 本身不属于bean名称的一部分，需要经过transformedBeanName 方法会去掉这个前缀，以获得实际的 Bean 名称。 对于非FactoryBean 来讲， name 和beanName 都是一样的 3.1.2 getObjectForBeanInstanceFactoryBean只有在实例化后才能通过getObject() 创建其他配置复杂的bean 在看IOC源码的时候，发现即使我们已经创建出来了对象的实例，还是要走一个方法再去处理下，这里就是对FactoryBean的处理，因为它可以产生对象，所以你getBean的时候取到的不是它本身，而是通过它生成的产品。【如果要取它本身，getBean(&amp;+beanName)】 我们先来回忆下IOC源码中那个处理FactoryBean的简略代码：我们可以看到，无论是直接取单例的bean，还是创建单例、多例、自定义生命周期的bean，都会经过bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);这个方法，我们现在就来看看这里到底是做了什么： 123456789101112131415161718192021222324252627282930313233protected Object getObjectForBeanInstance( Object beanInstance, String name, String beanName, RootBeanDefinition mbd) &#123; //如果是对FactoryBean的解引用，但bean对象不是FactoryBean，抛出异常 if (BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; !(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(transformedBeanName(name), beanInstance.getClass()); &#125; //如果Bean实例不是FactoryBean，或者指定名称是FactoryBean的解引用，也就是普通的bean调用，则直接返回当前的Bean实例 if (!(beanInstance instanceof FactoryBean) || BeanFactoryUtils.isFactoryDereference(name)) &#123; return beanInstance; &#125; //处理对FactoryBean的调用 Object object = null; if (mbd == null) &#123; //从Bean工厂缓存中获取给定名称的实例对象 object = getCachedObjectForFactoryBean(beanName); &#125; if (object == null) &#123; // Return bean instance from factory. FactoryBean factory = (FactoryBean) beanInstance; //如果从Bean工厂生产的Bean是单态模式的，则缓存 if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) &#123; mbd = getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic()); //调用FactoryBeanRegistrySupport类的getObjectFromFactoryBean方法，实现FactoryBean生产Bean对象实例的过程 object = getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// Bean工厂生产Bean实例对象protected Object getObjectFromFactoryBean(FactoryBean factory, String beanName, boolean shouldPostProcess) &#123; // Bean工厂是单态模式，并且Bean工厂缓存中存在指定名称的Bean实例对象 if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) &#123; synchronized (getSingletonMutex()) &#123; // 直接从Bean工厂缓存中获取指定名称的Bean实例对象 Object object = this.factoryBeanObjectCache.get(beanName); // Bean工厂缓存中没有指定名称的实例对象，则生产该实例对象 if (object == null) &#123; // 调用Bean工厂的getObject方法生产指定Bean的实例对象 object = doGetObjectFromFactoryBean(factory, beanName, shouldPostProcess); // 将生产的实例对象添加到Bean工厂缓存中 this.factoryBeanObjectCache.put(beanName, (object != null ? object : NULL_OBJECT)); &#125; return (object != NULL_OBJECT ? object : null); &#125; &#125; // 调用Bean工厂的getObject方法生产指定Bean的实例对象 else &#123; return doGetObjectFromFactoryBean(factory, beanName, shouldPostProcess); &#125;&#125;//调用Bean工厂的getObject方法生产指定Bean的实例对象 private Object doGetObjectFromFactoryBean( final FactoryBean factory, final String beanName, final boolean shouldPostProcess) throws BeanCreationException &#123; Object object; try &#123; if (System.getSecurityManager() != null) &#123; AccessControlContext acc = getAccessControlContext(); try &#123; //实现PrivilegedExceptionAction接口的匿名内置类 //根据JVM检查权限，然后决定BeanFactory创建实例对象 object = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123; public Object run() throws Exception &#123; //调用BeanFactory接口实现类的创建对象方法 return factory.getObject(); &#125; &#125;, acc); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; //调用BeanFactory接口实现类的创建对象方法 object = factory.getObject(); &#125; &#125; catch (FactoryBeanNotInitializedException ex) &#123; throw new BeanCurrentlyInCreationException(beanName, ex.toString()); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, &quot;FactoryBean threw exception on object creation&quot;, ex); &#125; //创建出来的实例对象为null，或者因为单态对象正在创建而返回null if (object == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException( beanName, &quot;FactoryBean which is currently in creation returned null from getObject&quot;); &#125; //为创建出来的Bean实例对象添加BeanPostProcessor后置处理器 if (object != null &amp;&amp; shouldPostProcess) &#123; try &#123; object = postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(beanName, &quot;Post-processing of the FactoryBean&#x27;s object failed&quot;, ex); &#125; &#125; return object; &#125; 经过getObjectForBeanInstance 处理，最终返回了userServiceProxy这个FactoryBean 本身 3.2 获取FactoryBean 创建的对象FactoryBean 本身已经实例化完成了，现在可以获取由它创建的对象了12 // 获取代理对象UserService userService = (UserService) context.getBean(&quot;userServiceProxy&quot;); 由于userServiceProxy 是FactoryBean, 现在执行getBean(&quot;beanName&quot;) 说明我们要获取由它创建的对象了。下面跟着代码进行简单分析。 3.2.1 transformedBeanName 方法进入源码，再次来到getBean 流程，可以看到，经过transformedBeanName处理后，name 和beanName 保持一致。 3.2.2 getObjectForBeanInstance此时getSingleton,一级缓存中已经有了IOC 容器启动过程的中创建的实例， 直接获取即可。再次进入getObjectForBeanInstance 方法 3.2.3 FactoryBean.getObject在getObjectForBeanInstance 方法中，逐渐深入最终会进入到ProxyFactoryBean 重写的getObject 方法（getObject 是接口FactoryBean 中定义的方法还记得吗） 在getObject 方法中，可以获取userServiceProxy 创建的对象，即一个代理对象 4. FactoryBean 的应用场景FactoryBean 可以用于各种高级应用场景，以下是一些典型的使用场景： 4.1 创建代理对象FactoryBean 常用于创建 AOP 代理对象。例如，Spring AOP 内部大量使用 FactoryBean 来创建代理对象。 在上面的动态代理Demo中，我们就展示了一个通过FactoryBean创建代理对象的复杂例子。 4.2 创建复杂的 Bean 实例在某些情况下，创建一个 Bean 可能涉及复杂的初始化逻辑。通过 FactoryBean，我们可以将这些逻辑封装在 getObject 方法中，从而简化配置。 很多开源项目在集成Spring 时都使用到FactoryBean，比如 MyBatis3 提供 mybatis-spring项目中的 org.mybatis.spring.SqlSessionFactoryBean：123456&lt;!-- spring和MyBatis整合，不需要mybatis的配置映射文件 --&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/*.xml&quot;&gt;&lt;/property&gt;&lt;/bean&gt; 123456789101112public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123; private static final Log LOGGER = LogFactory.getLog(SqlSessionFactoryBean.class);...public SqlSessionFactory getObject() throws Exception &#123; if (this.sqlSessionFactory == null) &#123; this.afterPropertiesSet(); &#125; return this.sqlSessionFactory; &#125;...&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring AOP  注解方式原理详解","slug":"Spring-AOP-注解方式原理详解","date":"2023-06-23T03:08:57.000Z","updated":"2024-07-23T07:53:08.084Z","comments":true,"path":"4316da89/","permalink":"http://example.com/4316da89/","excerpt":"","text":"本文基于Spring AOP 实践 和 Spring AOP XML配置方式原理详解, 来继续讲解 基于注解方式实现AOP 自动代理的原理。 在Spring AOP 实践一文中，我们探讨了通过在XML配置文件中使用ProxyFactoryBean来配置代理对象的方法，并在需要时手动获取代理对象以实现AOP功能。 然而，在大型生产环境中，这种配置方式显得繁琐且不切实际。为了解决这一问题，Spring提供了一种基于AbstractAutoProxyCreator的自动代理机制，使得我们无需为每个Bean手动配置ProxyFactoryBean。 AbstractAutoProxyCreator通过自动检测Bean的类型和相应的切面（Aspect）来创建代理对象，从而简化了配置过程。 注解方式实现的AOP 自动代理机制使用的是AbstractAutoProxyCreator的子类AnnotationAwareAspectJAutoProxyCreator 如果你已经了解了 Spring bean 实例化 Spring IOC 容器启动过程拓展点 Spring AOP 实践 Spring AOP XML配置方式原理详解 那么现在来理解注解方式的自动代理机制其实已经比较容易了。 接下来，我们将以一个Spring Boot项目为示例，探讨AnnotationAwareAspectJAutoProxyCreator 实现自动代理的原理。 0. 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Servicepublic class UserService &#123; public void createUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); &#125; public void deleteUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); &#125;&#125;@Aspect@Componentpublic class LoggingAspect &#123; //定义一个匹配userService中所有方法的切点表达式 @Pointcut(&quot;execution(* com.example.codingInAction.service.UserService.*(..))&quot;) public void userServiceAllMethod() &#123; &#125; // 在方法执行之前执行的通知 @Before(&quot;userServiceAllMethod()&quot;) public void logBefore(JoinPoint joinPoint) &#123; System.out.println(&quot;Before method: &quot; + joinPoint.getSignature().getName()); &#125; // 在方法执行之后执行的通知 @After(&quot;userServiceAllMethod()&quot;) public void logAfter(JoinPoint joinPoint) &#123; System.out.println(&quot;After method: &quot; + joinPoint.getSignature().getName()); &#125; // 定义一个只匹配 UserService.createUser 方法的切点表达式 @Around(&quot;execution(* com.example.codingInAction.service.UserService.createUser(..))&quot;) public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable &#123; long startTime = System.currentTimeMillis(); System.out.println(joinPoint.getSignature().getName() + &quot; 方法开始执行&quot;); Object result = joinPoint.proceed(); // 执行目标方法 long endTime = System.currentTimeMillis(); System.out.println(joinPoint.getSignature().getName() + &quot; 方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125;@SpringBootApplicationpublic class CodingInActionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CodingInActionApplication.class, args); &#125;&#125; 1. AnnotationAwareAspectJAutoProxyCreator 继承、实现关系解析AnnotationAwareAspectJAutoProxyCreator是Spring AOP实现的核心类之一用于在Spring容器中扫描和处理带有@Aspect注解的bean。 AnnotationAwareAspectJAutoProxyCreator 继承关系较为复杂，它是多个类和接口的组合体，主要继承关系如下： 1.1 BeanPostProcessor在 Spring IOC 容器启动过程拓展点一文中，已经详细讲解过BeanPostProcessor的作用，此处不再赘述，直接来看它的3个子类 1.1.1 InstantiationAwareBeanPostProcessor 图中置灰的2个方法，是继承自BeanPostProcessor的2个方法 InstantiationAwareBeanPostProcessor自有的3个方法中有2个方法名称和BeanPostProcessor中方式名称相同，但是入参和返回值略有不同 postProcessBeforeInstantiation1234@Nullable default Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; 在bean 的实例化之前，会调用这个方法，其逻辑存在于下面代码中resolveBeforeInstantiation方法中。 这个方法可以返回一个代理对象，来替代 Bean 的默认实例化过程。但通常情况下，代理对象是在 Bean 实例化之后创建的，所以这个方法一般返回 null。 123456789@Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; Object beanInstance = doCreateBean(beanName, mbdToUse, args);&#125; postProcessAfterInstantiation在 bean create之后，populate之前调用。返回 true 表示允许属性注入，返回 false 则跳过属性注入。 123default boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; return true; &#125; postProcessProperties在populate 属性注入过程中调用，可以对属性值进行检查或修改。12345@Nullable default PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) throws BeansException &#123; return null; &#125; 1.1.2 SmartInstantiationAwareBeanPostProcessorSmartInstantiationAwareBeanPostProcessor 是 Spring 框架中的一个接口，它扩展了 InstantiationAwareBeanPostProcessor 接口，提供了更细粒度的控制和额外的钩子方法来介入 Spring Bean 的实例化过程。这个接口主要用于在 Bean create之前、create之后、populate之前、populate之后等多个阶段执行自定义逻辑，从而实现更加复杂和灵活的 Bean 初始化控制。 predictBeanType在实际创建 Bean 实例之前预测其类型。这对于提前检测某些类型相关的元数据很有用。 123default Class&lt;?&gt; predictBeanType(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; determineCandidateConstructors确定要用于创建 Bean 实例的候选构造函数。允许自定义选择用于实例化 Bean 的构造函数。 12345default Constructor&lt;?&gt;[] determineCandidateConstructors(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; getEarlyBeanReference允许在 Bean 实例化之前提前暴露 Bean 的引用。通常用于解决循环依赖问题 123default Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; return bean; &#125; 1.2 AbstractAutoProxyCreatorAbstractAutoProxyCreator 是一个抽象类，它继承自 ProxyProcessorSupport 并实现了 SmartInstantiationAwareBeanPostProcessor 和 BeanFactoryAware 接口。这些接口和类提供了创建代理对象和与 Spring 容器集成的基础功能。 它的主要作用是自动为 Spring 容器中的 bean 创建代理对象，以便在这些 bean 的方法调用时插入横切关注点的逻辑。具体来说，AbstractAutoProxyCreator 的功能包括： 扫描和筛选 bean：在 Spring 容器初始化时，扫描所有 bean，根据配置的切点筛选出需要增强的 bean。 创建代理对象：为符合条件的 bean 创建代理对象，代理对象可以是 JDK 动态代理或 CGLIB 代理。 注册代理对象：将创建的代理对象注册到 Spring 容器中，替换原始的 bean。 处理生命周期回调：实现 BeanPostProcessor 接口中的 postProcessBeforeInitialization 和 postProcessAfterInitialization 方法，在 bean 初始化前后执行代理逻辑。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; /** * Convenience constant for subclasses: Return value for &quot;do not proxy&quot;. * @see #getAdvicesAndAdvisorsForBean */ @Nullable protected static final Object[] DO_NOT_PROXY = null; /** * Convenience constant for subclasses: Return value for * &quot;proxy without additional interceptors, just the common ones&quot;. * @see #getAdvicesAndAdvisorsForBean */ protected static final Object[] PROXY_WITHOUT_ADDITIONAL_INTERCEPTORS = new Object[0]; /** Logger available to subclasses. */ protected final Log logger = LogFactory.getLog(getClass()); /** Default is global AdvisorAdapterRegistry. */ private AdvisorAdapterRegistry advisorAdapterRegistry = GlobalAdvisorAdapterRegistry.getInstance(); /** * Indicates whether or not the proxy should be frozen. Overridden from super * to prevent the configuration from becoming frozen too early. */ private boolean freezeProxy = false; /** Default is no common interceptors. */ private String[] interceptorNames = new String[0]; private boolean applyCommonInterceptorsFirst = true; @Nullable private TargetSourceCreator[] customTargetSourceCreators; @Nullable private BeanFactory beanFactory; private final Set&lt;String&gt; targetSourcedBeans = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); private final Map&lt;Object, Object&gt; earlyProxyReferences = new ConcurrentHashMap&lt;&gt;(16); private final Map&lt;Object, Class&lt;?&gt;&gt; proxyTypes = new ConcurrentHashMap&lt;&gt;(16); // 保存已经处理过的bean信息。这个映射用于保存bean实例到布尔值的映射，指示这些bean是否已经被代理或不需要代理。缓存这些信息可以提高性能，避免重复处理。private final Map&lt;Object, Boolean&gt; advisedBeans = new ConcurrentHashMap&lt;&gt;(256);&#125; 下面来分析一下AbstractAutoProxyCreator 的具体子类 1.2.1 AbstractAdvisorAutoProxyCreator 作用：这个类是 AbstractAutoProxyCreator 的直接子类，它的主要作用是自动为 Spring Bean 创建代理对象，并将配置的切面（advice）应用到这些代理对象上。 工作原理：它扫描 Spring 容器中的所有 Advisor（一个 Advisor 包含一个 Advice 和一个 Pointcut），并根据 Pointcut 的匹配规则，自动为匹配的 Bean 创建代理对象，并应用对应的 Advice。 1.2.2 AspectJAwareAdvisorAutoProxyCreator作用：这个类是 AbstractAdvisorAutoProxyCreator 的子类，主要用于处理基于 AspectJ 方式的 AOP 配置。工作原理：它和 AnnotationAwareAspectJAutoProxyCreator 类似，但主要用于处理通过 XML 配置文件或其他非注解方式配置的 AspectJ 切面。 1.2.3 AnnotationAwareAspectJAutoProxyCreator 作用：这个类是 AspectJAwareAdvisorAutoProxyCreator 的子类，它在 AbstractAdvisorAutoProxyCreator 的基础上增加了对 AspectJ 注解的支持。 工作原理：它不仅扫描容器中的 Advisor，还扫描使用了 AspectJ 注解（如 @Aspect、@Before、@After 等）的 Bean，并将这些注解配置的切面应用到匹配的 Bean 上。 2. 自动代理工作流程2.1 AnnotationAwareAspectJAutoProxyCreator的实例化2.1.1 registerBeanPostProcessors我们已经知道AnnotationAwareAspectJAutoProxyCreator其本质一个BeanPostProcessor 在 [Spring IOC 容器启动过程拓展点](obsidian://open?vault=Documents&amp;file=second-brain%2F1-tech%2FSpring%20%E5%AE%B6%E6%97%8F%2Fnew%2F3-%20Spring%20%E6%8B%93%E5%B1%95%E7%82%B9) 一文中，已经详细介绍过 一个BeanPostProcessor的实例化或者注册过程，是在registerBeanPostProcessors`流程中 12345678910111213141516AbstractApplicationContext.java@Override public void refresh() throws BeansException, IllegalStateException &#123; // 1. 创建beanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2.Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // 3.Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // 4. bean的生命周期管理和依赖关系的装配 finishBeanFactoryInitialization(beanFactory);&#125; 展开registerBeanPostProcessors 看一下123456789101112131415161718192021PostProcessorRegistrationDelegate.javapublic static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));&#125;AbstractBeanFactory.javapublic void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123; // Remove from old position, if any this.beanPostProcessors.remove(beanPostProcessor); // Track whether it is instantiation/destruction aware if (beanPostProcessor instanceof InstantiationAwareBeanPostProcessor) &#123; this.hasInstantiationAwareBeanPostProcessors = true; &#125; if (beanPostProcessor instanceof DestructionAwareBeanPostProcessor) &#123; this.hasDestructionAwareBeanPostProcessors = true; &#125; // Add to end of list this.beanPostProcessors.add(beanPostProcessor); &#125; 2.1.2 hasInstantiationAwareBeanPostProcessors根据上面的继承依赖结构，可以看出AnnotationAwareAspectJAutoProxyCreator 实现了 InstantiationAwareBeanPostProcessor ，所以hasInstantiationAwareBeanPostProcessors会被设置为true 状态标记: 当Spring容器初始化时，会扫描并注册所有的BeanPostProcessor，并在适当的时候设置这个变量的值。如果容器中注册了至少一个InstantiationAwareBeanPostProcessor，这个变量会被设置为true。用于决定是否执行某些特定的处理逻辑。例如，在实例化bean之前，Spring容器会检查这个变量以决定是否需要调用InstantiationAwareBeanPostProcessor的postProcessBeforeInstantiation方法。 性能提升：如果没有注册任何InstantiationAwareBeanPostProcessor，则可以跳过一些不必要的检查和调用，从而提高性能。 2.2 代理对象的生成时机- init 阶段业务bean 代理对象的生成时机，也可以理解成是AnnotationAwareAspectJAutoProxyCreator 的介入 bean 的生命周期，为业务bean生成代理对象的时机。 在 Spring bean 实例化一文中，已经介绍过，BeanPostProcessor 是在bean 实例化的init 阶段，通过 postProcessAfterInitialization 方法来介入普通bean 的生命周期，为其生成代理对象的 123456789101112131415161718192021222324252627public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; invokeAwareMethods(beanName, bean); applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); invokeInitMethods(beanName, wrappedBean, mbd); applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; @Override public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; for (BeanPostProcessor processor : getBeanPostProcessors()) &#123; Object current = processor.postProcessAfterInitialization(result, beanName); if (current == null) &#123; return result; &#125; result = current; &#125; return result; &#125;&#125; 当遇到AnnotationAwareAspectJAutoProxyCreator时， 会进行其postProcessAfterInitialization方法，开始执行代理对象生成的逻辑，下图debug 图片中，可以看到相关信息， 以及实际进入到的是AnnotationAwareAspectJAutoProxyCreator的父类，AbstractAutoProxyCreator 2.3 wrapIfNecessary在SpringBoot 项目启动过程中，所有的业务bean 实例化过程中都在在initializeBean 阶段进入AnnotationAwareAspectJAutoProxyCreator.postProcessAfterInitialization方法，只要这个拓展点存在。也就是说，所有的bean都会进行是否代理的判断，只是有的不需要直接返回原bean即可，有的需要就行进行代理对象的生成并返回 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public abstract class AbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware &#123; @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean; &#125; // 用于为Bean创建代理对象以实现AOP（面向切面编程）的功能 protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; // 检查Bean名称是否非空且是否已经在targetSourcedBeans集合中。 // 如果满足条件，说明这个Bean不需要代理，直接返回原始Bean。 if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; // 从advisedBeans缓存中检查是否已经记录了该Bean不需要代理,即缓存中存在且值为Boolean.FALSE，直接返回原始Bean。 if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; // 检查Bean是否是Spring的基础设施类，比如Advice、Advisor等 // 检查是否应该跳过代理该Bean if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; // 如果满足以上条件，记录该Bean不需要代理并返回原始Bean，看又出现了缓存用于提升性能 this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // Create proxy if we have advice. // 获取可以用在该bean 上的增强 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; // 如果没有需要用在该bean的Advice, this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建该bean的代理对象并记录 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; // 如果没有需要用在该bean的Advice, 记录该bean不需要代理直接返回即可 this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; &#125; wrapIfNecessary方法的重点逻辑看2步 getAdvicesAndAdvisorsForBean 为当前类寻找可用的增强 createProxy 如果找到了可用的增强，则创建代理对象2.4 getAdvicesAndAdvisorsForBean为当前类寻找可用的增强 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator &#123; @Override @Nullable protected Object[] getAdvicesAndAdvisorsForBean( Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123; List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; &#125; return advisors.toArray(); &#125; protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; // 先找出当前Spring 容器中存在的所有Advisor List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); // 根据Advisor 找出可以用在当前bean上的增强 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors; &#125; // 找出当前Spring 容器中存在的所有Advisor protected List&lt;Advisor&gt; findCandidateAdvisors() &#123; Assert.state(this.advisorRetrievalHelper != null, &quot;No BeanFactoryAdvisorRetrievalHelper available&quot;); return this.advisorRetrievalHelper.findAdvisorBeans(); &#125; // 根据Advisor 找出可以用在当前bean上的增强 protected List&lt;Advisor&gt; findAdvisorsThatCanApply( List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123; return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123; ProxyCreationContext.setCurrentProxiedBeanName(null); &#125; &#125;&#125; 最终得到当前类可用的bean, 代理逻辑挺深的 找到当前Spring 容器中所有的Advisor 找到可以用在当前类的Advisor ：对找到的所有的Advisor循环判断是否可以用在当前类上 我们重点看第二步，findAdvisorsThatCanApply 这个方法 2.4.1 findAdvisorsThatCanApply-&gt;canApply在一组候选的Advisor中，找出可以应用于指定类的Advisor。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public abstract class AopUtils &#123; public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) &#123; if (candidateAdvisors.isEmpty()) &#123; return candidateAdvisors; &#125; List&lt;Advisor&gt; eligibleAdvisors = new ArrayList&lt;&gt;(); // 先处理 IntroductionAdvisor for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; boolean hasIntroductions = !eligibleAdvisors.isEmpty(); // 再处理其他类型的Advisor for (Advisor candidate : candidateAdvisors) &#123; if (candidate instanceof IntroductionAdvisor) &#123; // already processed continue; &#125; if (canApply(candidate, clazz, hasIntroductions)) &#123; eligibleAdvisors.add(candidate); &#125; &#125; return eligibleAdvisors; &#125; // 对于IntroductionAdvisor，canApply(candidate, clazz)最终也是使用这个方法 public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; if (advisor instanceof IntroductionAdvisor) &#123; return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass); &#125; else if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pca = (PointcutAdvisor) advisor; return canApply(pca.getPointcut(), targetClass, hasIntroductions); &#125; else &#123; // It doesn&#x27;t have a pointcut so we assume it applies. return true; &#125; &#125; // 这里是真正的过滤逻辑， 先匹配类，再匹配方法 public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) &#123; Assert.notNull(pc, &quot;Pointcut must not be null&quot;); if (!pc.getClassFilter().matches(targetClass)) &#123; return false; &#125; MethodMatcher methodMatcher = pc.getMethodMatcher(); if (methodMatcher == MethodMatcher.TRUE) &#123; // No need to iterate the methods if we&#x27;re matching any method anyway... return true; &#125; IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null; if (methodMatcher instanceof IntroductionAwareMethodMatcher) &#123; introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher; &#125; Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;&gt;(); if (!Proxy.isProxyClass(targetClass)) &#123; classes.add(ClassUtils.getUserClass(targetClass)); &#125; classes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetClass)); for (Class&lt;?&gt; clazz : classes) &#123; Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz); for (Method method : methods) &#123; if (introductionAwareMethodMatcher != null ? introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions) : methodMatcher.matches(method, targetClass)) &#123; return true; &#125; &#125; &#125; return false; &#125;&#125; 整体逻辑 先把Advisor 分成两类，IntroductionAdvisor 和其他Advisor, 先检查和处理IntroductionAdvisor的主要原因是它们对目标类结构的影响较大，通过引入新的接口和功能，改变了目标类的形态。因此，在处理其他常规Advisor之前，确保IntroductionAdvisor已经被正确应用 对Advidor 依次进行类匹配、方法匹配， 看是否符合切点表达式，在以下方法中具体实现 Advisor 是一个复合概念，包括配套的Pointcut 和Advice。 Pointcut 中包含了对类的过滤条件 ClassFilter、方法的过滤条件MethodMatcher Advice 是符合Pointcut 切点条件的方法上需要执行的增强逻辑。 1canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) 观察这个方法的过滤逻辑， 其实和 Spring AOP XML配置方式原理详解中getInterceptorsAndDynamicInterceptionAdvice方法的逻辑是一样的，都是通过ClassFilter匹配类，以及MethodMatcher匹配方法实现， 只不过在手动配置方式中，我们需要手动显示写明类去自定义实现 Pointcut、MethodMatcher ，但是在自动代理的注解方式中， Spring 会自动按照我们给出的切点表达式，自动实现这一功能。 2.5 createProxy12345public class ProxyFactory extends ProxyCreatorSupport &#123; public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader); &#125;&#125; 逻辑从这里开始就和 Spring AOP 注解方式原理详解中开始完全重合了，就不再赘述 createAopProxy： 确定动态代理的类型， JDK 动态代理 or CGlib, 判断的逻辑也非常简单，可以简单认为就是有没有实现接口 实现了接口，用JDK 动态代理 没有实现接口，用CGlib 动态代理 getProxy：根据确定的动态代理，创建target 的代理对象 最终给userService 生成了一个Cglib 动态代理对象 2.6 执行目标方法不论是JDK 动态代理对象，还是CGLIB 动态代理对象， 执行目标方法时和和 Spring AOP XML配置方式原理详解 中的逻辑完全一致，底层是公用事业一套代码逻辑的，这里就不再赘述。 3. 代理对象的获取方式对比手动配置方式使用ProxyFactoryBean, 不介入到bean得生命周期，而是在实例化完成后通过getObjectForBeanInstance 完成代理对象的生成 注解方式的自动代理机制，介入bean 的生命周期，在init 阶段，通过BeanPostProcessor.postProcessAfterInitialization获取代理对象。 但是不论哪种方式， 底层判断使用哪种代理，增强织入的逻辑、以及方法的执行均是使用同一套代码完全相同的逻辑","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring AOP XML配置方式原理详解","slug":"Spring-AOP-XML配置方式原理详解","date":"2023-06-10T13:34:09.000Z","updated":"2024-07-23T07:29:58.414Z","comments":true,"path":"a10675df/","permalink":"http://example.com/a10675df/","excerpt":"","text":"本文重点分析 Spring AOP 实践一文中，通过ProxyFactoryBean手动配置动态代理的实现原理。 原理分析将基于以下示例代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class UserService &#123; public void createUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); &#125; public void deleteUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); &#125;&#125;// 定义一个前置增强public class LoggingBeforeAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); &#125;&#125;// 定义一个后置增强public class LoggingAfterAdvice implements AfterReturningAdvice &#123; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;After method: &quot; + method.getName()); &#125;&#125;// 定义一个 环绕增强public class LoggingMethodInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 方法执行前逻辑 long startTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot; 方法开始执行&quot;); // 通过反射执行目标方法 Object result = invocation.proceed(); // 方法执行后逻辑 //System.out.println(&quot;After method: &quot; + invocation.getMethod().getName()); long endTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot;方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 前置增强 --&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingMethodInterceptor&quot; class=&quot;com.example.codingInAction.aop.LoggingMethodInterceptor&quot;/&gt; &lt;!-- 使用 ProxyFactoryBean 配置代理对象 --&gt; &lt;bean id=&quot;userServiceProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;userService&quot;/&gt; &lt;!-- 拦截器 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingMethodInterceptor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 强制使用CGLIB代理 --&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 从启动入口开始分析 123456789101112public class CodingInActionApplication&#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); // 获取代理对象 UserService userService = (UserService) context.getBean(&quot;userServiceProxy&quot;); // 调用方法，观察 AOP 切面的效果 userService.createUser(&quot;john&quot;); userService.deleteUser(&quot;john&quot;); &#125;&#125; 1.ProxyFactoryBean 实例化1new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;) 该行代码对应Spring IOC 容器的启动过程 如图中所示，应用上下文启动后，IOC 容器 beanFactory 需要初始化5个bean， 都是在XML 文件中定义的数据，其实前4个都是我们非常熟悉的普通业务bean。userServiceProxy 是配置的ProxyFactoryBean, 当实例化userServiceProxy时，与常见流程略有不同,主要是以下2点 1.1 isFactoryBeanuserServiceProxy会在isFactoryBean 判断中结果为true, 需要加上FactoryBean 前缀 &amp; 后才开始进行实例化， 在介绍FactoryBean时，已经提到 FactoryBean也是一个bean , 所以在IOC 容器启动过程中，也会进行实例化 针对一个FactoryBean 使用 getBean(&quot;&amp;beanName&quot;) 可以获取 FactoryBean 实例本身，而不是 FactoryBean 创建的对象。 使用 getBean(&quot;beanName&quot;) 则获取由 FactoryBean 创建的对象。 基于以上2点，我们可以得到，在IOC 容器启动，实例化bean的过程中， 经过getBean(“&amp;userServiceProxy”)， 最终放入IOC 容器中的userServiceProxy 这个 FactoryBean本身。 1.2 getObjectForBeanInstance进入我们应该非常熟悉的getBean 流程这是IOC 容器在进行bean 的初始化流程，对于userServiceProxy 来讲，此时三级缓存中肯定不存在它的缓存， 所以会进入到单例bean 的创建流程，创建流程就不进去细看了，可以去参考文章Spring bean 实例化。只重点看getObjectForBeanInstance的处理逻辑 。 在Spring bean 实例化一文中重点讲过的用于处理FactoryBean 的getObjectForBeanInstance 方法， getBean 方法传入的参数name 是&amp;userServiceProxy， 说明经过getObjectForBeanInstance 方法处理后，最终返回了FactoryBean 本身， 在这次debug 过程中，即是ProxyFactoryBean 2.创建动态代理对象-FactoryBean.getObjectSpring IOC 容器启动完成后，就可以从容器中获取需要的bean 了1UserService userService = (UserService) context.getBean(&quot;userServiceProxy&quot;);由于userServiceProxy 是FactoryBean, 现在执行getBean(&quot;userServiceProxy&quot;), 说明需要获取由它创建的动态代理对象 2.1 getObjectForBeanInstance进入源码，再次来到getBean 流程， 此时getSingleton,一级缓存中已经有了IOC 容器启动过程的中创建userServiceProxy实例， 直接获取即可。再次进入getObjectForBeanInstance 方法 2.2 FactoryBean.getObject在getObjectForBeanInstance 方法中， 逐层深入源码来到ProxyFactoryBean.getObject 方法。 实现 FactoryBean 接口的类，可以通过重写 getObject 方法来创建并返回实际的对象实例。 分析ProxyFactoryBean.getObject() ,主要代码可以分成2个步骤 initializeAdvisorChain getSingletonInstance 2.3 initializeAdvisorChain12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private synchronized void initializeAdvisorChain() throws AopConfigException, BeansException &#123; // 检查Advisor Chain是否已经初始化 // 如果advisorChainInitialized标志已经为true，表示Advisor Chain已经初始化过了，方法直接返回，不再进行初始化。 if (this.advisorChainInitialized) &#123; return; &#125; // 检查Interceptor名称列表是否为空。如果interceptorNames为空，则跳过初始化。 if (!ObjectUtils.isEmpty(this.interceptorNames)) &#123; if (this.beanFactory == null) &#123; throw new IllegalStateException(&quot;No BeanFactory available anymore (probably due to serialization) &quot; + &quot;- cannot resolve interceptor names &quot; + Arrays.asList(this.interceptorNames)); &#125; // Globals can&#x27;t be last unless we specified a targetSource using the property... // 检查interceptorNames数组的最后一个元素是否以GLOBAL_SUFFIX结尾。 // 如果是Global类型，并且targetName为null且targetSource为EMPTY_TARGET_SOURCE， // 则抛出AopConfigException异常，表示在Global Interceptor之后需要一个目标。 if (this.interceptorNames[this.interceptorNames.length - 1].endsWith(GLOBAL_SUFFIX) &amp;&amp; this.targetName == null &amp;&amp; this.targetSource == EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException(&quot;Target required after globals&quot;); &#125; // Materialize interceptor chain from bean names. for (String name : this.interceptorNames) &#123; // 如果名称以GLOBAL_SUFFIX结尾： if (name.endsWith(GLOBAL_SUFFIX)) &#123; // 检查beanFactory是否为ListableBeanFactory类型。如果不是，抛出AopConfigException异常。 if (!(this.beanFactory instanceof ListableBeanFactory)) &#123; throw new AopConfigException( &quot;Can only use global advisors or interceptors with a ListableBeanFactory&quot;); &#125; // 如果是ListableBeanFactory类型， 则将全局Advisor添加到Advisor Chain中。 addGlobalAdvisors((ListableBeanFactory) this.beanFactory, name.substring(0, name.length() - GLOBAL_SUFFIX.length())); &#125; else &#123; // 如果名称不是以GLOBAL_SUFFIX结尾 Object advice; // 根据名称检查Bean是单例（singleton）还是原型（prototype）。 if (this.singleton || this.beanFactory.isSingleton(name)) &#123; // 如果是单例或this.singleton为true，则从beanFactory中获取实际的advice实例 // 注意，此时IOC 容器已经启动完成， getBean会从三层缓存中获取实例返回 advice = this.beanFactory.getBean(name); &#125; else &#123; // 如果是原型（prototype），则创建一个对象 advice = new PrototypePlaceholderAdvisor(name); &#125; // 将advice添加到Advisor Chain中。 addAdvisorOnChainCreation(advice); &#125; &#125; &#125; this.advisorChainInitialized = true;&#125; 该方法的主要逻辑是根据配置的interceptorNames初始化AdvisorChain，确保在执行切面逻辑时，所有的Advisor和Interceptor都已正确配置和初始化。 AdvisorChain 就是一个List数据结构，存储根据interceptorName 获取对应实例1advice = this.beanFactory.getBean(name); 对于单例bean来讲，就是从前面启动完成的IOC 容器中，根据name 通过getBean 方法取出对应的实例 2.4 getSingletonInstance12345678910111213public class ProxyFactoryBean extends ProxyCreatorSupport implements FactoryBean&lt;Object&gt;, BeanClassLoaderAware, BeanFactoryAware &#123; private synchronized Object getSingletonInstance() &#123; this.singletonInstance = getProxy(createAopProxy()); return this.singletonInstance; &#125; // 根据确定的动态代理，创建target 的代理对象 protected Object getProxy(AopProxy aopProxy) &#123; return aopProxy.getProxy(this.proxyClassLoader); &#125;&#125; 以上代码删除了部分细节，只保留重点逻辑 createAopProxy： 确定动态代理的类型， JDK 动态代理 or CGlib, 判断的逻辑也非常简单，可以简单认为就是有没有实现接口 实现了接口，用JDK 动态代理 没有实现接口，用CGlib 动态代理 getProxy：根据确定的动态代理，创建target 的代理对象 2.4.1 createAopProxy确定动态代理的类型， JDK动态代理 or CGlib动态代理 关于动态代理，可以点击阅读Java 动态代理1234567891011121314151617181920212223242526272829303132333435public class ProxyCreatorSupport extends AdvisedSupport &#123; protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this); &#125;&#125;// 确定动态代理的类型public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &#123; @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; + &quot;Either an interface or a target is required for proxy creation.&quot;); &#125; // 判断目标类是否是接口。如果是接口，使用JDK动态代理。 // 如果是代理类，也使用JDK动态代理。 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; return new JdkDynamicAopProxy(config); &#125; // 如果目标类既不是接口，也不是代理类，则使用CGLIB代理。 return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125; &#125;&#125; 传进来的config 就是userServiceProxy 这个ProxyFactoryBean, 里面有各种信息,可以根据这些信息帮助判断动态代理的类型。 2.4.2 getProxyadvised 指的就是前面示例代码中配置的ProxyFactoryBean , 它的targetSource 是要被代理的userService 3.Cglib动态代理对象-CglibAopProxy3.1 getProxy123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123class CglibAopProxy implements AopProxy, Serializable &#123; @Override public Object getProxy(@Nullable ClassLoader classLoader) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Creating CGLIB proxy: &quot; + this.advised.getTargetSource()); &#125; try &#123; // 获取目标类的 Class 对象， 并将其设置为代理类的父类，因为cglib代理是通过生成子类的方式实现的 Class&lt;?&gt; rootClass = this.advised.getTargetClass(); Assert.state(rootClass != null, &quot;Target class must be available for creating a CGLIB proxy&quot;); Class&lt;?&gt; proxySuperClass = rootClass; // 检查rootClass的名称是否包含CGLIB的类分隔符 &quot;$$&quot;，$$通常用来分隔原始类名和附加的代理类信息 // 如果包含，说明 rootClass 还有它的父类，要把proxySuperClass 设置为这个父类 if (rootClass.getName().contains(ClassUtils.CGLIB_CLASS_SEPARATOR)) &#123; proxySuperClass = rootClass.getSuperclass(); Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces(); for (Class&lt;?&gt; additionalInterface : additionalInterfaces) &#123; // 获取目标类实现的所有接口，并将这些接口添加到advised对象中。 this.advised.addInterface(additionalInterface); &#125; &#125; // Validate the class, writing log messages as necessary. // 验证代理超类是否合法 validateClassIfNecessary(proxySuperClass, classLoader); // Configure CGLIB Enhancer... // 创建Enhancer实例，用于生成代理类。 Enhancer enhancer = createEnhancer(); // 如果传入了classLoader，则将其设置为Enhancer的类加载器。 if (classLoader != null) &#123; enhancer.setClassLoader(classLoader); // 如果类加载器是SmartClassLoader的实例，并且代理类的超类是可重载的，则禁用缓存 if (classLoader instanceof SmartClassLoader &amp;&amp; ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) &#123; enhancer.setUseCache(false); &#125; &#125; // 设置代理类的父类 enhancer.setSuperclass(proxySuperClass); // 设置代理类实现的接口 enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised)); // 设置命名策略，确保生成的代理类有合适的名称 enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); // 设置生成策略，使用ClassLoaderAwareGeneratorStrategy来处理类加载器。 enhancer.setStrategy(new ClassLoaderAwareGeneratorStrategy(classLoader)); // 获取用于代理的方法回调， 回调必须实现MethodInterceptor接口 Callback[] callbacks = getCallbacks(rootClass); // 创建一个与回调数组长度相同的类型数组。将每个回调的类型添加到类型数组中。 Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length]; for (int x = 0; x &lt; types.length; x++) &#123; types[x] = callbacks[x].getClass(); &#125; // fixedInterceptorMap only populated at this point, after getCallbacks call above // 设置回调过滤器，指定哪个回调应该用于哪个方法。 enhancer.setCallbackFilter(new ProxyCallbackFilter( this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset)); enhancer.setCallbackTypes(types); // Generate the proxy class and create a proxy instance. return createProxyClassAndInstance(enhancer, callbacks); &#125; catch (CodeGenerationException | IllegalArgumentException ex) &#123; throw new AopConfigException(&quot;Could not generate CGLIB subclass of &quot; + this.advised.getTargetClass() + &quot;: Common causes of this problem include using a final class or a non-visible class&quot;, ex); &#125; catch (Throwable ex) &#123; // TargetSource.getTarget() failed throw new AopConfigException(&quot;Unexpected AOP exception&quot;, ex); &#125; &#125;&#125;class ObjenesisCglibAopProxy extends CglibAopProxy &#123; @Override protected Object createProxyClassAndInstance(Enhancer enhancer, Callback[] callbacks) &#123; // 获取代理类的Class 对象 Class&lt;?&gt; proxyClass = enhancer.createClass(); Object proxyInstance = null; // 检查是否值得尝试使用Objenesis。 if (objenesis.isWorthTrying()) &#123; try &#123; // 如果值得尝试，则尝试使用Objenesis实例化代理对象 proxyInstance = objenesis.newInstance(proxyClass, enhancer.getUseCache()); &#125; catch (Throwable ex) &#123; logger.debug(&quot;Unable to instantiate proxy using Objenesis, &quot; + &quot;falling back to regular proxy construction&quot;, ex); &#125; &#125; // 如果proxyInstance仍然是null，则使用常规方式通过默认构造函数实例化代理对象 if (proxyInstance == null) &#123; // Regular instantiation via default constructor... try &#123; // 获取代理类的构造函数，根据是否有构造参数决定使用哪个构造函数 Constructor&lt;?&gt; ctor = (this.constructorArgs != null ? proxyClass.getDeclaredConstructor(this.constructorArgTypes) : proxyClass.getDeclaredConstructor()); // 设置构造函数可访问， private 构造函数是不可访问的 ReflectionUtils.makeAccessible(ctor); // 使用构造函数实例化代理对象 proxyInstance = (this.constructorArgs != null ? ctor.newInstance(this.constructorArgs) : ctor.newInstance()); &#125; catch (Throwable ex) &#123; throw new AopConfigException(&quot;Unable to instantiate proxy using Objenesis, &quot; + &quot;and regular proxy instantiation via default constructor fails as well&quot;, ex); &#125; &#125; // 设置回调用 ((Factory) proxyInstance).setCallbacks(callbacks); return proxyInstance; &#125; &#125; 3.2 ObjenesisCglibAopProxy从2.4.1-createAopProxy 代码中可以看出，如果是cglib 动态代理，最终返回的是ObjenesisCglibAopProxy，而不是直接返回CglibAopProxy 在Spring AOP框架中，CglibAopProxy和ObjenesisCglibAopProxy都用于创建CGLIB代理，二者的区别与联系如下 实例化方式 CglibAopProxy: 直接使用CGLIB库的Enhancer类来创建代理类，通常会调用目标类的构造函数。 ObjenesisCglibAopProxy: 利用Objenesis库来实例化代理对象，避免了直接调用目标类的构造函数，提供了一种更灵活的实例化方式。 应用场景 CglibAopProxy: 适用于一般的CGLIB代理场景，当目标类的构造函数没有特殊要求时，是Spring AOP的默认选择。 ObjenesisCglibAopProxy: 适用于需要在不调用构造函数的情况下创建代理的场景，特别是当目标类的构造函数较为复杂或有特殊限制时，提供了一种更灵活的解决方案。 3.3 getCallbacks-自动实现 MethodInterceptor在Java 动态代理一文， 关于 CGLIB 动态代理，我们手动实现了一个MethodInterceptor, 并将其设置为Enchaner的Callback 12345678910111213141516171819202122public class HelloWorldInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;After method: &quot; + method.getName()); return result; &#125; &#125;public class CglibDynamicProxyDemo &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(HelloWorldImpl.class); enhancer.setCallback(new HelloWorldInterceptor()); HelloWorld proxy = (HelloWorld) enhancer.create(); proxy.sayHello(); proxy.sayBye(); &#125; &#125; 3.3.1 Callback12345678package org.springframework.cglib.proxy; public interface Callback &#123; &#125;package org.springframework.cglib.proxy;public interface MethodInterceptor extends Callback &#123; Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable;&#125; Callback 是一个接口，MethodInterceptor 是其常用的实现之一。MethodInterceptor 其核心方法是 intercept，负责拦截代理对象的方法调用，应用相应的Advice 增强逻辑，并最终调用目标对象的方法。 3.3.2 MethodInceptor 在CglibAopProxy的实现在此次XML 配置形式的AOP 中， 并没有手动实现MethodInceptor 的逻辑。 MethodInceptor 的具体实现 由CglibAopProxy 背后帮我们偷偷做了， 实现的逻辑这行代码中， 进去看下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Callback[] callbacks = getCallbacks(rootClass);private Callback[] getCallbacks(Class&lt;?&gt; rootClass) throws Exception &#123; // Parameters used for optimization choices... // 是否需要公开代理对象。 boolean exposeProxy = this.advised.isExposeProxy(); // 代理配置是否被冻结。 boolean isFrozen = this.advised.isFrozen(); // 目标源是否是静态的（即目标对象在创建时已经确定，不会变化）。 boolean isStatic = this.advised.getTargetSource().isStatic(); // Choose an &quot;aop&quot; interceptor (used for AOP calls). // 创建一个DynamicAdvisedInterceptor实例，用于处理AOP调用。这是主要的AOP拦截器。 Callback aopInterceptor = new DynamicAdvisedInterceptor(this.advised); // Choose a &quot;straight to target&quot; interceptor. (used for calls that are // unadvised but can return this). May be required to expose the proxy. Callback targetInterceptor; if (exposeProxy) &#123; targetInterceptor = (isStatic ? new StaticUnadvisedExposedInterceptor(this.advised.getTargetSource().getTarget()) : new DynamicUnadvisedExposedInterceptor(this.advised.getTargetSource())); &#125; else &#123; targetInterceptor = (isStatic ? new StaticUnadvisedInterceptor(this.advised.getTargetSource().getTarget()) : new DynamicUnadvisedInterceptor(this.advised.getTargetSource())); Callback targetDispatcher = (isStatic ? new StaticDispatcher(this.advised.getTargetSource().getTarget()) : new SerializableNoOp()); Callback[] mainCallbacks = new Callback[] &#123; aopInterceptor, // for normal advice 处理常规的AOP增强。 // 优化情况下直接调用目标对象的方法。 targetInterceptor, // invoke target without considering advice, if optimized // 对于没有增强的方法，什么也不做。 new SerializableNoOp(), // no override for methods mapped to this // 直接调用静态目标的方法。 targetDispatcher, // 代理配置的调度器。 this.advisedDispatcher, // 处理equals方法的拦截器。 new EqualsInterceptor(this.advised), // 处理equals方法的拦截器。 new HashCodeInterceptor(this.advised) &#125;; Callback[] callbacks; return callbacks; &#125;省略了部分代码只看重点，可以看到最终返回的Callback数组中包含6个数据，其中包括多个MethodInceptor的实现类。提前看下创建完成的userService 实例debug 信息， Callback信息和代码中的数据是可以一一对应上的 MethodInterceptor 在CglibAopProxy 有多个实现，均已私有类的形式存在，下面重点分析一下DynamicAdvisedInterceptor，常规的AOP 增强逻辑的织入均是由它实现。 3.4 执行目标方法-DynamicAdvisedInterceptor.intercept3. 4 方法执行-intercept经过getProxy获取Cglib 动态代理对象后， 将通过代理对象执行业务逻辑12userService.createUser(&quot;john&quot;); userService.deleteUser(&quot;john&quot;); 下面将跟随debug 信息来分析 代理对象方法的执行。执行userService.createUser(&quot;john&quot;); 代码会来到CglibAopProxy中DynamicAdvisedInterceptor.intercept 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable &#123; private final AdvisedSupport advised; public DynamicAdvisedInterceptor(AdvisedSupport advised) &#123; this.advised = advised; &#125; @Override @Nullable public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try &#123; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; // Get as late as possible to minimize the time we &quot;own&quot; the target, in case it comes from a pool... target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); // 获取适用于当前类当前方法的增强，还记得“筛选条件”吗 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // 如果拦截器链为空并且方法是public的,直接通过methodProxy调用目标对象的方法。 if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; // We need to create a method invocation... // 创建一个CglibMethodInvocation对象并调用其proceed方法，执行拦截器链中的所有拦截器逻辑。 retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125; @Override public boolean equals(@Nullable Object other) &#123; return (this == other || (other instanceof DynamicAdvisedInterceptor &amp;&amp; this.advised.equals(((DynamicAdvisedInterceptor) other).advised))); &#125; /** * CGLIB uses this to drive proxy creation. */ @Override public int hashCode() &#123; return this.advised.hashCode(); &#125; &#125; MethodIntercept.intercept， 在本示例中指的是具体实现类DynamicAdvisedInterceptor.intercept 是目标方法执行的拦截入口，拦截后，重点逻辑有2处 getInterceptorsAndDynamicInterceptionAdvice获取当前类当前方法上可用的advice, CglibMethodInvocation.proceed, 通过ReflectiveMethodInvocation.proceed递归Advice 增强逻辑 和目标方法 3.4.1 getInterceptorsAndDynamicInterceptionAdvice在增强逻辑和目标方法执行前，，需要先把Spring 容器中所有Advice 进行筛选，获取在当前类当前方法上可用的advice。 关于筛选逻辑，使用的是Advisor 、Pointcut 和Advice。 Advisor 是一个复合概念，包括配套的Pointcut 和Advice。 Pointcut 中包含了对类的过滤条件 ClassFilter、方法的过滤条件MethodMatcher Advice 是符合Pointcut 切点条件的方法上需要执行的增强逻辑。 看图中高亮的66行代码，就是我们在自定义的 LoggingAdvisor、LoggingPointcut重写的方法最终可以用在UserService.createUser 上的Advice/Interceptor 有3个 一个自定义的LoggingAdvisor 2个直接定义的Advice, LoggingBeforeAdvice、LoggingAfterAdvice， 它们会被处理成DefaulrPointcutAdvisor, 默认对所有类的所有方法均有效 当执行delete方法是，符合条件的interceptor 只有2个, 符合预期结果 缓存的应用针对每个方法可用的advice 列表， 这里使用了缓存来提升性能12345678910public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object&gt; cached = this.methodCache.get(cacheKey); if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this, method, targetClass); this.methodCache.put(cacheKey, cached); &#125; return cached; &#125; 3.4.2 CglibMethodInvocation.proceedCglibMethodInvocation是CglibAopProxy中的一个内部类，它继承了`ReflectiveMethodInvocation 并重写了 proceed方法1234567891011121314151617181920212223242526272829303132333435363738394041class CglibAopProxy implements AopProxy, Serializable &#123; private static class CglibMethodInvocation extends ReflectiveMethodInvocation &#123; @Override @Nullable public Object proceed() throws Throwable &#123; return super.proceed(); &#125;&#125;````#### ReflectiveMethodInvocation`ReflectiveMethodInvocation.proceed` 是CGLIB 动态代理处理目标方法调用 核心逻辑。它根据`currentInterceptorIndex`来判断是执行Advice 增强逻辑，还是执行目标方法的调用```javapublic class ReflectiveMethodInvocation implements ProxyMethodInvocation, Cloneable &#123; public Object proceed() throws Throwable &#123; // We start with an index of -1 and increment early. // 检查当前拦截器索引是否已经到达拦截器链的末尾。如果是，则调用invokeJoinpoint方法，直接执行目标方法。 if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return invokeJoinpoint(); &#125; // 增加当前拦截器索引，并获取下一个拦截器或增强逻辑对象 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; return proceed(); &#125; &#125; else &#123; return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125; &#125;&#125; ReflectiveMethodInvocation.proceed 的递归调用ReflectiveMethodInvocation.proceed代码中并没有使用for 循环来执行多个Advice, 而是使用递归调用的方式 实现Advice 增强逻辑 和目标方法的执行 如何理解其中递归调用 如果Advice增强 还未全部执行，则取下一个执行Advice, 通过MethodInterceptor.invoke执行增强逻辑，同时在MethodInterceptor.invoke 同样有对ReflectiveMethodInvocation.proceed,继续判断如果是增强，执行同样的操作。 如果所有Advice增强 均已被访问过，则调用invokeJoinpoint()执行目标方法 所以当DynamicAdvisedInterceptor.intercept中执行到new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed()， 首先来到父类 ReflectiveMethodInvocation.proceed， 通过currentInterceptorIndex 判断执行LoggingAdviorLoggingMethodInterceptor.invoke 的增强逻辑。 进入LoggingAdviorLoggingMethodInterceptor.invoke后，运行增强逻辑，再次调用 ReflectiveMethodInvocation.proceed， 通过currentInterceptorIndex 判断执行增强LoggingBeforeAdvice， 程序将LoggingBeforeAdvice包装成了MethodBeforeAdviceIntercept， 调用MethodBeforeAdviceIntercept.invoke 进入MethodBeforeAdviceInceptor.invoke后，再次调用ReflectiveMethodInvocation.proceed, 通过currentInterceptorIndex 判断执行增强LoggingAfterAdvice,程序将LoggingAfterAdvice包装成了AfterReturningAdviceIntercept， 调用AfterReturningAdviceIntercept.invoke 进入MethodBeforeAdviceInceptor.invoke后，再次调用ReflectiveMethodInvocation.proceed, 通过currentInterceptorIndex 判断需要执行invokeJoinpoint 执行new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed()，来到父类 ReflectiveMethodInvocation.proceed 通过currentInterceptorIndex 判断执行LoggingAdviorLoggingMethodInterceptor.invoke 的增强逻辑。 再次调用 ReflectiveMethodInvocation.proceed，通过currentInterceptorIndex 判断执行增强LoggingBeforeAdvice 再次调用 ReflectiveMethodInvocation.proceed定义好的before 逻辑执行完成后，再次进入ReflectiveMethodInvocation.proceed， 执行afterAdvice 通过currentInterceptorIndex 判断执行增强LoggingAfterAdvice 再次进入ReflectiveMethodInvocation.proceed，可以看到advice 已经全部执行了，可以去调用invokeJoinpoint,即实际的业务方法了 后面一层层出栈将Advice 的全部执行完成即可。 4. JDK动态代理对象-JdkDynamicAopProxy如果想要使用JDK 动态代理来实现，需要修改下代码，涉及到的代码修改后如下 123456789101112131415161718192021222324252627282930313233343536public interface UserI &#123; void createUser(String username); void deleteUser(String username); &#125;public class UserService implements UserI &#123; @Override public void createUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); &#125; @Override public void deleteUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); &#125;&#125;public class CodingInActionApplication &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); UserI userService = (UserI) context.getBean(&quot;userServiceProxy&quot;); // 调用方法，观察 AOP 切面的效果 userService.createUser(&quot;john&quot;); userService.deleteUser(&quot;john&quot;); &#125;&#125; XML 文件修改如下1234567891011121314151617181920212223242526272829303132&lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 前置增强--&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingAdvisor&quot; class=&quot;com.example.codingInAction.aop.LoggingAdvisor&quot;/&gt; &lt;bean id=&quot;userServiceProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;userService&quot;/&gt; &lt;!-- 指定使用的接口 --&gt; &lt;property name=&quot;proxyInterfaces&quot;&gt; &lt;list&gt; &lt;value&gt;com.example.codingInAction.service.UserI&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 拦截器 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingAdvisor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 强制使用JDK动态代理 --&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; 4.1 getProxy通过Proxy类，利用反射创建代理对象，整体比较简单，可以参考Java 动态代理中对Proxy 类的介绍，这里不再赘述 123456789101112final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; @Override public Object getProxy(@Nullable ClassLoader classLoader) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Creating JDK dynamic proxy: &quot; + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this); &#125; &#125; 4.2 实现 InvocationHandler观察JdkDynamicAopProxy 这个类的定义，可以看到这个类本身就实现了InvocationHandler1final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123;&#125; 在java 动态代理中说到，通过Proxy 类获取了一个参数为InvocationHandler 的构造函数创建代理对象，并将自定义的InvocationHandler 传进去 观察JdkDynamicAopProxy 创建代理对象的过程，遵循这一原则，且传进入的参数就是JdkDynamicAopProxy 本身。 4.2 执行目标方法-InvocationHandler.invoke根据在java 动态代理中学习的源码，对于JDK 动态代理，当执行代理对象的方法时，首先会被自定义InvocationHandler.invoke 方法。 所以这里就是进入到JdkDynamicAopProxy.invoke 方法中 InvocationHandler.invoke 和CGLIB 动态代理中的MethodInterceptor.intercept一样，负责拦截代理对象的方法调用，应用相应的Advice 增强逻辑，并最终调用目标对象的方法。 所以其重点逻辑也是一样的 getInterceptorsAndDynamicInterceptionAdvice获取当前类当前方法上可用的advice ReflectiveMethodInvocation.proceed, 通过ReflectiveMethodInvocation.proceed递归Advice 增强逻辑 和目标方法, JdkDynamicAopProxy并没有继承ReflectiveMethodInvocation实现一个新的子类，而是直接使用的ReflectiveMethodInvocation 123456789101112131415161718192021222324252627282930313233343536373839404142434445final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // Get the interception chain for this method. List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; // We need to create a method invocation... MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); &#125; // Massage return value if necessary. Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException( &quot;Null return value from advice does not match primitive return type for: &quot; + method); &#125; return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; // Must have come from TargetSource. targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125; &#125;&#125; 4.3.1 getInterceptorsAndDynamicInterceptionAdvice和3.4.1 小节中的内容一样 4.3.2 ReflectiveMethodInvocation.proceed和3.4.1 小节中的逻辑一致， 都是通过ReflectiveMethodInvocation.proceed的递归调用实现增强逻辑和目标方法的执行 5. MethodInterceptor.invoke &amp; MethodInterceptor.intercpt在前面的内容中， 多次提到MethodInterceptor ， MethodInterceptor.invoke和MethodInterceptor.intercpt 这2个方法，要注意区分一下， 这2个MethodInterceptor指的不是同一个，虽然二者的功能类似 5.1 org.springframework.cglib.proxy.MethodInterceptororg.springframework.cglib.proxy.MethodInterceptor 是 CGLIB（Code Generation Library）库中的接口， 1234package org.springframework.cglib.proxy;public interface MethodInterceptor &#123; Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable;&#125; 在Java 动态代理 CGLIB 动态部分，使用的是这个MethodInterceptor 123456789public class HelloWorldInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;After method: &quot; + method.getName()); return result; &#125; &#125; 5.2 org.aopalliance.intercept.MethodInterceptororg.aopalliance.intercept.MethodInterceptor 是 AOP Alliance 规范中的一个接口，Spring AOP 采用了这一规范来提供方法拦截功能。AOP Alliance 是一个标准化的 AOP API 规范，旨在提供统一的 AOP 编程接口。 123public interface MethodInterceptor extends Interceptor &#123; Object invoke(MethodInvocation invocation) throws Throwable;&#125; 在Spring AOP 实践， 实现环绕增强时，使用的是这个MethodInterceptor 12345678910111213141516171819// 定义一个 环绕增强public class LoggingMethodInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 方法执行前逻辑 long startTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot; 方法开始执行&quot;); // 通过反射执行目标方法 Object result = invocation.proceed(); // 方法执行后逻辑 //System.out.println(&quot;After method: &quot; + invocation.getMethod().getName()); long endTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot;方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125; 5.3 区别org.springframework.cglib.proxy.MethodInterceptor 和 org.aopalliance.intercept.MethodInterceptor 都是强大的方法拦截器接口，允许在方法调用前后添加自定义逻辑。各自有不同的适用场景和实现机制。 适用范围： org.springframework.cglib.proxy.MethodInterceptor 适用于基于类的代理，尤其是无接口的类。 org.aopalliance.intercept.MethodInterceptor 适用于基于接口的代理，广泛用于 Spring AOP 框架中。 实现机制： CGLIB 基于字节码操作，通过生成目标类的子类实现代理。 AOP Alliance 基于接口，通过代理接口实现方法拦截。 依赖库： org.springframework.cglib.proxy.MethodInterceptor 是 CGLIB 库的一部分，需要引入 CGLIB 依赖。 org.aopalliance.intercept.MethodInterceptor 是 AOP Alliance 规范的一部分，Spring AOP 默认支持这一规范。 方法签名： CGLIB 的 MethodInterceptor 使用 intercept 方法，其参数包括目标对象、方法对象、参数数组和方法代理。 AOP Alliance 的 MethodInterceptor 使用 invoke 方法，其参数是一个封装了方法调用信息的 MethodInvocation 对象。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring 启动过程 拓展点","slug":"Spring-启动过程-拓展点","date":"2023-05-28T09:18:57.000Z","updated":"2024-09-05T11:38:58.320Z","comments":true,"path":"114991e5/","permalink":"http://example.com/114991e5/","excerpt":"","text":"Spring框架提供了丰富的扩展点，允许开发者在bean的生命周期的不同阶段插入自定义逻辑，从而增强应用的功能和灵活性。拓展点包括BeanFactoryPostProcessor、BeanPostProcessor、各种Aware等。下面来具体讲解各个拓展点的作用以及它们是如何介入到bean 的生命周期中。 除了Aware接口和BeanPostProcessor，还有许多其他扩展点，如BeanFactoryPostProcessor、ApplicationListener、InitializingBean、FactoryBean等。这些扩展点的合理使用可以极大地提高Spring应用的可扩展性和可维护性。 1.BeanFactoryPostProcessorBeanFactoryPostProcessor 是 Spring 框架中的一个函数式接口，它在bean 开始整个创建流程之前 起作用。 通过实现该接口可以在 Bean 开始整个创建流程之前读取 BeanFactory 中的 BeanDefinition 并进行修改，比如调整 Bean 的属性、依赖关系等定义。 Spring 自带了一些 BeanFactoryPostProcessor 的实现，用户也可以根据需要自定义实现以适应特定场景，从而实现更灵活的应用配置。 12345@FunctionalInterface public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException; &#125; 1.1 注册时机 and 作用过程-invokeBeanFactoryPostProcessors前面说到BeanFactoryPostProcessor 是 Spring 框架在bean 开始整个创建流程之前 起作用。具体的位置如下,位于refresh 中的invokeBeanFactoryPostProcessors 方法中， 通过invoke 这个命名就可以知道这里需要调用所有BeanFactoryPostProcessor 的具体实现逻辑对bean 定义进行修改 12345678910111213141516AbstractApplicationContext.java@Override public void refresh() throws BeansException, IllegalStateException &#123; // 1. 创建beanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2.BeanFactoryPostProcessor起作用 invokeBeanFactoryPostProcessors(beanFactory); // 3.注册 BeanPostProcessor registerBeanPostProcessors(beanFactory); // 4. bean的生命周期管理和依赖关系的装配 finishBeanFactoryInitialization(beanFactory);&#125; 执行BeanFactoryPostProcessor逻辑前， 需要有BeanFactoryPostProcessor的实例，那么BeanFactoryPostProcessor是如何实例化的呢, 下面来看下 BeanFactoryPostProcessor 的实例化和具体起作用的过程 先进入123AbstractApplicationContext.javaprotected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); &#125; 再进入PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors的方法，可以看到此时传进来了3个BeanFactoryPostProcessor，这3个BeanFactoryPostProcessor 是在应用上下文ApplicationContext 里面存储维护的，但是此时还没有看到自定义的 来看一下PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors 的具体处理逻辑.BeanFactoryPostProcessors将bean 分成了好几类分别进行处理， 1.2 BeanDefinitionRegistryPostProcessor12345public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException; &#125; BeanDefinitionRegistryPostProcessor 继承了BeanFactoryPostProcessor ， 并增加了一个方法， 在执行BeanFactoryPostProcessor 前，需要找出所有的BeanDefinitionRegistryPostProcessor, 并且先执行自己的postProcessBeanDefinitionRegistry方法，再执行继承来的postProcessBeanFactory 方法。看以下重点代码,BeanDefinitionRegistryPostProcessor包括参数中传进来来的和从beanFactory 中找到的， 其中从beanFactory找到的BeanDefinitionRegistryPostProcessor，还没有进行实例化，需要实例化后才能使用，这个实例化的过程和业务bean 的实力化过程是同一个 123456789101112131415161718192021222324if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); // 从传参中找到 BeanDefinitionRegistryPostProcessor for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; registryProcessor.postProcessBeanDefinitionRegistry(registry); registryProcessors.add(registryProcessor); &#125; // 从beanFactory 中找到BeanDefinitionRegistryPostProcessor并进行实例化 postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); &#125; &#125; //先执行BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法 invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); //再执行BeanFactoryPostProcessor的postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); &#125; 1.3 执行顺序- Ordered在invoke 完BeanDefinitionRegistryPostProcessor后，就开始按照优先级顺序处理BeanFactoryPostProcessor。 Spring提供了一些机制来管理多个BeanFactoryPostProcessor的执行顺序，其执行顺序分别是 PriorityOrdered 接口 优先级接口 Ordered NonOrdered 1.3.1 优先级接口 OrderedSpring允许BeanFactoryPostProcessor实现Ordered接口来指定执行顺序。Ordered接口要求实现一个方法getOrder()，该方法返回一个整数，定义了BeanFactoryPostProcessor的执行顺序。数值越小，优先级越高，越优先执行 例如，以下是一个BeanFactoryPostProcessor实现，它使用了Ordered接口来指定其执行顺序： 123456789101112131415161718 @Component public class CustomBeanFactoryPostProcessor implements BeanFactoryPostProcessor, Ordered &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; // 获取名为 &quot;myBean&quot; 的 BeanDefinitionBeanDefinition beanDefinition = beanFactory.getBeanDefinition(&quot;myBean&quot;); // 修改 &quot;myBean&quot; 的属性值 beanDefinition.getPropertyValues().add(&quot;name&quot;, &quot;Modified by BeanFactoryPostProcessor&quot;); &#125; @Override public int getOrder() &#123; return 10; // 数值越小，优先级越高 &#125; &#125; 1.3.2 PriorityOrdered 接口PriorityOrdered是Ordered接口的一个子接口，允许BeanFactoryPostProcessor在其他普通Ordered执行。这主要用于那些必须首先应用的处理器，比如那些涉及配置如何加载的处理器。12345678910111213public class CustomPriorityOrderedBeanFactoryPostProcessor implements BeanFactoryPostProcessor, PriorityOrdered &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // 定制处理逻辑 System.out.println(&quot;Executing CustomPriorityOrderedBeanFactoryPostProcessor&quot;); &#125; @Override public int getOrder() &#123; return 5; // 数值越小，优先级越高 &#125; &#125; 1.3.3 NonOrderedNonOrdered并不是一个接口，指的是没有实现Ordered 或者 PriorityOrdered 的 BeanFactoryPostProcessor， 它会放在最后执行。 所以，综上，在Spring容器启动过程中，BeanFactoryPostProcessor的调用顺序如下： 首先，实现PriorityOrdered的BeanFactoryPostProcessor按照它们的顺序值被调用。 其次，实现Ordered接口的普通BeanFactoryPostProcessor按照它们的顺序值被调用。 最后，未实现任何排序接口的BeanFactoryPostProcessor按照它们的注册顺序被调用。 1.3.4 处理逻辑在invoke 完BeanDefinitionRegistryPostProcessor后，就开始按照优先级顺序处理BeanFactoryPostProcessor。 代码逻辑会先找出所有的BeanFactoryPostProcessor， 然后将其分类为PriorityOrderedBeanFactoryPostProcessor、OrderedBeanFactoryPostProcessor、NonOrderedBeanFactoryPostProcessor, 并按照优先级顺序分别invoke postProcessBeanFactory 方法 123456789101112131415161718192021222324252627public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // 找出所有的 BeanFactoryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // 分类 for (String ppName : postProcessorNames) &#123; // processedBeans保存已处理的BeanFactoryPostProcessor 名称 if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // orderedPostProcessor 在后面也会通过getBean实例化，逻辑比较简单，我省略了，nonOrderedPostProcessor同理 orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // 分别invoke postProcessBeanFactory方法 invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);&#125; 1.4 BeanFactoryPostProcessor也是bean无论是 BeanDefinitionRegistryPostProcessor,还是BeanFactoryPostProcessor, 在通过getBeanNamesForType获取名称后，invoke postProcessBeanFactory 方法之前，需要先进行实例化操作（都要调用方法了，肯定要有对象存在啊）。 BeanFactoryPostProcessor 的实例化过程和业务bean 的实例化过程 完全相同，都是getBean流程完成实例化操作。 12345678910111213141516// 实例化 BeanDefinitionRegistryPostProcessorpostProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); // 实例化 BeanFactoryPostProcessorString[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); 2.BeanPostProcessorBeanPostProcessor是Spring框架中一个非常强大的扩展点，提供的一个接口，用于在bean的init操作前后执行自定义逻辑。Spring AOP就是通过BeanPostProcessor实现的 BeanPostProcessor也是一个接口，包含2个方法 postProcessBeforeInitialization: 在bean init之前执行。 postProcessAfterInitialization: 在bean init 之后执行。 12345public interface BeanPostProcessor &#123; Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 2.1 注册时机-registerBeanPostProcessors依然回到refresh方法中 ，其中registerBeanPostProcessors 方法涉及到BeanPostProcessor的注册流程。 12345678910111213141516AbstractApplicationContext.java@Override public void refresh() throws BeansException, IllegalStateException &#123; // 1. 创建beanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2.BeanFactoryPostProcessor起作用 invokeBeanFactoryPostProcessors(beanFactory); // 3.注册 BeanPostProcessor registerBeanPostProcessors(beanFactory); // 4. bean的生命周期管理和依赖关系的装配 finishBeanFactoryInitialization(beanFactory);&#125; 进入registerBeanPostProcessors分析具体代码 123456789101112131415161718192021222324252627282930PostProcessorRegistrationDelegate.javapublic static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; // 找出所有 BeanPostProcessor 名称 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); //按照优先级别 对BeanPostProcessor 名称 List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; // orderedPostProcessor 在后面也会通过getBean 实例化，逻辑比较简单，我省略了，nonOrderedPostProcessor同理 orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); registerBeanPostProcessors(beanFactory, orderedPostProcessors); registerBeanPostProcessors(beanFactory, internalPostProcessors);&#125; 可以看到registerBeanPostProcessors 的整理流程比较类似，都是 用beanFactory.getBeanNamesForType找出所有名字 分类 getBean 实例化 一个比较明显的区别是 BeanFactoryPostProcessor在实例化后会直接调用接口postProcessBeanFactory执行逻辑，但是BeanPostProcessor 的实例只会先添加到beanFactory 中，等到业务bean的init 阶段才会执行逻辑。 由此可见 注册BeanFactoryPostProcessor 用到的是invokeBeanFactoryPostProcessors，BeanPostProcessor 只是registerBeanPostProcessors， 这里的方法命名还是相当准确的 2.2 执行顺序-Ordered从上面的代码中可以看到 Spring 管理多个BeanPostProcessor的执行顺序，其实现和BeanFactoryPostProcessor 完全一致， PriorityOrdered 接口 优先级接口 Ordered NonOrdered 这里给出一些实际代码示例就不再赘述了。123456789101112131415161718192021222324252627282930313233343536373839404142public class MyBeanPostProcessor implements BeanPostProcessor, Ordered &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 自定义逻辑 return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; // 自定义逻辑 return bean; &#125; @Override public int getOrder() &#123; return 10; // 返回一个数值来指定执行顺序 &#125;&#125;public class PriorityLoggingBeanPostProcessor implements BeanPostProcessor, PriorityOrdered &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 在bean初始化之前打印日志 System.out.println(&quot;Before Initializing Bean &#x27;&quot; + beanName + &quot;&#x27;: &quot; + bean.getClass().getSimpleName()); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; // 初始化后的处理可以在这里添加，此示例仅在初始化前打印 return bean; &#125; @Override public int getOrder() &#123; // 返回值较低表示优先级较高，此处返回最高优先级 return PriorityOrdered.HIGHEST_PRECEDENCE; &#125;&#125; 2.3 BeanPostProcessor也是bean通过registerBeanPostProcessors 代码可知， BeanPostProcessor和Bean FactoryPostProcessor 一样, 通过getbean 进行实例化的1BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); 并在实例化后添加到beanFactory 中进行管理12345678PostProcessorRegistrationDelegate.javaprivate static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanPostProcessor&gt; postProcessors) &#123; for (BeanPostProcessor postProcessor : postProcessors) &#123; beanFactory.addBeanPostProcessor(postProcessor); &#125; &#125; 2.4 Spring 启动过程中会用到的 BeanPostProcessor2.4.1 InstantiationAwareBeanPostProcessor 图中置灰的2个方法，是继承自BeanPostProcessor的2个方法 InstantiationAwareBeanPostProcessor自有的3个方法中有2个方法名称和BeanPostProcessor中方式名称相同，但是入参和返回值略有不同 postProcessBeforeInstantiation1234@Nullable default Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; 在bean 的实例化之前，会调用这个方法，其逻辑存在于下面代码中resolveBeforeInstantiation方法中。 这个方法可以返回一个代理对象，来替代 Bean 的默认实例化过程。但通常情况下，代理对象是在 Bean 实例化之后创建的，所以这个方法一般返回 null。 1234567891011@Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; Object beanInstance = doCreateBean(beanName, mbdToUse, args);&#125; postProcessAfterInstantiation在 bean create之后，populate之前调用。返回 true 表示允许属性注入，返回 false 则跳过属性注入。 123default boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; return true; &#125; postProcessProperties在populate 属性注入过程中调用，可以对属性值进行检查或修改。12345@Nullable default PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) throws BeansException &#123; return null; &#125; 2.4.2 SmartInstantiationAwareBeanPostProcessorSmartInstantiationAwareBeanPostProcessor 是 Spring 框架中的一个接口，它扩展了 InstantiationAwareBeanPostProcessor 接口，提供了更细粒度的控制和额外的钩子方法来介入 Spring Bean 的实例化过程。这个接口主要用于在 Bean create之前、create之后、populate之前、populate之后等多个阶段执行自定义逻辑，从而实现更加复杂和灵活的 Bean 初始化控制。 predictBeanType在实际创建 Bean 实例之前预测其类型。这对于提前检测某些类型相关的元数据很有用。123default Class&lt;?&gt; predictBeanType(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; determineCandidateConstructors确定要用于创建 Bean 实例的候选构造函数。允许自定义选择用于实例化 Bean 的构造函数。 12345default Constructor&lt;?&gt;[] determineCandidateConstructors(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125; getEarlyBeanReference允许在 Bean 实例化之前提前暴露 Bean 的引用。通常用于解决循环依赖问题 123default Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; return bean; &#125; 2.5 BeanFactoryPostProcessor vs BeanPostProcessorBeanFactoryPostProcessor和BeanPostProcessor名称相似，但是作用大不相同，下面给出一些对比 为了更清楚地比较 BeanFactoryPostProcessor 和 BeanPostProcessor，下表总结了它们的关键差异： 特征 BeanFactoryPostProcessor BeanPostProcessor 目的 修改或调整 bean 的配置元数据 在 bean 初始化前后对实例进行修改或增强 作用对象 操作 BeanDefinition（bean 的定义） 直接操作 bean 实例 执行时机 在所有 bean 实例化前，容器启动过程中，加载完所有 bean 定义之后执行 对每个 bean，分别在初始化Initialization方法之前和之后执行 方法接口 postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) postProcessBeforeInitialization(Object bean, String beanName) postProcessAfterInitialization(Object bean, String beanName) 影响范围 可以修改整个容器中的所有 bean 定义 对每个 bean 实例的修改是独立的 应用示例 修改 bean 的作用域、解析配置文件中的占位符等 创建代理对象以实现 AOP，执行自定义初始化或清理代码等 执行顺序控制接口 通常可以通过实现 Ordered 或 PriorityOrdered 接口来控制执行顺序 同样可以实现 Ordered 或 PriorityOrdered 来控制执行顺序 3. 无所不知的AwareSpring框架中，Aware接口的作用是让bean能够拿到对Spring容器中的各种资源，从而增强bean的功能和灵活性。 不同的 Aware 基本都能够见名知意，Aware之前的名字就是可以拿到什么资源，例如BeanNameAware可以拿到BeanName，以此类推。调用时机需要注意：所有的Aware方法都是在init阶段之前调用的 3.1 Aware调用时机在Spring 启动过程中涉及到Aware ,都是在populate后，init 之前调用的。 其调用代码如下， 12345678910protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; // 调用 bean 相关的 Aware invokeAwareMethods(beanName, bean); // 调用 ApplicationContext 的相关 Aware applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); invokeInitMethods(beanName, wrappedBean, mbd); applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; 在Spring 中一些会用到Aware 列举如下， 这也是在实际运行中它们会被调用的顺序 BeanNameAware: 最先被调用，用于设置bean的名称。 BeanClassLoaderAware: 在bean实例化后，用于设置bean的类加载器。 BeanFactoryAware: 在bean populate 完成后，用于设置bean的BeanFactory。 EnvironmentAware: 在bean的populate 完成后，用于设置bean的环境信息。 EmbeddedValueResolverAware: 在bean的populate 完成后，用于设置Spring EL解析器。 ApplicationContextAware: 最后被调用，用于设置bean的ApplicationContext。 下面将分组进行解释 3.2 Aware Group 1- Bean 相关Aware在invokeAwareMethods方法中，会调用以下3个Aware BeanNameAware: 用于让bean获取其在容器中的名称。在实例化之后，设置依赖之前被调用。 BeanClassLoaderAware: 用于让bean获取类加载器。这通常在bean实例化之后和依赖注入之前被调用。 BeanFactoryAware: 用于让bean获取它所在的BeanFactory实例。在依赖注入之后，bean初始化之前被调用。 点击查看invokeAwareMethods， 其逻辑涉及到3个Aware 接口 1.BeanFactoryAware123public interface BeanFactoryAware &#123; void setBeanFactory(BeanFactory beanFactory) throws BeansException;&#125; 作用：允许bean获取BeanFactory实例，从而能够访问Spring容器中的其他bean。 使用场景：在需要动态获取或创建bean的场景下使用，例如实现复杂的依赖关系或自定义初始化逻辑。 2.BeanNameAware123public interface BeanNameAware &#123; void setBeanName(String name);&#125; 实现 BeanNameAware 接口的 bean 会在 Spring 容器创建并初始化该 bean 时，调用 setBeanName 方法，将容器中为该 bean 配置的名称传递给它。这对于需要知道自己在容器中的名称的 bean 来说非常有用。 3.3 Aware Group 2-ApplicationContext 相关Aware并不是所有的Aware接口都使用同样的方式调用。Bean××Aware都是在代码中直接调用的，而ApplicationContext相关的Aware都是通过BeanPostProcessor#postProcessBeforeInitialization()实现的 EnvironmentAware: 允许bean访问Spring的Environment接口，用于获取环境属性和配置文件信息。 EmbeddedValueResolverAware: 允许bean获取Spring的字符串值解析器，特别是用来解析Spring EL表达式（SpEL）。 ApplicationContextAware: 允许bean获取ApplicationContext，这是BeanFactory的一个子接口，提供更多容器功能和应用上下文相关的信息。 跟进代码最后来到ApplicationContextAwareProcessor中，ApplicationContextAwareProcessor 是一个BeanPostProcessor, 最后在其重写的postProcessBeforeInitialization方法中，会调用如下方法。 3.4 Aware执行时机12345678910protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; invokeAwareMethods(beanName, bean); applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); invokeInitMethods(beanName, wrappedBean, mbd); applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; 示例代码123456789101112131415161718192021import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.BeanFactoryAware;import org.springframework.stereotype.Component;@Componentpublic class MyBeanFactoryAwareBean implements BeanFactoryAware &#123; private BeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; System.out.println(&quot;BeanFactory has been set: &quot; + beanFactory); &#125; public void doSomething() &#123; // 使用beanFactory获取另一个bean MyOtherBean otherBean = beanFactory.getBean(MyOtherBean.class); otherBean.performTask(); &#125;&#125; 4.Bean生命周期对bean 的生命周期做细化的话可以分为以下阶段 实例化（Instantiation）： Spring容器使用构造函数或工厂方法实例化bean。 属性填充（Dependency Injection）： Spring容器进行依赖注入，将所有需要的属性和依赖注入到bean实例中。 设置特殊回调接口（Aware接口）： 如果bean实现了Aware接口，Spring容器会在这个阶段调用相应的方法。 包括BeanNameAware、BeanClassLoaderAware、BeanFactoryAware等。 初始化前处理（BeanPostProcessor的postProcessBeforeInitialization方法）： Spring容器会在这个阶段调用所有注册的BeanPostProcessor的postProcessBeforeInitialization方法。 初始化（Initialization）： 如果bean实现了InitializingBean接口，Spring容器会调用其afterPropertiesSet方法。 如果bean配置了自定义的init方法，Spring容器会调用该方法。 初始化后处理（BeanPostProcessor的postProcessAfterInitialization方法）： Spring容器会在这个阶段调用所有注册的BeanPostProcessor的postProcessAfterInitialization方法。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring AOP  实践","slug":"Spring-AOP-实践","date":"2023-05-26T09:46:34.000Z","updated":"2024-07-23T03:47:32.899Z","comments":true,"path":"62ebaa0e/","permalink":"http://example.com/62ebaa0e/","excerpt":"","text":"1. 为什么需要AOP关于消除重复代码，定义公共父类使用继承的方式实现是一种常见的思路。但是例如性能监控、事务管理，这类重复代码的特点是和业务代码紧密结合在一起，无法通过继承的方式解决。 比如在程序运行中，想计算每个方法的行时间, 就没有办法通过继承的方式去消除这类重复代码 12345678910111213141516171819202122public class UserService &#123; public void createUser(String username) &#123; long startTime = System.currentTimeMillis(); // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); long endTime = System.currentTimeMillis(); System.out.println(&quot;createUser方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); &#125; public void deleteUser(String username) &#123; long startTime = System.currentTimeMillis(); // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); long endTime = System.currentTimeMillis(); System.out.println(&quot;deleteUser方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); &#125;&#125; AOP 就是解决这类重复的方式。 AOP是Aspect Oriented Programing的简称， 面向切面编程。 在AOP中，将重复性代码抽取出来是很容易的，但如何将这些独立的逻辑融合到业务逻辑中完成和原来一样的业务操作，这才是事情的关键，也正是AOP要解决的主要问题。 本文将先介绍Spring 中各种使用AOP的方法，作为后面介绍原理的前置知识。 具体实现原理可以阅读以下文章:Spring AOP XML配置方式原理详解Spring AOP 注解方式原理详解 2. 手动配置代理 - ProxyFactoryBean12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class UserService &#123; public void createUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Creating user: &quot; + username); &#125; public void deleteUser(String username) &#123; // 模拟业务处理 System.out.println(&quot;Deleting user: &quot; + username); &#125;&#125;// 定义一个前置增强public class LoggingBeforeAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); &#125;&#125;// 定义一个后置增强public class LoggingAfterAdvice implements AfterReturningAdvice &#123; @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable &#123; System.out.println(&quot;After method: &quot; + method.getName()); &#125;&#125;// 定义一个 环绕增强public class LoggingMethodInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; // 方法执行前逻辑 long startTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot; 方法开始执行&quot;); // 通过反射执行目标方法 Object result = invocation.proceed(); // 方法执行后逻辑 //System.out.println(&quot;After method: &quot; + invocation.getMethod().getName()); long endTime = System.currentTimeMillis(); System.out.println(invocation.getMethod().getName()+ &quot;方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125; applicationContext.xml 配置如下 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 前置增强 --&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingMethodInterceptor&quot; class=&quot;com.example.codingInAction.aop.LoggingMethodInterceptor&quot;/&gt; &lt;!-- 使用 ProxyFactoryBean 配置代理对象 --&gt; &lt;bean id=&quot;userServiceProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;userService&quot;/&gt; &lt;!-- 拦截器 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingMethodInterceptor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 强制使用CGLIB代理 --&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 运行程序启动代码，可以得到如下截图 1234567891011121314public class CodingInActionApplication&#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); // 获取代理对象 UserService userService = (UserService) context.getBean(&quot;userServiceProxy&quot;); // 调用方法，观察 AOP 切面的效果 userService.createUser(&quot;john&quot;); userService.deleteUser(&quot;john&quot;); &#125;&#125; 以上xml 中的配置可以等价替换成如下代码，运行结果是一致的 123456789101112131415161718192021class UserServiceTest &#123; @Test void createUser() &#123; UserService target = new UserService(); BeforeAdvice beforeAdvice = new LoggingBeforeAdvice(); AfterReturningAdvice afterAdvice = new LoggingAfterAdvice(); MethodInterceptor methodInterceptor = new LoggingMethodInterceptor(); ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.setTarget(target); proxyFactory.addAdvice(methodInterceptor); proxyFactory.addAdvice(beforeAdvice); proxyFactory.addAdvice(afterAdvice); UserService proxy = (UserService) proxyFactory.getProxy(); proxy.createUser(&quot;john&quot;); proxy.deleteUser(&quot;john&quot;); &#125; 通过以上代码来简单介绍一下AOP 中的专业术语 2.1 连接点（Joinpoint）连接点是程序执行中的某个特定点。Spring AOP中的连接点通常是方法的执行。例如，在UserService类中，createUser方法的执行就是一个连接点。连接点可以是类初始化、字段访问、方法调用等。 在UserService类中，方法createUser的执行是一个连接点。 123public void createUser(String username) &#123; System.out.println(&quot;Creating user: &quot; + username);&#125; 2.2 增强（Advice）通知是围绕连接点执行的代码。Spring AOP支持五种类型的通知： 前置增强（Before Advice）：在方法执行之前执行。 后置增强（After Returning Advice）：在方法成功执行之后执行。 异常增强（After Throwing Advice）：在方法抛出异常后执行。 最终增强（After (finally) Advice）：在方法执行之后，无论是否抛出异常都会执行。 环绕增强（Around Advice）：在方法执行之前和之后执行。 在前面的代码示例中，就分别定义了前置增强、后置增强和环绕增强 2.3 织入 Advice在前面的代码示例中，有连接点 joinpoint 和 增强 Advice，看运行结果我们可能注意到一个问题：Advice 增强被默认织入(weaving)了目标类(target)的所有方法中，即interceptorNames 中配置的拦截器会对目标对象userService中所有方法起作用，这是 因为没有定义具体的 Pointcut 来限制拦截范围。 12345678910111213141516&lt;!-- 使用 ProxyFactoryBean 配置代理对象 --&gt; &lt;bean id=&quot;userServiceProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;userService&quot;/&gt; &lt;!-- 拦截器 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingMethodInterceptor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 强制使用CGLIB代理 --&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 为了更加灵活,更有选择地将增强 织入某些类的某些特定的方法中 ，可以定义 Pointcut 和 Advisor。这样可以明确地指定在哪些连接点 joinpoint 上应用Advice 增强。 2.3.1 Pointcut -接口实现Pointcut 有不同的实现方式 可以是通过Pointcut接口实现 也可以是切点表达式 这一节内容先介绍接口实现方式， 后面自动代理机制部分再介绍表达式方式。Spring通过org.springframework.aop.Pointcut接口描述切点, Pointcut 由ClassFilter和MethodMatcher构成，它通过ClassFilter定位到某些特定类上，通过MethodMatcher定位到某些特定方法上，这样Pointcut就拥有了描述某些类的某些特定方法的能力。123456789101112131415161718192021public interface Pointcut &#123; /** * Return the ClassFilter for this pointcut. * @return the ClassFilter (never &#123;@code null&#125;) */ ClassFilter getClassFilter(); /** * Return the MethodMatcher for this pointcut. * @return the MethodMatcher (never &#123;@code null&#125;) */ MethodMatcher getMethodMatcher(); /** * Canonical Pointcut instance that always matches. */ Pointcut TRUE = TruePointcut.INSTANCE;&#125; 我们可以定义一个Pointcut 匹配UserService.create方法。 12345678910111213141516171819202122232425262728293031323334public class LoggingPointcut implements Pointcut &#123; @Override public ClassFilter getClassFilter() &#123; return clazz -&gt; clazz == UserService.class; &#125; @Override public MethodMatcher getMethodMatcher() &#123; return new MethodMatcher() &#123; @Override public boolean matches(Method method, Class&lt;?&gt; targetClass) &#123; if (method.getName().equals(&quot;createUser&quot;)) &#123; return true; &#125; return false; &#125; @Override public boolean isRuntime() &#123; return true; &#125; @Override public boolean matches(Method method, Class&lt;?&gt; targetClass, Object... args) &#123; if (method.getName().equals(&quot;createUser&quot;)) &#123; return true; &#125; return false; &#125; &#125;; &#125;&#125; 通过数据库查询的概念，可以这样来理解以上joinpoint、Advice、pointcut 3个概念。 连接点相当于数据库中的记录，而切点相当于查询条件。切点和连接点不是一对一的关系，一个切点可以匹配多个连接点。 根据每个查询条件 (切点 pointcut) 找到对应记录(连接点 Joinpoint )后，对记录执行的操作，相当于增强Advice 2.3.2 Advisor 切面Advisor是一个非常重要的概念,它将切点（Pointcut）和增强（Advice）结合起来，形成一个切面（Aspect）。Advisor包含两个主要部分： Pointcut：定义在哪些连接点（通常是方法执行）上应用通知。 Advice：定义在连接点上执行的具体操作，可以是在方法执行前、后或环绕方法执行。 在这里我们可以把上面例子中的环绕增强改成Advisor的形式，以给它增加“筛选条件” pointcut 123456789101112131415public class LoggingAdvisor implements PointcutAdvisor &#123; @Override public Pointcut getPointcut() &#123; return new LoggingPointcut(); &#125; @Override public Advice getAdvice() &#123; return new LoggingMethodInterceptor(); &#125; @Override public boolean isPerInstance() &#123; return true; &#125;&#125; 修改applicationContext.xml 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 以下内容是使用 ProxyFactoryBean 配置代理对象， 用 Advisor 增加切点--&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 前置增强--&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingAdvisor&quot; class=&quot;com.example.codingInAction.aop.LoggingAdvisor&quot;/&gt; &lt;bean id=&quot;userServiceProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;userService&quot;/&gt; &lt;!-- 拦截器 --&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingAdvisor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 强制使用CGLIB代理 --&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 运行前面相同的启动代码，可以得到相同的运行结果。可以看到，增加了“筛选条件”的环绕增强，如预期一样，如预期一样，环绕增强只在create方法上发挥了作用。 3. 自动代理机制-AbstractAutoProxyCreator在以上 XML AOP 的实现中，每一个需要被代理的Bean都需要使用一个ProxyFactoryBean进行配置,，并在需要时手动获取代理对象以实现AOP功能。 然而，在大型生产环境中，这种配置方式显得繁琐且不切实际。为了解决这一问题，Spring提供了一种基于AbstractAutoProxyCreator的自动代理机制，使得我们无需为每个Bean手动配置ProxyFactoryBean。AbstractAutoProxyCreator通过自动检测Bean的类型和相应的切面（Aspect）来创建代理对象，从而简化了配置过程。 AbstractAutoProxyCreator 有很多子类，下面将介绍各个子类如何配置完成自动代理机制。 3.1 BeanNameAutoProxyCreator使用 BeanNameAutoProxyCreator 后，你不再需要手动配置和获取 userServiceProxy 代理对象。Spring 会自动为指定的 Bean 创建代理对象。你只需要获取原始的 userService，Spring 会自动为它应用增强。 修改applicationContext.xml 1234567891011121314151617181920212223242526272829303132333435 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;&lt;!-- 自动代理机制 启用 BeanNameAutoProxyCreator --&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingAdvisor&quot; class=&quot;com.example.codingInAction.aop.LoggingAdvisor&quot;/&gt; &lt;!-- 定义 前置增强--&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;bean class=&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt; &lt;property name=&quot;beanNames&quot;&gt; &lt;list&gt; &lt;value&gt;userService&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loggingAdvisor&lt;/value&gt; &lt;value&gt;loggingBeforeAdvice&lt;/value&gt; &lt;value&gt;loggingAfterAdvice&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 修改CodingInActionApplication，不再主动获取代理对象 1234567891011121314151617public class CodingInActionApplication &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); // 手动配置并手动获取代理Bean // UserService userService = (UserService) context.getBean(&quot;userServiceProxy&quot;); // 自动代理机制 UserService userService = (UserService) context.getBean(&quot;userService&quot;); // 调用方法，观察 AOP 切面的效果 userService.createUser(&quot;john&quot;); userService.deleteUser(&quot;john&quot;); &#125;&#125; 运行启动代码，可以得到相同的运行结果 3.2 DefaultAdvisorAutoProxyCreatorAbstractAdvisorAutoProxyCreator 是 AbstractAutoProxyCreator 的直接子类，它扫描 Spring 容器中的所有 Advisor（一个 Advisor 包含一个 Advice 和一个 Pointcut），并根据 Pointcut 的匹配规则，自动为匹配的 Bean 创建代理对象，并应用对应的 Advice。 DefaultAdvisorAutoProxyCreator 是 AbstractAdvisorAutoProxyCreator 的具体实现类 我们简化下代码，只保留实现了Advisor 的环绕增强来看下运行结果 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 环绕增强 --&gt; &lt;bean id=&quot;loggingAdvisor&quot; class=&quot;com.example.codingInAction.aop.LoggingAdvisor&quot;/&gt; &lt;!-- 启用自动代理 --&gt; &lt;bean class=&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot;/&gt;&lt;/beans&gt; 运行和上面一样的CodingInActionApplication， 可以得到如下结果 3.3 基于AspectJ 实现的自动代理终于来到日常开发中， 最常见的AOP 配置方式了，基于AspectJ 注解的方式。 以上提到的所有AOP 配置方式中，不论是使用手动配置的ProxyFactoryBean，还是自动代理的BeanNameAutoProxyCreator、DefaultAdvisorAutoProxyCreator，都需要实现Pointcut和Advice接口描述切点和增强，并用Advisor整合两者。 AspectJ则采用注解来描述切点、增强。 两者只是表述方式不同，描述内容的本质是完全相同的，这就好比一个用中文、一个用英文讲述同一个伊索寓言一样。 AspectJ 是一个强大的面向切面编程（AOP）框架，独立于 Spring 但可以无缝集成。 3.3.1 AspectJAwareAdvisorAutoProxyCreatorAspectJAwareAdvisorAutoProxyCreator是 AbstractAdvisorAutoProxyCreator 的子类，主要用于处理基于 AspectJ 方式的 AOP 配置。 它和 AnnotationAwareAspectJAutoProxyCreator 类似，但主要用于处理通过 XML 配置文件或其他非注解方式配置的 AspectJ 切面。 3.3.2 AnnotationAwareAspectJAutoProxyCreatorAnnotationAwareAspectJAutoProxyCreator是AspectJAwareAdvisorAutoProxyCreator 的子类。 AnnotationAwareAspectJAutoProxyCreator 扫描使用了 AspectJ 注解（如 @Aspect、@Before、@After 等）的 Bean，并将这些注解配置的切面应用到匹配的 Bean 上。 pointcut-切点表达式定义一个 LoggingAspect 1234567891011121314151617181920212223242526272829303132333435363738import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;import org.aspectj.lang.JoinPoint;@Aspectpublic class LoggingAspect &#123; //定义一个匹配userService中所有方法的切点表达式 @Pointcut(&quot;execution(* com.example.codingInAction.service.UserService.*(..))&quot;) public void userServiceAllMethod() &#123; &#125; // 在方法执行之前执行的通知 @Before(&quot;userServiceAllMethod()&quot;) public void logBefore(JoinPoint joinPoint) &#123; System.out.println(&quot;Before method: &quot; + joinPoint.getSignature().getName()); &#125; // 在方法执行之后执行的通知 @After(&quot;userServiceAllMethod()&quot;) public void logAfter(JoinPoint joinPoint) &#123; System.out.println(&quot;After method: &quot; + joinPoint.getSignature().getName()); &#125; // 定义一个只匹配 UserService.createUser 方法的切点表达式 @Around(&quot;execution(* com.example.codingInAction.service.UserService.createUser(..))&quot;) public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable &#123; long startTime = System.currentTimeMillis(); System.out.println(joinPoint.getSignature().getName() + &quot; 方法开始执行&quot;); Object result = joinPoint.proceed(); // 执行目标方法 long endTime = System.currentTimeMillis(); System.out.println(joinPoint.getSignature().getName() + &quot; 方法执行时间: &quot; + (endTime - startTime) + &quot;ms&quot;); return result; &#125;&#125; 借一张来描述下各个部分的使用方式和含义 修改applicationContext.xml，并运行启动代码，运行结果依然和之前保持一致。 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 启用 AspectJ 自动代理 --&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义切面的 Bean --&gt; &lt;bean id=&quot;loggingAspect&quot; class=&quot;com.example.codingInAction.aop.LoggingAspect&quot;/&gt;&lt;/beans&gt; 4. 自动代理机制-基于Schema配置切面如果项目不能使用JDK 5.0，那么就无法使用基于@AspectJ注解的切面了。但是使用AspectJ切点表达式的大门依旧向我们敞开着，因为Spring提供了基于Schema配置的方法，它完全可以替代基于@AspectJ注解声明切面的方式。依然是做同一件事的两种不同表达形式 在Spring的XML配置中，&lt;aop:config&gt;标签可以直接定义切点和通知，并将它们应用到目标对象上。这种方式简化了配置，不需要额外的Java类来定义Pointcut和Advisor。 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 定义业务类的 Bean --&gt; &lt;bean id=&quot;userService&quot; class=&quot;com.example.codingInAction.service.UserService&quot;/&gt; &lt;!-- 定义 前置增强--&gt; &lt;bean id=&quot;loggingBeforeAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingBeforeAdvice&quot;/&gt; &lt;!-- 定义 后置增强 --&gt; &lt;bean id=&quot;loggingAfterAdvice&quot; class=&quot;com.example.codingInAction.aop.LoggingAfterAdvice&quot;/&gt; &lt;bean id=&quot;loggingMethodInterceptor&quot; class=&quot;com.example.codingInAction.aop.LoggingMethodInterceptor&quot;/&gt; &lt;!-- 配置AOP --&gt; &lt;aop:config&gt; &lt;!-- 定义切点，匹配 UserService 类中的所有方法 --&gt; &lt;aop:pointcut id=&quot;userServiceMethods&quot; expression=&quot;execution(* com.example.codingInAction.service.UserService.*(..))&quot;/&gt; &lt;aop:pointcut id=&quot;userServiceCreateMethod&quot; expression=&quot;execution(* com.example.codingInAction.service.UserService.createUser(..))&quot;/&gt; &lt;!-- 定义 advisor，将 MethodInterceptor 应用于切点 --&gt; &lt;aop:advisor advice-ref=&quot;loggingMethodInterceptor&quot; pointcut-ref=&quot;userServiceCreateMethod&quot;/&gt; &lt;aop:advisor advice-ref=&quot;loggingBeforeAdvice&quot; pointcut-ref=&quot;userServiceMethods&quot;/&gt; &lt;aop:advisor advice-ref=&quot;loggingAfterAdvice&quot; pointcut-ref=&quot;userServiceMethods&quot;/&gt; &lt;/aop:config&gt;&lt;/beans&gt; 5.切面类型总结根据以上代码扩充并总结下切面类型","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring bean 实例化过程","slug":"Spring-bean-实例化过程","date":"2023-05-22T08:50:03.000Z","updated":"2024-07-12T05:37:10.993Z","comments":true,"path":"678b23b2/","permalink":"http://example.com/678b23b2/","excerpt":"","text":"在Spring IOC 容器 和 Spring bean 一文中，介绍了Spring IOC 容器和bean 一些相关基础知识。 Spring IOC 容器的作用是 管理 Bean 的生命周期，控制 Bean 的依赖注入。 本文内容将具体介绍Spring IOC 容器是如何管理bean 的生命周期和bean 之间的依赖关系的。 先来看一张整体框架图 读取Bean配置信息：Spring容器首先读取Bean的配置信息，这些配置信息可以来自XML配置文件、Java类（带有@Configuration注解）或通过注解（如@Autowired）的方式定义。 注册Bean定义：根据读取的配置信息，Spring将Bean的定义（包括类名、依赖关系等）注册到Bean定义注册表中。 实例化Bean：Spring根据Bean定义注册表中的信息，实例化相应的Bean。这个过程中会处理依赖注入和循环依赖的问题。 使用Bean：应用程序可以从Spring容器中获取Bean实例并使用它们。Spring容器会根据需要从Bean缓存池中返回已经实例化并初始化好的Bean。 以下代码分析基于Spring boot 2.3.4 版本进行分析。 直接从服务启动run 方法，快进到 refresh 方法看重点 123456public class CodingInActionApplication&#123; public static void main(String[] args) &#123; SpringApplication.run(CodingInActionApplication.class, args); &#125; &#125; 123456789AbstractApplicationContext.java@Override public void refresh() throws BeansException, IllegalStateException &#123; // 1. 创建beanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2. bean的生命周期管理和依赖关系的装配 finishBeanFactoryInitialization(beanFactory);&#125; 本文将重点介绍DefaultListableBeanFactory 和 finishBeanFactoryInitialization方法中整个流程 1.bean 容器-DefaultListableBeanFactoryAbstractApplicationContext.obtainFreshBeanFactory 根据前面的内容我们知道， ApplicationContext 是面向应用的容器，但在Spring 框架层面，BeanFactory才是IOC 容器。 根据代码可知，在Spring boot 的启动过程中， BeanFactory使用的是DefaultListableBeanFactory。 先来看下， BeanFactory作为Spring IOC 容器,有哪些变量来实现功能123456789101112131415161718192021222324252627282930313233343536public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &#123; /** Map of bean definition objects, keyed by bean name. */ //存储所有注册的bean定义,键是bean的名称。 private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256); /** Map from bean name to merged BeanDefinitionHolder. */ //从bean名称到合并的`BeanDefinitionHolder`的映射。在处理bean定义继承和合并时，存储合并后的bean定义。 private final Map&lt;String, BeanDefinitionHolder&gt; mergedBeanDefinitionHolders = new ConcurrentHashMap&lt;&gt;(256); /** Map of singleton and non-singleton bean names, keyed by dependency type. */ //从依赖类型到单例和非单例bean名称的映射。用于根据类型查找所有相关的bean名称，包括单例和非单例bean private final Map&lt;Class&lt;?&gt;, String[]&gt; allBeanNamesByType = new ConcurrentHashMap&lt;&gt;(64); /** Map of singleton-only bean names, keyed by dependency type. */ //- 从依赖类型到单例bean名称的映射。用于根据类型查找所有单例bean名称，便于单例bean的管理和查找。 private final Map&lt;Class&lt;?&gt;, String[]&gt; singletonBeanNamesByType = new ConcurrentHashMap&lt;&gt;(64); /** List of bean definition names, in registration order. */ //按注册顺序存储的bean定义名称列表。维护bean定义的注册顺序，便于按顺序处理bean定义。 private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256); /** List of names of manually registered singletons, in registration order. */ //按注册顺序存储的手动注册的单例名称集合。存储通过手动方式注册的单例bean，便于管理和查找。 private volatile Set&lt;String&gt; manualSingletonNames = new LinkedHashSet&lt;&gt;(16); /** Cached array of bean definition names in case of frozen configuration. */ @Nullable private volatile String[] frozenBeanDefinitionNames; /** Whether bean definition metadata may be cached for all beans. */ private volatile boolean configurationFrozen;&#125; 从以上DefaultListableBeanFactory 的变量可以看出， 维护了各种维度的beanDefinition loadBeanDefinitions是将解析后的bean定义按bean名称 -&gt; bean定义的逻辑存放到beanDefinitionMap这个ConcurrentHashMap中。 同时，也会更新其他几个重要的ConcurrentHashMap，如mergedBeanDefinitionHolders、allBeanNamesByType、singletonBeanNamesByType，以便于更高效的bean管理和依赖解析。 loadBeanDefinitions方法不仅仅是存放bean定义，还包括解析、验证和注册多个步骤。 beanDefinitionNames列表也会在这个过程中被更新，以维护bean定义的注册顺序。 下面进入obtainFreshBeanFactory进行分析12345AbstractApplicationContext.javaprotected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); return getBeanFactory(); &#125; 1.1 refreshBeanFactory12345678910111213141516171819AbstractRefreshableApplicationContext.java @Override protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; // 1. 创建beanFactory DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); // 2. 读取Bean配置信息, 填充DefaultListableBeanFactory中变量 loadBeanDefinitions(beanFactory); this.beanFactory = beanFactory; &#125; catch (IOException ex) &#123; &#125; &#125; 1.1.1 loadBeanDefinitions具体过程待补充 ：可以参考https://blog.csdn.net/andy_zhang2007/article/details/85381148 1.2 getBeanFactory12345678910AbstractRefreshableApplicationContext.java @Override public final ConfigurableListableBeanFactory getBeanFactory() &#123; DefaultListableBeanFactory beanFactory = this.beanFactory; if (beanFactory == null) &#123; throw new IllegalStateException(&quot;BeanFactory not initialized or already closed - &quot; + &quot;call &#x27;refresh&#x27; before accessing beans via the ApplicationContext&quot;); &#125; return beanFactory; &#125; 2. bean 的生命周期在 finishBeanFactoryInitialization 方法中，管理的bean 都是 非懒加载单例bean123456789AbstractApplicationContext.java@Override public void refresh() throws BeansException, IllegalStateException &#123; // 1. 创建beanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 2. bean的生命周期管理和依赖关系的装配 finishBeanFactoryInitialization(beanFactory);&#125;在Spring中，Bean的生命周期包括几个重要的阶段： 实例化（Instantiation）： Bean被创建，通过调用构造方法实例化。 属性注入（Property Population）： Spring通过依赖注入将Bean的依赖关系注入。 初始化（Initialization）： 在所有属性被设置之后，Spring可以调用定制的初始化方法。 销毁（Destruction）： 在Spring容器关闭之前，可以调用定制的销毁方法。 3. 三层缓存 根据上面的框架图可知， 可以看到实例化后bean 会放到缓存中。 既然使用缓存，其经典使用方式必然是“有就直接获取，没有就创建并回填缓存”， bean 缓存的使用过程也不例外， 同样遵循这一流程 不过在Spring 中， 这个缓存比较特殊的一点是由3层本地缓存构成。 想要了解三层缓存机制，首先需要了解各层缓存中存放的具体内容，下面来分析一下 1234567891011public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry /** Cache of singleton objects: bean name to bean instance. */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); /** Cache of singleton factories: bean name to ObjectFactory. */ private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); /** Cache of early singleton objects: bean name to bean instance. */ private final Map&lt;String, Object&gt; earlySingletonObjects = new ConcurrentHashMap&lt;&gt;(16);&#125; singletonObjects：存放init完成的单例bean， 此时的bean是成熟完整。 earlySingletonObjects：存储由singletonFactories创建的早期引用,即提前暴露的对象（已经完成instantiation，但是还没有populate 、init）。 singletonFactories：存储用于生成早期单例bean引用的工厂对象。当一个单例bean正在创建过程中，还没有完成init 阶段是时（比如还没有注入依赖），就会暂时存入这个缓存。 earlySingletonObjects 和singletonFactories 一起完成bean 早期引用的管理， 早期引用是为了解决bean 的循环依赖singletonObjects、earlySingletonObjects中的value 是Object，存放的也就是完整bean 引用，和早期bean 引用。下面重点分析比较陌生的singletonFactories。 3.1 函数式接口 ObjectFactory要想singletonFactories 存放的内容，需要先了解函数式接口ObjectFactory Java 8引入的函数式接口（Functional Interface）概念，是指仅有一个抽象方法的接口（除了Object类的公有方法外）。这种接口允许被隐式转换为Lambda表达式。java.lang.FunctionalInterface注解用于标记一个接口是函数式接口，这个注解不是必须的，但它可以帮助开发者和编译器验证接口是否满足函数式接口的条件。 Lambda表达式可以用来简洁地 implements 函数式接口。 在解决循环依赖时用到的singletonFactories， 其value 就是 ObjectFactory12345@FunctionalInterface public interface ObjectFactory&lt;T&gt; &#123; T getObject() throws BeansException; &#125; 4.非懒加载的单例bean-getBeanSpring IOC 容器现在有了bean 的定义信息，就可以正式开始bean的生命周期管理和依赖关系的装配了。 实例化bean的入口就在前面提到的DefaultListableBeanFactory中， 根据bean 名称循环获取bean 实例 从doGetBean的逻辑中可以看到各种作用域的bean 其实都在这个方法中创建，例如singleton(单例) 、prototype（每次都创建新实例）， 平时我们经常提到的三层缓存解决循环依赖，其实指的都是非懒加载的单例bean ,作用域是prototype 的bean 是无法用这种方式解决循环依赖的。看下面的代码，由于作用域是prototype 的bean 并不需要三层缓存的参与，所以少了对于三层缓存的管理， 调用调研同一个createBean 创建新的实例。 所以下面我们重点讲解单例bean 的创建过程， 其他作用域的bean 自然就懂了。 123456789101112DefaultListableBeanFactory.java@Override public void preInstantiateSingletons() throws BeansException &#123; List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); for (String beanName : beanNames) &#123; if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; getBean(beanName); &#125; &#125; &#125; 以下省略了部分代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114AbstractBeanFactory.javapublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false); &#125;protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = transformedBeanName(name); Object bean; // 对于一个bean 走到这里有两种情况 1. bean 的正常创建流程 2. 循环依赖的情况 // 针对 bean 的正常创建流程， getSingleton 的返回是null // 针对循环依赖触发的bean 获取，通过getSingleton可以获取到由三级缓存生成的二级缓存，早期引用，从而解决循环依赖问题。 // 先尝试从缓存中获取 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; // 缓存中存在则直接返回 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; try &#123; RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. // 在创建某个 Bean 之前，必须先确保它所依赖的所有其他Bean 都已经创建并初始化。 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between &#x27;&quot; + beanName + &quot;&#x27; and &#x27;&quot; + dep + &quot;&#x27;&quot;); &#125; // 注册所有依赖于当前bean 的bean 信息 // 该信息使用 Map&lt;String, Set&lt;String&gt;&gt; dependentBeanMap 记录 registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;&#x27;&quot; + beanName + &quot;&#x27; depends on missing bean &#x27;&quot; + dep + &quot;&#x27;&quot;, ex); &#125; &#125; &#125; // 单例bean的创建，缓存中没有则需要创建并回写缓存 if (mbd.isSingleton()) &#123; // sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // Prototype 是作用域，代表每次调用getBean从容器中获取对象时，都返回一个新的实例 // 所以 对于Prototype作用域，不会走getSingleton 使用3层缓存的逻辑， 直接调用createBean 生成新的实例即可 else if (mbd.isPrototype()) &#123; // It&#x27;s a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); if (!StringUtils.hasLength(scopeName)) &#123; throw new IllegalStateException(&quot;No scope name defined for bean ´&quot; + beanName + &quot;&#x27;&quot;); &#125; Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(&quot;No Scope registered for scope name &#x27;&quot; + scopeName + &quot;&#x27;&quot;); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, &quot;Scope &#x27;&quot; + scopeName + &quot;&#x27; is not active for the current thread; consider &quot; + &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;, ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; return (T) bean; &#125; 函数getSingleton有多个重载版本， 在上面这段代码中就涉及到2个12345public Object getSingleton(String beanName) &#123; &#125;public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;&#125; 5. 从缓存中获取bean-getSingletongetSingleton(String beanName) 的作用是从缓存中获取bean, 其具体逻辑还涉及到getSingleton的第3个重载版本，具体逻辑如下 5.1 缓存管理123456789101112131415161718192021222324252627282930313233343536373839代码均在 DefaultSingletonBeanRegistry.java public Object getSingleton(String beanName) &#123; return getSingleton(beanName, true); &#125;@Nullable protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // Quick check for existing instance without full singleton lock // 首先从 singletonObjects（单例缓存）中快速获取 Bean 实例，如果存在则直接返回。 Object singletonObject = this.singletonObjects.get(beanName); // 如果初步检查没有找到实例，并且该单例当前正在创建中，则从 earlySingletonObjects（早期单例缓存）中查找。 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; //如果仍未找到实例，并且允许早期引用，则进入同步块。 //在同步块内，再次从 singletonObjects 和 earlySingletonObjects 中检查实例。 // 这是为了避免在进入同步块的过程中，有其他线程已经创建了该单例实例。 synchronized (this.singletonObjects) &#123; // Consistent creation of early reference within full singleton lock singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); //如果仍未找到实例，则尝试从 singletonFactories 中获取单例工厂， // 并singletonFactory创建早期引用，将其放入 earlySingletonObjects 中，并从 singletonFactories 中移除。 if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; &#125; &#125; return singletonObject; &#125; 5.2 双重校验锁在用java 实现单例模式时，一种经典的方式是， 双检锁/双重校验锁（DCL，即 double-checked locking） 第一个检查在进入同步块之前，避免了不必要的同步。 第二个检查在进入同步块之后，确保实例在多线程环境中正确初始化。 123456789101112131415public class Singleton &#123; private static volatile Singleton instance; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 在这个Object getSingleton(String beanName, boolean allowEarlyReference)方法中，同样使用了 双重校验锁机制，但它包含更多的逻辑以处理 Spring 框架中的具体需求，特别是早期单例引用和单例工厂的处理。严格来说，它不完全是经典的双重校验锁模式，但其思想是一致的，即通过两次检查（一次在同步块外，一次在同步块内）来优化性能并确保线程安全。 这种设计在 Spring 框架中用于确保 Bean 的创建是线程安全的，同时尽可能减少同步开销，以提高性能。 6.缓存中不存在则创建-getSingleton来看doGetBean 方法中，第2个getSingleton 方法 1234567891011121314151617181920212223protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; // 第一个getSingleton：尝试从缓存中获取 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; // 缓存中存在则直接返回 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125;else&#123; // 第2个getSingleton：缓存中没有则需要创建并回写缓存 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125;catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; return bean;&#125; 6.1 ObjectFactory 的匿名类实现-createBean查看这个getSingleton方法的完整定义，可以看到第二个参数是前面提到的函数式接口ObjectFactory，1public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;&#125; 在缓存中不存在尝试去创建bean实例的逻辑中， 传入的参数如下 1234567891011 // 2. 如果一级缓存没有获取到， 则使用另一个getSingleton 重载函数，去创建bean// 这里传入了一个ObjectFactory的匿名实现类，里面是bean 创建的真正逻辑 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125;&#125;); 可以看到在传入getSingleton的第二个参数时，使用lambda表达式传入了一个匿名类实现，该匿名类中的createBean 包含了实例化bean 的逻辑 Java编译器会自动将这个Lambda表达式转换成ObjectFactory接口的一个匿名实现类。这个过程完全是自动的，背后的转换对开发者来说是透明的。 进入该重载版本看一下具体逻辑 123456789101112131415161718192021222324DefaultListableBeanFactory.javapublic Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; //加锁同步块 synchronized (this.singletonObjects) &#123; // 从一级缓存中尝试获取bean实例 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; //判断该bean 是否正在创建 //如果已经正在创建了，此次创建动作要报错 beforeSingletonCreation(beanName); // 调用ObjectFactory.getObject会走到上面匿名类的实现逻辑， 即会走到createBean逻辑 singletonObject = singletonFactory.getObject(); newSingleton = true; if (newSingleton) &#123; // init完成的bean， 添加到一级缓存，并从二三级缓存中删除 addSingleton(beanName, singletonObject); &#125; //bean创建完成，从singletonsCurrentlyInCreation删除 afterSingletonCreation(beanName); &#125; return singletonObject; &#125; &#125; 1singletonObject = singletonFactory.getObject(); 当该getSingleton 逻辑走到 ObjectFactory.getObject时，实际会调用到会走到上面匿名类的实现逻辑， 即会走到createBean逻辑, 即在getBean 方法中的匿名类 12345678sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125;catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125;); 进入createBean看一下具体逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122AbstractAutowireCapableBeanFactory.java protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)&#123; Object beanInstance = doCreateBean(beanName, mbdToUse, args);&#125;protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. //检查是否已经对 Bean 定义进行了后处理，如果没有，则调用 applyMergedBeanDefinitionPostProcessors 方法应用后处理器。 synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Post-processing of merged bean definition failed&quot;, ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); //如果允许循环引用，并且当前 Bean 是单例，则调用 addSingletonFactory 方法，提供一个回调以获取早期 Bean 引用。 if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Eagerly caching bean &#x27;&quot; + beanName + &quot;&#x27; to allow for resolving potential circular references&quot;); &#125; // 添加第3级缓存， 此处第二个参数又是一个ObjectFactory的匿名类实现 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex); &#125; &#125; // 验证循环引用的处理过程是否正确 if (earlySingletonExposure) &#123; // 尝试获取早期引用，那么这个早期引用肯定是因为循环依赖，其他bean在getSingleton(beanName, true)生产出来的 // 因为该bean 自己的生产过程中，只会主动添加一级、三级缓存 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; // 表示init后，Bean实例未被代理,在未代理的情况下，exposedObject 和 bean 是相同的引用 // 同时在理论上，getSingleton(beanName, false)获取到的应该也是相同的引用。 if (exposedObject == bean) &#123; // 如果存在早期暴露的单例引用，并且exposedObject未被代理，将exposedObject替换为早期暴露的单例引用。 // 理论上不存在代理时，earlySingletonReference bean exposedObject 三者应该是相同的 // exposedObject = earlySingletonReference这一赋值操作即使在大多数情况下看似多余， // 但它确保了整个初始化过程的一致性，尤其在处理代理对象和循环依赖问题时，保证了最终暴露的Bean实例是正确的。 // 这种设计提高了代码的健壮性和可维护性，确保了在各种复杂场景下的正确性。 exposedObject = earlySingletonReference; &#125; // 存在代理操作时，要确保依赖当前bean 的其他bean 引用到了正确的版本 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; // 获取所有依赖当前Bean的Bean名称。 String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; // 尝试移除只为类型检查而创建的单例Bean。如果成功移除，表示这个Bean只是为类型检查而创建的，不是实际使用的Bean。 // 通过这个循环，Spring会过滤掉那些只为类型检查而创建的Bean，保留那些实际依赖当前Bean的Bean。 if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; // 这段逻辑确保在处理循环依赖时，确保依赖的Bean使用的是最终版本的Bean，而不是中间状态的原始Bean。 // 如果存在实际依赖当前Bean的Bean。抛出BeanCurrentlyInCreationException异常 // 因为这意味着有Bean在循环依赖的过程中使用了当前Bean的原始版本，但最终当前Bean被包装（如被AOP代理）。 // 这意味着被依赖的Bean使用的不是最终版本的Bean，这可能导致一些问题。 throw new BeanCurrentlyInCreationException(beanName, &quot;Bean with name &#x27;&quot; + beanName + &quot;&#x27; has been injected into other beans [&quot; + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + &quot;] in its raw version as part of a circular reference, but has eventually been &quot; + &quot;wrapped. This means that said other beans do not use the final version of the &quot; + &quot;bean. This is often the result of over-eager type matching - consider using &quot; + &quot;&#x27;getBeanNamesForType&#x27; with the &#x27;allowEagerInit&#x27; flag turned off, for example.&quot;); &#125; &#125; &#125; &#125; // Register bean as disposable. // 将一个Bean注册为可销毁的（disposable） try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex); &#125; return exposedObject; &#125; 6.2 doCreateBean-createBeanInstance使用反射创建bean 实例,整个过程可以分为三个步骤： 获取类的 Class 对象实例 根据 Class 对象实例获取 Constructor 对象， 这里默认使用无参构造函数， 等待后面的populate 填充属性 使用 Constructor 对象的 newInstance 方法获取反射类对象1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; // Make sure bean class is actually resolved at this point. // 获取bean 的Class 对象，Class是通过反射创建bean 的基础 Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); // 检查 Bean 类是否为 public，如果不是且不允许非 public 访问，则抛出 BeanCreationException 异常。 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Bean class isn&#x27;t public, and non-public access not allowed: &quot; + beanClass.getName()); &#125; // 如果 mbd 配置了一个实例提供者（Supplier），则通过该Supplier创建 Bean 实例。 Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return obtainFromSupplier(instanceSupplier, beanName); &#125; // 如果配置了工厂方法名，则通过工厂方法创建 Bean 实例。 if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // Shortcut when re-creating the same bean... // 标志是否已经解析了构造函数或工厂方法。 boolean resolved = false; //标志是否需要自动装配， 即bean之间是否有依赖关系 boolean autowireNecessary = false; // 只有在没有传递构造函数参数的情况下，才会进行缓存检查。这是因为如果有参数传入，必然需要重新解析构造函数。 if (args == null) &#123; //进入同步块，确保对 mbd 的检查和修改是线程安全的。 synchronized (mbd.constructorArgumentLock) &#123; //检查 resolvedConstructorOrFactoryMethod 是否已经被解析并缓存。 if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; //如果 resolved 为 true，则表示已经有缓存的构造函数 if (resolved) &#123; //根据 autowireNecessary 的值决定使用哪种方式创建 Bean 实例 //如果需要自动装配（autowireNecessary 为 true），则调用 autowireConstructor 方法，通过自动装配的方式创建 Bean 实例。 if (autowireNecessary) &#123; return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; //如果不需要自动装配，则调用 instantiateBean 方法，使用无参构造函数创建 Bean 实例。 return instantiateBean(beanName, mbd); &#125; &#125; // Candidate constructors for autowiring? // 调用 BeanPostProcessor 确定候选的构造函数。 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args); &#125; // Preferred constructors for default construction? ctors = mbd.getPreferredConstructors(); if (ctors != null) &#123; return autowireConstructor(beanName, mbd, ctors, null); &#125; // No special handling: simply use no-arg constructor. // 无参构造函数 return instantiateBean(beanName, mbd);&#125; 6.2.1 获取Class对象在Spring 启动过程中，bean 的实例化用反射机制完成。 反射机制的运行依赖于Class 对象。在createBeanInstance代码中， 获取Class 对象有两种选择， Class.forName ClassLoader.loadClass 6.2.2 instantiateBean-无参构造函数实例化bean比较简单，总体流程遵循常见的反射讲解中，最简单的那种demo12constructorToUse = clazz.getDeclaredConstructor();ctor.newInstance(argsWithDefaultValues); 6.2.3 autowireConstructor-构造函数注入实例化beanautowireConstructor有可能会遇到循环依赖。 构造函数注入方式中，bean 必须已经实例化完成，因此三层缓存机制中提前暴露的早期引用是如何解决构造函数注入引发的循环依赖的。 6.3 earlySingletonExposurebean 已经完成了初步 实例化， 虽然还不完美（还没有进行 第二步populate和第三步 init），但是已经能被人认出来了（根据对象引用能定位到堆中的对象），所以 Spring 此时将这个对象提前曝光出来让大家认识，让大家使用。 提前暴露引用的逻辑，是添加第3层缓存， 1addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); ObjectFactory 的匿名类实现是getEarlyBeanReference， getEarlyBeanReference 方法中处理了AOP 代理的情况，bean 需要被AOP 代码，会返回代理对象的引用。 6.4 doCreateBean- populateBean在属性填充阶段，也有可能会遇到循环依赖。这一阶段的循环依赖可以通过三层缓存提前暴露早期引用解决。 6.5 doCreateBean- initializeBean只留重点代码，bean 的init 流程如下 12345678910protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; invokeAwareMethods(beanName, bean); applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); invokeInitMethods(beanName, wrappedBean, mbd); applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; init 过程中，涉及到多个拓展点，如 Aware、BeanPostProcessor，具体关于拓展点的介绍，可以阅读Spring 启动过程拓展点拓展点 6.5.1 Aware-invokeAwareMethods点击查看invokeAwareMethods， 其逻辑涉及到3个Aware 接口。 Spring框架中，Aware接口的作用是让bean能够拿到对Spring容器中的各种资源，从而增强bean的功能和灵活性。 不同的 Aware 基本都能够见名知意，Aware之前的名字就是可以拿到什么资源，例如BeanNameAware可以拿到BeanName，以此类推。调用时机需要注意：所有的Aware方法都是在init阶段之前调用的 6.5.2 BeanPostProcessorapplyBeanPostProcessorsBeforeInitialization 和applyBeanPostProcessorsAfterInitialization 是BeanPostProcessor 的接口实现, 分别在init 前后调用，可以修改bean 实例， Spring AOP 就是基于BeanPostProcessor 实现的 1234567891011public interface BeanPostProcessor &#123; @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125;&#125; 6.5.3 invokeInitMethods - InitializingBean123456789101112protected void invokeInitMethods(String beanName, Object bean, @Nullable RootBeanDefinition mbd)&#123; ((InitializingBean) bean).afterPropertiesSet(); if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) &#123; String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, mbd); &#125; &#125;&#125; InitializingBean是Spring框架中定义的一个接口，用于在bean的所有属性设置完成后执行自定义的init 逻辑。它是Spring生命周期回调机制的一部分，使得bean可以在属性注入完成后但在使用之前执行一些自定义的初始化工作。123public interface InitializingBean &#123; void afterPropertiesSet() throws Exception;&#125; 实现InitializingBean接口的bean可以通过afterPropertiesSet方法在Spring容器完成依赖注入后但在使用bean之前执行一些初始化逻辑。典型的使用场景包括： 检查依赖属性：确保所有必需的属性已经被设置，并且满足某些业务约束。 执行初始化操作：例如，建立数据库连接、加载配置文件、启动辅助服务等。 其他初始化逻辑：在bean被使用之前需要完成的任何其他准备工作。 @PostConstruct注解除了实现InitializingBean接口，Spring还提供了一个更常用的注解@PostConstruct，可以用于同样的初始化目的。@PostConstruct是Java EE的标准注解，通常更简洁并且更符合注解驱动开发的风格。 使用@PostConstruct注解的示例： 1234567891011121314151617181920212223import javax.annotation.PostConstruct;import org.springframework.stereotype.Component;@Componentpublic class MyBeanWithPostConstruct &#123; private String someProperty; // Setter for dependency injection public void setSomeProperty(String someProperty) &#123; this.someProperty = someProperty; &#125; @PostConstruct public void init() &#123; // 执行初始化逻辑 if (this.someProperty == null) &#123; throw new IllegalArgumentException(&quot;Property &#x27;someProperty&#x27; is required&quot;); &#125; System.out.println(&quot;@PostConstruct: Properties have been set, someProperty=&quot; + this.someProperty); // 其他初始化代码... &#125;&#125; InitializingBean与@PostConstruct的区别 实现方式： InitializingBean：通过实现接口的方法来定义初始化逻辑。 @PostConstruct：通过在方法上使用注解来定义初始化逻辑。 使用场景： InitializingBean：更适用于需要显式实现接口的场景，通常在框架或底层代码中使用。 @PostConstruct：更适用于应用层代码，更加简洁和直观。 灵活性： InitializingBean：必须实现接口，不支持多个初始化方法。 @PostConstruct：可以在类中定义多个初始化方法（通过多个注解）。6.5.4 invokeCustomInitMethod 这里的init 指的是在 XML 配置或 Java 配置中指定的自定义 init-method 方法。在 Spring 框架中，当一个 Bean 的生命周期到达初始化阶段时，如果该 Bean 配置了自定义的初始化方法，Spring 将会调用这个方法来进行一些初始化操作。在 XML 配置中，可以通过 init-method 属性指定一个 Bean 的自定义初始化方法。例如：123&lt;bean id=&quot;exampleBean&quot; class=&quot;com.example.MyBean&quot; init-method=&quot;customInit&quot;&gt; &lt;!-- Bean 属性配置 --&gt;&lt;/bean&gt; 在 Java 配置中，可以使用 @Bean 注解的 initMethod 属性来指定自定义初始化方法。例如：12345678@Configurationpublic class AppConfig &#123; @Bean(initMethod = &quot;customInit&quot;) public MyBean exampleBean() &#123; return new MyBean(); &#125;&#125; invokeCustomInitMethod 方法的作用就是在 Bean 初始化过程中，调用在 XML 或 Java 配置中指定的自定义初始化方法。 6.5.5 拓展点执行顺序以上内容中提到的拓展点，其执行顺序在代码中已经有比较清晰的展示，这里再强调一下 Aware BeanPostProcessor的postProcessBeforeInitialization`方法。如果有多个BeanPostProcessor，会按顺序调用它们的postProcessBeforeInitialization方法。(其实这个步骤中也会有相关Aware) 使用@PostConstruct注解的方法。此时，所有依赖已经注入完毕，Bean已经完全配置好，但还没有执行任何自定义的初始化方法。 实现InitializingBean接口的afterPropertiesSet方法。 在XML配置或Java配置中指定的自定义init-method方法。 BeanPostProcessor的postProcessAfterInitialization方法。如果有多个BeanPostProcessor，会按顺序调用它们的postProcessAfterInitialization方法 6.6 缓存管理-addSingleton当通singletonObject = singletonFactory.getObject() 获得到bean 后，需要重新管理3层缓存中的数据 123456789// init完成的bean， 添加到一级缓存，并从二三级缓存中删除protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125;&#125; 7. 再看getBean-从2种视角出发在第4小节doGetBean 的注释中受了，对于一个bean 触发getBean 的逻辑有2中情况 bean 的正常创建流程 依赖注入触发的getBean 再看看下getSinngleton 的代码123456789101112131415161718192021222324252627282930313233343536373839代码均在 DefaultSingletonBeanRegistry.java public Object getSingleton(String beanName) &#123; return getSingleton(beanName, true); &#125;@Nullable protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // Quick check for existing instance without full singleton lock // 首先从 singletonObjects（单例缓存）中快速获取 Bean 实例，如果存在则直接返回。 Object singletonObject = this.singletonObjects.get(beanName); // 如果初步检查没有找到实例，并且该单例当前正在创建中，则从 earlySingletonObjects（早期单例缓存）中查找。 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; //如果仍未找到实例，并且允许早期引用，则进入同步块。 //在同步块内，再次从 singletonObjects 和 earlySingletonObjects 中检查实例。 // 这是为了避免在进入同步块的过程中，有其他线程已经创建了该单例实例。 synchronized (this.singletonObjects) &#123; // Consistent creation of early reference within full singleton lock singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); //如果仍未找到实例，则尝试从 singletonFactories 中获取单例工厂， // 并singletonFactory创建早期引用，将其放入 earlySingletonObjects 中，并从 singletonFactories 中移除。 if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; &#125; &#125; return singletonObject; &#125; 在正常的创建流程中，getSingleton(beanName, true)返回的通常是null，因为此时Bean尚未创建完毕。 在依赖注入的场景中，通过getSingleton(beanName, true)可以通过3级缓存获取到二级缓存 早期引用，从而解决循环依赖问题。 可以看出在一个bean 的正常创建流程中， 只会触发对一级、三级缓存的操作， 并不会主动生成早期引用， 只有在循环依赖的情况下，才会触发对2级缓存。 8. getObjectForBeanInstance现在不论是正常的创建流程需要createBean，还是依赖注入可以直接获取早期引用，获取到sharedInstance 都没有直接返回，而是经过getObjectForBeanInstance 处理后才返回。123456789101112131415161718192021222324252627282930AbstractBeanFactory.javapublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false); &#125;// 省略了非常多代码，只保留了相关逻辑protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; // 尝试从缓存中获取 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; // 缓存中存在则直接返回 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125;else&#123; // 缓存中没有则需要创建并回写缓存 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125;catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; return bean;&#125;在 Spring 框架中，getObjectForBeanInstance 方法用于处理FactoryBean 这种特殊的bean ，以确保返回给用户的是正确类型和状态的对象。关于理解 Spring FacrotyBean简单来讲，FactoryBean 也是一个bean ， 但是通过它可以生产出其他bean。 FactoryBean有两种用法 使用 getBean(&quot;&amp;beanName&quot;) 可以获取 FactoryBean 实例本身，而不是 FactoryBean 创建的对象。 使用 getBean(&quot;beanName&quot;) 则获取由 FactoryBean 创建的对象。 getObjectForBeanInstance的存在就是为了处理如果一个bean 是FactoryBean，那到底是返回FactoryBean，还是返回FactoryBean 创建的对象 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253protected Object getObjectForBeanInstance( Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &#123; // 检查 name 是否包含特殊符号 &amp;。 // 如果包含就表示getBean需要返回的是FactoryBean本身。而不是通过FactoryBean创建的对象。 if (BeanFactoryUtils.isFactoryDereference(name)) &#123; //如果 beanInstance 是 NullBean 类型，直接返回它。 if (beanInstance instanceof NullBean) &#123; return beanInstance; &#125; //如果从name 判断是FactoryBean， 但是instanceof 判断不是 FactoryBean 类型，抛出 BeanIsNotAFactoryException 异常。 if (!(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(beanName, beanInstance.getClass()); &#125; //如果提供了 mbd，将 isFactoryBean 设置为 true，表示这是一个工厂 Bean。 if (mbd != null) &#123; mbd.isFactoryBean = true; &#125; return beanInstance; &#125; // name不以 &amp; 开头， 代表getBean 需要的是 普通Bean 或 通过FactoryBean创建的对象： // 如果 beanInstance 不是 FactoryBean，说明它是一个普通bean, 直接返回即可。 if (!(beanInstance instanceof FactoryBean)) &#123; return beanInstance; &#125; // 以下过程是通过FactoryBean创建对象 Object object = null; //如果提供了 mbd，将 isFactoryBean 设置为 true。 if (mbd != null) &#123; mbd.isFactoryBean = true; &#125; else &#123; //否则，调用 getCachedObjectForFactoryBean(beanName) 尝试从缓存中获取 FactoryBean 创建的对象。 //没有 mbd/beandefinition 的情况下，无法知道 FactoryBean 的详细信息，只能依赖缓存,通过beanName 尝试获取FactoryBean创建的对象 //这种设计确保了在缺少 mbd 元数据时，Spring 仍能可靠地提供 Bean 实例，同时最大限度地利用缓存以提高性能。 object = getCachedObjectForFactoryBean(beanName); &#125; //如果 object 为 null，表示缓存中没有对象，需要从 FactoryBean 获取 if (object == null) &#123; // Return bean instance from factory. //将 beanInstance 转换为 FactoryBean 类型。 FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) beanInstance; // Caches object obtained from FactoryBean if it is a singleton. // 缓存中没有则要尝试获取mbd if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) &#123; mbd = getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic()); object = getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object; &#125; 9. 三级缓存的转换流程 一个非懒加载的单例bean 实例化过程中， 只会主动去添加一级、三级缓存，只有循环依赖才会触发二级缓存 对于一个bean ,不论是完整引用，还是早期引用，还是生成早期引用的ObjectFactory，在同一时刻， 只会存在于一级缓存中 9.1 为什么需要第三级缓存-addSingletonFactorydoCreateBean-&gt;addSingletonFactory， 在create 步骤后， populate 步骤前 第三级缓存的存在主要是为了处理代理机制。通常情况下，代理对象会在Bean的init阶段生成。如果在解决循环依赖时提前暴露的引用不是代理对象的引用，而是原始对象的引用，即doCreateBean代码中 bean 和exposedObject 不一致123456BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args);Object bean = instanceWrapper.getWrappedInstance();populateBean(beanName, mbd, instanceWrapper);Object exposedObject =initializeBean(beanName, exposedObject, mbd) 但是如果可以在循环依赖的处理中处理中就为bean 生成代理对象的引用（如果需要代理的话）， 那么就可以和init阶段产生的代理引用保持一致了。这个功能是通过getEarlyBeanReference 来完成的如果是需要代理的对象，getEarlyBeanReference就会生成其代理对象的引用，而不是原对象的引用。 在解决循环依赖提前暴露引用时，如果提前暴露的引用不是其代理对象的引用的话，就会产生数据不一致的情况。 123456789101112addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; &#125; 这里又有一个ObjectFactory的匿名实现类， 且添加进了三级缓存singletonFactories中， 下面来具体看下getEarlyBeanReference实现了什么 getEarlyBeanReference由此可见，三级缓存用于生产二级缓存中存放的早期引用，如果是需要代理的对象，getEarlyBeanReference就会生成其代理对象的引用，而不是原对象的引用。 之所以需要三级缓存是因为代理机制的存在， 在整个bean 的生命周期中，会在init 阶段生成其代理对象（如果需要的话），那么在解决循环依赖提前暴露引用时，如果提前暴露的引用不是其代理对象的引用的话，就会产生数据不一致的情况 123456789protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (SmartInstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().smartInstantiationAware) &#123; exposedObject = bp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; return exposedObject;&#125; 9.2 二级缓存 12345678910111213141516171819202122232425262728293031 protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // Quick check for existing instance without full singleton lock Object singletonObject = this.singletonObjects.get(beanName); // 如果没有找到实例且该Bean正在创建中 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; // 从二级缓存中获取早期引用 singletonObject = this.earlySingletonObjects.get(beanName); // 如果二级缓存中没有且允许早期引用 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 在全局锁内一致地创建早期引用 synchronized (this.singletonObjects) &#123; // 再次检查一级缓存 singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // 再次检查二级缓存 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; // 通过三级缓存创建早期引用 singletonObject = singletonFactory.getObject(); // 将早期引用放入二级缓存 this.earlySingletonObjects.put(beanName, singletonObject); // 从三级缓存中移除工厂 this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; &#125; &#125; return singletonObject; &#125; 9.3 一级缓存getSingleton -&gt; addSingleton，在bean的实例化完成后， 会将其引用放入一级缓存，同时删除2、3级缓存12345678protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; 10. 循环依赖在Spring IOC容器 和 Spring bean讲过，Bean 依赖关系声明方式有3种 基于构造函数的依赖注入 基于 Setter 方法 基于字段10.1 循环依赖的产生 循环依赖的产生基于依赖关系的3种声明方式，也可以分为3种 A 的构造方法中依赖了 B 的实例对象，同时 B 的构造方法中依赖了 A 的实例对象 A 的构造方法中依赖了 B 的实例对象，同时 B 的某个 field 或者 setter 需要 A 的实例对象，以及反之 A 的某个 field 或者 setter 依赖了 B 的实例对象，同时 B 的某个 field 或者 setter 依赖了 A 的实例对象，以及反之 Spring 中 非懒加载的单例bean, 初始化过程可以分为3个步骤，循环依赖的步骤集中在第一步和第二步： createBeanInstance， 通过构造函数创建实例 populateBean，填充属性/依赖注入 initializeBean，初始化10.2 循环依赖的解决-三层缓存、提前暴露引用Spring 循环依赖的理论依据其实是 Java 基于引用传递，当我们获取到对象的引用时，对象的 field 或者或属性是可以延后设置的。三层缓存中的二、三级缓存涉及用于提前暴露引用，以此解决循环依赖问题。关于三级缓存，具体可以看上面的内容 10.3 循环依赖的解决前提在3级缓存的机制下， 以上三种情况只能解决2&amp;3，1无法解决因为Spring容器能顺利实例化以构造函数注入方式配置的Bean有一个前提：Bean构造函数入参引用的对象必须已经准备就绪，即需要完成populate和init 这两个步骤，不能只有一个引用，因此提前曝光也没用。由于这个机制的限制，如果两个Bean都采用构造函数注入，而且都通过构造函数入参引用对方，就会发生类似于线程死锁的循环依赖问题。将构造函数注入方式调整为属性注入方式就可以了。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Spring IOC容器 和 Spring bean","slug":"Spring-IOC-容器-和Spring-bean","date":"2023-05-17T07:38:57.000Z","updated":"2024-07-11T10:01:01.813Z","comments":true,"path":"50be4554/","permalink":"http://example.com/50be4554/","excerpt":"","text":"1. 为什么需要IOCIOC是面向对象编程中的一种设计原则，它的核心思想是将对象的创建和依赖关系的管理从应用程序代码中转移到外部容器。只需在代码中声明需要的对象或实例，而不需要自己创建它们。IOC容器会根据这些声明自动注入所需的实例。使用IOC 有以下好处 1.1 解耦与简化代码在传统的编程方式中，类与类之间的依赖关系往往是通过直接实例化来实现的。例如：1234567891011public class ServiceA &#123; private ServiceB serviceB; public ServiceA() &#123; this.serviceB = new ServiceB(); &#125; public void performAction() &#123; serviceB.doSomething(); &#125;&#125; 在这种方式中，ServiceA直接创建了ServiceB的实例，这导致了两者之间的强耦合。如果我们需要更换ServiceB的实现或修改其创建逻辑，就需要修改ServiceA的代码。这不仅增加了维护难度，也违反了开闭原则（Open/Closed Principle）。 通过IOC，我们可以将依赖关系的管理交给容器：12345678910111213@Componentpublic class ServiceA &#123; private final ServiceB serviceB; @Autowired public ServiceA(ServiceB serviceB) &#123; this.serviceB = serviceB; &#125; public void performAction() &#123; serviceB.doSomething(); &#125;&#125; 在这种方式中，ServiceA不再负责创建ServiceB的实例，而是声明它需要一个ServiceB的实例。IOC容器会自动注入ServiceB的实例，从而实现了解耦。 1.2 提高代码的可测试性传统方式中的强耦合使得单元测试变得困难，因为测试ServiceA时需要实际的ServiceB实例。而通过IOC，依赖关系由容器管理，使得我们可以轻松地替换依赖对象为模拟对象（Mock Object），从而简化了测试：1234567891011121314151617181920@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = AppConfig.class)public class ServiceATest &#123; @Mock private ServiceB serviceB; @InjectMocks private ServiceA serviceA; @Test public void testPerformAction() &#123; // 配置mock行为 when(serviceB.doSomething()).thenReturn(&quot;Mock Response&quot;); // 调用方法并验证 serviceA.performAction(); verify(serviceB).doSomething(); &#125;&#125;通过IOC容器管理依赖关系，我们能够更容易地替换实际依赖对象，从而提高了测试的便捷性和覆盖率。 1.3 配置与管理的灵活性IOC容器通常提供灵活的配置方式，可以通过注解或配置文件来管理依赖关系。例如，在Spring框架中，可以使用Java配置类或XML配置文件来定义依赖关系： 1.4 支持高级功能除了依赖注入，现代IOC容器通常还提供诸如AOP（Aspect-Oriented Programming，面向切面编程）、声明式事务等高级功能。这些功能进一步提高了代码的灵活性和可维护性。例如，AOP可以用于实现日志记录、事务管理等横切关注点，而无需在业务代码中添加相关逻辑。 2. Spring IOC 容器分类Spring IOC容器的主要实现有两种：BeanFactory和ApplicationContext，它们之间有一定的层次关系和联系。以下是对这些容器及其联系的详细说明： 2.1 Spring IOC 容器的主要实现1.1 BeanFactoryBeanFactory是Spring框架中最基础的IOC容器。它提供了基本的依赖注入机制，负责管理Bean的实例化、配置和生命周期。 1.2 ApplicationContextApplicationContext是在BeanFactory基础上扩展的高级容器，提供了更多面向应用的功能，它还提供了国际化支持和框架事件体系，更易于创建实际应用。 一般称BeanFactory为IoC容器，而称ApplicationContext为应用上下文。但有时为了行文方便，也将ApplicationContext称为Spring容器。 2.2 ApplicationContext的具体实现及其功能 ClassPathXmlApplicationContext：从类路径下的XML配置文件加载上下文。 FileSystemXmlApplicationContext：从文件系统中的XML配置文件加载上下文。 AnnotationConfigApplicationContext：从Java配置类加载上下文。 2.2.1 ClassPathXmlApplicationContext从类路径下的XML配置文件中加载Spring应用上下文。 12ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);MyBean myBean = context.getBean(MyBean.class); 2.2.2 FileSystemXmlApplicationContext从文件系统中的XML配置文件中加载Spring应用上下文。 12ApplicationContext context = new FileSystemXmlApplicationContext(&quot;C:/config/applicationContext.xml&quot;);MyBean myBean = context.getBean(MyBean.class); 2.2.3 WebApplicationContextWebApplicationContext 是 Spring 框架中专为 Web 应用设计的应用上下文，它扩展了 ApplicationContext，提供了与 Web 环境相关的特性和功能。在 Spring MVC 中，WebApplicationContext 扮演着关键角色，通过配置控制器、视图解析器等组件，管理 Web 请求的处理流程，访问 ServletContext、获取 Web 应用参数等 与 Servlet 关联：WebApplicationContext 可以访问 ServletContext，从而能够获取 Web 应用的环境参数。 支持国际化：通过 Web 环境的 MessageSource，支持国际化消息资源的获取。 与 Spring MVC 集成：WebApplicationContext 是 Spring MVC 的核心组件，用于配置和管理控制器、视图解析器等 MVC 组件。 在传统Spring应用中，WebApplicationContext经常与XML配置一起使用，通过ContextLoaderListener或ContextLoaderServlet来初始化和管理 2.2.4 AnnotationConfigApplicationContext从Java配置类中加载Spring应用上下文，支持基于注解的配置。 1234567891011@Configuration@ComponentScan(basePackages = &quot;com.example&quot;)public class AppConfig &#123; @Bean public MyBean myBean() &#123; return new MyBean(); &#125;&#125;ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);MyBean myBean = context.getBean(MyBean.class); 2.3 BeanFactory与ApplicationContext的联系对于两者的用途，可以进行简单划分：BeanFactory是Spring框架的基础设施，面向Spring本身；ApplicationContext面向使用Spring框架的开发者，几乎所有的应用场合都直接使用ApplicationContext而非底层的BeanFactory。 层次关系： ApplicationContext继承了BeanFactory的所有功能，同时扩展了许多高级功能。 BeanFactory提供了基础的IOC容器功能，而ApplicationContext在其基础上提供了更丰富的企业级功能。 使用方式： 在实际开发中，通常直接使用ApplicationContext，因为它提供了更强大的功能和更友好的开发体验。 BeanFactory更多地用于底层框架的实现和一些特殊的资源受限场景。 初始化方式： BeanFactory的bean是懒加载的，只有在第一次访问时才会被初始化。 ApplicationContext的bean默认在启动时就会被全部初始化。 3. Spring IOC 容器的启动过程3.1 XML 配置下 Spring 容器的启动过程在Spring Web应用中，Spring IOC容器（WebApplicationContext）的启动和初始化是由Web容器（如Tomcat、Jetty等）驱动的。 3.1.1 ContextLoaderListenerContextLoaderListener是Spring框架中的一个监听器，用于在Web容器启动时创建并启动Spring的应用上下文WebApplicationContext。它主要负责： 创建并启动Spring的应用上下文WebApplicationContext 管理Spring的根上下文（Root ApplicationContext）,使其在整个Web应用中可用。 在应用关闭时（contextDestroyed方法）销毁上下文，正确关闭Spring上下文，释放资源。 123456789101112&lt;web-app&gt; &lt;!-- 配置 Spring 的 ContextLoaderListener --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置 Spring 的应用上下文文件位置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; 当Web容器（如Tomcat、Jetty等）启动时，ContextLoaderListener会监听到容器的启动事件，随后执行以下步骤： 读取contextConfigLocation参数：ContextLoaderListener读取web.xml中的contextConfigLocation参数，获取Spring配置文件的位置。 加载Spring配置文件：根据contextConfigLocation参数指定的位置，加载Spring的配置文件。通常，这些文件是XML格式的配置文件，但也可以是其他类型的配置文件，如Java配置类。 初始化WebApplicationContext：创建并初始化WebApplicationContext，加载配置文件中的所有bean定义，并进行依赖注入和初始化。 注册上下文：将创建的WebApplicationContext注册到ServletContext中，使其在整个Web应用中可用。属性名为WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE。3.1.2 ContextLoaderServlet ContextLoaderServlet是Spring框架中的一个Servlet，用于在Servlet初始化时启动Spring的WebApplicationContext。与ContextLoaderListener类似，它负责： 加载Spring的应用上下文。 管理Spring的根上下文（Root ApplicationContext），使其在整个Web应用中可用。 在Servlet销毁时，正确关闭Spring上下文，释放资源。 以下是在web.xml中配置ContextLoaderServlet的示例：1234567891011121314&lt;web-app&gt; &lt;!-- 配置 Spring 的 ContextLoaderServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;contextLoader&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.context.ContextLoaderServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- 配置 Spring 的应用上下文文件位置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; 当Web容器（如Tomcat、Jetty等）启动时，ContextLoaderServlet会在Servlet初始化阶段执行以下步骤： 读取contextConfigLocation参数：ContextLoaderServlet读取web.xml中的contextConfigLocation参数，获取Spring配置文件的位置。 加载Spring配置文件：根据contextConfigLocation参数指定的位置，加载Spring的配置文件。通常，这些文件是XML格式的配置文件，但也可以是其他类型的配置文件，如Java配置类。 初始化WebApplicationContext：创建并初始化WebApplicationContext，加载配置文件中的所有bean定义，并进行依赖注入和初始化。 注册上下文：将创建的WebApplicationContext注册到ServletContext中，使其在整个Web应用中可用。 Servlet生命周期管理：ContextLoaderServlet在init方法中启动Spring上下文，在destroy方法中关闭上下文。3.1.3 ContextLoaderListener vs ContextLoaderServlet ContextLoaderListener是启动Spring WebApplicationContext的最常用方式，适用于大多数Web应用。ContextLoaderServlet较少使用，通常用于需要精细控制上下文启动顺序的特殊场景。 3.2 Springboot项目 IOC 容器的启动过程对于Web应用，Spring Boot使用AnnotationConfigServletWebServerApplicationContext作为ApplicationContext。这是AnnotationConfigApplicationContext的一个派生类，专门用于Web应用程序。 创建SpringApplication实例 根据合适的应用类型确定ApplicationContext类 加载配置和初始化 启动嵌入式Web服务器（如果是Web应用） Spring Boot 应用的启动过程通常从一个包含 main 方法的类开始，该类使用了 @SpringBootApplication 注解： 123456@SpringBootApplicationpublic class MySpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MySpringBootApplication.class, args); &#125;&#125; @SpringBootApplication 是一个组合注解，包含了以下三个注解： @SpringBootConfiguration：标识这是一个 Spring Boot 配置类。 @EnableAutoConfiguration：启用 Spring Boot 的自动配置机制。 @ComponentScan：启用组件扫描，自动发现并注册被 @Component、@Service、@Repository、@Controller 等注解标识的 Spring Bean。 SpringApplication.run 方法执行以下步骤： 准备环境：创建并配置 Environment，加载应用配置文件（如 application.properties）。 创建应用上下文：创建合适的 ApplicationContext 实例（如 AnnotationConfigServletWebServerApplicationContext 用于 Web 应用）。 自动配置：根据类路径中的依赖和应用配置，自动配置 Spring 应用组件。 刷新上下文：初始化 Spring 应用上下文，扫描和注册所有 Spring Bean。 启动嵌入式服务器：如果是 Web 应用，启动嵌入式 Web 服务器（如 Tomcat）。 运行应用：启动应用并处理所有定义的 CommandLineRunner 和 ApplicationRunner 实现。 3.3 Spring Boot vs 传统 Spring 启动方式3.3.1 配置简化 传统 Spring：通常需要大量的 XML 配置文件或 Java 配置类来定义 Bean 和依赖关系。 Spring Boot：通过自动配置和约定优于配置，极大地简化了配置，只需少量配置文件或注解。3.3.2 嵌入式服务器 传统 Spring：通常需要在外部 Web 服务器（如 Tomcat）中部署应用。 Spring Boot：支持嵌入式服务器，应用可以打包为一个可执行的 JAR 文件，直接运行。 3.3.3 启动速度 传统 Spring：启动过程较为繁琐，需要手动配置和管理许多组件。 Spring Boot：启动过程高度自动化，启动速度更快，开发体验更好。 Spring IOC 容器管理着 Bean 的生命周期，控制着 Bean 的依赖注入。 上面介绍完了Spring IOC 容器， 下面就来介绍一下它管理的 bean 一些相关基础知识。 4. Bean 定义方式不管是XML还是注解，它们都是表达Bean定义的载体，其实质都是为Spring IOC容器提供Bean定义的信息 4.1 XML 配置1234567891011&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;myBean&quot; class=&quot;com.example.MyBean&quot;&gt; &lt;property name=&quot;property&quot; value=&quot;value&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; 4.2 基于注解的配置Spring从2.0开始引入基于注解的配置方式，在3.1时得到了进一步的完善。常见的注解包括 @Component、@Service、@Repository 和 @Controller，这些注解将类声明为 Spring 管理的 Bean。1234@Componentpublic class MyBean &#123; // class definition&#125; @Component：通用注解，适用于所有层次的类，用于将类标识为 Spring 容器管理的Bean。在实际开发中也可以选择更具体的注解来标识不同层次的组件 @Repository：数据访问层，用于对DAO实现类进行标注。 @Service：数据访问层，用于对Service实现类进行标注。 @Controller：控制器层，用于对Controller实现类进行标注。 4.3 基于 Java 类的配置 Java ConfigJava Config 是通过使用 @Configuration 注解的类来定义 Spring 容器的配置。这样的类可以包含一个或多个 @Bean 注解的方法，这些方法的返回值会被 Spring 容器注册为 Bean。 @Configuration 类本质上是一个特殊的 @Component，其主要目的是为了定义 Bean。 所以任何标注了@Configuration的类，本身也相当于标注了@Component，即它们可以像普通的Bean一样被注入其他Bean中。 1234567891011import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class AppConfig &#123; @Bean public MyService myService() &#123; return new MyServiceImpl(); &#125;&#125; 使用示例: 配置数据源和 JPA对于数据访问层，可以通过 Java Config 来配置数据源（DataSource）、实体管理器工厂（EntityManagerFactory）和事务管理器（TransactionManager）。 12345678910111213141516171819202122232425262728293031323334353637import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.datasource.DriverManagerDataSource;import org.springframework.orm.jpa.JpaTransactionManager;import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;import org.springframework.transaction.PlatformTransactionManager;import javax.persistence.EntityManagerFactory;import javax.sql.DataSource;@Configurationpublic class DataConfig &#123; @Bean public DataSource dataSource() &#123; DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(&quot;com.mysql.cj.jdbc.Driver&quot;); dataSource.setUrl(&quot;jdbc:mysql://localhost:3306/mydb&quot;); dataSource.setUsername(&quot;user&quot;); dataSource.setPassword(&quot;password&quot;); return dataSource; &#125; @Bean public LocalContainerEntityManagerFactoryBean entityManagerFactory(DataSource dataSource) &#123; LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean(); em.setDataSource(dataSource); em.setPackagesToScan(&quot;com.example.myapp.model&quot;); // Other JPA properties can be set here return em; &#125; @Bean public PlatformTransactionManager transactionManager(EntityManagerFactory emf) &#123; JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory(emf); return transactionManager; &#125;&#125; 5.Bean依赖关系声明方式Bean 之间的依赖关系可以通过多种方式进行声明和管理，以实现依赖注入（Dependency Injection, DI） 无论是 XML 配置还是基于注解的配置，都可以归类为以下三种主要的依赖注入方式：基于构造函数、基于 Setter 方法和基于字段 5.1 基于构造函数的依赖注入构造函数注入是通过在构造函数中声明依赖来进行注入的，这种方式有助于确保依赖关系在对象创建时就已经完全满足。 XML 配置：通过 &lt;constructor-arg&gt; 元素。 注解配置：通过在构造函数上使用 @Autowired 注解。 5.1.1 XML 配置在 XML 配置中，通过 &lt;constructor-arg&gt; 元素来指定构造函数参数的依赖注入1234&lt;bean id=&quot;myRepository&quot; class=&quot;com.example.MyRepositoryImpl&quot; /&gt;&lt;bean id=&quot;myService&quot; class=&quot;com.example.MyService&quot;&gt; &lt;constructor-arg ref=&quot;myRepository&quot; /&gt;&lt;/bean&gt; 5.1.2 基于注解配置通过 @Autowired 注解在构造函数上标注。 12345678910@Componentpublic class MyService &#123; private MyRepository myRepository; @Autowired public MyService(MyRepository myRepository) &#123; this.myRepository = myRepository; &#125; // Business methods&#125; 5.2 基于 Setter 方法的DI XML 配置：通过 &lt;property&gt; 元素。 注解配置：通过在 Setter 方法上使用 @Autowired 注解。5.2.1 XML 配置通过 &lt;property&gt; 元素来配置 Setter 方法注入。12345&lt;bean id=&quot;myRepository&quot; class=&quot;com.example.MyRepositoryImpl&quot; /&gt;&lt;bean id=&quot;myService&quot; class=&quot;com.example.MyService&quot;&gt; &lt;property name=&quot;myRepository&quot; ref=&quot;myRepository&quot; /&gt;&lt;/bean&gt; 5.2.2 基于注解配置123456789@Componentpublic class MyService &#123; private MyRepository myRepository; @Autowired public void setMyRepository(MyRepository myRepository) &#123; this.myRepository = myRepository; &#125;&#125; 5.3 基于字段的依赖注入字段注入是直接在类的字段上使用 @Autowired 注解来标识依赖。这种方式最为简洁，但XML 配置通常不推荐这种方式 5.3.1 基于注解配置直接在字段上使用 @Autowired 注解 1234567@Componentpublic class MyService &#123; @Autowired private MyRepository myRepository; // Business methods&#125; 6. Bean 扫描无论是使用 XML 配置还是基于注解的方式，定义好的 Bean 和Bean 之间的依赖关系都需要通过 Spring 的扫描机制才能被 Spring 容器识别并管理,从而起作用。Bean 扫描主要通过两种方式实现：基于 XML 配置和基于注解的方式。 6.1 基于 XML 的 Bean 扫描在 Spring 早期版本中，XML 配置是一种常见的配置方式，通过 XML 文件指定 Bean 扫描路径来实现自动发现和注册 Bean。 6.1.1 使用 &lt;context:component-scan&gt; 元素XML 配置文件中的 &lt;context:component-scan&gt; 元素用于指定包路径，Spring 容器会扫描这些包路径下的类，并根据注解自动注册为 Bean。123456789101112&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 扫描指定包路径下的所有组件类 --&gt; &lt;context:component-scan base-package=&quot;com.example&quot; /&gt;&lt;/beans&gt; 在这个示例中，&lt;context:component-scan&gt; 元素会扫描 com.example 包及其子包中的所有类，并自动注册带有 @Component、@Service、@Repository、@Controller 等注解的类为 Spring Bean。 6.1.2 指定多个包路径可以通过逗号分隔的方式指定多个包路径。1&lt;context:component-scan base-package=&quot;com.example, com.anotherexample&quot; /&gt; 6.2 基于注解的 Bean 扫描（Spring Boot）Spring Boot 通过自动配置和注解的方式，简化了 Bean 扫描的配置过程。通常情况下，只需在主启动类上添加一些注解，即可完成 Bean 扫描的配置。 自定义扫描的包路径，并可以显式使用 @ComponentScan 注解。123456789101112import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.ComponentScan;@SpringBootApplication@ComponentScan(basePackages = &quot;com.example&quot;)public class MyApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MyApplication.class, args); &#125;&#125; 如果不显示使用@ComponentScan ，其实@SpringBootApplication注解 是一个组合注解，包含了 @ComponentScan，但是智慧默认会扫描主启动类所在包及其子包中的所有组件类。 同样可以指定多个包路径。1@ComponentScan(basePackages = &#123;&quot;com.example&quot;, &quot;com.anotherexample&quot;&#125;)","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"}]},{"title":"Java动态代理","slug":"Java动态代理","date":"2020-05-16T07:04:53.000Z","updated":"2024-07-23T03:35:20.126Z","comments":true,"path":"abd111cb/","permalink":"http://example.com/abd111cb/","excerpt":"","text":"学习动态代理前，建议先学习下Java 反射与实践 在Java中，动态代理是一种设计模式，它允许在运行时创建代理类和代理对象，从而在不修改目标对象代码的情况下，为对象提供额外的功能，比如日志记录、事务管理、安全检查等。 Java 中动态代理的实现有2种方式 JDK 动态代理 CGLIB 动态代理 下面将从实际代码出发，对其实现原理进行解释。 1.JDK 动态代理JDK 动态代理是 Java 标准库中提供的一种代理实现机制 它主要依靠 java.lang.reflect.Proxy 类和 java.lang.reflect.InvocationHandler 接口来创建和管理代理对象。 JDK 动态代理只能通过实现接口的方式生成代理对象 1.1 代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface HelloWorld &#123; void sayHello(); void sayBye();&#125;public class HelloWorldImpl implements HelloWorld &#123; @Override public void sayHello() &#123; System.out.println(&quot;Hello, world!&quot;); &#125; @Override public void sayBye() &#123; System.out.println(&quot;Bye bye, world!&quot;); &#125;&#125;public class HelloWorldHandler implements InvocationHandler &#123; private Object target; public HelloWorldHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); Object result = method.invoke(target, args); System.out.println(&quot;After method: &quot; + method.getName()); return result; &#125;&#125;public class JdkDynamicProxyDemo &#123; public static void main(String[] args) &#123; HelloWorld helloWorld = new HelloWorldImpl(); HelloWorldHandler handler = new HelloWorldHandler(helloWorld); HelloWorld proxy = (HelloWorld) Proxy.newProxyInstance( helloWorld.getClass().getClassLoader(), helloWorld.getClass().getInterfaces(), handler); proxy.sayHello(); proxy.sayBye(); &#125;&#125; 运行结果如下 接下来进行源码分析 1.2 创建动态代理对象-Proxy.newProxyInstance1234HelloWorld proxy = (HelloWorld) Proxy.newProxyInstance( helloWorld.getClass().getClassLoader(), helloWorld.getClass().getInterfaces(), handler); Proxy 通过类加载器和接口集合动态地生成或查找代理类，并使用提供的InvocationHandler创建一个新的代理实例， 进入源码看一下 123456789101112public class Proxy implements java.io.Serializable &#123; @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) &#123; Constructor&lt;?&gt; cons = getProxyConstructor(caller, loader, interfaces); return newProxyInstance(caller, cons, h); &#125;&#125; 我们将重点分析newProxyInstance 这个方法， 进入源码， 该方法主要流程可以分为2个步骤，都是使用反射的典型步骤 getProxyConstructor newProxyInstance1.3 getProxyConstructor getProxyConstructor是一个私有方法，负责获取或生成代理类的构造函数。 1234567891011121314151617181920212223242526272829public class Proxy implements java.io.Serializable &#123; private static Constructor&lt;?&gt; getProxyConstructor(Class&lt;?&gt; caller,ClassLoader loader,Class&lt;?&gt;... interfaces) &#123; // optimization for single interface // 单接口优化，大多数实际应用中，代理通常只需要实现一个接口，这种情况提供了优化的机会。单接口优化的主要目的是减少处理时间和简化生成代理类的复杂度。 if (interfaces.length == 1) &#123; Class&lt;?&gt; intf = interfaces[0]; if (caller != null) &#123; checkProxyAccess(caller, loader, intf); &#125; return proxyCache.sub(intf).computeIfAbsent( loader, (ld, clv) -&gt; new ProxyBuilder(ld, clv.key()).build() ); &#125; else &#123; // interfaces cloned // 当有多个接口时，方法首先克隆接口数组，以避免修改原始数据。这是一种防御性编程技巧，确保数据的不可变性。 final Class&lt;?&gt;[] intfsArray = interfaces.clone(); if (caller != null) &#123; checkProxyAccess(caller, loader, intfsArray); &#125; final List&lt;Class&lt;?&gt;&gt; intfs = Arrays.asList(intfsArray); return proxyCache.sub(intfs).computeIfAbsent( loader, (ld, clv) -&gt; new ProxyBuilder(ld, clv.key()).build() ); &#125; &#125;&#125; proxyCache.sub(intf).computeIfAbsent: 这是一种高效的缓存访问模式，computeIfAbsent方法来尝试获取或创建代理类的构造函数, 如果缓存中没有相应的构造函数，会调用ProxyBuilder来动态生成一个新的代理类，并将其存储在缓存中。 checkProxyAccess: 这个方法检查调用者是否有权限使用指定的类加载器创建代理。这是一个安全检查，防止安全漏洞。 直接进入build 看创建流程 12345678910111213141516Constructor&lt;?&gt; build() &#123; Class&lt;?&gt; proxyClass = defineProxyClass(module, interfaces); final Constructor&lt;?&gt; cons; try &#123; cons = proxyClass.getConstructor(constructorParams); &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); return cons; &#125; 1.3.1 defineProxyClass -获取代理类的Class对象1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283private static final class ProxyBuilder &#123; private static final Unsafe UNSAFE = Unsafe.getUnsafe(); // prefix for all proxy class names private static final String proxyClassNamePrefix = &quot;$Proxy&quot;; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); // a reverse cache of defined proxy classes private static final ClassLoaderValue&lt;Boolean&gt; reverseProxyCache = new ClassLoaderValue&lt;&gt;(); // interfaces需要代理的接口列表 private static Class&lt;?&gt; defineProxyClass(Module m, List&lt;Class&lt;?&gt;&gt; interfaces) &#123; // 代理类的包名，初始为 null。 String proxyPkg = null; // 代理类的访问标志，初始为 PUBLIC | FINAL。 int accessFlags = Modifier.PUBLIC | Modifier.FINAL; // 遍历接口列表 for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); // 如果接口不是public，则认为是包级私有的。将 accessFlags 设置为 FINAL，并记录包名。 if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; // non-public, final String pkg = intf.getPackageName(); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; // 如果所有非public接口不在同一个包中，则抛出异常。 throw new IllegalArgumentException( &quot;non-public interfaces from different packages&quot;); &#125; &#125; &#125; // 确定代理类的包名 if (proxyPkg == null) &#123; // all proxy interfaces are public // PROXY_PACKAGE_PREFIX 是 “com.sun.proxy” proxyPkg = m.isNamed() ? PROXY_PACKAGE_PREFIX + &quot;.&quot; + m.getName() : PROXY_PACKAGE_PREFIX; &#125; else if (proxyPkg.isEmpty() &amp;&amp; m.isNamed()) &#123; throw new IllegalArgumentException( &quot;Unnamed package cannot be added to &quot; + m); &#125; if (m.isNamed()) &#123; if (!m.getDescriptor().packages().contains(proxyPkg)) &#123; throw new InternalError(proxyPkg + &quot; not exist in &quot; + m.getName()); &#125; &#125; /* * Choose a name for the proxy class to generate. */ // 使用一个全局计数器生成唯一的代理类名称。 long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg.isEmpty() ? proxyClassNamePrefix + num : proxyPkg + &quot;.&quot; + proxyClassNamePrefix + num; // 获取用于加载代理类的类加载器。 ClassLoader loader = getLoader(m); trace(proxyName, m, loader, interfaces); /* * Generate the specified proxy class. */ // 使用 ProxyGenerator 生成代理类的字节码 byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces.toArray(EMPTY_CLASS_ARRAY), accessFlags); try &#123; // 将字节码转换为 Class 对象并加载到 JVM 中 Class&lt;?&gt; pc = UNSAFE.defineClass(proxyName, proxyClassFile, 0, proxyClassFile.length, loader, null); reverseProxyCache.sub(pc).putIfAbsent(loader, Boolean.TRUE); return pc; &#125; catch (ClassFormatError e) &#123; throw new IllegalArgumentException(e.toString()); &#125; &#125;&#125; 1.3.1.1 代理类包名-proxyPkg关于 proxyPkg 的逻辑， 从上面的代码中可以看出： 如果有包级私有接口：代理类必须定义在这些接口所在的包中，以保证访问权限的一致性。如果包级私有接口分布在不同的包中，会抛出异常。 如果没有包级私有接口：如果所有接口都是公共的（public），代理类会默认定义在 com.sun.proxy 包中，或者 com.sun.proxy.&lt;module_name&gt;（如果模块被命名）。 这种设计确保了代理类生成时能够正确处理访问权限，同时提供了一个默认的命名空间（com.sun.proxy）来存放公共接口的代理类。 接口权限级别在Java中，类和接口的权限级别主要有以下四种（但接口只使用其中两种 public 和 Package-private ）： Public（公共）：任何地方都可以访问。 Protected（受保护的）：不能用于顶级类或接口，仅用于类的成员，允许同包中的类和子类访问。 Package-private（包级私有）：如果没有指定访问修饰符，表示只有同一个包中的类可以访问。 Private（私有的）：不能用于顶级类或接口，仅用于类的成员，表示只有该类本身可以访问。 代理类必须能够访问所有需要代理的接口，才能进行实现。 生成代理类时，如果遇到多个非public接口（包级私有接口）位于不同的包中，代理类将无法同时访问这些接口。这是因为包级私有接口只能在定义它们的包内访问。因此，必须确保所有包级私有接口在同一个包中，否则会抛出异常。 同时如果代理类需要实现的接口中，有包级私有（package-private）接口，那么代理类应该被标记为final，不能再被其他类继承。从而确保这些包级私有接口的实现不会被其他包中的类继承和使用，从而遵循严格的访问控制规则。 Modifier.PUBLIC | Modifier.FINAL这段代码表示一个组合的访问修饰符，其中 | 是按位或运算符，将两个修饰符组合在一起。具体来说： Modifier.PUBLIC：表示公共访问修饰符，值为 1。公共修饰符表示该类或成员可以被任何其他类访问。 Modifier.FINAL：表示最终修饰符，值为 16。最终修饰符表示该类不能被继承，或该方法不能被重写，或该字段的值不能被更改。 在定义代理类时，通过按位或运算符 |，组合的修饰符 Modifier.PUBLIC | Modifier.FINAL 可以用于确保生成的代理类是公共且不可继承的。这在动态代理生成过程中非常重要，确保代理类的正确访问级别和不可变性。 1.3.1.2 代理类全限定名-proxyNameproxyName 指的是代理类的全限定名，全限定名包括包名和类名，这样可以确保代理类在类加载器范围内的唯一性，并且符合 Java 类命名的规范。。 根据以上代码，可以看出其生成逻辑 确定proxyPkg 全局计数器，nextUniqueNumber 是一个全局的 AtomicLong，用于生成唯一的数字。getAndIncrement 方法保证每次调用都会返回一个唯一的数字，并将计数器递增。 proxyPkg不为空的情况下，proxyName 长这样， com.sun.proxy.Proxy0 或 com.sun.proxy.module.Proxy0， 其中0可以替换成递增的数字 1.3.1.3 代理类字节码1byte[] ProxyGenerator.generateProxyClass(String proxyName, Class&lt;?&gt;[] interfaces, int accessFlags) proxyName：代理类的全限定名,如 com.sun.proxy.Proxy0。 interfaces：代理类需要实现的接口数组。 accessFlags：代理类的访问修饰符, 如 `Modifier.PUBLIC | Modifier.FINAL generateProxyClass 方法通过字节码生成技术，创建一个新的代理类的字节码 1.3.2 getConstructor获取代理类构造函数，且是获取参数为InvocationHandler 的构造函数 1.4 newProxyInstance在反射中技术中，经典的获取实例对象的方法就是1cons.newInstance在前面的步骤中，获取了参数为InvocationHandler 的构造函数 Constructor, 那么在实例化代理对象时， 就需要传入类型为InvocationHandler的参数， 本文示例代码中传入的是实现了InvocationHandler 的 HelloWorldHandler 1.5 基于动态对象执行目标方法1proxy.sayHello(); 调用代理对象的方法， 会进入自定义的InvocationHandler.invoke方法在invoke 方法中， 可以添加自定义逻辑，比如在AOP 中，可以添加增强 执行目标类的真正方法 至此代理对象已经生成。 1.6 反射在JDK 动态代理中的应用根据以上源码和示例代理的分析，可以看到 JDK 动态代理完全基于反射运行。主要体现在以下几个方面： 接口方法的动态实现： 通过使用Proxy.newProxyInstance生成的代理类，实际上在内存中创建了一个实现了指定接口的新类。这个过程是完全动态的，利用反射机制查询接口方法并在代理类中生成相应的方法实现。 方法调用的拦截： InvocationHandler的invoke方法的实现通常会使用反射来动态调用目标对象的方法。通过Method对象的invoke方法，可以在运行时调用任何对象的任意方法。 类型信息的动态处理： 反射机制允许动态代理在运行时查询关于类和接口的元数据（如方法名、参数类型、返回类型等），这些信息对于正确转发方法调用是必需的。 2. CGLIB动态代理CGLIB通过生成目标类的子类来实现代理 可以代理没有实现接口的类和实现了接口的类， 相比JDK 只能代理实现了接口的类，有较强的灵活性 但不能代理final类和final方法，并且有性能开销和依赖CGLIB库的缺点。 2.1 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142public interface HelloWorld &#123; void sayHello(); void sayBye(); &#125;public class HelloWorldImpl implements HelloWorld &#123; @Override public void sayHello() &#123; System.out.println(&quot;Hello, world!&quot;); &#125; @Override public void sayBye() &#123; System.out.println(&quot;Bye bye, world!&quot;); &#125; &#125;public class HelloWorldInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;After method: &quot; + method.getName()); return result; &#125; &#125;public class CglibDynamicProxyDemo &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(HelloWorldImpl.class); enhancer.setCallback(new HelloWorldInterceptor()); HelloWorld proxy = (HelloWorld) enhancer.create(); proxy.sayHello(); proxy.sayBye(); &#125; &#125; 运行结果如下 2.2 EnhancerEnhancer 类用于生成一个目标类的子类（即代理类），并通过在代理类中拦截方法调用来实现动态代理。这个过程包括指定要代理的目标类、设置回调、生成代理类等步骤。 1public class Enhancer extends AbstractClassGenerator &#123;&#125; setSuperclass(Class&lt;?&gt; superclass)设置代理类的父类，即目标类。代理类将继承这个父类，从而可以拦截父类的方法调用。 setCallback(Callback callback)设置回调，用于拦截方法调用并定义拦截逻辑。Callback 是一个接口，MethodInterceptor 是其常用的实现之一。 create()生成代理类的实例。create 方法使用先前设置的父类和回调来动态创建代理类。 2.3 MethodInterceptor1234567891011enhancer.setCallback(new HelloWorldInterceptor()); public class HelloWorldInterceptor implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;Before method: &quot; + method.getName()); Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;After method: &quot; + method.getName()); return result; &#125; &#125; 自定义的HelloWorldInterceptor实现了MethodInterceptor MethodInterceptor 是 Callback 接口的一个实现，其核心方法是 intercept，用于定义方法调用时的拦截逻辑。 每次通过代理类调用目标方法时，都会经过intercept 方法去调用父类中真正的方法， 其作用类似于InvocationHandler.invoke 12345678package org.springframework.cglib.proxy; public interface Callback &#123; &#125;package org.springframework.cglib.proxy;public interface MethodInterceptor extends Callback &#123; Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable;&#125; obj：代理对象本身。 Method method：被拦截的方法对象， 就是反射中的那个Method args：方法参数 MethodProxy proxy：用于调用父类方法的代理对象。 当执行代理对象的方法时， 其逻辑会进入到intercept 方法中 2.4 MethodProxy在代理类的生成过程中，CGLIB 会为每个方法创建对应的 MethodProxy 对象。MethodProxy 对象封装了目标方法的信息，并且在调用时可以直接调用父类的方法，而不需要通过反射机制。 与直接使用反射调用方法相比，MethodProxy 具有更高的性能。因为 MethodProxy 通过生成的字节码直接调用目标类的方法，避免了反射调用的开销。反射调用方法时，需要进行一系列检查和操作，而 MethodProxy 可以在生成字节码时优化这些操作，从而提高方法调用的效率。 2.4.1 create 结合debug 信息， 解释MethodProxy.create 方法中，各个参数的含义 c1：代理类的父类，即目标类 c2:：代理类 desc：用于描述方法的签名。在图中显示为 &quot;()V&quot;，表示方法没有参数，返回值为 void。 name1：目标类中需要代理的方法名 name2：代理类中对应的代理方法名。 2.4.2 invokeSuper123456789101112public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; // 初始化 MethodProxy 对象，确保 FastClass 已初始化 init(); FastClassInfo fci = fastClassInfo; // 通过 FastClass 调用父类方法 return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException e) &#123; throw e.getTargetException(); &#125; &#125; 2.5 创建动态代理对象-enhancer.createenhancer实例设置了必要信息后，就可以调用create 方法创建代理对象了 123456789101112131415161718192021222324public class Enhancer extends AbstractClassGenerator &#123; public Object create() &#123; classOnly = false; argumentTypes = null; return createHelper(); &#125; private Object createHelper() &#123; preValidate(); // 创建了一个唯一的键 `key`，用于标识生成的代理类 Object key = KEY_FACTORY.newInstance((superclass != null) ? superclass.getName() : null, ReflectUtils.getNames(interfaces), filter == ALL_ZERO ? null : new WeakCacheKey&lt;CallbackFilter&gt;(filter), callbackTypes, useFactory, interceptDuringConstruction, serialVersionUID); this.currentKey = key; Object result = super.create(key); return result; &#125;&#125; 2.5.1 AbstractClassGenerator.create123456789101112131415161718192021222324252627282930313233343536373839abstract public class AbstractClassGenerator&lt;T&gt; implements ClassGenerator &#123; protected Object create(Object key) &#123; try &#123; // 获取用于加载代理类的类加载器 // 这个类加载器通常是目标类的类加载器。 ClassLoader loader = getClassLoader(); Map&lt;ClassLoader, ClassLoaderData&gt; cache = CACHE; //从缓存中获取与当前类加载器对应的 `ClassLoaderData` 对象。 ClassLoaderData data = cache.get(loader); if (data == null) &#123; // 双重检查锁定 synchronized (AbstractClassGenerator.class) &#123; cache = CACHE; data = cache.get(loader); if (data == null) &#123; // 创建新数据，使用 `WeakHashMap` 作为缓存，允许类加载器被垃圾回收。 Map&lt;ClassLoader, ClassLoaderData&gt; newCache = new WeakHashMap&lt;ClassLoader, ClassLoaderData&gt;(cache); data = new ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; // 从 `ClassLoaderData` 对象中获取或生成代理类。 Object obj = data.get(this, getUseCache()); if (obj instanceof Class) &#123; return firstInstance((Class) obj); &#125; return nextInstance(obj); &#125; catch (RuntimeException | Error ex) &#123; throw ex; &#125; catch (Exception ex) &#123; throw new CodeGenerationException(ex); &#125; &#125;&#125; 2.6 基于动态对象执行目标方法1proxy.sayHello(); 执行业务代码， 会进入自定义的HelloWorldInterceptor.intercept 方法在 intercept 方法中， 可以添加自定义逻辑，比如在AOP 中，可以添加增强 执行目标类的真正方法 2.7 代理类命名规则在CGLIB生成的代理类名称中，$$$$通常用来分隔原始类名和附加的代理类信息。这种命名约定使得在调试、日志记录以及运行时反射操作中，更容易识别和处理代理类。1HelloWorldImpl$$EnhancerByCGLIB$$abcdef12 HelloWorldImpl 是原始类的名称。 $$$$ 是CGLIB的类分隔符。 EnhancerByCGLIB 表示这是一个由CGLIB生成的增强类。 abcdef12 是一串随机字符或哈希值，用于区分不同的代理实例。 判断类名是否包含$$$$。这可以识别出当前类是否是CGLIB生成的代理类。 2.8 ASM 与 CGLIB 的关系CGLIB 是一个基于 ASM 的字节码操作库。ASM 是一个底层的字节码操作框架，提供了更细粒度的字节码操作功能。CGLIB 在此基础上进行了更高层次的封装，简化了字节码操作的复杂性，使得开发人员可以更方便地生成和操作字节码。 2.8.1 ASM 的特点 低级别字节码操作：ASM 允许开发人员直接操作 Java 字节码，提供了极大的灵活性和控制力。 高性能：由于直接操作字节码，ASM 的性能非常高，可以用于生成高效的字节码。2.8.2 CGLIB 的特点 基于 ASM 封装：CGLIB 在 ASM 的基础上进行了封装，提供了更高层次的 API，使得字节码操作更为简便。 简化动态代理实现：通过 CGLIB，开发人员可以更方便地实现动态代理，而无需深入理解字节码的具体细节。 3 JDK vs CGLib3.1 实现机制JDK动态代理 基于接口：JDK 动态代理要求目标类实现一个或多个接口。代理类实现这些接口，并将方法调用委托给 InvocationHandler。 反射机制：JDK 动态代理使用反射机制来调用目标方法。通过 java.lang.reflect.Proxy 类和 java.lang.reflect.InvocationHandler 接口实现。 字节码生成：JDK 动态代理使用 JVM 自带的字节码生成工具生成代理类的字节码，不依赖外部库。 CGLIB动态代理 基于继承：CGLIB 动态代理通过继承目标类来创建代理类。因此，它不要求目标类实现接口。 字节码生成：CGLIB 使用 ASM 库在运行时生成代理类的字节码。代理类继承目标类，并通过方法拦截器（MethodInterceptor）拦截方法调用。 FastClass 机制：CGLIB 提供 FastClass 机制，通过索引直接调用方法，避免了反射调用的开销，提高了性能。 3.2 适用场景JDK动态代理 适用于实现了接口的类：JDK 动态代理只能代理实现了一个或多个接口的类。 简单场景：适用于需要代理的类和方法比较简单，且符合接口约束的场景。 CGLIB动态代理 适用于未实现接口的类：CGLIB 可以代理未实现接口的类，适用范围更广。 复杂场景：适用于需要代理的类和方法较复杂，或者无法修改目标类以实现接口的场景。 3.3 性能比较JDK动态代理 反射开销：由于使用反射机制，方法调用的性能可能较低，特别是在大量调用时，反射开销显著。 方法调用：每次方法调用都需要通过 InvocationHandler，导致一定的性能损失。 CGLIB动态代理 字节码生成：通过 ASM 库动态生成字节码，性能较高。 FastClass 机制：通过 FastClass 机制，方法调用的性能接近于直接调用，远高于反射调用。 3.4 内存开销JDK动态代理 较低内存开销：由于代理类较为简单，且不需要生成额外的字节码，内存开销较低。 类加载器：代理类由 JVM 生成并加载，不依赖外部类加载器。 CGLIB动态代理 较高内存开销：需要生成和加载额外的字节码，内存开销较高。 类加载器：生成的代理类需要额外的类加载器进行加载和管理。 3.5 可维护性和扩展性JDK动态代理 易于理解和维护：基于接口的代理模式较为简单，易于理解和维护。 扩展性有限：只能代理实现了接口的类，对于未实现接口的类，需要修改类结构。 CGLIB动态代理 复杂度较高：由于涉及字节码生成和方法拦截，理解和维护较为复杂。 高扩展性：可以代理未实现接口的类，适用范围更广，更具扩展性。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java反射实践与原理","slug":"java反射实践与原理","date":"2020-05-15T06:25:11.000Z","updated":"2024-07-11T07:39:58.741Z","comments":true,"path":"b381342a/","permalink":"http://example.com/b381342a/","excerpt":"","text":"反射作为一种高级技术，虽然在业务开发中很少直接编写相关代码，但实际存在于 Java 开发中的方方面面。 Spring Framework： 依赖注入：使用反射实例化对象、设置属性和调用方法，实现IoC。 AOP：通过反射在方法调用前后动态添加逻辑，如日志记录和事务管理。 Hibernate： 对象关系映射（ORM）：利用反射读取和写入实体类属性，实现Java对象与数据库表的映射。 JUnit测试框架：使用反射发现和执行测试方法，支持注解定义测试。 Java 标准库中的动态代理： java.lang.reflect.Proxy 使用反射创建代理对象，并将方法调用委托给 InvocationHandler。 RPC（远程过程调用）： 动态代理实现远程接口，使本地调用像调用本地方法一样调用远程服务。 Java 序列化： 反射获取对象字段及其值，将对象转换为字节流。 JSON/XML 解析库： 如 Jackson、Gson 和 JAXB，使用反射将 JSON 或 XML 数据与 Java 对象相互转换。 开发工具和 IDE：使用反射检查和操作运行中的应用程序，获取对象信息、调用方法等。 0. 什么是反射反射指的是允许程序在运行时动态地检查和操作类、方法、字段等。通过反射，程序可以在运行时了解一个类的结构，并且可以创建对象、调用方法、访问和修改字段等。 如何理解“反”“反”在反射中的含义可以理解为“反向操作”或“反查”。 通常，我们在编写代码时会显式地调用方法、访问字段或创建对象，比如：12Person person = new Person();person.setName(&quot;Alice&quot;); 这是正向操作，即程序明确知道要操作的类和方法。这种方式称为编译时绑定，因为所有的类型、方法和变量调用在编写代码时就已确定，并在编译期间已经建立了它们的关联。这种方式依赖于静态类型检查，能够在编译阶段捕获许多错误，同时也提高了代码的执行效率。 而反射则相当于反向操作，程序在编写代码时并不知道具体的类和方法（编码时只是给出了“字面名称”，而不是实际的类和方法），而是在运行时通过反射机制获取类的信息并进行操作。这种方式称为运行时绑定，因为代码在运行时才确定要调用的具体类、方法或属性。 1234Class&lt;?&gt; clazz = Class.forName(&quot;Person&quot;);Object person = clazz.newInstance();Method setNameMethod = clazz.getMethod(&quot;setName&quot;, String.class);setNameMethod.invoke(person, &quot;Alice&quot;); 在这个反射的例子中，我们没有在代码中直接调用 Person 类或其方法。相反，我们在运行时加载了类，检索了构造函数和方法，并动态地调用了它们。 “反”与“正”的对比 性能：正常方法（编译时绑定）通常性能更高，因为它们在编译时就已经解决了大部分引用问题；而反射（运行时绑定）在查找和调用过程中需要消耗额外的资源，性能相对较低。 类型安全：正常方法在编译时就能检查类型安全性，而反射则需要程序员在运行时手动确保类型的正确性，这增加了出错的风险。 灵活性：反射提供了极高的灵活性，可以在运行时动态加载和操作类，这在开发通用框架或需要大量运行时信息的复杂系统中非常有用。 反射的工作原理反射基于两部分内容实现 java.lang.Class 类 java.lang.reflect 包中的类（如 Method, Field, Constructor 等）来实现 1. Class 类Class类也是一个实实在在的类，存在于JDK的java.lang包中。 12345public final class Class&lt;T&gt; implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement &#123;&#125; Java 编译器将 Java 源代码（.java 文件）编译后 ，产生.class 文件， 保存了类的字节码及相关的元数据。 当 JVM 运行加载一个类时，它会读取相应的 .class 文件，并根据字节码信息生成一个 Class 对象表示该类。 这个 Class 对象是 JVM 内存中的一个运行时数据结构，包含了类的详细信息，如类名、修饰符、字段、方法、接口、父类等。 Class 对象在 JVM 的方法区（Java 8 及之前）或元空间（Java 8 及之后）中分配内存，存储类的元数据。 无论创建多少个该类的实例对象，它们都共享同一个 Class 对象。 1.1 .class 文件的内容.class 文件包含以下内容： 魔数（Magic Number）：用于识别文件格式。 版本信息：表示编译器生成该 .class 文件时使用的 JDK 版本。 常量池（Constant Pool）：保存字面量和符号引用。 访问标志（Access Flags）：描述类或接口的访问级别和其他属性。 类、父类和接口信息：包括类名、父类名和实现的接口。 字段（Fields）：类的字段信息。 方法（Methods）：类的方法信息。 属性（Attributes）：类的其他属性信息，如注解、源文件信息等。 1.2 Class 对象的生成时机当 JVM 运行加载一个类，读取相应的 .class 文件 时，会进行以下步骤： 加载（Loading）：通过类加载器读取 .class 文件的字节码。 链接（Linking）： 验证（Verification）：确保字节码符合 JVM 规范，不会破坏 JVM 的安全性。 准备（Preparation）：为类的静态变量分配内存，并将其初始化为默认值。 解析（Resolution）：将常量池中的符号引用替换为直接引用。 初始化（Initialization）：执行类的静态初始化块和静态变量的初始化。 在这些步骤完成之后，JVM 会在内存中创建一个 Class 对象来表示这个类。这个 Class 对象包含了类的所有元数据，并且无论创建多少个该类的实例对象，它们都共享同一个 Class 对象。 [[JVM#类加载-加载，生成Class对象]] 1.3 Class 对象的唯一性对于同一个类，无论创建多少个实例对象，它们共享同一个 Class 对象。 类加载器在决定 Class 对象的唯一性上起着关键作用。如果同一个类被不同的类加载器加载，那么它们会有不同的 Class 对象。 比如创建一个Shapes类，那么，JVM就会创建一个Shapes对应Class类的Class对象，无论创建多少个实例对象，在JVM中都只有一个Class对象。 可以通过以下代码验证唯一性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ClassUniqueDemo &#123; public static void main(String[] args) &#123; // 创建多个实例对象 Person person1 = new Person(&quot;Alice&quot;, 30); Person person2 = new Person(&quot;Bob&quot;, 25); // 获取 Class 对象 Class&lt;?&gt; class1 = person1.getClass(); Class&lt;?&gt; class2 = person2.getClass(); Class&lt;?&gt; class3 = Person.class; // 打印 Class 对象的哈希码 System.out.println(&quot;class1: &quot; + class1.hashCode()); System.out.println(&quot;class2: &quot; + class2.hashCode()); System.out.println(&quot;class3: &quot; + class3.hashCode()); // 验证所有实例对象的 Class 对象是否相同 System.out.println(&quot;class1 == class2: &quot; + (class1 == class2)); System.out.println(&quot;class1 == class3: &quot; + (class1 == class3)); &#125;&#125;class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 1.4 关于Class 的一点总结到这，我们可以总结一下关于Class 的相关信息 Class类是Java中的一种类，与关键字class不同。 Class对象是由Java虚拟机（JVM）加载的，它代表Java中的类或接口。 每个通过class关键字定义的类，在编译后都会生成一个.class文件。JVM加载这个.class文件，并生成对应的Class对象。 无论一个类创建了多少个实例，所有这些实例都共享同一个Class对象。这是因为Class对象表示类的元数据，存储了类的结构信息，而实例则是类的具体实现。 Class类的构造函数是私有的，确保了Class对象只能由JVM内部创建。开发者不能直接通过构造函数创建Class对象，而是通过类加载机制间接地获得Class对象。 2. 使用反射访问类的各个组成部分2.1 获取Class 对象获取一个类的 Class 对象有4种， 但是前3种更常用 通过类名 12Class&lt;?&gt; clazz = ClassName.class; 通过对象实例： 12Class&lt;?&gt; clazz = objectInstance.getClass(); forName 全限定类名： 1Class&lt;?&gt; clazz = Class.forName(&quot;com.example.ClassName&quot;); 通过 ClassLoader 获取 Class 对象(Spring bean 创建过程中会用到这种方式) 123ClassLoader classLoader = Thread.currentThread().getContextClassLoader();Class&lt;?&gt; clazz = classLoader.loadClass(&quot;com.example.MyClass&quot;); Class.forName vs ClassLoader.loadClass Class.forName和ClassLoader.loadClass都是通过全限定名获取Class对象的方法，但它们在类的初始化行为、使用场景和加载器选择上存在显著区别： 类的初始化：Class.forName默认会触发类的初始化，而ClassLoader.loadClass默认不会。 使用场景：Class.forName适用于简单场景和需要触发初始化的情况；ClassLoader.loadClass适用于需要控制类加载器和避免类初始化的情况。 加载器的选择：Class.forName使用当前线程的上下文ClassLoader，而ClassLoader.loadClass可以显式指定ClassLoader。 2.2 获取构造函数 ConstructorClass 类中有以下4个方法来获取构造函数 getConstructors()：获取所有公共/public构造函数。 getConstructor(Class&lt;?&gt;... parameterTypes)：获取指定参数类型的公共构造函数。 getDeclaredConstructors()：获取所有声明的构造函数（包括公共、保护、默认（包）访问和私有）。 getDeclaredConstructor(Class&lt;?&gt;... parameterTypes)：获取指定参数类型的声明的构造函数（包括公共、保护、默认（包）访问和私有）。 2.2.1 constructor.newInstance使用构造函数获取实例化对象从以上代码示例中可以看出，一般情况下我们使用反射获取一个对象的步骤： 12Constructor&lt;?&gt; constructor = clazz.getConstructor();Object instance = constructor.newInstance(); 2.3 Method![ getMethods()：获取所有公共方法，包括继承的方法。 getMethod(String name, Class&lt;?&gt;... parameterTypes)：获取指定名称和参数类型的公共方法，包括继承的方法。 getDeclaredMethods()：获取所有声明的方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes)：获取指定名称和参数类型的声明的方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 2.4 Field getFields()：获取所有公共字段，包括继承的公共字段。 getField(String name)：获取指定名称的公共字段。 getDeclaredFields()：获取所有声明的字段，包括公共、保护、默认（包）访问和私有字段，但不包括继承的字段。 getDeclaredField(String name)：获取指定名称的声明的字段，包括公共、保护、默认（包）访问和私有字段，但不包括继承的字段。 2.5 getInterfaces1public Class&lt;?&gt;[] getInterfaces() 返回一个 Class 对象数组，表示类或接口实现的所有接口。 2.6 示例代码以下是一个完整的示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class ReflectionExample &#123; public static void main(String[] args) &#123; try &#123; // 获取Class对象 Class&lt;?&gt; clazz = Class.forName(&quot;com.example.codingInAction.reflectionPractice.Person&quot;); // 获取所有构造函数 Constructor&lt;?&gt;[] constructors = clazz.getDeclaredConstructors(); for (Constructor&lt;?&gt; constructor : constructors) &#123; System.out.println(&quot;Constructor: &quot; + constructor); &#125; // 获取无参构造函数 Constructor&lt;?&gt; constructor1 = clazz.getDeclaredConstructor(); System.out.println(&quot;Constructor1: &quot; + constructor1); Constructor&lt;?&gt; constructor2 = clazz.getDeclaredConstructor(String.class); System.out.println(&quot;Constructor2: &quot; + constructor2); Constructor&lt;?&gt; constructor3 = clazz.getDeclaredConstructor(int.class); System.out.println(&quot;Constructor3: &quot; + constructor3); Constructor&lt;?&gt; constructor4 = clazz.getConstructor(String.class, int.class); System.out.println(&quot;Constructor4: &quot; + constructor4); Object alex = constructor4.newInstance(&quot;Alex&quot;, 30); System.out.println(alex); // 获取所有方法 Method[] methods = clazz.getDeclaredMethods(); for (Method method : methods) &#123; System.out.println(&quot;Method: &quot; + method); &#125; // 获取指定名称和参数类型的声明的方法 Method setAgeMethod = clazz.getDeclaredMethod(&quot;setAge&quot;, int.class); System.out.println(&quot;Method: &quot; + setAgeMethod); // 如果是私有方法，需要设置成 可访问 // setAgeMethod.setAccessible(true); setAgeMethod.invoke(alex, 35); Method getAgeMethod = clazz.getDeclaredMethod(&quot;getAge&quot;); int age = (Integer) getAgeMethod.invoke(alex); System.out.println(&quot;alex&#x27;s age is &quot; + age); // 获取所有字段 Field[] fields = clazz.getDeclaredFields(); for (Field field : fields) &#123; System.out.println(&quot;Field: &quot; + field); &#125; // 获取指定名称的声明的字段 Field ageField = clazz.getDeclaredField(&quot;age&quot;); System.out.println(&quot;Field: &quot; + ageField); //如果是private, 需要设置成 “可访问” ageField.setAccessible(true); System.out.println(&quot;Age: &quot; + ageField.get(alex)); &#125; catch (ClassNotFoundException | NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e) &#123; e.printStackTrace(); &#125; catch (NoSuchFieldException e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 3. 反射的缺点3.1 破坏封装性在面向对象编程中，封装性是指将对象的属性和实现细节隐藏起来，只暴露必要的接口给外部使用。通过访问控制修饰符（如 private、protected、public），类可以控制哪些成员可以被外部访问，从而保护对象的内部状态，确保对象的一致性和安全性。 从上面的代码可以明显看出一个问题， 我们定义的private 构造函数和字段， 通过getDeclared* 和setAccessible 后可以使得原本私有的成员变得可访问，这无疑破坏了priavte 的语义，也就是封装性。 访问私有方法 访问私有变量 反射破坏封装性的影响 安全性问题：私有字段和方法的访问控制被绕过，可能会导致程序的安全性问题。 对象一致性：私有字段的修改可能会破坏对象的一致性，导致不可预知的行为。例如，某个字段可能需要通过特定的方法进行修改，以确保其值的合法性，而直接修改字段可能会绕过这些检查。 维护性降低：使用反射访问私有成员会使代码变得难以维护，因为这些操作依赖于类的内部实现，而不是其公开的接口。类的实现细节变化可能会导致反射代码失效。 如何避免反射破坏封装性 最小化反射的使用：尽量减少反射的使用，尤其是对于私有成员的访问。 使用适当的访问修饰符：确保类的设计合理，公开必要的接口，私有化不应被外部访问的成员。 安全管理器：在敏感应用中，使用安全管理器来限制反射操作，防止未经授权的访问。 3.2 效率低大家都说 Java 反射效率低，你知道原因在哪里么 反射效率低的原因主要在于额外的类型检查和安全检查、方法调用的间接性、缺乏编译时优化以及增加的内存开销。在实际开发中，除非确实需要动态性和灵活性，否则应尽量避免使用反射，以提高代码的性能和可维护性。如果必须使用反射，应尽量减少反射调用的次数，或者在初始化阶段使用反射将结果缓存起来，以降低运行时的开销。 1. 额外的类型检查和安全检查 类型检查： 反射在运行时执行，JVM 需要在每次访问字段或调用方法时进行类型检查，以确保操作的合法性。这与普通方法调用的编译时类型检查相比，增加了额外的开销。 安全检查： 反射需要进行安全检查（如访问控制检查），特别是在设置 setAccessible(true) 时。这些检查在每次反射调用时都会进行，增加了运行时的开销。 2. 方法调用的间接性普通方法调用是通过直接的字节码指令进行的，JVM 可以进行各种优化，如内联（inlining）、即时编译（JIT）等。而反射调用是通过反射 API 间接调用方法，不能享受这些优化。 3. 缺乏编译时优化编译时优化可以显著提高代码执行效率，但反射操作是在运行时决定的，因此编译器无法进行这些优化。编译器对普通方法调用可以进行多种优化，如常量折叠、循环展开等，但对反射操作则无能为力。 4. 内存开销反射操作会带来额外的内存开销，包括： 创建和维护反射对象（如 Method、Field 等）。 反射调用时需要创建数组来传递参数和返回值。 反射调用的结果需要进行类型转换，这也会增加内存开销。 4. 源码解析-invoke重点介绍method.invoke 的实现原理 1234567891011121314151617181920212223242526272829@CallerSensitive@ForceInline // to ensure Reflection.getCallerClass optimization@HotSpotIntrinsicCandidatepublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; // 检查是否需要进行访问控制检查 if (!override) &#123; // 获取调用者的类 Class&lt;?&gt; caller = Reflection.getCallerClass(); // 检查访问权限，检查调用者是否有权限调用目标方法。如果目标方法是静态的，则第三个参数为 null，否则为目标对象的类。 checkAccess(caller, clazz, Modifier.isStatic(modifiers) ? null : obj.getClass(), modifiers); &#125; // 获取MethodAccessor实例 // 这是一个volatile字段，确保多线程访问时的可见性。 MethodAccessor ma = methodAccessor; // read volatile // 如果 methodAccessor 为空，则调用此方法获取一个新的 MethodAccessor 实例。 // MethodAccessor 是实际执行反射调用的接口，其实现由JVM提供，可能是生成的字节码或本地代码。 if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; // 使用MethodAccessor调用目标方法 return ma.invoke(obj, args);&#125; 4.1 优化与性能通过注解 @ForceInline 和 @HotSpotIntrinsicCandidate，JVM可以对 invoke 方法进行内联优化和本地代码优化，从而减少反射调用的性能开销。 4.2 acquireMethodAccessor12345678910111213141516171819public final class Method extends Executable &#123; private MethodAccessor acquireMethodAccessor() &#123; // First check to see if one has been created yet, and take it // if so MethodAccessor tmp = null; if (root != null) tmp = root.getMethodAccessor(); if (tmp != null) &#123; methodAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newMethodAccessor(this); setMethodAccessor(tmp); &#125; return tmp; &#125;&#125; 从以上代码可以看出， 生成MethodAccessor时用到了工厂模式， 说明有多个MethodAccessor，下面来具体看一下MethodAccessor及其实现 4.3 MethodAccessorMethodAccessor 是一个内部接口，用于抽象反射机制中实际的方法调用实现。具体的实现类有几种，其中包括 DelegatingMethodAccessorImpl、MethodAccessorImpl 和 NativeMethodAccessorImpl。每个实现类都有其特定的作用和实现方式。 其实现可能是动态生成的字节码（如MethodAccessorImpl），或者是通过JNI调用本地代码（如 NativeMethodAccessorImpl）。具体实现可能会在不同的JVM中有所不同，但主要目的是为了提高反射调用的性能。 12345public interface MethodAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */ public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException; &#125; NativeMethodAccessorImpl 使用JNI来调用本地方法，具有较高的性能。 MethodAccessorImpl 使用生成字节码的方式来提高性能。 DelegatingMethodAccessorImpl 用于在运行时动态替换 MethodAccessor 实现，以优化反射调用的性能。 4.3.1 NativeMethodAccessorImplNativeMethodAccessorImpl 使用 JNI（Java Native Interface）来调用本地方法。它是通过本地代码实现的，在冷启动方面具有较高的效率，但是实际调用是性能较慢。 123456789101112131415161718192021222324252627282930313233343536373839404142/** Used only for the first few invocations of a Method; afterward, switches to bytecode-based implementation */class NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) &#123; this.method = method; &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; // We can&#x27;t inflate methods belonging to vm-anonymous classes because // that kind of class can&#x27;t be referred to by name, hence can&#x27;t be // found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; return invoke0(method, obj, args); &#125; void setParent(DelegatingMethodAccessorImpl parent) &#123; this.parent = parent; &#125; private static native Object invoke0(Method m, Object obj, Object[] args);&#125; 4.3.2 MethodAccessorImplMethodAccessorImpl 是通过生成字节码来提高反射调用的性能。具体实现涉及生成动态字节码，以直接调用目标方法。 123456abstract class MethodAccessorImpl extends MagicAccessorImpl implements MethodAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */ public abstract Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException; &#125; 4.3.3 DelegatingMethodAccessorImplDelegatingMethodAccessorImpl 是一种委托实现，它将调用委托给另一个 MethodAccessor 实例。这种设计通常用于在运行时动态替换 MethodAccessor 实现，以提高性能。 1234567891011121314151617class DelegatingMethodAccessorImpl extends MethodAccessorImpl &#123; private MethodAccessorImpl delegate; DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) &#123; setDelegate(delegate); &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; return delegate.invoke(obj, args); &#125; void setDelegate(MethodAccessorImpl delegate) &#123; this.delegate = delegate; &#125;&#125; 4.4 invoke 实现的两种方式从MethodAccessor的3个实现类可以看出，invoke 方法内部的实现涉及到两种不同的方式：原生（native）实现方式和Java字节码实现方式。这两种实现方式旨在优化不同阶段的反射调用性能。下面详细解释这两种实现方式以及它们在invoke方法中的动态切换。 4.4.1 初始实现：Native 实现方式在反射调用的初始阶段，使用JNI（Java Native Interface）/ NativeMethodAccessorImpl 方式可以==快速生成==一个可调用的反射方法。这是因为JNI调用直接利用了现有的本地代码实现，不需要额外的字节码生成过程。 这种方式启动快，适合初次和少量调用。 生成速度 生成快：初次调用反射方法时，使用JNI（Java Native Interface）方式可以快速生成一个可调用的反射方法。这是因为JNI调用直接利用了现有的本地代码实现，不需要额外的字节码生成过程。 运行性能 运行性能相对较慢：虽然JNI方式生成速度快，但在实际调用过程中，反射调用通过JNI进行本地方法调用，没有针对Java方法调用的优化。在需要多次调用同一个反射方法时，运行性能会比较低。 4.4.2 优化阶段：Java 字节码实现方式当反射调用达到一定频率时，JVM会动态切换到基于Java 字节码 MethodAccessorImpl实现方式。这种方式通过动态生成字节码来直接调用目标方法。 1. 生成速度 生成较慢：使用字节码生成方式需要在运行时动态生成和编译Java字节码，这个过程相对复杂，初次生成时会比JNI方式慢。2. 调用过程 运行时有性能优化：一旦生成了字节码实现，JVM的即时编译器（JIT）可以对这些字节码进行优化，从而提高执行效率。3. 运行性能 执行比较快：生成字节码后，JVM的即时编译器（JIT）可以对这些字节码进行优化，从而提高执行效率。特别是在多次调用时优势明显。 根据以上2种方式的特点介绍，可以总结为 JNI方式生成快，但是运行性能相对较慢。 字节码生成方式生成较慢，但生成后调用时性能更高，因为JVM的即时编译器可以对字节码进行优化。 动态切换所以当反射调用达到一定次数后，更希望执行速度得到优化，JVM就会动态切换，会从JNI方式切换到字节码生成方式，以提高运行时性能。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]}],"categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://example.com/tags/AI/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"Ilya sutskever‘s 30  papers","slug":"Ilya-sutskever‘s-30-papers","permalink":"http://example.com/tags/Ilya-sutskever%E2%80%98s-30-papers/"},{"name":"personal projects","slug":"personal-projects","permalink":"http://example.com/tags/personal-projects/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/tags/MySQL/"},{"name":"chatGPT","slug":"chatGPT","permalink":"http://example.com/tags/chatGPT/"},{"name":"Programming","slug":"Programming","permalink":"http://example.com/tags/Programming/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/tags/Mybatis/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]}